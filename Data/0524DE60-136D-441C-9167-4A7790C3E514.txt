iChipå…†ç´šæ™ºæ…§çŸ½æ™¶ç‰‡ä¹‹ç ”ç©¶ï¼šæ¼”ç®—æ³•ï¼Œæ¶æ§‹ï¼Œèˆ‡å¯¦ç¾æŠ€è¡“--å­è¨ˆç•«ä¸€ï¼šçŸ½
è…¦ï¼šç”¨æ–¼æ™ºæ…§è¦–è¨Šè¾¨è­˜ä¹‹å…†ç´šæ™¶ç‰‡æ¶æ§‹è¨­è¨ˆç ”ç©¶ï¼ˆç¬¬ä¸‰å¹´ï¼‰ 
Silicon Brain: Tera-scale Architecture Design for Intelligent Visual 
Recognition 
è¨ˆåŠƒç·¨è™Ÿï¼šNSC 97-2221-E-002-238-MY3 
åŸ·è¡ŒæœŸé™ï¼š2010/08/01 ~ 2011/07/31 
å­è¨ˆåŠƒä¸»æŒäººï¼šé™³è‰¯åŸº æ•™æˆ  Email: 
åŸ·è¡Œæ©Ÿæ§‹ï¼šåœ‹ç«‹å°ç£å¤§å­¸é›»å­å·¥ç¨‹å­¸ç ”ç©¶æ‰€ 
lgchen@cc.ee.ntu.edu.tw 
 
ä¸­æ–‡æ‘˜è¦ 
ä»¥æ‘©çˆ¾å®šå¾‹è¶¨å‹¢ä¸æ–·æˆé•·çš„åŠå°é«”è£½ç¨‹æŠ€è¡“ï¼Œä»¥åŠè¨±å¤šç³»çµ±æ™¶ç‰‡è¨­è¨ˆçš„æ–¹æ³•æ¼”é€²ï¼Œ
å¦‚å¤šæ ¸å¿ƒæ¶æ§‹ã€æ™¶ç‰‡é¡ç¶²è·¯é€šè¨Šã€ä¸²æµè™•ç†ç­‰ï¼Œä½¿å¾—ç¡¬é«”çš„è¨ˆç®—èƒ½åŠ›è¶Šä¾†è¶Šå¼·ï¼Œè®“å–®ä¸€
çŸ½æ™¶ç‰‡å…·æœ‰è™•ç†æ›´å¤šæ›´è¤‡é›œæ™ºæ…§å‹é‹ç®—çš„å¯èƒ½ã€‚è—‰ç”±ä¸æ–·æ¼”é€²çš„åŠå°é«”ç§‘æŠ€ï¼Œç‚ºäº†åœ¨æœª
ä¾†æä¾›å„é¡æ™ºæ…§å‹æ‡‰ç”¨ï¼Œæˆ‘å€‘è¨ˆç•«ä»¥æ¨¡ä»¿å¤§è…¦çš„çµæ§‹èˆ‡é‹ç®—æ¨¡å‹ï¼Œä¾†è¨­è¨ˆå‡ºä¸€å€‹é«˜æ•ˆèƒ½
æ™ºæ…§å‹è™•ç†ç³»çµ±å¹³å°ã€‚åœ¨æœ¬è¨ˆç•«ä¸­æˆ‘å€‘æå‡ºä»¥åŠå¯¦ä½œä¸€ä»¿ç”Ÿæ™ºæ…§å‹è¾¨è­˜ç³»çµ±ï¼Œä¸¦å…·æœ‰å¯
èª¿æ•´è¦æ¨¡çš„ç‰¹æ€§ä»¥å› æ‡‰æŠ€è¡“å¢é•·ã€‚æ­¤ç³»çµ±åŒ…å«é‹ç®—æ¨¡å‹ã€è¨˜æ†¶é«”ç·¨è­¯å™¨å’Œå¤šæ ¸å¿ƒç¡¬é«”é‹
ç®—å¹³å°ã€‚åœ¨é‹ç®—æ¨¡å‹ä¸Šï¼Œæˆ‘å€‘çµåˆäº†ç‰¹å¾µå€¼é›œæ¹Šæ¼”ç®—æ³•(Feature-Selective Hashing)ï¼Œ
æå‡ºäº†é«˜æ•ˆç‡çš„ä»¿æ–°çš®è³ªéšå±¤è¾¨è­˜ç³»çµ±ï¼Œæä¾›äº†å¯èª¿æ•´è¦æ¨¡ä»¥åŠå¿«é€Ÿé‹ç®—çš„ç‰¹æ€§ã€‚åœ¨è¨˜
æ†¶é«”ç·¨è­¯å™¨éƒ¨åˆ†ï¼Œå…¶å¯å°‡ä¸Šè¿°ä»¿å¤§è…¦é‹ç®—æ¨¡å‹è½‰æ›æˆç¡¬é«”çš„è¨˜æ†¶é«”å½¢å¼ä¸¦è¨­å®šè‡³å¤šæ ¸å¿ƒ
ç¡¬é«”é‹ç®—å¹³å°ã€‚æœ€å¾Œåœ¨å¤šæ ¸å¿ƒç¡¬é«”é‹ç®—å¹³å°éƒ¨åˆ†ï¼Œæˆ‘å€‘è¨­è¨ˆè¨˜æ†¶é«”ã€å°åŒ…å„²å­˜æ ¼å¼èˆ‡é‹
ç®—æŒ‡ä»¤é›†ï¼Œä¸¦åˆ©ç”¨FPGAå¹³å°å¯¦ä½œå¤šæ ¸å¿ƒç³»çµ±ï¼Œä¾†æ”¯æ´å¤šé¡ç‰©é«”ã€å‹•ä½œå’Œäººè‡‰çš„å³æ™‚è¾¨è­˜
åŠŸèƒ½ã€‚ 
 
é—œéµå­—ï¼šå¯èª¿æ•´è¦æ¨¡ï¼Œç‰¹å¾µå€¼é›œæ¹Šæ¼”ç®—æ³•ï¼Œå³æ™‚è¾¨è­˜ 
 
ABSTRACT 
 As semiconductor process technology evolves to keep the scaling in Mooreâ€™s Law, and 
many methodologies of system chip design are proposed (such as multi-core architecture, 
chip-based communication network, serial processing, etc.), hardware computation become 
more and more powerful. It is possible to deal with more and more complicated intelligent 
computation in a single silicon chip now. In order to serve various intelligent applications in 
the future, we aim to mimic the brainâ€™s structure and computation model, to design a high 
performance intelligent processing system platform. In this project, we propose and 
implement a biomimetic and intelligent recognition system, and have the scalable property to 
cope with the growth of technology. The system integrates Feature-Selective Hashing (FSH), 
which is a highly efficient neocortex-like hierarchical recognition system for providing a 
scalable and fast computing feature. On the other side, a memory compiler converts the above 
brain-like computation model into the hardware-oriented memory format with a multi-core 
instruction set. Finally, in the part of multi-core hardware computation platform, we propose 
new memory architecture, packet storage format, and computation instruction set to 
implement a multi-core system for real-time multi-object, human face, and action recognition 
using FPGA. 
 
Keywords: scalableï¼ŒFeature-Selective Hashing (FSH)ï¼Œreal-time recognition 
5.1.2 Core Design . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51
5.1.3 Network-on-Chip Design . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53
5.1.4 NC Network Mapping . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 55
5.2 Neocortical Memory Map Generator . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 56
5.3 Chip Implementation Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 56
5.4 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59
6 Conclusion 60
Bibliography 62
2
3.4 An example to show the concept of object selectivity of cortical columns in inferior temporal
cortex. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25
3.5 Overview of the proposed framework. The framework consists of two stages: feature
extraction and feature matching. In the stage of feature extraction, features are computed
in 5-layer hierarchy: Image-S1-C1-S2-C2 [2]. Through this processing, input image is
represented as a D-dimensional vector and then fed into NN classifier as query. In the stage
of feature matching, first we use one of the features (local features, gist-like features and
color features) as the input of hash functions H, and lookup the similar object candidates
in L hash tables. Then, these candidates are all fed into NN classifier and matched with
the query. Last, we output the category label of returned NN as answer. . . . . . . . . . 26
3.6 The classification accuracy on variant viewpoints test set for different number of searched
candidates (controlled by different L) with three kinds of FSH: (a) LFSH (b) GFSH (c)
CFSH. The baseline represents the accuracy of exhaustive search. For each curve in (a) and
(b), data points from left to right are obtained using L = 1, 2, 5, 8, 10, 12, 14, 16, 18, 20, 25, 30
and 50, respectively. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29
3.7 The classification accuracy with three kinds of FSH for different number of searched can-
didates on two variant illumination test sets: (a) variant illumination colors test set (b)
variant illumination directions test set. The baseline represents the accuracy of exhaustive
search. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30
3.8 The top 10 nearest neighbors returned by exhaustive search and three kinds of FSH. The
left most image with red bounding box is the query and its nearest neighbors are ordered
from left to right. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30
3.9 Experimental results with three kinds of FSH for different number of learned categories:
(a) The classification accuracy (b) The computation complexity (c) The reduction rate of
computation complexity. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31
3.10 The biologically plausible network mapping from the proposed framework. (Left panel)
The illustration of proposed local feature-selective hashing. (Right panel) The schematic
drawing of biologically plausible network. C2 units consists of D neurons, each of which
is tuned for specific complex prototypes. CC units consists of many clusters of cortical
columnar regions (shown as blue cylinders), each of which have several columnar regions
(shown as circle inside the CC units) for memory association. After the CC units receive
the stimulus from C2 units, only a few columnar regions will be activated (shown as red
circle) while others are inhibited. Thus, the columnar regions in CC units fire sparsely to
WTA units. WTA units match the overall C2 unit response with its associated memory
from CC units and then get the answer. The tentative corresponding brain areas of various
units are specified in the brackets. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33
4.1 A schematic diagram of a multi-layer NC model. (This figure only shows the feature
extraction stage and single scale in each layer) . . . . . . . . . . . . . . . . . . . . . . . . 35
4.2 A schematic diagram of sparse data access caused by inhibition/sparsifing input (left di-
agram), limited receptive field (middle diagram), and FSH (right diagram). The colored
units represent the required data to compute features in output units, while gray-scale
units are unused data. Note that units with same color are correlated. . . . . . . . . . . . 36
4
5.9 Bio-inspired network mapping. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 56
5.10 The flow of memory map generator with graphical illustrations. . . . . . . . . . . . . . . 57
5.11 (a) The floorplan. (b) The chip layout (c) The chip summary. . . . . . . . . . . . . . . . 58
6
Chapter 1
Introduction
1.1 Trend of Technologies and Intelligent Applications
Have you ever used your digital camera to take a nice picture with your friends? If yes, you must
have experiences that your camera captured where human faces are and automatically focused on those
locations. Besides, those cameras also can detect what the scene is and automatically configure their
shutter and aperture. Some of them can even catch the timing you smile and get a snapshot! They
seem so â€smartâ€ to see the world and make everyone to be a professional photographer. This is one of
the many things that machine helps us in our daily life. Other similar scenario happens in surveillance
system, smart car and smart home. These smart machines can monitor the surrounding and provide
safety, convenience and efficiency. As the technologies continue to evolve, our computers have more and
more computing capacity, which drives a lot of intelligent applications to emerge as shown in Fig. 1.1.
The need of intelligent computing is not only in our physical life but also in the so-called cloud -
Internet. Since we are in the era where radio equipped computers dominate, the amount of multimedia
data is growing extremely fast. Youtube have reported that more than 35 hours of video are being
uploaded to the video-sharing site every minute in 2010 as shown in Fig. 1.2. In this rate, we need to
handle over one zettabyte of information annually. Those things tell us that we really need many smart
agents in the virtual cloud to analyze and organize these huge amount of data efficiently, thus intelligent
computing will become a major part of data processing in the recent future. We need an efficient and
scalable platform to provide the required computation capability.
Thanks to the advance of silicon technology, more and more transistors can be implemented in a
single chip and operate at higher speed. That is, we can utilize more memory and computing resources
to have potential to do intelligent computing as human brain(about 100 billions of neurons). On the
other hand, multi-core technology is also developing to keep law of scaling in Mooreâ€™s Law. A recent
work proposed by Intel is a 48-core processing chip - â€single-chip cloud computerâ€ [3], which claimed its
architecture resembles a scalable cluster of computers and shows great computing capacity as shown in
Fig. 1.2. With those fruitful achievements, can current computers have human-like intelligence? The
answer is obvious â€No.â€ Things like understanding spoken language, distinguishing a cat from a dog, and
playing a game of catch are easy for a 5-age child but very difficult for current computers. We believe the
gap is due to the total difference between brain and current computer architecture and computing style.
To meet the requirements of future intelligent applications, we need memory and computing architecture
breakthrough to approach human brain. Therefore, our main design strategy is through mimicking brain
to have some innovations for designing efficient computing architecture.
In this report, we started from exploring brainâ€™s computing style and architecture, then designed
a brain-like computing system, which can be easily scalable with the amount of resources for future
8
Figure 1.3: â€Single-chip cloud computerâ€, a 48-core processing chip proposed by Intel Corporation.
intelligent applications. Our system targets on widely-used visual recognition applications. Next section
we give an overview of current brain-mimicking approaches.
1.2 Toward Intelligence: Brain-mimicking Approaches
1.2.1 Human Brain Capability
Human brain have many remarkable capabilities so that we can easily adapt to the environment, learn
to keep our safety, and survive in the earth now. Many artificial intelligence researchers have tried hard
for a long time to develop a computation model with human-like intelligence but still have a large gap in
almost every aspect. What are features human brain have but current models lacks? In the following we
state main features of human brain capabilities.
â€¢ 1. Rapid processing. Our brain can complete a recognition tasks within 250ms. One famous rule
called â€™hundred step ruleâ€™ says that the information entering your brain can only traverse a chain
one hundred neurons long, which points out the computation and energy efficient of human brain.
However, the current computers may take about one billion instructions to do the same job.
â€¢ 2. Large memory capacity and efficient retrieval. We learn about 10, 000 to 30, 000 objects in our
life. Even though that, our brain still can recognize or recall everything quickly and accurately.
However, the current models have weak scalability and always degrade its performance dramatically
as the complexity of problem increasing.
â€¢ 3. A unified system with versatility. The core of human brain for information processing is com-
posed of billions of homogeneous basic components - neocortex. Our brain use this neocortical
system to process various signals from vision, auditory, smell, touch, etc. However, the current
models are usually designed for specific applications and hard to extend to other problems. For in-
stance, a success face recognition model may not be applied to cat recognition or speech recognition
successfully.
â€¢ 4. Life-long learning. This is an important factor for intelligence. Human brain are always modifying
itself to adapt to the surrounding. However, the current models still have weak and inefficient
learning capability, thus they usually need a long time for off-line training to guarantee enough
performance.
10
 




	

 



  






ï¬€
ï¬ ï¬‚

ï¬ƒ

ï¬€


 !
"
# $$%&#
!
"
'
()
"
#*
)

+
ï¬ ,
-
.


-
,

/
.
,ï¬
ï¬€
0ï¬
ï¬€
1
,
-
.
2
3
4
!
5
"
%6
!
7
*%*%58%
!
&
9
#:&: ;<5# =#
"
#5
"
%6
!
>
?
#@%5#
7
*%*%58%
!
&
9
# :& :
!
#
4
A6
!
>
'
"
A
4
5
"
4
A#
7
*%*%58%
!
&
9
# :& : B%#A<A5B%5<$
)
"
A
4
5
"
4
A#
>
C
%*%58%
!
&
DEE
A6<5B#
)
F
#@#$ 6; G
4
*<
!
H
%
)4
<$
'
()
"
#*
Figure 1.4: Categorization of brain-mimicking approaches and the corresponding mapping to different
levels of human brain system.
Figure 1.5: Overview of System Design Flow.
12
Chapter 2
Background Knowledge of Neocortical
Computing Model
In the early days, the brain was considered as a black box because we could know how it works. Each
researcher designed his intelligent processing model just in function-mimicking level with his own insight,
thus there were many divergent algorithms proposed for different intelligent applications. However, these
algorithms only contribute limited intelligent capability. None of them can solve general problems like the
brain does. In recent years, more and more cues about how the brain works were found by neuroscientists.
These achievements inspire us that since the human brain is the most successful intelligent machine, why
do we not learn from it? Therefore, current researchers try to build models [10, 11, 12, 13, 14] which
mimic the architectures and the data processing mechanisms of the neocortex in brain to solve intelligent
problems. These models are called â€Neocortical Computing Modelâ€ (NC model) throughout this report.
This chapter we give an overview of our basic NC model â€“ HMAX, and briefly introduce the human
visual system first in the following section.
2.1 Fundamental of Human Visual System
Thanks for the efforts from neuroscientists, we now know many features of visual information processing
in the brain. The processing flow of human visual system is shown in Fig. 2.1. The visible light from
surrounding is sensed by our eyes and refracted to the retina. It is then transformed to electrical pulses
by the photoreceptor cells of retina and transmitted along the optic nerve. The signals from left and
right eye cross at the optic chiasm, then go through Lateral Geniculate Nucleus (LGN), and finally enter
the visual cortex (also called neocortex) which starts from the rear of brain. The part before entering
the visual (black dotted arrow in Fig. 2.1) is responsible for early vision processing which extracts the
basic information about the contrast, color, and motion for the latter information processing of the
visual cortex. Hence, most of the researches for human visual processing mainly focus on the visual
cortex because it is believed to be the core of visual information processing and neural representation
generation.
There are two main pathways for visual information processing in the visual cortex (green and blue
arrows in Fig. 2.1). The first one is the ventral stream (also known as â€what pathwayâ€), which is
associated with object recognition and form representation. And the second one is the dorsal stream
(also known as â€where pathwayâ€), which is involved in the guidance of actions and recognizing where
objects are in space. These two pathways have different function but are similar in structure. In this
report, we mainly focus on the mechanism in ventral stream because our initial target is to recognize
objects in static images.
14
Figure 2.2: The concept mapping between cortex visual hierarchy and tuning property of each region.
our recognition system and further extend it to be a more scalable model. Therefore, we will introduce
it more clearly in the following.
2.2.1 Previous Work: HMAX
HMAX is a hierarchical processing model mimicking the feedforward ventral stream for visual feature
extraction. It was first proposed by Riesenhuber and Poggio [15], extended by Serre [10], and further
improved by Mutch [2]. In its simplest form, the model consists of multi-layer of computation units
where simple S units alternate with complex C units. According to the tuning properties of simple
and complex cells found in V1 [17], simple units and complex units are designed for feature detection
and pooling respectively. The simple units respond to certain input patterns at specific position in the
receptive fields. Thus, they receive the afferent inputs and match them with learned prototypes to detect
corresponding features. For example, in Serreâ€²s HMAX implementation, Gabor filters [20] are used at
bottom-level as prototypes, while at higher level, prototypes are learned by randomly sampling patches
from training images. The complex units pool the stimulus from afferent simple units and providing
the scale and location invariance. In HMAX, they are generally modeled by max operations in the
corresponding receptive fields. Through interleaving the simple and complex units hierarchically, one
can build the HMAX model for extracting the invariant features of an input image into a feature vector.
Each component of a feature vector represents the strength of response to the corresponding complex
prototypes learned at higher level. HMAX is also explicitly multiscale: its bottom-level simple units
are computed at all scales, and subsequent complex units pool over both position and scale. Our NC
model is based on Mutchâ€²s improved HMAX model â€“ FHLib [2], which stacks two levels of simple and
complex units to construct five-layer hierarchy: Image-S1-C1-S2-C2. In the following, we give its complete
description layer by layer and the model overview is shown in Fig. 2.4.
Overview of Base HMAX Model
Image Layer The input image is converted to grayscale and then constructed to a multi-scale image
pyramid in order to providing scale invariance.
S1 Layer S1 layer is the response of matching different orientation 2D Gabor filters with the Image
layer at each possible position and scale. While the image layer is a 3D pyramid of pixels, the S1 layer is
16
  
Figure 2.4: Overview of FHLib (adopted in [2]). Each layer has units covering three spatial dimensions
(x/y/scale), and at each 3D location, an additional dimension of feature type. Each layer is computed
from the previous by applying template matching or max pooling filters, and the NN Classifier is in the
backend of FHLib for making decision.
18
Figure 2.5: Dense vs. sparse S2 features. Dense S2 features in the base model are sensitive to all
orientations of C1 units at each position. Sparse features are sensitive only to a particular orientation at
each position. A 4 Ã— 4 S2 feature for a 4-orientation model is shown here. Stronger C1 unit responses
are shown as darker.
Figure 2.6: Inhibition in S1/C1. The weaker units (i.e., orientations) at each position are suppressed.
A 4 Ã— 4 of units (at a single scale) is shown here for a 4-orientation model. Stronger unit responses are
shown as darker.
and in turn ignore the non-dominant orientations as shown in Fig. 4.2 (e.g. a 4 Ã— 4 Ã— 4 dense
prototype patch is constrained to a 4Ã— 4 sparse prototype patch).
â€¢ Lateral Inhibition Lateral inhibition refers to units suppressing their less-active neighbors. In FHLib,
S1/C1 units are inhibited to a few dominant orientations at each position and scale as shown in Fig.
2.6. Essentially these units are competing to describe the dominant orientation at their location.
â€¢ Limited Receptive Field It is to constrain the spatial range of feature inputs instead of filtering at
every position. In FHLib, each S2 feature is computed over a limited range relative to its location
in the image from which it was originally sampled as shown in Fig. 2.6. This modification can
remove some false-alarm cases due to cluttered background but also have less position invariance.
â€¢ Feature Selection Similar to the concept of sparsify input, some dimensions of C2 vector may be
redundant and non-informative for classification. In FHLib, it use SVM to determine the weight of
each dimension and then drop features with low weight, which results in dimension reduction.
With the above modifications, in the setting of [2], the classification rate of Caltech 101 dataset [22]
increase from 41% to 56%, and the number of operations can be reduced 53.75% respect to the base
model. These results demonstrate the value of utilizing the concept of sparsity into the NC model, which
also inspire us to propose the memory association scheme for introducing the sparsity to nearest neighbor
matching stage. The details of proposed method are given in the next chapter.
20
Chapter 3
Neocortical Computing Model using
Feature-Selective Hashing
3.1 Introduction
3.1.1 Problem of Current Neocortical Computing Model
Capability of the primate visual system outperforms the best computer vision systems in every aspect
such as speed, generalization ability, scalability and plasticity. Therefore, in order to achieve the ultimate
goal of developing a human-like visual machine, building a cortex-like model by mimicking the processing
flow and network structure of visual cortex has always been a major approach. Several cortex-inspired
NC models have been proposed and applied successfully to high-level visual tasks, like face, object, action
recognition and localization [10, 11, 12, 13, 14, 16]. The core of these models is to learn invariant and
discriminative features and describe the complex and variant visual inputs with compact representations.
Although there have been several works about using NC models to get the invariant feature representa-
tions, which performs well, less attention has been given to a biologically plausible and efficient feature
matching model which mimics the memory association in higher levels of the ventral stream. In previous
works, the most common ways to do feature matching for classification are NN search [11], SVM [10] and
artificial neural network [13]. All of them suffer from long matching or training time when handling large
database. For instance, in a five-layer FHLib network with NN classifier for 128Ã— 128 image recognition,
the operation profiling per input image is shown in Fig. 3.1. From this profiling, we can see that the
number of operations in NN stage is increasing dramatically as the number of learned instances (C2 vec-
tor) increase, and hence the NN stage become a major part of total timing cost. It indicates the problem
of current NC models is lack of latency scalability and unsuitable for large-scale recognition problem and
online learning functionality. However, recent read-out experiments have shown that the time course
in monkey inferior temporal (IT) cortex, which is considered to be handling object categorization, can
be just as short as 12.5 milliseconds [23]. This implies primates and humans can read out the object
identity in an extremely effective way. The response time for above FHLib network is shown in Fig.
3.2, which tells the gap between current NC model and human capability (recognizing within 250ms for
distinguishing 10,000 to 30,000 classes).
3.1.2 Inspirations from Neuroscience and Computer Science
Learning and memorizing objects via categorization is a common scheme for avoiding exhaustive feature
matching. Within computer science, in order to quickly find the nearest neighbors in a large database,
22
Figure 3.3: Examples of original images (left of arrows) with their corresponding form prototypes (right
of arrows), and the mapping to C2 vectors.
one can categorize the data by building trees [24, 25] or hash tables [26, 27, 28] and then search fewer
candidates only, instead of exhaustive search. These methods provide theoretical guarantee on the search
quality and efficiency with some proper constraints.
Similarly, within neuroscience, it has been found that the neural activity in IT cortex shows its object
selectivity in alignment with cortical columnar organization, which means groups of cells responding
to similar complex features (e.g. objects form) are clustered together in localized cortical regions [29].
Selectivity of cells within a column is similar but not identical. If we emphasize the similarity among
cells within a column, we can regard the columns as units for description of object features. For example,
suppose we have seen many different objects and learned their form prototypes in our IT (corresponding
to each element of C2) as shown in Fig. 3.3. When we see a familiar object again, we only activate
those cortical columns of IT correlated to its form, and show object selectivity for a specific group of
classes as shown in Fig. 3.4. Another study about thalamocortical regions suggests that stored memories
are organized into similarity-based hierarchies via hash-like storage, which is sparse and enables large
amounts of data to be stored in a compact space [30]. We believe that such mechanisms are the keys for
the rapid feature matching in primate visual system.
Therefore, to link those biological evidences to our NC model, we investigate one of the state-of-the-
art techniques called Locality-Sensitive Hashing (LSH) for approximately nearest neighbors search. LSH
overcomes the curse of dimensionality and performs well even in high dimensional space. The concept of
LSH is similar to the cortical columnar organization in IT, which groups the correlated memory (feature)
together and just like a hash table. Inspired from LSH and the mechanism in IT, we proposed Feature-
Selective Hashing (FSH) in our NC model, which provides the scalability and efficiency. In the following,
we briefly give an overview of LSH as background.
Locality-Sensitive Hashing
Locality-sensitive hashing is an indexing scheme proposed by Indyk et al. [26]. Through hashing data
points into corresponding buckets, it can categorize large amount of data into several subsets based on
their locality. It is very useful to reduce the query time of finding NN, because one can only search the
data collided with query in the same bucket instead of exhaustive search. However the trade-off is one
may not find the exact NN (said râˆ—). Fortunately, using LSH functions, it can be guaranteed that distance
of the returned approximate NN (said r) to the query q satisfies: d(r, q) = (1 + Îµ) Â· d(râˆ—, q), with a small
error Îµ > 0. Therefore, utilizing LSH for Approximate Nearest Neighbor (ANN) search can both ease the
24
Figure 3.5: Overview of the proposed framework. The framework consists of two stages: feature extraction
and feature matching. In the stage of feature extraction, features are computed in 5-layer hierarchy:
Image-S1-C1-S2-C2 [2]. Through this processing, input image is represented as a D-dimensional vector
and then fed into NN classifier as query. In the stage of feature matching, first we use one of the features
(local features, gist-like features and color features) as the input of hash functions H, and lookup the
similar object candidates in L hash tables. Then, these candidates are all fed into NN classifier and
matched with the query. Last, we output the category label of returned NN as answer.
vector w is usually constructed by sampling each component randomly from a normal distribution. For
simplicity, we set w as a standard vector ed (i.e. a vector with d
th component equal to one and other
components equal to zero), where d is randomly chosen from 1 to D. Furthermore, we binarize the
returned value of hash functions as
h(x) =
{
1, if wTx+ b â‰¥ 0;
0, otherwise;
(3.3)
which is also a typical response modeled in many neural networks. Thus, Hj can be represented as a
K-bit binary code.
3.2 Proposed Neocortical Computing Model Using Feature-
Selective Hashing
The proposed framework builds on the FHLib and attempts to mimic the property of object selective
organization in IT by incorporating the feature-selective hashing scheme. We test this approach with
objects recognition tasks and the results show improvements on matching speed and learning scalability,
while maintaining the classification accuracy. We first give an overview of our framework, then describe
the implementation details of FSH with local and holistic features respectively, and finally evaluate their
performance in object recognition tasks.
3.2.1 Framework
The overall framework (shown in Fig. 3.5) can be divided into two stages: feature extraction and feature
matching. In the stage of feature extraction, images are reduced to feature vectors, which are computed
through the five-layer hierarchy of FHLib described briefly as follows. Image layer is an image pyramid
with multi-scale resolution. S1 layer is the response of matching different orientation Gabor filters with
26
formulation is similar to LFSH. Given the training set containing n gist-like feature vectors G = {gi},
i = 1, . . . , n and gi âˆˆ RM Â·O, we define the kth GFSH function as follows:
hGk (gi) =
{
1, if gidk + bk â‰¥ 0;
0, otherwise;
(3.5)
where 1 â‰¤ dk â‰¤M Â·O and bk can be just set to zero as well because each component of gist-like features
is normalized.
For color-based HFSH (CFSH), inspired from the response properties of bipolar cells, which have the
preference for either red-green or blue-yellow opponency [34], we accumulate the color histogram of input
images on the opponent color space:ï£«ï£­ O1O2
O3
ï£¶ï£¸ =
ï£«ï£­ (Râˆ’G)/âˆš2(R +Gâˆ’ 2B)/âˆš6
(R +G+B)/
âˆš
3
ï£¶ï£¸ (3.6)
where the intensity is represented in O3 and the color information is in O1 and O2. To construct the
opponent histogram, we divide the opponent color space into S bins and count the number of pixels for
each bin to get a color histogram of size S as input of hash functions. In addition, for simplicity, we
only construct one hash table instead of L and let K = S. Even when adopting such simplification, this
method still performs well in retrieving objects with similar color to queryâ€™s. For detailed formulation,
given the training set containing n color histograms C = {ci}, i = 1, . . . , n and ci âˆˆ RS, we define the kth
CFSH function as following equation:
hCk (ci) =
{
1, if cik + bk â‰¥ 0;
0, otherwise;
(3.7)
where bk is heuristically set to 100 in the following experiments.
3.3 Experimental Results
To evaluate the performance of the proposed framework, we test it on the Amsterdam Library of Object
Images (ALOI) dataset [35]. The ALOI dataset consists of 110,250 images comprising 1,000 different
object categories. Each object category is collected under different viewpoints, illumination colors and
illumination directions. It is suitable for evaluating the efficiency and scalability of FSH because ALOI
contains a large number of objects with variations.
In our setting of FHLib model, we follow the parameter settings described in [2]. For training, we
choose four viewpoints (0â—¦, 90â—¦, 180â—¦, 270â—¦) in each category as training images and randomly sample one
C1 patch per image, while the remaining images compose the testing set. Thus, training a full ALOI
dataset using FHLib will sample 4Ã—1000 C1 patches and form a 4000-dimension C2 vector per image.
Firstly, to test the efficiency of FSH, we train our model on the full ALOI dataset with different
settings of L and K, which results in the trade-off between searching range and classification accuracy,
and test it on different viewpoint images. The results are averaged over 5 runs and shown in Fig. 3.6.
From this result, FSH shows its efficiency on reducing the searching range while maintaining the accuracy.
In Fig. 3.6 (a)(b), the efficiency of LFSH and GFSH increases with K, but at the same time we need
larger L to provide enough accuracy. Thus, it shows the trade-off between performance and memory
requirement. Among these three approaches, CFSH has superior performance over others even using
only one hash table because the test set has large color inter-variation and low color intra-variation.
However, if we test it on the different illumination color and direction cases (shown in Fig. 3.7), CFSH
28
50 100 200 500 1000 2,000 4,000
0
10
20
30
40
50
60
70
80
90
100
Number of searched candidates
A
cc
ur
ac
y 
(%
)
Variant Illumination Directions
 
 
LFSH, K = 7
GFSH, K = 7
CFSH, K = 4
CFSH, K = 8
CFSH, K = 32
CFSH, K = 64
CFSH, K = 256
baseline
50 100 200 500 1000 2,000 4,000
0
10
20
30
40
50
60
70
80
90
100
Number of searched candidates
A
cc
ur
ac
y 
(%
)
Variant Illumination Colors
 
 
LFSH, K = 7
GFSH, K = 7
CFSH, K = 4
CFSH, K = 8
CFSH, K = 32
CFSH, K = 64
CFSH, K = 256
baseline
(a) (b)
Figure 3.7: The classification accuracy with three kinds of FSH for different number of searched candidates
on two variant illumination test sets: (a) variant illumination colors test set (b) variant illumination
directions test set. The baseline represents the accuracy of exhaustive search.
EX
H
A
U.
LF
SH
G
FS
H
CF
SH
Figure 3.8: The top 10 nearest neighbors returned by exhaustive search and three kinds of FSH. The left
most image with red bounding box is the query and its nearest neighbors are ordered from left to right.
tends to saturate when learning more than 200 categories. It might be a problem when facing larger
dataset, like 10,000 to 30,000 categories learned during a humanâ€™s whole life. We suggest that adopting
top-down feature selection scheme may be the key for further improving the reduction rate to fight against
this problem.
3.4 Summary and Discussions
In this chapter, we have shown that using FSH to emulate the memory association in IT can not only
improve the efficiency of feature matching but also provide the scalability of learning. Even though we
adopt a relatively simple way to determine the hash function, FSH still performs well in our experiments.
To further enhance the performance, one may replace the hashing scheme with other more complex
state-of-the-art techniques like Spectral Hashing [27] or Semantic Hashing [28]. In our implementation,
we utilize three features (local C2, gist-like and color-based features) to index the hash tables, but it is
open to use other features or information like context, texture or prior knowledge. Another important
issue of the future work is how to fuse these features properly in order to provide more efficient and
accurate looking up. Interestingly, using hash to activate the relevant data and gate the irrelevant also
provides the sparsity in memory association. It has been widely found that the sparsity constitutes
a general principle of sensory coding in the nervous system [21]. Utilizing sparse coding in our brain
provides several advantages like increasing the capacity of memory, making read-out easier and saving
30
energy, and FSH also provide similar advantages since benefiting from the sparsity.
To categorize our memories in higher brain areas, tree-based method is another possible approach and
also has been widely used in computer science. We didnâ€™t choose tree-based method in our framework
due to its poorer biological plausibility. A tree-based memory structure grows when learning more data
and increases its depth as well. Therefore, many decisions need to be made when descending the tree
to find the answer. Furthermore, we usually have to trace back the route when descending the tree to
verify the answer getting from the leaf node, which makes the number of decision makings even larger.
We argue that it is unreasonable for too many IT neurons to fire sequentially (for making decisions) and
then finding answers within such a small time interval of about 12.5ms. A study has showed that the
firing rates of neurons are barely above 100Hz in the visual system [36], which implies a neuron probably
at most fires once during the feedforward ventral stream (only as short as 80-100ms). On the contrary,
hash-based structure is more biologically plausible because it provides more parallelism and is also in
agreement with the cortical columnar organization in IT geometrically (see later paragraph). As a result,
we choose the hash-based structure rather than tree-based.
Although we can investigate the brain functions through techniques like functional magnetic reso-
nance imaging (fMRI), it is still uncertain how the visual cortex implements the mechanisms of memory
organization, association and retrieval. Therefore, to provide an answer to this question, we propose a
biologically plausible network mapping from our framework as shown in Fig. 3.10. In the feature ex-
traction stage of the proposed framework, HMAX mimics the structure and tuning properties of visual
cortex, and it corresponds to the visual cortex hierarchy from V1, V4 to anterior inferior temporal cortex
(AIT). The C2 feature vectors which are outputted from HMAX represent the matching scores of learned
prototypes, so each component can be mapped to V4/AIT neurons (called C2 units) tuned for complex
features like shape. In the feature matching stage, we assume FSH tables for organizing object-level
memory and providing efficient lookup operations are both functionally and structurally in agreement
with the property of cortical columnar regions in IT. We map FSH tables to clusters of cortical columnar
regions (called CC units), and each CC unit organizes the object-level memory into several CC regions
as buckets. Similarly, only a few CC regions are activated by the stimulus from C2 units. Finally, the
NN classifier responsible for similarity-based classification corresponds to neurons of prefrontal cortex
(PFC), which function as Winner-Take-All (WTA) units to get the most possible object identity. It is
conjectured that the derived network accounting for memory association are fundamental building blocks
in the region of IT and PFC, and we will seek for more behavioral and electrophysiological evidences to
support our model in the future.
32
Chapter 4
Neocortical Computing System using
Push-based Dataflow Processing
4.1 Computation Analysis of Neocortical Computing Model
NC models commonly contain a large number of units and interconnections are therefore computationally
expensive. An 140Ã—140 image recognition requires around 1.93 Gflops computation and GBps-level data
bandwidth at 10 fps. As shown in Fig. 3.2, in current single-core CPU, it is hard to achieve human
capability for real-time recognition applications. However, they are highly amenable to parallelization.
Fig. 4.1 is a schematic diagram of a NC model. In each layer, the units perform the same operations
(e.g. convolve with a filter bank) at every position and scale with no data dependency between each unit.
Therefore, parallelism can be easily introduced within each layer. Due to this feature, NC models are
mapped well to Graphical Processing Units (GPU) utilizing Single Instruction Multiple Data (SIMD).
Several works were proposed using GPU to accelerate NC models and demonstrated great speedup [37, 38].
However, the performance gain is not scalable due to the high bandwidth of NC model. A GPUâ€²s
processors all still share a common memory, which becomes the bottleneck of the system as the network
of NC model becomes larger and more complex. That is to say, scalability is not supported. Besides, each
layer requires the previous layer to be fully (or at least partially) available before computing its output.
Thus the parallelism is hardly introduced across different layers in GPU. Another reason is data required
in different layers may locate faraway and also under different instructions.
Another severe problem results from the sparsity of NC model. In chapter 2 and 3, we have described
that increasing the sparsity of NC model can provide both performance and efficiency. And NC model
can benefits from that and become scalable for large-scale network and problem. However, it also makes
a problem for conventional computing system due to the fact that sparsity brings about irregular data
access. Fig. 4.2 illustrates the irregular data access caused by inhibition, sparsifing input, limited receptive
field, and FSH. In this figure, the colored units of input layer are required for computing features in units
of output layer. These required data are so sparse and with low data locality, thus it is hard to access
sparse data efficiently through the large integrated memory in the conventional computing system. For
sparse matrix computation, the irregular data access with low data locality leads to long memory access
latency. Conventional processors utilize cache memory to reuse the previously accessed data. However,
the characteristic of low data locality for sparse matrix computation leads to poor cache performance
because few data can be reused. Most of the data should be accessed from the main memory. As a result,
the NC system in conventional processor is memory-bounded and non-scalable. A common way for GPU
to resolve this problem is to utilize large size of cache to load the whole layer (or quite large data array)
and parallelize large-scale matrix computation. It leads to much more bandwidth, energy and resource
34
Figure 4.2: A schematic diagram of sparse data access caused by inhibition/sparsifing input (left diagram),
limited receptive field (middle diagram), and FSH (right diagram). The colored units represent the
required data to compute features in output units, while gray-scale units are unused data. Note that
units with same color are correlated.
consumption due to the large data redundancy. There is a trade-off between performance and efficiency
in current computing platform.
To sum up, the NC model has four main features: (1) large number of units and interconnections, (2)
same operation and no data dependency within layer, (3) data causality across layer, (4) sparse features
forwarding. For conventional single core and many-core processors, feature (1) and (4) cause the severe
problem â€“ massive and irregular data access, which results in power, bandwidth usage inefficiency, slow
response and no scalability. And feature (3) prevents simple parallelism to be implemented in GPU across
layer, but it still have rooms for further pipelining. Therefore, an efficient and scalable hardware platform
for NC models is needed.
4.2 Proposed Push-based Dataflow Structure in Many-Core
Architecture
To address the massive and irregular memory access issue, we proposed a push-based dataflow processing
by mimicking the data processing mechanism of brain. A conventional Von Neumann architecture utilize
a shared memory and run the program by accessing data and instructions from this memory. However, no
data access is required in the brain. All the information (spikes) is actively and automatically forwarded
to the required fan-out. We call this mechanism â€push-based processingâ€ or â€event-driven processingâ€,
which has been used in spike-based neural network hardware architecture [39] and provides fast response
and efficiency. On the contrary, the conventional computing systems use â€pull-based processingâ€ for data
accessing. In the following we state the differences between both schemes and show the advantages of
push-based processing.
4.2.1 Comparison between Pull-based and Push-based Processing
Pull-based Processing In pull-based processing, the fan-out is active while the fan-in is passive. As shown
in Fig. 4.3, the output unit actively access the required data from input units, which passively wait for
being accessed. A common transaction is the fan-out first transfer the read command with address to
fan-in, and then the fan-in prepare data and transfer it to fan-out. In addition, Fig. 4.3 illustrates two
36
Figure 4.3: A schematic diagram of pull-based processing and its pseudocode. The left diagram shows the
dense data array access, while the right one shows the sparse data access. The former scheme has good
performance but causes a lot of data and bandwidth redundancy. The latter scheme has good efficiency
but causes long latency due to irregular data access. These pull-based schemes illustrate the trade-off
between efficiency and performance.
38
(a)
(b)
Figure 4.5: An example of push-based dataflow processing. (a) Unit I pushes packet to the PE of unit
O1,1, then the intermediate result computed by PE is updated to ME in unit O1,1. (b) After pushing to
unit O1,1, unit I next pushes packet to the PE of unit O1,2, then the intermediate result computed by
PE is updated to ME in unit O1,1.
40
RISC 
(GPU)
External 
Memory
RISC 
(GPU)
Push-
DF
External 
Memory
Push-
DF
Push-
DF
Push-
DF
External 
Memory
Push-
DF
Push-
DF
Push-
DF
Push-
DF
Push-
DF
(a) (b) (c)
Figure 4.7: System block diagram of three processors in experiments. (a) RISC and GPU. (b) 1D-
interconnected Push-DF (c) 2D-interconnected Push-DF.
4.3.1 Experimental Settings and Definitions
System Definitions
For convention, we define the abstractions of RISC, GPU and Push-DF without losing the generalization
and use them in the following experiments. The system overview is shown in Fig. 4.7. Each core share
a single bus and a common external memory. All the information of NC model is stored in external
memory. We assume each core only have a few registers to buffer the required data and thus need to
access the external memory frequently if necessary. Each core of RISC and GPU is linked to the bus as
Fig .4.7(a), while Push-DF have interconnection between cores additionally as Fig .4.7(b) and (c). They
can be linked as a 1D chain or a 2D network for different parallel and pipeline scheme. For simplicity, we
assume every core can access the external memory at same time.
When executing the filter operations, RISC is SISD (Single Instruction Single Data) structure and
execute operations sequentially. As opposed to RISC, GPU is SIMD structure and usually access a large
data array then compute at once. For this common strategy to provide the speedup, in our experiments,
we assume that GPU only support dense pull-based processing used for SIMD, even when handling
the sparse data structure of NC model. This feature shows its power in performance but weakness in
efficiency. On the contrary, RISC can use sparse pull-based processing to access the required data only but
compute sequentially. The proposed Push-DF also supports SIMD parallel processing for performance
consideration and benefits from push-based processing for providing efficiency. In the experiments, Push-
DF use hybrid SIMD/SISD structure. SIMD is used for computing S1 stage and SISD for others, because
S1 takes the major part of total computation loading and its regular operation is also suitable for SIMD
(as opposed to irregular limited RF in C2 and sparse patches in S2). For the scheme of task partition
in many-core scenario, as described in previous section, RISC and GPU utilize the within-layer partition
as Fig. 4.8(a), while Push-DF utilizes both the within-layer and between-layer partition as Fig. 4.8(b).
The summary of above features in these three system abstractions is listed in Table 4.1.
NC Model Settings
The NC model used for evaluation is a six-stage and single scale feature hierarchy: IM-S1-C1-S2-C2-NN.
The input is a 64 Ã— 64 gray-scale image, and then reduced to a 64D C2 vector, which is matched with
1,024 instances to find NN in the last. To evaluate the impact of sparsity, we consider three settings of
NC model â€“ dense, FHLib and sparse as shown in Table 4.2. The dense NC model has fully dense feature
hierarchy and require filter operations at every position. FHLib has sparsity in S2/C2 stage resulting
from sparse S2 patches and C2 limited RF (here we ignore S1/C1 inhibition due to its similar effect to
42
Table 4.2: The settings of sparsity in dense, FHLib and sparse NC model.
sparse S2 patches). We set C2 limited RF ranged in a 3 Ã— 3 S2 units in the following experiments. The
sparse NC model has sparsity in all stage. The method for introducing the sparsity in S1/C1/NN stage
is randomly choose a percentage of required data to push to the next layer. The percentage is defined by
a factor K. For instance, suppose each S1 unit is computed by convolving a 4Ã— 4 gabor filter with 4Ã— 4
image units, and KS1 = 0.25. Given this KS1, we only push 4Ã— 4Ã— 0.25 = 4 feature values to compute
corresponding S1 units. C1 is similar to S1, while NN is randomly choose a percentage of instances to
match, the effect of which is like FSH. In the following experiments, we set KS1 = 0.2, KC1 = 0.4 and
KNN = 0.2 heuristically.
Cost and Performance Measure Definitions
For system efficiency evaluation, we measure the cost of total external memory access and power con-
sumption per input image. The external memory access Mex consists of feature values read/write and
prototype coefficient read. We assume each core can access one feature value or coefficient at one time
(or in one clock). Thus the total external memory access is to count the total times of read/write. The
power consumption is estimated by the total filter operations. Given the number of operations ni and
operation cost ci in each stage i, the power cost P =
âˆ‘
i nici. The operation cost is 1 for SISD but bigger
than 1 for SIMD because one operation in SIMD involves parallel multiple PEs execution.
For system performance evaluation, we measure the latency L of completing the whole flow per input
image. For convention, we assume that the computation time of PEs can be ignored because it can be
easily hidden by pipelining with memory access. Therefore, the latency can be simplified by estimating the
required time of external memory access. However, this estimated latency can not reflect the problem of
a memory-bounded system because we have assumed every core can access the external memory at same
time. That is, we can use many cores to parallelize the processing for free lunch (unlimited increasing
bandwidth at any given time). As a result, we constrain the external memory bandwidth to a single
access at one time (clock), and estimate the normalized latency Lnorm = max(L,Mex).
4.3.2 Experimental Results
In the experiments, under above definitions and settings, we estimate Mex, P , L, Lnorm of 1, 2, 4, 6, 12
cores RISC, GPU and Push-DF respectively. 1, 2, 4 and 6 cores Push-DF are 1D chain configuration,
while 12 cores Push-DF are interconnected as 2 Ã— 6 2D configuration. The results of Mex are shown in
Fig. 4.9. The Mex of Push-DF drops largely as the core number increases and it outperforms others
because the push-based processing with many-core architecture can reduce the external memory access.
On the contrary, single core Push-DF cannot make use of advantages of push-based processing so that
the Mex is high in this case. GPU utilizes the SIMD structure to keep small Mex because the data reuse
44
Dense
 








    
	

 
 














ï¬€ï¬ï¬‚ï¬ƒ
 !"
#$%
$&'
(
)*
+
(a)
 
 
 
 
 
 
    
	

 
 


	










ï¬€ï¬ï¬‚
ï¬ƒ !
"#$
#%
&'
()
*
FHLib
(b)
Sparse
 
 

 
 

 


 

 


 

 


    
	

 
 


	









ï¬€
ï¬ï¬‚
ï¬ƒ !
"#$
#%&
'
()
*
(c)
Figure 4.9: Total count of external memory access in RISC, GPU and Push-DF with three types of NC
model: (a) Dense NC model, (b) FHLib, (c) Sparse NC model.
46
   






 


 

 

	 











 ï¬€
ï¬
ï¬‚ ï¬ƒ
  !
Dense
 
  






 


 

 
	

 






 

 
ï¬€ ï¬ï¬‚
Dense
(a) (d)
 
  






 


 

 

	 











 ï¬€
ï¬
ï¬‚ ï¬ƒ
  !
FHLib Dense
 
  






 


 

 
	









 

 
ï¬€ ï¬ï¬‚
(b) (e)
 
  






 


 

 

	 











 ï¬€
ï¬
ï¬‚ ï¬ƒ
  !
Sparse
 
  






 


 

 
	









 

 
ï¬€ ï¬ï¬‚
Sparse
(c) (f)
Figure 4.12: Operation count and power cost in RISC, GPU and Push-DF with three types of NC model:
(a) operation count in dense NC model, (b) operation count in FHLib, (c) operation count in sparse NC
model, (d) power cost in dense NC model, (e) power cost in FHLib, (f) power cost in sparse NC model.
48
Chapter 5
Neocortical Computing System-on-Chip
Implementation
In this chapter, we follow the proposed push-based dataflow structure and implement a 36-core Neo-
cortical Computing System-on-Chip (NCSoC) for realization of intelligent object recognition. NCSoC
is an homogeneous many-core Application-Specific Instruction-set Processor (ASIP) with defined NC
Instruction-Set Architecture (NCISA). To optimize for two main features of NC model â€“ high band-
width interconnection and sparse information forwarding, we designed the core with proposed push-based
dataflow structure and the NoC(Network-on-Chip) with Kautz topology. To link NC model to NCSoC,
we proposed a Neocortical Memory Map Generator (NMG) that transform the whole NC network into
the memory content for NCSoC. For evaluating our NCSoC, we map a six-layer and five-scale FHLib for
128 Ã— 128 object recognition into NCSoC by NMG. This network can support 1,000 classes of face and
object recognition. We compare NCSoC with other single/multi core processors. Our platform achieves
more hardware efficiency than others and provide high scalability for future intelligent applications.
5.1 Neocortical Computing System-on-Chip Design
5.1.1 System Overview
Our recognition system block diagram is shown in Fig. 5.1, which contains a 36-core NCSoC, a RISC,
a main memory and two 64-bit buses. NCSoC is an homogeneous many-core Application-Specific
Instruction-set Processor (ASIP) with defined NC Instruction-Set Architecture (NCISA). To represent a
specific NC model in NCSoC, we configure (programm) the memory content of each core, which is com-
posed of NC network parameters, routing information, NC instructions, etc. RISC is mainly responsible
for sending input packets to NCSoC and receiving the answer outputted by NCSoC. The memory content
used for NCSoC is stored in the main memory. The system working flow is described as follows. First,
we store the memory map which is mapped from a trained NC model in the main memory for system
configuration. Second, for an input image from camera or stored dataset, RISC first constructs an image
pyramid and then packs it with corresponding address of target core into many input packets. Then,
RISC sends these packets through bus sequentially to NCSoC. Third, triggered by these packets, each
core of NCSoC starts to compute its own data and communicate with others through NoC and finally
output the answer to the RISC. The information of action and routing for each core can be accessed from
the main memory through two 64-bit buses. In our implementation of NCSoC, it can provide answer in
33.3 ms for a 128Ã— 128 input image from 1,000 classes when operating at 225 MHz. In the following, we
will state the implementation of core and NoC in NCSoC.
50
Value Fan-in# Action
Target Address
1
Coefficient Address
1
Target Address
2
Coefficient Address
2
Memory Format
(a)
ValueActionTarget Address Coefficient Address
NoC Packet Format
(b)
Figure 5.3: (a) General memory format. (b) General packet format.
  

 	



	





 	





 






 
 



	


ï¬€
ï¬




 ï¬‚

ï¬‚

ï¬ƒ
	





ï¬‚

 




!
ï¬‚

ï¬‚

ï¬ƒ




"!

 # $




%"!


&
	



&

'






(
# 




(
 )


  




(
##*
 + 



	



	




ï¬






	



	










Figure 5.4: Pseudocode of NC core.
52
Kautz network 
with d=3, k=2
Task: AD   CB
1) AD   DC
2) DC   CB
Figure 5.6: An routing example of a Kautz network with d = 3 and k = 2. In the bottom example, the
underline alphabet is the preserved one after left-shifting.
Performance Evaluations of Kautz NoC
To evaluate the performance and efficiency of Kautz NoC, we map a NC model into 36-core architecture
with fully dedicated, mesh and Kautz NoC respectively. The NC model used for evaluation is a six-
layer and five scale feature hierarchy from IM to NN. The input is a 128 Ã— 128 gray-scale image, and
then reduced to a 1024-D C2 vector, which is matched with 4,000 instances to find NN in the last. In
this experiment, we assign the task of each core heuristically and keep constant core number used for
each layer. To compare these three NoC, we first measure the performance-to-cost ratio (PCR). PCR is
adopted from [41] and defined by:
PCR =
BWeff
A
(5.1)
where BWeff is the effective bandwidth and A is the wire area cost. They are computed by:
BWeff =
âˆ‘
pâˆˆ{packets}
w(p)
f(p)
AvgDist(p)
(5.2)
A = WireCount (5.3)
where w(p) is the width of packet p, w(i) is the width of link i, f(p) is its firing rate, and AvgDist(p)
is the average distance traversed by each packet, measured in number of hops. We assume that width
of each link and packet is equal to unit value, and thus A is simply measured by the total wire number.
The result is shown in Fig. 5.7. From this result, Kautz network has lowest wire number but the best
PCR among others, which indicates that Kautz is way better than mesh in efficiency with lower wiring
number.
To explore the advantage of Kautz NoC about the log-diameter feature, we further measure the
congestion rate for each link and its distribution. The histogram of estimated congestion rate is shown
in Fig 5.8. As expected, the fully dedicated network has the lightest traffic since it is the direct mapping
54
             
 
 
 



 
 
 









             

	

 
	 





	 	
ï¬€ ï¬
ï¬‚




ï¬ƒ

 

	 !
ï¬€"
	ï¬‚ #$%
ï¬ƒ
&
'( '
ï¬
	

 )

"


ï¬€

*
+

	
,

-
+


.
ï¬€
#


ï¬€


	
"
.
/
0
"ï¬€




ï¬€
 $
,1 2



345678
9:9
9:;65
865:;<=
Figure 5.9: Bio-inspired network mapping.
NN cores in left and right side (as ventral stream) and finally back to the output core in front side. The
number of cores in each layer is determined by estimating its total memory usage. In the higher level of
feature hierarchy, the number of required matching prototypes is more larger than lower level, and thus
it need more cores to partition the matching tasks. In our final implementation, we use 2 cores for image
layer, 6 cores for S1 layer, 3 cores for C1 layer, 8 cores for S2/C2 layer and 16 cores for NN layer.
5.2 Neocortical Memory Map Generator
Before running a NC model on NCSoC, the given software model has to be transformed to the memory
content which can be interpreted by NC Cores. Therefore, we proposed a Neocortical Memory Map
Generator (NMG) to bridge the both ends for system programmability. Fig. 5.10 illustrates the NMG
flow, which contains four stages: task partition/core assignment, NC network parsing, optimization and
memory format transformation. The system planning helps NMG for several configurations like network
mapping, address space definition, memory format, etc.
First, in the stage of task partition and core assignment, according to the setting of network mapping
and address space definition, we partition the NC hierarchical network into several subsets and assign
cores to them and corresponding address blocks respectively. The task partition scheme has discussed
in previous chapter. A common strategy is to count available core number for each layer and make
partitions with equal spacing. Second, in the stage of NC network parsing, we trace the whole NC
network and collect the required information for each unit, including number of fan-in, type of action and
the target address of fan-out units and corresponding coefficients. Third, in the stage of optimization,
we can further utilize the SIMD and multicast features to reduce the number of firing packets and make
more efficient usage of memory. Benefited from SIMD structure, we can merge multiple firing to single
packets if their required data and target core are all the same. Even for the case of firing to different
core, we can use the multicast scheme to parallel the packet firings. In our implementation, through this
optimization can reduce 46.2% of memory usage and 35% running time due to the parallel computing
of SIMD. Last, according to the setting of memory format for each layer, we transform the compressed
parsing information into a memory map, which is then used to configure the NCSoC.
5.3 Chip Implementation Results
Our design is implemented in TSMC 65nm technology. The operating frequency is 200 MHz. Each NC
core have average 18 KB memory and total on-chip memory is 661 KB. The system throughput is to
56
(a) (b)
Technology TSMC 65nm 1P9M CMOS
Core Size 4.5   4.5 mm2
Supply Voltage 1.0V Core, 3.3V I/O
Hardware 
Resources
2.0M logic gates / 
329 2KB SRAM,
23128B Register File
Clock Frequency 225MHz
Response Time 30Hz (37.5ms) 
for 128   128 image
Power 269.8 mW
Performance 30.2 Gops / 1.8Tbps
(c)
Figure 5.11: (a) The floorplan. (b) The chip layout (c) The chip summary.
recognize one 128Ã— 128 image (out of 1,000 classes with 4 training images per class) with 37.5 ms which
meets the real-time requirement. Fig. 5.11 shows the chip layout and summary.
We compare the NCSoC performance with Intel i7-860 2.93 GHz CPU for running the same NC
model. The results are listed in Table 5.1. For one 128 Ã— 128 image recognition, NCSoC achieves 44.1
times speedup compared with CPU. It demonstrates that the Push-DF structure with NCISA increases
the system processing speed over conventional structure. Moreover, with better performance, NCSoC
only requires quite smaller area and power. The normalized performance for area and power efficiency
are 644x and 15,516x compared to CPU respectively. It is proven that NCSoC provides both efficiency
and performance so that it is suitable for future intelligent applications.
The comparisons of performance and efficiency with other state-of-the-art many-core architectures
are also listed in Table 5.2. The normalized Gops/W and Gops/mm2 of NCSoC are 111.85 and 1.49
respectively. The former is the best among others and achieves 48.84 times and 6.87 times of GTX 580
and Intel 80-tile. The latter is 1.38 times better than GTX 580 but worse than Intel 80-tile. Another
estimation is normalized Tbps/W and Tbps/mm2. Under this estimation, NCSoC is better than Intel
80-tile in both area and power efficiency.
In addition to providing better performance and efficiency, NCSoC is also a scalable architecture,
which can easily scale its future performance with Mooreâ€²s law and learn new object instances. The
performance of above platforms is easily bounded by memory bandwidth as discussed. On the contrary,
58
Chapter 6
Conclusion
As the technologies continue to evolve, our computers have more and more computing capacity, which
drives a lot of intelligent applications to emerge. The amount of multimedia data is also growing extremely
fast. To support various intelligent applications and manage this huge amount of data, we need an efficient
hardware platform to provide the required computation capability as human beings. However, it is difficult
for the current computer to complete the task like recognition, localization and detection that human
can make easily. To bridge the gap and realize the hardware system for approaching human capabilities,
our design strategy is through mimicking human brain to have some innovations for designing efficient
computing architecture and expect to make a novel computing architecture breakthrough. The main
contributions of this report are the scalable and efficient algorithm and architecture design of proposed
Neocortical Computing System for visual recognition applications.
In this report, we started from exploring brainâ€™s computing style and architecture, then designed a
brain-like computing system, which can be easily scalable with the amount of resources and supported
functionality. The ventral stream organized hierarchically is believed the core of human visual process-
ing. Therefore, we adopt one of the successful ventral-stream-mimicking model â€“ FHLib as the basic
Neocortical Computing model in our recognition system. However, the problem of current NC models
is lack of latency scalability and unsuitable for large-scale recognition problem and online learning func-
tionality. In the software analysis, the response time for FHLib increases dramatically as the number of
learned object instances increases. To solve this problem, inspired from the object selectivity of cortical
columns in IT and locality-sensitive hashing techniques, we proposed Feature-Selective Hashing to index
the object instances (C2 feature vectors) efficiently. From the experimental result, using FSH reduces at
most 90% of memory matching time and also provides the computation scalability when the number of
learned object instances increases. It proves that proposed NC model using FSH is both efficient and
scalable for our target system requirement.
For the architecture design of NC model, we first analyze the computation of NC model and state
its main problem â€“ massive and irregular data access, which results in power inefficiency, redundant
external bandwidth usage, slow response and no scalability. To solve this problem, we inspired from
the information forwarding scheme of neurons and proposed a scheme called push-based processing. We
compare the push-based processing with pull-based processing in current computing system and show
its advantages in external memory access reduction and efficient sparse data forwarding. For supporting
push-based processing, we proposed a Push-based Data Flow structure. Each unit of Push-DF maintains
its own feature value and fires the final feature value to fan-out units sequentially according to the target
addresses. Push-DF is suitable for a many core architecture and support both within-layer and between-
layer task partition. From the performance evaluation result, Push-DF provides both the performance
and efficiency for NC model at same time. Utilizing push-based processing greatly reduces the massive
60
Bibliography
[1] Youtube, â€œGreat scott! over 35 hours of video uploaded every minute to youtube,â€ 2010.
[2] J. Mutch and D. Lowe, â€œObject class recognition and localization using sparse features with limited
receptive fields,â€ International Journal of Computer Vision, vol. 80, no. 1, pp. 45â€“57, 2008.
[3] J. Rattner, â€œSingle-chip cloud computer,â€ Intel Corporation, 2010.
[4] P. Viola and M. Jones, â€œRapid object detection using a boosted cascade of simple features,â€ Computer
Vision and Pattern Recognition, 2001.
[5] D. Lowe, â€œDistinctive image features from scale-invariant keypoints,â€ International Journal of Com-
puter Vision, vol. 60, no. 2, pp. 91â€“110, 2004.
[6] A. Oliva and A. Torralba, â€œModeling the shape of the scene: A holistic representation of the spatial
envelope,â€ International Journal of Computer Vision, vol. 42, no. 3, pp. 145â€“175, 2001.
[7] R. Lippmann, â€œAn introduction to computing with neural nets,â€ IEEE ASSP Magazine, vol. 4,
pp. 4â€“22, Apr. 1987.
[8] J. Hopfield, â€œNeural networks and physical systems with emergent collective computational abilities,â€
Proceedings of the National Academy of Sciences, vol. 79, no. 8, pp. 2554â€“2558, 1982.
[9] T. Kohonen, â€œThe self-organizing map,â€ Proceedings of the IEEE, vol. 78, no. 9, pp. 1464â€“1480,
1990.
[10] T. Serre, L. Wolf, S. Bileschi, M. Riesenhuber, and T. Poggio, â€œRobust object recognition with cortex-
like mechanisms,â€ IEEE Transactions on Pattern Analysis and Machine Intelligence, pp. 411â€“426,
2007.
[11] D. George and J. Hawkins, â€œTowards a mathematical theory of cortical micro-circuits,â€ PLoS Com-
putational Biology, vol. 5, no. 10, p. e1000532, 2009.
[12] N. Pinto, D. Doukhan, J. DiCarlo, and D. Cox, â€œA high-throughput screening approach to discovering
good forms of biologically inspired visual representation,â€ PLoS Computational Biology, vol. 5, no. 11,
p. e1000579, 2009.
[13] Y. LeCun, K. Kavukcuoglu, and C. Farabet, â€œConvolutional networks and applications in vision,â€ in
Circuits and Systems (ISCAS), Proceedings of 2010 IEEE International Symposium on, pp. 253â€“256,
IEEE, 2010.
[14] H. Lee, R. Grosse, R. Ranganath, and A. Ng, â€œConvolutional deep belief networks for scalable
unsupervised learning of hierarchical representations,â€ in Machine Learning (ICML), Proceedings of
the 26th Annual International Conference on, pp. 609â€“616, ACM, 2009.
62
[31] L. PauleveÂ´, H. JeÂ´gou, and L. Amsaleg, â€œLocality sensitive hashing: A comparison of hash function
types and querying mechanisms,â€ Pattern Recognition Letters, vol. 31, no. 11, pp. 1348â€“1358, 2010.
[32] J. Wolfe and S. Bennett, â€œPreattentive object files: Shapeless bundles of basic features,â€ Vision
Research, vol. 37, no. 1, pp. 25â€“43, 1997.
[33] A. Torralba, R. Fergus, and Y. Weiss, â€œSmall codes and large image databases for recognition,â€
IEEE Conference on Computer Vision and Pattern Recognition, pp. 1â€“8, 2008.
[34] D. Dacey, â€œPrimate retina: cell types, circuits and color opponency,â€ Progress in Retinal and Eye
Research, vol. 18, no. 6, pp. 737â€“763, 1999.
[35] J. Geusebroek, G. Burghouts, and A. Smeulders, â€œThe Amsterdam Library of Object Images,â€
International Journal of Computer Vision, vol. 61, no. 1, pp. 103â€“112, 2005.
[36] S. Thorpe and M. Imbert, â€œBiological constraints on connectionist modelling,â€ Connectionism in
Perspective, pp. 63â€“92, 1989.
[37] T. Poggio, U. Knoblich, J. Mutch, et al., â€œCNS: a GPU-based framework for simulating cortically-
organized networks,â€ 2010.
[38] A. Coates, P. Baumstarck, Q. Le, and A. Ng, â€œScalable learning for object detection with GPU hard-
ware,â€ in Intelligent Robots and Systems (IROS), IEEE/RSJ International Conference on, pp. 4287â€“
4293, IEEE, 2009.
[39] R. Serrano-Gotarredona, M. Oster, P. Lichtsteiner, A. Linares-Barranco, R. Paz-Vicente, F. GoÂ´mez-
RodrÂ´Ä±guez, L. CamunËœas-Mesa, R. Berner, M. Rivas-PeÂ´rez, T. Delbruck, et al., â€œCAVIAR: A 45k
neuron, 5M synapse, 12G connects/s AER hardware sensoryâ€“processingâ€“learningâ€“actuating system
for high-speed visual object recognition and tracking,â€ Neural Networks, IEEE Transactions on,
vol. 20, no. 9, pp. 1417â€“1438, 2009.
[40] D. Bassett and E. Bullmore, â€œSmall-world brain networks,â€ The Neuroscientist, vol. 12, no. 6, p. 512,
2006.
[41] E. Bolotin, I. Cidon, R. Ginosar, and A. Kolodny, â€œCost considerations in network on chip,â€ Inte-
gration, the VLSI Journal, vol. 38, no. 1, pp. 19â€“42, 2004.
64
97 å¹´åº¦å°ˆé¡Œç ”ç©¶è¨ˆç•«ç ”ç©¶æˆæœå½™æ•´è¡¨ 
è¨ˆç•«ä¸»æŒäººï¼šé™³è‰¯åŸº è¨ˆç•«ç·¨è™Ÿï¼š97-2221-E-002-238-MY3 
è¨ˆç•«åç¨±ï¼šiChip å…†ç´šæ™ºæ…§çŸ½æ™¶ç‰‡ä¹‹ç ”ç©¶ï¼šæ¼”ç®—æ³•ï¼Œæ¶æ§‹ï¼Œèˆ‡å¯¦ç¾æŠ€è¡“--å­è¨ˆç•«ä¸€ï¼šçŸ½è…¦ï¼šç”¨æ–¼æ™ºæ…§
è¦–è¨Šè¾¨è­˜ä¹‹å…†ç´šæ™¶ç‰‡æ¶æ§‹è¨­è¨ˆç ”ç©¶ 
é‡åŒ– 
æˆæœé …ç›® 
å¯¦éš›å·²é”
æˆæ•¸ï¼ˆè¢«
æ¥å—æˆ–å·²
ç™¼è¡¨ï¼‰
é æœŸç¸½é”
æˆæ•¸(å«å¯¦
éš›å·²é”æˆ
æ•¸) 
æœ¬è¨ˆç•«
å¯¦éš›è²¢
ç»ç™¾åˆ†
æ¯” 
å–®ä½
å‚™è¨»ï¼ˆè³ªåŒ–èªªæ˜ï¼šå¦‚æ•¸å€‹è¨ˆç•«
å…±åŒæˆæœã€æˆæœåˆ—ç‚ºè©²æœŸåˆŠ
ä¹‹å°é¢æ•…äº‹...ç­‰ï¼‰ 
æœŸåˆŠè«–æ–‡ 0 0 100%  
ç ”ç©¶å ±å‘Š/æŠ€è¡“å ±
å‘Š 0 0 100%  
ç ”è¨æœƒè«–æ–‡ 0 0 100% 
ç¯‡
 
è«–æ–‡è‘—ä½œ 
å°ˆæ›¸ 0 0 100%   
ç”³è«‹ä¸­ä»¶æ•¸ 0 0 100%  å°ˆåˆ© å·²ç²å¾—ä»¶æ•¸ 0 0 100% ä»¶  
ä»¶æ•¸ 0 0 100% ä»¶  
æŠ€è¡“ç§»è½‰ 
æ¬Šåˆ©é‡‘ 0 0 100% åƒå…ƒ  
ç¢©å£«ç”Ÿ 2 2 100%  
åšå£«ç”Ÿ 2 2 100%  
åšå£«å¾Œç ”ç©¶å“¡ 0 0 100%  
åœ‹
å…§ 
åƒèˆ‡è¨ˆç•«äºº
åŠ› 
ï¼ˆæœ¬åœ‹ç±ï¼‰ 
å°ˆä»»åŠ©ç† 0 0 100% 
äººæ¬¡
 
æœŸåˆŠè«–æ–‡ 0 2 100%  
ç ”ç©¶å ±å‘Š/æŠ€è¡“å ±
å‘Š 0 0 100%  
åœ‹
å¤– 
è«–æ–‡è‘—ä½œ 
ç ”è¨æœƒè«–æ–‡ 3 4 100% 
ç¯‡
1.Yu-Ju Lee, Chuan-Yung Tsai 
and Liang-Gee Chen, A 
Cortex-like Model for Rapid 
Object Recognition Using 
Feature-Selective Hashing, in 
International Joint 
Conference on Neural Networks 
2011 (IJCNN 2011), San Jose, 
August, 2011 
2.Shao-Han Tang, Chuan-Yung 
Tsai, Yu-Han Chen and 
Liang-Gee Chen, Intelligent 
Image Inpainting based on a 
