ï¨ˆæ”¿é™¢åœ‹å®¶ç§‘å­¸å§”å“¡æœƒ 
å°ˆé¡Œè¨ˆç•«çµæ¡ˆå ±å‘Š 
æ‡‰ç”¨æ–¼å¯èª¿å¼å‚³è¼¸ä¹‹å¤šåª’é«”æ™ºè²¡æ¬Šä¿è­·ç³»çµ± 
NSC95-2221-E-390-034 
é»ƒï¨šå“² åŠ©ï§¤æ•™æˆ  åœ‹ï§·é«˜é›„å¤§å­¸ é›»æ©Ÿå·¥ç¨‹å­¸ç³» 
 
 
 
ä¸­æ–‡æ‘˜è¦ 
çœ¾æ‰€çš†çŸ¥ï¼Œæ™ºæ…§è²¡ç”¢æ¬Šçš„ä¿è­·ç›¸ç•¶é‡è¦ã€‚å¦‚ä½•ä½¿å¤šåª’é«”è³‡è¨Šåœ¨å‚³è¼¸éç¨‹ä¸­ï¼Œé©ç•¶
çš„å—åˆ°ä¿è­·ï¼Œå¯¦ç‚ºä¸€é‡è¦çš„ç ”ç©¶èª²é¡Œã€‚ 
åœ¨æœ¬è¨ˆç•«ä¸­ï¼Œæˆ‘å€‘æå‡ºï¦ºæ‡‰ç”¨å¯èª¿å¼ç·¨ç¢¼çš„æ™ºæ…§è²¡ç”¢æ¬Šä¿è­·ç³»çµ±ã€‚æœ¬å ±å‘Šé—¡è¿°ï¦º
è¨ˆç•«æœŸé–“çš„ï¥¸é …ä¸»è¦é”æˆä»»å‹™ã€‚ç”±æ–¼å¯èª¿å¼ç·¨ç¢¼ç‚ºæœªï¤­å¤šåª’é«”å£“ç¸®çš„è¶¨å‹¢ä¹‹ã„§ï¼Œ
æˆ‘å€‘å°‡é‡å°å¯èª¿å¼ç·¨ç¢¼ï¼Œé€²ï¨ˆç›¸é—œçš„æ™ºæ…§è²¡ç”¢æ¬Šä¿è­·ã€‚é¦–å…ˆï¼Œæˆ‘å€‘é…åˆå­˜å–æ§åˆ¶
çš„è§€ï¦£ï¼Œçµåˆå¯†ç¢¼å­¸èˆ‡ï¥©ä½æµ®æ°´å°çš„å¯¦ä½œæ–¹æ³•ï¼Œæå‡ºï¦ºç›¸é—œçš„æ™ºæ…§è²¡ç”¢æ¬Šä¿è­·ç³»
çµ±ã€‚å†è€…ï¼Œé‡å°ä»¥å°æ³¢ç·¨ç¢¼ä¹‹å¯èª¿å¼å½±åƒï¼Œä»¥åŠä»¥ JPEG ç‚ºä¸»çš„æ¼¸æ¬¡å‚³è¼¸å½±åƒï¼Œ
æˆ‘å€‘æ¡ç”¨åŸºå› æ¼”ç®—æ³•ï¼Œæå‡ºï¦ºæ—¢èƒ½ç¶­æŒåŠ å…¥æµ®æ°´å°ä¹‹å½±åƒå“è³ªï¼Œåˆå¯ç¢ºä¿æµ®æ°´å°
å¼·å¥æ€§çš„æ–¹æ³•ï¼Œä¸¦ç²è‡´ï¥¼å¥½çµæœã€‚ 
åŸºæ–¼ä¸Šè¿°ï¼Œæ–¼è¨ˆç•«æœŸé–“ï¼Œå…±æœ‰åŒ…å«å°ˆæ›¸ä¸‰å†Šï¼Œå°ˆæ›¸ç« ç¯€ä¸‰ç« ï¼Œåœ‹éš›æœŸåˆŠå››ç¯‡ï¼Œåœ‹
éš›æœƒè­°ï¥æ–‡åç¯‡ï¼Œèˆ‡ä¸­è¯æ°‘åœ‹å°ˆï§ä¸€ä»¶ï¼Œå…±äºŒåä¸€ç¯‡åˆŠå‡ºæˆ–å·²è¢«æ¥å—ï¼Œåƒ…ä¾›ï¥«è€ƒã€‚ 
 
é—œéµè© 
å­˜å–æ§åˆ¶ã€å¯èª¿å¼ç·¨ç¢¼ã€å¯†ç¢¼ã€æµ®æ°´å°ã€åŸºå› æ¼”ç®—æ³• 
 
 1
å ±å‘Šå…§å®¹ 
 
 
ä¸€ã€ å‰è¨€ 
å¯èª¿å¼ç·¨ç¢¼ (scalable coding)ï¼Œåœ¨æ–¼å¯ä»¥é©æ‡‰å‚³è¼¸çš„é »å¯¬å¤§å°ï¼Œä»¥åŠåŒ…å«æ‰‹æ©Ÿã€
é›»è…¦è¢å¹•ã€èˆ‡é«˜ç•«è³ªé›»è¦–ç­‰é‹ç®—èƒ½ï¦Šå·®ï¥¢æ€§æ¥µå¤§çš„æ¥æ”¶ç«¯å…ƒä»¶ï¼Œåªè¦åœ¨ç·¨ç¢¼ç«¯é€²
ï¨ˆä¸€æ¬¡ç·¨ç¢¼çš„ç¨‹åºï¼Œæ¥æ”¶ç«¯å³å¯ä¾ç…§éœ€æ±‚ï¼Œç”±ç›¸åŒçš„å£“ç¸®æª”æ¡ˆä¸­ï¼Œæ“·å–æ‰€éœ€çš„éƒ¨
ä»½é€²ï¨ˆè§£ç¢¼ã€‚ 
 
å¯èª¿å¼ç·¨ç¢¼çš„é”æˆæ–¹å¼ï¼Œä¸»è¦å€åˆ†ç‚ºï¥©ä½é¤˜å¼¦è½‰æ› (discrete cosine transform, 
DCT) èˆ‡ï¥©ä½å°æ³¢è½‰æ› (discrete wavelet transform, DWT) ç­‰ï¥¸å¤§ï¦´åŸŸã€‚ç›®å‰ï¼Œä»¥ 
DCT ç‚ºä¸»çš„å¯èª¿å¼ç·¨ç¢¼æ–¹æ³•ï¼Œå·²è¢«ç´å…¥ MPEG-4 åœ‹éš›æ¨™æº–ä¹‹ä¸­ã€‚ä½†åŸºæ–¼å­¸è¡“ç ”
ç©¶çš„ç‰¹æ€§ï¼Œç”±æ–¼èˆ‡å¯èª¿å¼ç·¨ç¢¼ç›¸é—œçš„æ™ºæ…§è²¡ç”¢æ¬Šä¿è­·æ–¹æ³•å°šï¥§å¤šï¨Šï¼Œå› æ­¤ï¼Œæ­¤ä¸€
èª²é¡Œç›¸ç•¶å€¼å¾—é€²ï¨ˆå­¸è¡“æ€§ç ”ç©¶ã€‚ 
 
æœ¬è¨ˆç•«ä»¥é”æˆå¯èª¿å¼ç·¨ç¢¼çš„æ™ºæ…§è²¡ç”¢ä¿è­·ç³»çµ±ç‚ºç›®çš„ã€‚è€ƒï¥¾ä¸Šè¿°ï¥¸å¤§ï¦´åŸŸï¼Œé¦–
å…ˆï¼Œæˆ‘å€‘ä»¥ï¥©ä½é¤˜å¼¦è½‰æ›ç‚ºä¸»çš„å¯èª¿å¼å¤šåª’é«”ï¼Œæ¡å–å­˜å–æ§åˆ¶çš„è§€ï¦£ï¼Œçµåˆå¯†ç¢¼
å­¸èˆ‡æµ®æ°´å°æ–¹æ³•ï¼Œå®Œæˆä¸¦é©—è­‰ï¦ºç›¸é—œçµæœã€‚å†è€…ï¼Œæˆ‘å€‘ä»¥ (1) ï¥©ä½å°æ³¢è½‰æ›çš„
å¯èª¿å¼å½±åƒã€ä»¥åŠ (2) JPEG æ¼¸æ¬¡å‚³è¼¸ (progressive transmission) ç‚ºåŸºç¤ï¼Œé…åˆ
åŸºå› æ¼”ç®—æ³• (ä¸€ç¨®æœ€ä½³åŒ–è¨“ï¦–çš„æ–¹æ³•)ï¼Œå®Œæˆï¦ºæ—¢èƒ½ç¶­æŒåŠ å…¥æµ®æ°´å°ä¹‹å½±åƒå“
è³ªï¼Œåˆå¯ç¢ºä¿æµ®æ°´å°å¼·å¥æ€§çš„ç›¸é—œæµ®æ°´å°æ¼”ç®—æ³•ã€‚ 
 
 
äºŒã€ ç ”ç©¶ç›®çš„ 
æœ¬è¨ˆç•«çš„ç ”ç©¶ç›®çš„åœ¨æ–¼é‡å°å¯èª¿å¼ç·¨ç¢¼çš„æ™ºæ…§è²¡ç”¢æ¬Šä¿è­·æ–¹æ³•é€²ï¨ˆç ”ç©¶ã€‚æˆ‘å€‘é…
åˆæ¨™æº–çš„ DCT æ–¹æ³•ï¼Œèˆ‡ç›¸é—œå­¸è¡“ç ”ç©¶çš„ DWT æ–¹æ³•ï¼Œåˆ†åˆ¥æå‡ºç›¸é—œå¯¦ä½œæš¨ç›¸
é—œæ¼”ç®—æ³•ï¼Œä»¥å› æ‡‰æ™ºæ…§è²¡ç”¢æ¬Šä¿è­·çš„éœ€æ±‚ã€‚ 
 
 
ä¸‰ã€ ç ”ç©¶æ–¹æ³• 
æœ¬è¨ˆç•«å¯åŠƒåˆ†ç‚ºä¸‰å¤§å€å¡Šï¼Œè©³å¦‚ä¸‹é èµ· A, B, C éƒ¨åˆ†æ‰€è¿°ã€‚ 
 
 3
Decrypt Decode/Compose
Buffer
Buffer
Key
Generation
X i Ei Bi
Bi 1
Ki 1
K i
U i
T i
 
åœ– 1.  è§£å¯†èˆ‡è§£å£“ç¸®ç¤ºæ„åœ–ã€‚ 
 
åœ– 2. ä»£è¡¨åœ¨å¢é€²å±¤ä¸­ï¼Œçµåˆå¯†ç¢¼èˆ‡æµ®æ°´å°ä¹‹å­˜å–æ§åˆ¶ç¤ºæ„åœ–ã€‚åœ¨ä¸ŠåŠåœ–ä¸­ï¼Œå‡
è¨­å·²ç¶“æ”¶åˆ°åŸºæœ¬å±¤è³‡è¨Š ï¼Œä½¿ç”¨åœ–ä¸­çš„ compose() å‡½ï¥©ï¼Œé…åˆè§£å‡ºçš„å¢é€²å±¤è³‡
è¨Š ï¼Œçµ„æˆå…·æœ‰è¼ƒä½³å“è³ªã€æ–°çš„åŸºæœ¬å±¤ ã€‚ï¥´æŒçºŒè§£å‡ºæ–°çš„å¢é€²å±¤ï¼Œå‰‡ä»¥æ­¤
æ–¹å¼ç¹¼çºŒçµ„åˆã€‚åŒæ™‚ï¼Œä½¿ç”¨ decrypt
0B
1E 1B
e() å‡½ï¥©ï¼Œé‡å°åœ– 1. ä¹‹ä¸­çš„å¯†é‘°  é€²ï¨ˆè§£
å¯†ã€‚ 
iK
 
åœ– 2. çš„ä¸­é–“éƒ¨åˆ†ï¼Œextract() å‡½ï¥©ä»£è¡¨æµ®æ°´å°çš„æŠ½å–ã€‚æŠ½å–æ–¹æ³•èˆ‡ C éƒ¨åˆ†çš„ DCT 
æµ®æ°´å°æ¼”ç®—æ³•ç›¸åŒï¼Œå…¬å¼ï¦œèˆ‰æ–¼ä¸‹ï¼š 
( )( ) ( ) ( )( )
â©â¨
â§ â‰¥â‹…=â€²
.,
;YkÎ±kY,
W m,nm,n
otherwise0
0if1
 
 
éƒ¨åˆ†ï¥«ï¥©çš„ä¸‹æ¨™ iï¼Œä»£è¡¨å¢é€²å±¤çš„ï¥©ç›®ã€‚é…åˆæŠ½å–å‡ºçš„æµ®æ°´å° ï¼Œä»¥åŠèˆ‡ä½¿
ç”¨è€…ç›¸é—œçš„å¯†é‘° ï¼Œæˆ‘å€‘å³å¯è§£å¯†å‡ºç§˜å¯†è³‡è¨Š ã€‚æ¥è‘—ï¼Œå¯†é‘° å³å¯è¢«é‹
ç”¨ï¤­è§£å¯†å¢é€²å±¤è³‡è¨Šã€‚åŒæ™‚ï¼Œèˆ‡æµ®æ°´å°ç›¸é—œçš„ï¥«ï¥© Pi äº¦å¯è¢«è§£å‡ºï¼Œä¸¦åšç‚ºä¸‹ä¸€
ç¢¼ç«¯å¿…é ˆç²å¾—æ‰€æœ‰èˆ‡ä½¿ç”¨è€…ç›¸é—œçš„å¯†é‘° ä¹‹å¾Œï¼Œå†ï¤­é‡å°å¤šåª’é«”è³‡ï¦¾é€²ï¨ˆæ¥
æ”¶ã€‚ 
æ­¤ iW
iG iF iK  
ç´šå¢é€²å±¤çš„è¼”åŠ©ã€‚ 
 
è§£ iG
 
 5
  
(a) (b) (c) 
åœ– 3.  (a) èˆ‡åŠ å…¥å¯†ç¢¼ç›¸é—œä¹‹ç”Ÿæˆæµ®æ°´å°ï¼Œå¤§å°ç‚º 128128Ã— . (b) åŒ…å« (a) éƒ¨åˆ†æµ®
æ°´å°çš„åŸºæœ¬å±¤ï¼Œå¤§å°ç‚º 512512Ã— . (c) å¢é€²å±¤å¤§å°ç‚º . 10241024Ã—
 
 
(a) (b) (c) 
åœ– 4.  ç¶“é 10% è³‡ï¦¾ä¸Ÿå¤±ä¹‹æ¥æ”¶ç«¯çµæœ. 
 
 7
å…ƒéŒ¯èª¤ï¥¡ (Bit Error Rate, BER) ç‚º ã€‚æ¨¡æ“¬çµæœæ–¼410âˆ’ åœ– 5. æ­¤è™•æ¡ç”¨ Motion 
JPEG é€²ï¨ˆæ¨¡æ“¬ã€‚å‡è¨­ç¬¬ 0 å¼µç•«é¢ç‚ºåŸºæœ¬å±¤ï¼Œå…¶ä»–çš„ç•«é¢ç‚ºå¢é€²å±¤ã€‚å‚³è¼¸éå¾Œï¼Œ
ï¥§å¯é¿å…çš„æœƒæœ‰éŒ¯èª¤ç”¢ç”Ÿã€‚ä½†æ˜¯ï¼Œé…åˆæ‰€æŠ½å‡ºçš„æµ®æ°´å°ï¼Œç›¸é—œçš„ user key èˆ‡ data 
key ç­‰è³‡è¨Šï¼Œå‡èƒ½ç„¡èª¤çš„è¢«è§£å‡ºï¼Œå¦‚åœ– 6. 
 
ç”± A éƒ¨åˆ†çš„çµæœï¼Œæˆ‘å€‘å¯ä»¥æ¨ï¥å‡ºï¼Œæå‡ºçš„æ–¹æ³•èƒ½æœ‰æ•ˆçš„é€²ï¨ˆå¯èª¿å¼ç·¨ç¢¼çš„å­˜
å–æ§åˆ¶ã€‚ 
 
 
 9
 
ç„¶è€Œï¼Œåœ¨å‚³è¼¸çš„éç¨‹ä¹‹ä¸­ï¼Œå¯èƒ½æœƒé­å—åˆ°å¤–ç•Œåˆ»æ„çš„æ”»æ“Šï¼Œï¦µå¦‚å°‡å«æœ‰æµ®æ°´å°çš„
å½±åƒï¼Œå†æ¬¡é€²ï¨ˆä½é€šï¦„æ³¢ã€ä¸­ä½ï¥©ï¦„æ³¢æˆ– JPEG å£“ç¸®ç­‰ã€‚æ­¤ï§æ”»æ“Šå‡æœƒå°æµ®æ°´
å°å¼·å¥ï¨ç”¢ç”Ÿï¥§ï¥¼å½±éŸ¿ï¼Œå› æ­¤ï¼Œæˆ‘å€‘åœ¨è¨­è¨ˆæ¼”ç®—æ³•æ™‚ï¼Œï¥¥å³å°‡ç›¸é—œçš„æ”»æ“Šæ–¹æ³•ç´
å…¥è€ƒæ…®ã€‚ 
 
åœ¨å¯¦é©—çµæœéƒ¨ä»½ï¼Œæˆ‘å€‘æ¡ç”¨æ¬Šé‡ 30  =Î»  é€²ï¨ˆæ¸¬è©¦ã€‚åœ– 7. ä»£è¡¨åŒ…å«æµ®æ°´å°åœ–å½¢ï¼Œ
ä¸»è§€å“è³ªï¨¦ç®—å¯ä»¥æ¥å—ï¼Œå®¢è§€çš„ PSNR å€¼ä¹Ÿé —é«˜ã€‚åœ– 8. ä»£è¡¨æŠ½å‡ºçš„æµ®æ°´å°ã€‚ç”±
æ¯”è¼ƒå¯å¾—ï¼Œç¶“éåŸºå› æ¼”ç®—æ³•çš„è¨“ï¦–ï¼Œæˆ‘å€‘çš„æå‡ºçš„æµ®æ°´å°æ–¹æ³•ï¼Œå‡å…·æœ‰å¼·å¥æ€§çš„
è¦æ±‚ã€‚ 
 
  
 (a) 
 With GA Without GA
 â‡“  â‡“  
LPF â‡’   
 81.54% 35.45% 
 (b) (c) 
MF â‡’   
 85.06% 39.26% 
 (d) (e) 
JPEG â‡’   
 96.29% 47.27% 
 (f) (g) 
åœ– 8.  è‡ªç¶“éæ”»æ“Šçš„å½±åƒä¸­ï¼ŒæŠ½å–å‡ºçš„æµ®æ°´å°æ¯”è¼ƒã€‚ï¥©å€¼ä»£è¡¨ BCR å€¼ã€‚ 
 
ç”± B éƒ¨åˆ†çš„çµæœï¼Œæˆ‘å€‘å¯ä»¥æ¨ï¥å‡ºï¼Œæå‡ºçš„æµ®æ°´å°æ–¹æ³•èƒ½æœ‰æ•ˆçš„é€²ï¨ˆå¯èª¿å¼ç·¨
ç¢¼å‚³è¼¸ï¼Œä¸¦å°æŠ—å¤–ï¤­çš„æ”»æ“Šã€‚ 
 
 
 11
  
åœ– 9.  è¼¸å‡ºå½±åƒçš„ PSNR å€¼æ¯”è¼ƒã€‚å¯ä»¥ç™¼ç¾å½±åƒå“è³ªéš¨è‘—æ¼¸æ¬¡å‚³è¼¸æ”¶åˆ°çš„è³‡è¨Šå¢
åŠ è€Œæå‡ã€‚ 
 
 
åœ– 10.  JPEG spectral selection mode æ¼¸æ¬¡å‚³è¼¸å¾Œï¼ŒæŠ½å–å‡ºçš„æµ®æ°´å°çµæœã€‚ä¸Šåœ–
ä»£è¡¨å‰ 24 stages çš„çµæœ, å¯ï¨Šåˆ°æ”¶åˆ°è³‡è¨Šæ„ˆå¤š, å½±åƒå“è³ªéš¨ä¹‹å¢åŠ , åŒæ™‚
 
ç”± C æ¨ï¥å‡ºï¼Œæå‡ºçš„æµ®æ°´å°æ–¹æ³•èƒ½æœ‰æ•ˆçš„é€²ï¨ˆå¯èª¿å¼ç·¨
å‚³è¼¸èˆ‡ç›¸é—œçš„æ™ºæ…§è²¡ç”¢æ¬Šä¿è­·ã€‚ 
 
æµ®æ°´å°äº¦ï¤å®¹ï§ åˆ†è¾¨. 
 éƒ¨åˆ†çš„çµæœï¼Œæˆ‘å€‘å¯ä»¥
ç¢¼
 
 13
S anography, and Watermarking of Multimedia Contents VI ecurity, Steg
Conference, San Jose, CA, January 18â€“22, 2004. 
 
 
 15
 
å°ˆæ›¸ç« ç¯€ï¼šï¼ˆå·²å‡ºç‰ˆ 3 ç« ï¼‰ 
[4] H.-C. Huang, J. S. Pan, W. C. Fang, and L. C. Jain, â€œAn Introduction to 
Intelligent Multimedia Data Hiding,â€ Intelligent Multimedia Data Hiding: 
New Directions, Chapter 1, pp. 3â€“10, Apr. 2007. 
[5] H.-C. Huang, J. S. Pan, C. Y. Huang, Y. H. Huang, and K. C. Huang, â€œTabu 
Search Based Multi-Watermarking over Lossy Networks,â€ Intelligent 
Multimedia Data Hiding: New Directions, Chapter 12, pp. 325â€“355, Apr. 
2007. 
[6] H.-C. Huang, J. S. Pan, W. C. Fang, and L. C. Jain, â€œPrograms Relating to 
Topics of This Book,â€ Intelligent Multimedia Data Hiding: New Directions, 
Appendix A, pp. 391â€“392, Apr. 2007. 
4 ç¯‡ï¼‰ 
[7] S. C. Chu, H.-C. Huang
 
åœ‹éš›æœŸåˆŠï¥æ–‡ï¼šï¼ˆå·²åˆŠå‡ºæˆ–æ¥å—
, Y. Shi, S. Y. Wu, and C. S. Shieh, 2007, â€œGenetic 
Watermarking for Zerotree-Based Applications,â€ Circuits, Systems and 
Signal Processing (accepted). (SCI, EI) 
[8] P. W. Tsai, S. C. Chu, H.-C. Huang, T. Chou, and J. D. Day, 2007, â€œA 
Strategy for Opposing DC Components Watermarking,â€ Journal of Digital 
Management (accepted). (EI) Information 
[9] H.-C. Huang, J. S. Pan, Y. H. Huang, F. H. Wang, and K. C. Huang, 2007, 
ques with Genetic Algorithms,â€ Circuits, 
 (accepted). (SCI, EI) 
â€œProgressive Watermarking Techni
Systems and Signal Processing
[10] F.-C. Chang, H.-C. Huang, and H.-M. Hang, â€œLayered Access Control 
 Watermarked Scalable Media,â€ Journal of VLSI Signal 
hnology, online 
available: Jun. 2007. (SCI, EI) 
 
åœ‹
[11] 
Schemes on
Processing Systems for Signal, Image, and Video Tec
éš›æœƒè­°ï¥æ–‡ï¼šï¼ˆå·²åˆŠå‡ºæˆ–æ¥å— 10 ç¯‡ï¼‰ 
H.-C. Huang, J. S. Pan, and C. M. Chu, â€œOptimized Copyright Protection 
Systems with Genetic-Based Robust Watermarking,â€ IEEE International 
Conference on Intelligent Information Hiding and Multimedia Signal 
[12] 
Processing, Kaohsiung, Taiwan, R.O.C., 2007 (accepted). (EI) 
H.-C. Huang, J. S. Pan, and Y. H. Huang, â€œInformation Protection and 
Recovery with Reversible Data Hiding,â€ IEEE International Conference on 
Intelligent Information Hiding and Multimedia Signal Processing, 
[13] g
Kaohsiung, Taiwan, R.O.C., 2007 (accepted). (EI) 
F.-C. Chang and H.-C. Huan , â€œA Programming Model for Distributed 
 17
å‡ºå¸­åœ‹éš›å­¸è¡“æœƒè­°å¿ƒå¾—å ±å‘Š 
                                                             
è¨ˆç•«ç·¨è™Ÿ NSC95-2221-E-390-034 
è¨ˆç•«åç¨± æ‡‰ç”¨æ–¼å¯èª¿å¼å‚³è¼¸ä¹‹å¤šåª’é«”æ™ºè²¡æ¬Šä¿è­·ç³»çµ± 
å‡ºåœ‹äººå“¡å§“å 
æœå‹™æ©Ÿé—œåŠè·ç¨± 
é»ƒï¨šå“² 
åœ‹ï§·é«˜é›„å¤§å­¸ é›»æ©Ÿå·¥ç¨‹å­¸ç³» åŠ©ï§¤æ•™æˆ 
æœƒè­°æ™‚é–“åœ°é» æœƒè­°æœŸé–“ï¼š2006/08/30~2006/09/01 æœƒè­°åœ°é»ï¼šä¸­åœ‹å¤§ï§“ã€ï¥£äº¬ 
æœƒè­°åç¨± International Conference on Innovative Computing, Information and Control 2006 
ç™¼è¡¨ï¥æ–‡é¡Œç›® 
1. Measurements and Improvements of Conducted Electromagnetic 
Interference Emission Caused by the Switching Circuit 
2. Image Texture Segmentation with Ant Colony Systems 
3. A Multiple-Instance Neural Networks based Image Content Retrieval 
System 
 
ä¸€ã€ï¥«åŠ æœƒè­°ç¶“é 
ç¬¬ä¸€å±†æ™ºæ…§è¨ˆç®—ã€è³‡è¨Šèˆ‡æ§åˆ¶åœ‹éš›æœƒè­° (International Conference on Innovative 
Computing, Information and Control 2006, ICICICâ€™06)ï¼Œ2006 ï¦ 8 æœˆ 30 æ—¥è‡³ 2006 ï¦ 9 æœˆ 1
æ—¥æ–¼ä¸­åœ‹å¤§ï§“ï¥£äº¬å¸‚çš„ï¥£äº¬äº¤é€šå¤§å­¸æ‰€èˆ‰ï¨ˆã€‚æ„Ÿè¬ï¨ˆæ”¿é™¢åœ‹å®¶ç§‘å­¸å§”å“¡æœƒçš„æ”¯æŒï¼Œæœ¬äºº
ä½¿ç”¨è¨ˆç•«ç¶“è²»ï¼Œæ”¯ä»˜ï¥«åŠ æœƒè­°çš„æ©Ÿç¥¨è²»ã€è¨»å†Šè²»èˆ‡ç”Ÿæ´»è²»ã€‚ 
 
æ­¤æœƒè­°è¦æ¨¡é —å¤§ï¼Œæœ‰è¶…éå››ç™¾äººèˆ‡æœƒï¼Œæœƒè­°ä¸‰å¤©æœŸé–“ï¼Œæ¯å¤©ä¸Šåˆå‡æœ‰ä¸€å ´ keynote 
speechï¼Œè³‡è¨Šå¦‚ä¸‹ï¼š 
Â¾ Watermarking, Steganography and Communications ç”±è‹±åœ‹ï§”æ•¦å¤§å­¸ Prof. 
Ingemar J. Cox æ¼”è¬›ï¼› 
Â¾ Missing Data Imputation with Parameter Optimization ç”±æ¾³æ´²é›ªï§¢ç§‘æŠ€å¤§å­¸ Prof. 
Chengqi Zhang æ¼”è¬›ï¼› 
Â¾ Knowledge Acquisition Tool Established by Data with Their Evaluationâ€“ SOR 
Network ç”±æ—¥æœ¬ä¹å·å·¥æ¥­å¤§å­¸ Prof Takeshi Yamakawa æ¼”è¬›ã€‚ 
 
åŒæ™‚ï¼Œæ–‡ç« å ±å‘Šçš„éƒ¨ä»½ï¼Œä¸¦åˆ†ç‚º 53 å€‹ session èˆ‰ï¨ˆ (ç¬¬ä¸€å¤©: 18 å€‹ï¼Œç¬¬äºŒå¤©: 18 
å€‹ï¼Œç¬¬ä¸‰å¤©: 17 å€‹)ã€‚ç›¸é—œèª²é¡Œï¼ŒåŒ…å«å¤šåª’é«”è™•ï§¤ã€æœ€ä½³åŒ–æŠ€è¡“ã€æ§åˆ¶ï§¤ï¥ã€é€šè¨ŠåŸï§¤ã€
é›»è…¦ç¶²ï¤·ã€è³‡è¨Šå®‰å…¨ã€è³‡ï¦¾å€‰å„²ç­‰ç­‰ï¼Œå…§å®¹ç›¸ç•¶å»£æ³›ã€‚é™¤ï¦ºï¥«èˆ‡é€²ï¨ˆå ±å‘Šçš„å ´æ¬¡ä¹‹å¤–ï¼Œ
äº¦å¯ï¥«åŠ å…¶ä»–ï¥§åŒï¦´åŸŸçš„å ´æ¬¡ï¼Œï¦°è½å ±å‘Šä¸¦å¢åŠ æ–°çŸ¥ã€‚ 
 
 
äºŒã€èˆ‡æœƒå¿ƒå¾— 
æœ¬äººæœƒè­°å…¨æœŸå‡å®Œå…¨ï¥«åŠ ã€‚é™¤ç¬¬ä¸€å¤©èˆ‡ç¬¬äºŒå¤©é€²ï¨ˆï¥æ–‡å ±å‘Šä¹‹å¤–ï¼Œç¬¬ä¸‰å¤©äº¦æ“”ä»» 
å‡ºå¸­åœ‹éš›å­¸è¡“æœƒè­°å¿ƒå¾—å ±å‘Š 
                                                             
è¨ˆç•«ç·¨è™Ÿ NSC95-2221-E-390-034 
è¨ˆç•«åç¨± æ‡‰ç”¨æ–¼å¯èª¿å¼å‚³è¼¸ä¹‹å¤šåª’é«”æ™ºè²¡æ¬Šä¿è­·ç³»çµ± 
å‡ºåœ‹äººå“¡å§“å 
æœå‹™æ©Ÿé—œåŠè·ç¨± 
é»ƒï¨šå“² 
åœ‹ï§·é«˜é›„å¤§å­¸ é›»æ©Ÿå·¥ç¨‹å­¸ç³» åŠ©ï§¤æ•™æˆ 
æœƒè­°æ™‚é–“åœ°é» æœƒè­°æœŸé–“ï¼š2006/12/18~2006/12/20 æœƒè­°åœ°é»ï¼šç¾åœ‹ã€åŠ å·ã€å¸•è–©è¿ªç´å¸‚ 
æœƒè­°åç¨± International Conference on Intelligent Information Hiding and Multimedia Signal Processing 2006 
ç™¼è¡¨ï¥æ–‡é¡Œç›® Reversible Data Hiding for 3D Point Cloud Model 
 
ä¸€ã€ï¥«åŠ æœƒè­°ç¶“é 
ç¬¬äºŒå±†æ™ºæ…§è³‡è¨Šéš±è—èˆ‡å¤šåª’é«”è¨Šè™Ÿè™•ï§¤åœ‹éš›æœƒè­° (International Conference on 
Intelligent Information Hiding and Multimedia Signal Processing 2006, IIHMSPâ€™06)ï¼Œ2006 ï¦
12 æœˆ 18 æ—¥è‡³ 2006 ï¦ 18 æœˆ 20 æ—¥æ–¼ç¾åœ‹åŠ å·ã€å¸•è–©è¿ªç´å¸‚çš„åœ‹éš›æœƒè­°ä¸­å¿ƒæ‰€èˆ‰ï¨ˆã€‚æ„Ÿè¬
ï¨ˆæ”¿é™¢åœ‹å®¶ç§‘å­¸å§”å“¡æœƒçš„æ”¯æŒï¼Œæœ¬äººä½¿ç”¨è¨ˆç•«ç¶“è²»ï¼Œæ”¯ä»˜ï¥«åŠ æœƒè­°çš„éƒ¨ä»½æ©Ÿç¥¨è²»ã€‚ 
 
æ­¤æœƒè­°ç”±æ–¼ä¸»é¡Œè¼ƒç‚ºé›†ä¸­ï¼Œå±¬ä¸­å‹è¦æ¨¡ï¼Œæœ‰è¶…éäºŒç™¾äº”åäººèˆ‡æœƒï¼Œæœƒè­°ä¸‰å¤©æœŸé–“ï¼Œ
å‰ï¥¸å¤©ä¸Šåˆå‡æœ‰ä¸€å ´ keynote speechï¼Œè³‡è¨Šå¦‚ä¸‹ï¼š 
Â¾ Digital Data Forensics ç”±ç¾åœ‹ï§æ¾¤è¥¿ï§¤å·¥å­¸é™¢ Prof. Yun Q. Shi æ¼”è¬›ï¼› 
Â¾ Intelligent Multimedia Processing for Human-Centric Digital Life ç”±å°ç£æˆåŠŸå¤§å­¸
ç‹é§¿ç™¼æ¼”è¬›ï¼› 
 
åŒæ™‚ï¼Œæ–‡ç« å ±å‘Šçš„éƒ¨ä»½ï¼Œä¸¦åˆ†ç‚º 18 å€‹ session èˆ‰ï¨ˆ (ç¬¬ä¸€å¤©: 6 å€‹ï¼Œç¬¬äºŒå¤©: 6 å€‹ï¼Œ
ç¬¬ä¸‰å¤©: 6 å€‹)ã€‚ç›¸é—œèª²é¡Œï¼ŒåŒ…å«è³‡ï¦¾éš±è—ã€ï¥©ä½æµ®æ°´å°ã€å‹•æ…‹å½±åƒè™•ï§¤ã€æ¼”åŒ–å¼è¨ˆç®—ã€
é›»è…¦ç¶²ï¤·ã€å½±åƒè¾¨ï§¼ç­‰ç­‰ï¼Œå…§å®¹è¼ƒç‚ºé›†ä¸­ï¼Œå¤šå±¬è¨Šè™Ÿè™•ï§¤ç¯„åœã€‚é™¤ï¦ºï¥«èˆ‡é€²ï¨ˆå ±å‘Šçš„å ´
æ¬¡ä¹‹å¤–ï¼Œäº¦å¯ï¥«åŠ å…¶ä»–ï¥§åŒï¦´åŸŸçš„å ´æ¬¡ï¼Œï¦°è½å ±å‘Šä¸¦é€²ï¨ˆæ·±å…¥è¨ï¥ã€‚ 
 
 
äºŒã€èˆ‡æœƒå¿ƒå¾— 
æœ¬äººæœƒè­°å…¨æœŸå‡å®Œå…¨ï¥«åŠ ã€‚é™¤é€²ï¨ˆï¥æ–‡å ±å‘Šä¹‹å¤–ï¼Œç¬¬äºŒã€ç¬¬ä¸‰å¤©äº¦æ“”ä»» Session 
Chairã€‚åœ¨æœƒè­°ä¹‹å‰ï¼Œæœ¬äººäº¦åŒæ™‚æ“”ä»»æ­¤æœƒè­°çš„ Executive Secretary ä»¥åŠ Program 
Committee Memberã€‚ 
 
å ±å‘Šçš„ä¸€ç¯‡è³‡è¨Šå¦‚ä¸‹ï¼š 
Â¾ C1-03ï¼šReversible Data Hiding for 3D Point Cloud Model 
 
Image Texture Segmentation with Ant Colony Systems 
Mei-Shin LaiÏª, Hsiang-Cheh HuangÂ§, Shu-Chuan ChuÏ¬, Yu-Hsiu HuangÏ¬Ê³and Kuang-Chih HuangÏ¬
ÏªNational Kaohsiung University of Applied Sciences, Kaohsiung, Taiwan, R.O.C. 
Â§National Kaohsiung Marine University, Kaohsiung, Taiwan, R.O.C. 
Ï¬Cheng Shiu University, Kaohsiung, Taiwan, R.O.C. 
Abstract 
A new scheme for texture segmentation based on Ant Colony 
Systems (ACS) is proposed in this paper. Texture segmentation 
is one of the important branches in image pattern recognition, 
which provides usefulness in many applications. Until now, how 
to find an effective way for accomplishing texture segmentation 
in practical applications is still a major task. In this paper, we 
employ wavelet coefficients and characteristics of different 
subbands to serve as the basis of characteristic vectors, and we 
use three feature-extraction elements, namely, the extrema, 
entropy, and energy, to compose the characteristic vector. To 
alleviate segmentation fragments caused from the information in 
high frequency bands of texture images, we integrate the fourth 
element, the mean variance, into the characteristic vector. 
Finally, we use ACS to find a trade-off between texture 
segmentation and fragments. Simulation results demonstrate the 
effectiveness and practicability of the proposed algorithm. 
1. Introduction
Texture segmentation forms an important branch for image 
analysis. Segmentation subdivides an image into its constituent 
parts or object. It depends on the global characteristics of an 
image, which is similar to the judgment of human perception. 
However, in the real world, there are too many objects with a 
variety of different characteristics; thus, there is no standard way 
to define the meaning of different textures clearly, and to 
describe these features effectively. At the beginning of 
researches in texture segmentation, researchers introduced some 
statistical models, such as the Markov random field and 
autoregressive model, to solve problems. 
Recently, researchers employed the transform domain 
techniques to conquer this task. By using some transform, such 
as Fourier transform or wavelet transform, we can transform the 
spatial domain texture images into the frequency domain signals 
(or different frequency bands), which provide the information 
about the directions and periodicities of the textures. In addition, 
other schemes for texture analysis, including multi-channel and 
multi-resolution analysis [1], short-time Fourier transform [2], 
wavelet transform [3], principal component analysis (PCA) [4], 
texture analysis with genetic algorithms [5], are all effective 
schemes for combating different problems arose in texture 
analysis and segmentation. 
In this paper, we apply wavelet transform in the spatial 
domain texture images, and then we use the wavelet coefficients 
and the characteristics of different subbands to serve as the basis 
for gathering the characteristic vectors. Next, we employ four 
feature extraction elements, namely, the extrema, the entropy, 
the energy, and the mean variance, and we treat them as the 
elements in the characteristic vectors. In order to alleviate the 
segmentation fragments and the accuracy of boundary detection, 
we apply the quadrant mean filter [6] to smooth out the 
characteristic vectors and the consequent results. Finally, we 
propose the clustering technique with ant colony system to 
conquer some commonly encountered problems in literature. 
This paper is organized as follows. In Sec. 2 we describe the 
characteristics collection scheme and structure based on wavelet 
transform. We will also explain the four characteristic elements 
employed in this paper, namely, the extrema, entropy, energy, 
and mean variance in this section. In Sec. 3 we state our scheme 
for improving the characteristic element with the normalization 
scheme and the quadrant mean filter. In Sec. 4 we address the ant 
colony optimization and ant colony system. Texture 
segmentation with ant colony systems is presented in Sec.5. 
Simulation results are demonstrated in Sec.6. Finally we 
summarize and conclude our major findings in Sec. 7. 
2. Characteristics collection 
In this paper, we use Daubechies D4 wavelet transform with 
three-layer pyramid structure, which is shown in Figure 1. 
Generally speaking, it is not easy to discriminate the textures 
based on the wavelet coefficients obtained, therefore, we need to 
take some characteristic factors proposed in literature, e.g., the 
fourteen characteristic factors proposed in [7][8]. In this paper, 
we take the extrema, entropy, and the energy of the texture 
image for the objective representation of the textures. 
The definition of the extrema is depicted by Eq. (1): 
{( , ) | ( 1, ) ( , ),
( 1, ) ( , )},
{( , ) | ( 1, ) ( , ),
( 1, ) ( , )}
r
r
Max f l m f l m f l m
                f l m f l m
Min f l m f l m f l m
                f l m f l m
  d
 d
  t
 t
.  (1) 
Moreover, the definition of the two-dimensional (2-D) extrema is 
{ ,
,
,
}
r c
r c
r c
r c
Ef Max Wf Max Wf
          Max Wf Min Wf
          Min Wf Max Wf
          Min Wf Min Wf
 Âˆ
Âˆ
Âˆ
Âˆ
.    (2) 
Based on Eqs. (1) and (2), we are able to calculate the extrema 
positions within different wavelet bands. 
In order to calculate the texture characteristics at position P,
we first defined a window centered at P, with width S and height 
T. Then, we are able to calculate the density of the extrema with 
Eq. (3): 
R
Ef
PD # ,     (3) 
Proceedings of the First International Conference on Innovative Computing, Information and Control (ICICIC'06)
0-7695-2616-0/06 $20.00  Â© 2006
Initialize 
Loop 
Each ant is positioned on a starting node 
  Loop 
    Each ant applies a state transition rule
 to incrementally build a solution 
 and a local pheromone updating rule
Until all ants have built a complete solution 
A global pheromone updating rule is applied 
Until End_condition  
And we will apply ACS into the texture segmentation, which 
will be described in Sec. 5. 
5. Texture segmentation 
Ant Colony Systems (ACS) are suitable for solving discrete 
optimization problems. However, during the training process, the 
pheromones to be recorded consume lots of memory. Therefore, 
how to deal with the memory allocation problem becomes a 
crucial problem in training with ACS. 
People proposed some texture segmentation scheme by 
combining the ACS with Markov random field in literature [11]. 
Suppose that in the training set, the number of data is S and the 
number of cluster is K. With the method in [11], the complexity 
of the memory required is  2SO , while with our algorithm, the 
memory required reduced to  SKO . With the pseudo-codes in 
Sec. 4, the procedures of our algorithm are depicted as follows. 
1 Initialize all the tracks with pheromone 
0W
2 Assume k ants for training. For every ant, 
2.a Use the transition rule with Eq. (12) to designate the 
data into every cluster: 
^ [ ( , )] [ ( , )] , 0arg max s c s c   if q qc C,                                          otherwiseEW KÂ˜ d  (12)  
with the following elements in Eqs. (13) and (14):  
[ ( , )] [ ( , )]( , )
[ ( , )] [ ( , )]k
u
s c s cC P s c
s u s u
E
E
W K
W K
Â˜  
Â˜Â¦
;  (13)  
,
,
2 2
( , )
( , ) ( ) ( )
11 ( , )
es e s
s s
s s neighborss
s c y u x x
           e e
N
K
G
   
Â§ Â·
 Â¨ Â¸
Â© Â¹
Â¦
.  (14)  
In Eq. (14), 
sy  and sx  are the characteristic vector and 
pixel value at position s,
eu  and ex  are the mean value 
and centroid of cluster e, sâ€™ is the neighborhood at 
position s. There are 
sN  neighbors in sâ€™. And G  means 
the kronecker delta function. 
2.b Use the local update rule, depicted in Eq. (15), to 
refresh the pheromone along the tracks: 
    0,)1(, WUWUW Â˜Â˜ eses   (15) 
where U  denotes the evaporation coefficient. 
3 Use the global update rule, depicted in Eq. (16), to refresh 
the pheromone along the tracks if (s, e) is in the best 
partition: 
    Meses 1,)1(, Â˜Â˜ UWUW    (16) 
where M denotes the metric for evaluating the results after 
clustering: 
,
,
2 2
( , )
( , ) ( ) ( , )es s s s s
s S s s neighobrs
M y u x x e eG
Â
Â§ Â·
   Â¨ Â¸
Â© Â¹
Â¦ Â¦  (17) 
4 Once the total number of iteration is reached, the algorithm 
is terminated. Otherwise, go back to Step 2 for another 
training iteration. 
6. Simulation results 
In our simulations, we take the Brondatz texture image database 
for examining the effectiveness of our proposed algorithm. The 
three test images are shown in Figure 3. We design three 
experiments to show the improvements and practicality with our 
algorithm.
Texture #1 Texture #2 Texture #3 
Figure 3 The three test images in our simulations. 
In Experiment #1, we perform Daubechies D4 wavelet 
transform with three-layer pyramid structure in Figure 1, and 
calculate three elements, namely, the density of extrema, entropy, 
and energy, of the test image. We use the well-known K-Means 
algorithm [12] for clustering, and we compare the results by 
either considering the three elements above, represented by 
Method #1, or the three in Method #1 plus the mean variance, 
represented by Method #2. Calculation of the four elements was 
depicted in Sec. 2. Results are demonstrated in Figure 4 with 
Texture #1 in Figure 3 for subjective evaluation. The correction 
rates with all three textures are depicted in Table 1. We can see 
that by taking the mean variance into account, we get better 
results objectively and subjectively. There are less fragments and 
better detection in the boundaries with Method #2. 
Texture #1 Method #1 Method #2 
Figure 4 Objective evaluation of Method #1 (by using 
three characteristic elements) and Method #2 
(Method #1 + mean variance). 
In Experiment #2, we examine the effectiveness of adding 
the quadrant mean filter into our algorithm. Again, Method #2 
denotes the use of four characteristic elements, which has the 
same meaning in Experiment #1. Here, Method #3 denotes the 
combination of Method #2 with the quadrant mean filter. The 
correction rates with all three textures are depicted in Table 1. 
We also compare the quadrant mean filters in Sec. 3, with two 
other schemes in literature, namely, the window mean [5], and 
Proceedings of the First International Conference on Innovative Computing, Information and Control (ICICIC'06)
0-7695-2616-0/06 $20.00  Â© 2006
A Multiple-Instance Neural Networks based Image Content Retrieval System
Shun-Chin Chuang, Yeong-Yuh Xu, and Hsin Chia Fu
Dept. of Computer Science Engineering
National Chiao-Tung University
Hsinchu, Taiwan, R.O.C.
scchuang@csie.nctu.edu.tw
Hsiang-Cheh Huang
Dept. of Microelectronic Engineering
National Kaohsiung Marine University
Kaohsiung, Taiwan, R.O.C.
Abstract
In this paper, we proposed a Multiple-Instance Neural
Network (MINN) for content-based image retrieval (CBIR).
In order to represent the rich content of an image without
precisely image segmentation, the image retrieval problem
is considered as a multiple-instance learning problem. A
set of exemplar images are selected by a user, each of which
is labelled as conceptual related (positive) or conceptual
unrelated (negative) image. Then, the proposed MINN is
trained by using the proposed learning algorithm to learn
the userâ€™s preferred image concept from the positive and
negative examples. Experimental results show that: (1)
without image segmentation and using only the color his-
togram as the image feature, the MINN without relevance
feedback performs slightly inferior to some leading image
retrieval methods, and (2) the MINN with the relevance
feedback can significantly improve the retrieving perfor-
mance from 40.3% to 59.3%, which outperforms to the re-
sults of some leading image retrieval methods.
1 Introduction
The ongoing proliferation of digital content available
over Internet leads to an increasing demand for systems
that can automatically query, search, and retrieve of relevant
images from large content databases and/or digital library.
Over the past decades, a considerable number of studies
have been made on content-based image retrieval (CBIR)
[4, 7, 5, 8, 2].
According to different query methods, image query sys-
tems can be divided into (1) the full automated query, and
(2) the user assistant query. For a full automated query,
global features, such as color histograms, are often used
for image retrieval. These query systems may ignore some
significant local details of sample images, so as to retrieve
some undesired images. On the other hand, the user assis-
tant query systems adopt local features to represent or to
index an image. In these systems, the local features often
obtained from some regions or subimages manually seg-
mented or sketched from an image. Their performance are
heavily dependent on how to precisely segmenting or skill-
ful sketching regions from an image. Instead of emphasiz-
ing on the precise region segmentation, Integrated Region
Matching (IRM) metric [8] is proposed to robust measure
the similarity between regions without requiring accurate
region segmentation. Later, two region-based fuzzy fea-
ture matching approaches [2, 3] are proposed to character-
ize each region with a fuzzy feature set. The user assistant
query systems also involve relevance feedback [9] to narrow
the gap between high-level concepts and low-level features
to improve the hit rate of the retrieval system.
Without precisely image segmentation, the image re-
trieval problem can be considered as a multiple-instance
learning problem, where each image is labelled either a
positive or negative. A positive image contains a set of
instances (subimages) where at least one instance is con-
ceptual to the user. On the other hand, a negative image
contains instances where no one is conceptual to the user.
The multiple-instance learning problem was first appeared
in [1]. Since a label is given to an image instead of each
instance in the image, the labelling of an instance is nei-
ther precisely nor completely. Therefore, the goal of the
multiple-instance learning is to search the â€œconcept areaâ€
which is at the location near to the intersection of the pos-
itive image features and far from the union of the negative
image features in the feature space.
In this paper, a statistical based neural network, called
multiple-instance neural network (MINN), is proposed for
the multiple-instance learning. The paper is organized as
follows. Section 2 presents the proposed MINN. Then, the
MINN based image retrieval system is described in Section
3. The implementation and some experimental results are
presented in Section 4. Concluding remarks are presented
in Section 5.
Proceedings of the First International Conference on Innovative Computing, Information and Control (ICICIC'06)
0-7695-2616-0/06 $20.00  Â© 2006
where f(Xi) =
âˆ‘N
b=1
âˆ‘Nb
t=1 p(xib(t)|Ï‰i) and
p(Î˜ri |Ï‰i, xib(t)) is a posterior probability of the clus-
ter ri in concept class Ï‰i given xib(t).
As to the conditional prior probability Pri , since
the EM algorithm can automatically satisfy the prob-
abilistic constraints
âˆ‘Ri
ri=1
Pri = 1 and Pri â‰¥ 0,
it is applied to update the Pri as follows: Pnewri =
1
N Â·Nb
âˆ‘N
b=1
âˆ‘Nb
t=1 p(Î˜ri |Ï‰i, xib(t).
The threshold value of MINN can also be learned by
the reinforced and anti-reinforced learning rules. An adap-
tive learning rule to train the threshold Ti is proposed as
T
(m+1)
i = T
(m)
i +Î³Î”T
(m)
i , where Î³ is a user defined learn-
ing rate 0 < Î³ â‰¤ 1, and Î”T (m)i is defined as E(m)p âˆ’E(m)n ,
where E(m)p and E(m)n are the misclassified rates of the pos-
itive and negative images in the mth iteration, respectively.
2.3 Retrieving Phase
As shown in Fig.1, an unlabel image is input to the
MINN, then the MINN labels the given image with one or
several matched classes. First, an unlabel image is applied
to all subnets in the MINN. In each subnet, computation
is performed according to the discriminate function. Then
the results are compared with the threshold Ti. Finally, the
ith element of the retrieval result vector V is set to 1 if the
value of the discriminate function is smaller than Ti, which
implies that the given image belongs to the concept class
i. Otherwise, the ith element of the recognition result vec-
tor V is set to 0 if the value of the discriminate function is
larger than Ti, which implies that the given image does not
belong to the concept class i. From the output vector, one
can recall which concept classes the given image belongs
to.
3 Image Representation
According to the concept of the multiple-instance prob-
lem, a set of conceptual images called positive images and
a set of non-conceptual images called negative images are
given. In each image, several instances are extracted. Then,
the MINN is trained to recognize the conceptual image
based on these instance extracted from the given images.
3.1 Instance Extraction
In order to represent the desired images properly, a num-
ber of instances are first selected from each image. Then,
features are extracted from instances. Instances can be se-
lected randomly, but it is not guaranteed that interesting in-
stances would be in these selected instances. Hence manual
selection of instances is suggested in the proposed system.
After deciding where to select an instance from the im-
age, a Gaussian-like mask is adopt to create a masked
image, and the color histogram of the masked image is
calculated. Given a selected point m = (mxi ,myi),
the Gaussian-like mask located at m is Gm(x, y) =
exp
(
âˆ’ 12
[
(xâˆ’mxi )2
Ïƒ2xi
+ (yâˆ’myi )
2
Ïƒ2yi
])
, where Ïƒ2xi and Ïƒ
2
yi are
variances of the Gaussian-like mask.
Suppose images are digitized as 24 bits RGB, mean-
ing that 8 bits or 256 linear levels of brightness for
red, green, and blue components, three histograms cor-
responding to the three color components of the masked
image are combined as a histogram vector h =
[h1, h2, Â· Â· Â· , h256âˆ—3âˆ’1]T . The nth element in h is eval-
uated as h(n) = Î£x,yGm(x, y), {(x, y); Ic(x, y) =
n mod 256}, where Ic(x, y) is the intensity value of the
cth color channel at the position (x, y) in the masked im-
age, and c is the quotient of the division of 256 by n.
3.2 Histogram Approximation
Instead of using color histograms as features of images,
the proposed system used the parameters of mixture density
functions which approximate color histograms of images as
features so as to decrease the dimensions of features and
speeds up the response time of querying. Given a color his-
togram H(n), where 0 â‰¤ n â‰¤ N , which is approximated by
a mixture Gaussian density function P (t), the similarity be-
tween H(n) and P (t) can be defined as their cross-entropyâˆ‘N
n=0âˆ’H(n) lnP (n), where P (n) is sampling from P (t).
The cross-entropy has the minimum value when P (n) is
equalized to H(n), where n = 0, 1, Â· Â· Â·N . In order to ap-
proximate H(n), the EM algorithm is applied to adjust the
parameters of each cluster in P (t). The updating equations
for the parameters in the cluster r of mixture model P (t)
are
Î¼
new
r =
âˆ‘N
n=0 H(n)p
old(Î˜r|n)nâˆ‘N
n=0 H(n)p
old(Î˜r|n)
, (8)
(Ïƒ
new
r )
2
=
âˆ‘N
n=0 H(n)p
old(Î˜r|n)(n âˆ’ Î¼newr )2âˆ‘N
n=0 H(n)p
old(Î˜r|n)
, (9)
P
new
r =
âˆ‘N
n=0 H(n)p
old(Î˜r|n)âˆ‘N
n=0 H(n)
, (10)
where p(Î˜r|n) is a posterior probability of the cluster r
given n.
4 Experiments
In order to evaluate the performance of the MINN based
image retrieval, 10 categories, which are Africa, Beach,
Buildings, Buses, Dinosaurs, Elephants, Flowers, Horses,
Mountains, and Food, of pictures are selected [8] from the
COREL Gallery 1, 000, 000. Each category contains 100
Proceedings of the First International Conference on Innovative Computing, Information and Control (ICICIC'06)
0-7695-2616-0/06 $20.00  Â© 2006
Measurements and Improvements of Conducted Electromagnetic 
Interference Emission Caused by the Switching Circuit 
Yuh-Yih Lu, Zhi-Hua Chen, Chung-Hsiung Yeh, and Hsiang-Cheh Huang*
Department of Electrical Engineering, Minghsin University of Science and Technology 
* National University of Kaohsiung 
1 Hsin-Hsing Rd., Hsin-Fong, Hsin-Chu, Taiwan , R.O.C. , 30401 
Abstract 
In general, the conducted electromagnetic 
interference (EMI) emission exists in most of the 
electronic products and affects the electromagnetic 
environments. In this paper, we design a switching 
circuit to observe and improve the conducted EMI 
emission.  We also discuss the conducted EMI 
effects with putting RC snubber or diode into the 
switching circuit. It is found that the switching 
circuits with RC snubber or diode can reduce the 
conducted EMI effect and accord with the limitations 
of FCC Part 15 Class B and EN 55011 Class B.  
1. Introduction 
The electromagnetic interference problems begin 
to be serious, as electronic products become part of 
our daily lives. EMI not only influences the function 
of circuit itself, but also interferes in the functions of 
other electronic products. The EMI requirements of 
all countries are of importance to manufacturers of 
electronic products [1]. Compliance with the EMI 
requirements is critical to the success of the product 
in the marketplace. Furthermore, the electromagnetic 
interference can be divided into conducted emission 
(CE) and radiated emission (RE). The conventional 
approach is to cure the CE problem by using EMI 
filter that can decrease the noise generated by the 
switching circuit [2]. In addition, a pre-compliance 
test is used since it reduces the cost of 
multi-compliance test and decreases the approval 
time. To search the most effective and economical 
method for reducing EMI phenomena in power 
electronics environment, the concept of how circuits 
generate and are influenced by electromagnetic noise 
should be understood. 
The electromagnetic characteristics of electronic 
products sold on worldwide must meet the mandatory 
requirements. To achieve this goal, low EMI noises 
generated layout, blocking coupling paths and use of 
an EMI filter are used to reduce conducted noises of 
electronic products. This paper studies the EMI 
phenomena based on simple switching circuit. Only 
conducted emission is focused for our study. RC 
snubber and diode are used to reduce conducted EMI 
effects.  
2. Experimental procedures 
The conducted electromagnetic interference 
affects environmental equipments by means of power 
line or signal line. Therefore, the aim of conducted 
EMI test is to measure the noise of electronic circuit 
and require it to be electromagnetically compatible 
with other devices. We use simulation software 
(PSPICE) to modify our design approach. Hence, the 
trial and error processes are reduced and achieve less 
time consuming and inexpensive. The PSPICE 
simulation software is done to observe the transient 
phenomena.
We design the switching circuit with varying the 
inductor load conditions. As shown in Fig. 1, the 
inductor load is in parallel with RC snubber or diode 
[3]. Agilent 54622D Oscilloscopes is used to measure 
the drain-source voltage of MOSFET. Fig.2 shows 
the block diagram of the conducted EMI testing 
system. The conducted EMI of the switching circuit 
(EUT) is measured with Agilent E7401A EMC 
Analyzer, Transient Limiter, Line Impedance 
Stabilization Network (LISN), in the frequency range 
of 0.15MHz to 30MHz [4]. The LISN is used to 
prevent noise external to the test from contaminating 
the measurement and present constant impedance in 
frequency and from site to site to the product 
between phase and ground between neutral and 
ground [5]. The conducted EMI measurement is set 
up referred to the FCC part 15 Class B [6] and EN 
55011 Class B [7] standards. 
Proceedings of the First International Conference on Innovative Computing, Information and Control (ICICIC'06)
0-7695-2616-0/06 $20.00  Â© 2006
(a) Load L1(33Î¼H). 
(b) Load L1 in parallel with RC snubber. 
(c) Load L1 in parallel with diode. 
Figure 4. The waveforms of V1 and the 
simulated results of the drain-source voltage 
(Vds) of the MOSFET. ( Vds: upper waveform, V1: 
lower waveform ) 
Figure 5. Physical diagram of switching 
circuit. 
(a) Load L1(33Î¼H). 
(b) Load L1 in parallel with RC snubber. 
(c) Load L1 in parallel with diode. 
Figure 6. The measured waveforms of V1 and 
the   voltage across the drain-source of the 
MOSFET ( Vds: upper waveform, V1: lower 
waveform ). 
4. Conclusions 
The implemented results show the effect of the 
MOSFET switch to generate the conducted emission. 
Before measuring the conducted EMI, PSPICE 
software is useful to predict the conducted emission. 
The PSPICE simulation can help the engineers to 
understand the cause of noise. In this article, we 
report the experimental results of switching circuit. It 
is found that the measured conducted emission 
decreases with adding diode or suitable RC snubber 
Proceedings of the First International Conference on Innovative Computing, Information and Control (ICICIC'06)
0-7695-2616-0/06 $20.00  Â© 2006
Reversible Data Hiding for 3D Point Cloud Model 
 
 
Hao Luo1,2, Jeng-Shyang Pan2, Zhe-Ming Lu1, Hsiang-Cheh Huang3 
1Harbin Institute of Technology Shenzhen Graduate School, 518055 Shenzhen, P. R. China 
2National Kaohsiung University of Applied Sciences, 807 Kaohsiung, Taiwan 
3National University of Kaohsiung, Taiwan 
luohao723@hotmail.com, jspan@cc.kuas.edu.tw, zhemingl@yahoo.com 
 
 
Abstract 
 
This paper proposes a reversible data hiding 
scheme for 3D point cloud model. It exploits the high 
correlation among neighbor vertices to embed data. It 
starts with creating a set of 8-neighbor vertices 
clusters with randomly selected seed vertices. Then an 
8-point integer DCT is performed on these clusters and 
an efficient highest frequency coefficient modification 
technique is employed to modulate the watermark bit. 
In data extraction, the modified clusters are retrieved 
first, and other operations are the inverse process of 
the data hiding. The original model can be perfectly 
recovered if it is intact. Our scheme is suitable for 
some specific applications where content accuracy of 
the original model must be guaranteed. Moreover, the 
method can be used for 3D point cloud model 
authentication, e.g., hiding a hash sequence.  
 
1. Introduction 
 
Many data hiding techniques on images, audios and 
videos are reported in the literatures. With large 
quantity of three-dimensional (3D) models created and 
transmitted in the Internet, data hiding on 3D models 
receives an increasing interest for applications such as 
copyright protection, content authentication and 
annotation, alteration detection, etc. In recent years, 3D 
point cloud models have gained the status of one of the 
mainstream 3D shape representations. Compared to a 
polygonal mesh representation, a point set 
representation has an advantage of being lightweight to 
store and transmit, due to its lack of connectivity 
information. Nowadays, most existing data hiding 
methods are for 3D mesh models; however, fewer 
approaches for 3D point cloud models are developed.  
As most available data hiding usually introduces 
irreversible degradation to the original medium, it may 
not be acceptable to some applications where content 
accuracy of the original model must be guaranteed, e.g., 
a medical model. Hence there is a need for reversible 
data hiding. In our context, reversibility refers to the 
ability to recover the original model in data extraction. 
Actually, it is advantageous to recover the original 
model from its watermarked version for the distortion 
introduced by the hiding process can be compensated. 
However, till the present time, there has been little 
attention paid to the reversible data hiding techniques 
for 3D point cloud models.  
The main idea of our method is attributed to the 
high correlation among neighboring vertices. It is well 
known that the discrete cosine transform (DCT) 
exhibits high efficiency in energy compaction of 
highly correlated data. For high correlated data, higher 
frequency is associated with smaller amplitude of the 
DCT coefficient in the statistical sense. In most cases, 
the first harmonic coefficient is larger than the last one 
and this fact is the basic principle of our reversible data 
hiding scheme. However, due to the finite 
representation of numbers in the computer, floating-
point DCT is sometimes not reversible and therefore 
not able to guarantee the reversibility of the whole data 
hiding process. In this paper, we employ an 8-point 
integer-to-integer DCT, exhibiting similar energy 
compacting property as the floating-point DCT and 
ensuring the perfect recovery of the original data 
during extraction. First, some vertices clusters are 
chosen as the entry of integer DCT, applying the 8-
point integer DCT on these clusters and an efficient 
highest frequency coefficient modification technique is 
used to modulate the data bit â€œ0â€ or â€œ1â€. After 
modulation, the inverse integer DCT is used to 
transform the modified coefficients into spatial 
coordinates. In data extraction, we need to recreate the 
modified clusters first, and subsequent procedures are 
the inverse process of data hiding. 
The rest of the paper is organized as follows. 
Section 2 reviews the related work on 3D model data 
hiding and watermarking. Section 3 extensively 
describes the proposed method. In Section 4, 
Proceedings of the 2006 International Conference on Intelligent
Information Hiding and Multimedia Signal Processing (IIH-MSP'06)
0-7695-2745-0/06 $20.00  Â© 2006
set of non-repeating seed vertices S={s1,s2,â€¦, sm}. In 
our case, each cluster contains 8 vertices, and 
obviously, the total number of the seeds m must satisfy 
the Formula (1). 
                               
8
nm ï£¯ ï£ºâ‰¤ ï£¯ ï£ºï£° ï£»
                           (1) 
 
 
 
 
 
 
 
 
 
 
 
 
 
Fig. 2 An example of a cluster 
 
Clustering This step aims to select disjoint point 
sets as the target of data hiding. As an example shown 
in Fig. 2, a point cluster consists of a given seed sj 
(1 )j mâ‰¤ â‰¤  and its 7 nearest neighbor vertices N1,N2,â€¦, 
N7, ranking in distance to sj growth. The clustering 
starts from the first seed s1, and 3D Euclidian distances 
are calculated between s1 and the other n-1 vertices. 
Then the nearest 7 vertices corresponding 7 smallest 
distances are chosen, and an 8 vertices cluster 
including the seed is formed. Now move to s2, its 
nearest 7 points can be chosen according to n-9 
distances except the visited points in the first cluster 
are examined. Operations like this are repeated for all 
seeds, and j clusters are created. Generally, suppose dl 
denotes the number of distances of sl need to compute, 
apparently it can be estimated as the Formula (2).  
              8 7 1ld n l l j= âˆ’ + â‰¤ â‰¤ã€€( )                 (2) 
The clusters information must be saved for data 
extraction. In this research, it refers to the indices of 
the vertices of all clusters. A secret key K is used to 
permute the index information. 
Forward Integer DCT To high correlated data, the 
DCTâ€™s energy compacting property results in large 
values of the first harmonics. In our scheme, an 8-point 
integer-to-integer DCT proposed in [10] is employed. 
Once the point cloud model is clustered, we apply 8-
point integer DCT to all clusters. To each cluster, 
coordinates of 8 vertices are input as the following 
order: the seed is the first entry, and input other 
vertices successively as the distance to the seed 
growth. Let us take the example of the Fig. 2, the input 
sequence is sj, N1,N2,â€¦, N7. In this way, 8 DCT 
coefficients, DC and AC1,AC2,â€¦,AC7, can be acquired 
from a cluster.  
Coefficients Modulation Before describing our 
method, we declare that the DCT coefficients symbols 
appeared in the context are all in absolute values. As a 
cluster has x, y and z coordinates, it has three sets of 
DCT coefficients. Here we only take the example of 
coefficients associated to the x-coordinates to 
demonstrate the data embedding and extraction 
process. Operations on the other two sets of 
coefficients are similar.  
We discuss a basic idea first. To 7 AC coefficients 
of a cluster, two distinct parts P1 and P2 are selected, 
where P1 is the range we are looking for the maximum 
and P2 is the modification area. The embedding 
procedure is: As long as a coefficient in P2 is smaller 
than the largest coefficient ACmax in P1, its value is 
doubled and the watermark bit is embedded. For the 
case that a coefficient of P2 is larger than ACmax in P1, 
ACmax is added to the coefficient. The embedding 
process can more formally be written as: 
max
2
max max
2     if   
, where   
      if  
i i
i
i i
AC W AC AC
AC i P
AC AC AC AC
+ â‰¤ï£±
â€² = âˆˆï£²
+ >ï£³
  (3) 
where W denotes the watermark bit, and 
1
max max jj PAC ACâˆˆ= . 
In the retrieving process we check if a coefficient 
out of P2 is larger than 2ACmax and if so, we subtract 
ACmax to get the original coefficient. In the other case 
we know that a doubling has been performed during 
embedding and after reading the watermarking bit the 
coefficient is divided by two to get the original 
coefficient. 
Next, an improved scheme is proposed to further 
increase the capacity. There are also two ranges P1 and 
P2 among AC1 to AC6, instead of among AC1 to AC7 in 
the basic scheme. In the embedding procedure we have 
to first discriminate between a typical and a nontypical 
distribution of the AC coefficients. A typical 
distribution is defined if the highest frequency 
coefficient AC7 is lower than the largest component 
ACmax in P1 and a nontypical one if AC7 is higher than 
ACmax. Depending on the kind of distribution a 
modification of the coefficients of region P2 is 
performed or not. For the case of a typical distribution,  
the coefficients of region P2 are shifted by 1bit or 2bits 
depending on a certain threshold T. That means during 
embedding, all coefficients which are smaller than a 
certain threshold are shifted by 2bits, otherwise a 1bit-
shift is performed. In the retrieving process the three 
cases (nontypical distribution, typical distribution (1 
bit-shift) and typical distribution (2 bit-shift)) are 
distinguished. In other words, we use the highest 
frequency component AC7 to discriminate between the 
three cases.  
js  
N1 
N2 
N4 
N3 
N5 
N7 
N6 
Proceedings of the 2006 International Conference on Intelligent
Information Hiding and Multimedia Signal Processing (IIH-MSP'06)
0-7695-2745-0/06 $20.00  Â© 2006
