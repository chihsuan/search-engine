2 
 
Haar-like scheme [7], which will be performed by the integral image 
block in Figure 1(a). The face features are evaluated by summing the 
pixel values in the rectangular sub-region (shown in Figure 1(b)). 
The result will then be sent to the detection block which uses 
cascaded classifiers to scan and find the location of faces.  
 
Figure 1 (a) Viola-Jones face detection procedure  
    (b) Integral image computation. 
(1) Integral image: The integral image method was firstly 
introduced to the digital image processing by Crow [13]. In 
Viola-Jones face detection, it is used for rapid computation of 
Haar-like features [7], which are defined as the (weighted) intensity 
difference between two to four rectangles. The integral image is 
constructed as follow. I(ğ‘¥,ğ‘¦) =  ï¿½ ğ‘–(ğ‘¥â€²,ğ‘¦â€²)
ğ‘¥â€²â‰¤ğ‘¥,ğ‘¦â‰¤ğ‘¦â€²  
I(x,y) is the integral value of all the image pixels in the 
rectangular region from (0,0) to (x,y). And i(xâ€™,yâ€™) is the value of the 
pixel at location (xâ€™, yâ€™). It is fast and efficient to use the integral 
image to compute the value of the face features in a rectangular 
sub-region area. As shown in Figure 1(b), for example, the value of 
point 4 is the sum of the sub-region area A+B+C+D. The value of 
point 3 is the sum of A+C. If we want to compute the value of the 
region D, it can be easily obtained by the value of ( I(1) + I(4) ) â€“ 
( I(2) + I(3) ), which only requires four value references.  
(2) Cascaded classifier structure with Ada-Boost: Boost is a 
method of finding high accuracy by combing â€œweakâ€ classifiers with 
moderate accuracy [14]. Ada-boost algorithm is a kind of 
appearance-based method which have shown superior performance 
compared to others [9]. There are two types of classifiers, â€œweakâ€ 
classifiers and â€œstrongâ€ classifiers. Weak classifiers have arithmetic 
value thresholds in recording human face features. A number of 
weak classifiers with similar features are combined together as a 
â€œstrongâ€ classifier. 
 
Figure 2 Cascaded structure of strong classifiers 
The cascade classifier structure, shown in Figure 2, is a critical 
component in the Viola-Jones detector. This structure rapidly and 
efficiently rejects most negative sub-window images while keeping 
almost all the positive ones. The input sub-window images pass 
through a series of nodes during detection. Each node represents a 
strong classifier, which would make a decision on whether the 
sub-window image should be kept for the next node or rejected. A 
strong classifier at a later stage contains more weak classifiers to 
provide better image checks and face detection.  
4. PARALLELISM IN DIFFERENT LEVELS 
The parallelism of the face detection exists in different 
algorithmic levels. This section discusses the potential parallelism at 
different levels of the face detection implementation. The face 
detection implementation is adopted and modified from OpenCV 
library[17], which applies the idea of Viola-Jones face detection 
algorithm. As shown Figure 3, the implementation can be divided 
into three parts. (1) Resize. The implementation uses the fixed-size 
scan window with a well-trained classifier library in the Ada-boost 
algorithm. Since the scan window size is fixed, an image needs to be 
resized into different resolutions. (2) Integral. This part performs the 
evaluation of the Haar-like features by using the integral image 
method. (3) Detect. By moving the scan window through the image, 
the sub-image is sent into the cascade classifier structure to detect the 
location of a face.  
 
Figure 3 The procedure of face detection implementation 
The parallelism of the algorithm can be extracted from different 
levels. This paper divides the parallelism into four levels (shown in 
Figure 4). Top level parallelism is demonstrated when different sizes 
of images are processed by different threads concurrently. Detection 
level parallelism can be exposed by performing the â€œdetectâ€ block on 
different sizes of images concurrently. Other parts (resize and 
integral) in the algorithm remain in the sequential scheme. Divided 
detection level is similar to the detection level, but the image is 
further divided into sub-images. The detection tasks of these 
sub-images are executed simultaneously by different threads. Weak 
classifier level exposes the parallelism by executing different weak 
classifiers in the cascaded structure concurrently. 
 
Figure 4 Different algorithmic levels of the face detection 
implementation 
4 
 
(2) Detection level parallelism. This level only parallelizes the 
detection block. The other parts, including the thread creation, are 
still executed sequentially. This strategy makes the speed of creating 
new threads too slow to sustain the demand of parallel execution. 
Processors are idled waiting for new threads to be created. Besides, 
the sequential part of the algorithm becomes the critical part of the 
program. The performance would not improve when the number 
processors increases. As shown in Figure8, the execution time does 
not improve when the system has more than 8 processors. 
(3) Divided detection level parallelism. This level returns a 
more satisfied result than the previous strategy. More parallelism of 
detection level can be extracted. Number of threads created in one 
time is sufficient and the size of different threads is more balanced. 
However, the sequential part is still plays the critical role in the 
program. Therefore the run time is similar to the detection level.  
(4) Weak classifier level parallelism. This is the lowest level in 
the algorithm. The number of threads is equal to the number of weak 
classifiers. Although it exposes the maximum potential parallelism, 
the overhead becomes the limiting factor of the performance 
enhancement. Since there could be thousands of weak classifiers, the 
time required to create these threads is already in average 8.17x of 
the total execution time of the sequential algorithm on a single 
processor. Another overhead is the sheer amount of synchronization 
transactions among the huge number of threads. 
 
Figure 8 Result of each parallelism level 
According to the experimental result, parallelizing the algorithm 
in higher levels poses the disadvantage of imbalance workload. 
When parallelizing the algorithm in lower levels, the overhead 
increases on the aspects of creating new threads and synchronization. 
The ratio of the sequential part to the algorithm also deteriorates the 
performance. To achieve the best performance, we should have a 
scheme to expose the significant parallelism in an appropriate level 
and avoid the overhead of having too many threads. 
 
7. A HYBRID PARALLEL SCHEME TO ACHIEVE 
HIGH PERFORMANCE 
Based on the experience from the previous section, we propose a 
multi-stages mixed-level parallelism scheme to achieve the 
maximum performance enhancement.  
 
Figure 9 Result of our modified programs 
The first implementation is a 2-stage scheme. Stages are executed 
sequentially. The second stage will start when the first stage is 
finished. The first stage will initiate multiple threads to perform the 
resize and integral blocks concurrently. The second stage implements 
the same scheme as in the â€œdivided detectionâ€ level. Since the block 
â€œdetectionâ€ takes most of the execution time in the algorithm and its 
parallelism can be well scaled in divided detection level. As shown 
in Figure9, when compared with a single processor, the 2-stage 
strategy can reach around 16x speed-up on a 16-core system. 
However, the 2-stage scheme cannot achieve better performance 
when the processor number is more than 16, due to the imbalanced 
work load in the first stage. 
The 3-stage scheme is implemented to further improve the 
performance. The first stage now only contains a multi-threaded 
version of the resize block. The second stage will process the integral 
part and the third stage will perform the parallel execution of the 
detection block. This scheme has better balanced tasks, and achieve 
the superior performance scalability. As shown in Figure9, the 
3-stage parallel strategy reaches a 27.8x and 37.5x speed-up on a 
32-core and 64-core system respectively. 
8. CONCLUSION                                                                                                         
This paper performs a comprehensive analysis of the parallelism 
of a face detection algorithm at different levels. We have 
demonstrated that, each parallelism level has its own potential to 
enhance performance, but also imposes different limiting factors to 
the overall performance. The imbalanced execution loads among 
threads adversely impact the performance as well. Based on the 
analysis results and design experience, this paper proposes a 
multi-staged hybrid scheme to retain the parallel performance and 
avoid the limiting factor. With this scheme, we are able to achieve up 
to 37.5x performance enhancement on a 64-core system.  
9.  REFERENCES 
[1] FA626 ULTRA HIGH SPEED 32-BIT RISCCPU 
http://www.faraday-tech.com/techDocument/FA626_ProdBrief_v1.2.pdf 
[2] The TILE-Gxâ„¢ processor family processor, http://www.tilera.com/  
[3] ARM cortex-A9 processor, http://www.arm.com/ 
[4] MIPS Technologies Announces Symmetric Multiprocessing (SMP) 
Support for Androidâ„¢ Platform on MIPS-Basedâ„¢ SoCs, 
http://www.mips.com/  
[5] Intel multicore technology, http://www.intel.com/ 
[6] AMD multi-core processing, http://www.amd.com/  
[7] C. Zhang and Z. Y. Zhang, â€œA Survey of Recent Advances in Face 
Detection â€, Microsoft Research, June 2010.  
[8] Y. Wei, X. Bing, C. Chareonsak, "FPGA Implementation of AdaBoost 
Algorithm for Detection of Face Biometrics", In Proc. IEEE International 
Workshop Biomedical Circuits and Systems, 2004. 
1 2 4 8 16 32 64
2stage 3.02 1.494 0.754 0.381 0.203 0.185 0.193
3stage 3.016 1.484 0.744 0.376 0.194 0.108 0.081
0
0.5
1
1.5
2
2.5
3
3.5
Execute Time
CORE_NUM
time(sec)
(sec/image)
 1 
åœ‹ç§‘æœƒè£œåŠ©å°ˆé¡Œç ”ç©¶è¨ˆç•«é …ä¸‹å‡ºå¸­åœ‹éš›å­¸è¡“æœƒè­°å¿ƒå¾—å ±å‘Š 
                                     æ—¥æœŸï¼š100 å¹´ 1 æœˆ 30 æ—¥ 
                                 
ä¸€ã€åƒåŠ æœƒè­°ç¶“é 
æ­¤æ¬¡æœƒè­°æ–¼åŠ å·æ´›æ‰ç£¯é™„è¿‘çš„å®‰ç´ç½•åŸå¸‚èˆ‰è¾¦ã€‚ç¸½å…±å…­å¤©çš„æœƒè­°ä¸­åŒ…å«äº†ä¸€ç™¾
å¤šç¯‡çš„ç ”ç©¶è«–æ–‡å ±å‘Šä»¥åŠè¨è«–ã€‚åœ¨ä¸€æ¨“çš„å±•ç¤ºå¤§å»³ä¸­ä¹Ÿæœ‰è¶…éç™¾å®¶çš„è¨­è¨ˆè‡ªå‹•åŒ–
å¤§å» åƒå±•ã€‚æ•´å€‹æœƒè­°å…§å®¹èˆ‡è­°ç¨‹çš„å®‰æ’éå¸¸çš„è±å¯Œã€‚ 
åœ¨è«–æ–‡å ±å‘Šèˆ‡ç ”è¨çš„éƒ¨åˆ†ï¼Œæ‰€æœ‰çš„ç ”ç©¶è«–æ–‡è¢«åˆ†æˆè¶…éäº”åå€‹è­°é¡Œï¼Œåˆ†åˆ¥æ–¼å››
å¤©çš„è­°ç¨‹ä¸­é€²è¡Œå ±å‘Šèˆ‡ç ”è¨ã€‚åœ¨æœ¬å¹´åº¦çš„è¨­è¨ˆè‡ªå‹•åŒ–æœƒè­°ä¸­ï¼Œå…ˆé€²è£½ç¨‹çš„è®Šç•°æ€§
èˆ‡é›»è·¯çš„å¯é æ€§æˆç‚ºè¨±å¤šè­°é¡Œä¸­çš„è¨è«–é‡é»ã€‚å¦‚ä½•åœ¨åŠå°é«”è£½ç¨‹æŒçºŒå¾®ç¸®åŒ–çš„é
ç¨‹ä¸­ç¶­æŒç³»çµ±çš„åŠŸèƒ½æ€§èˆ‡æå‡å¯é åº¦ï¼Œä»èˆŠæ˜¯ä¸€å€‹éå¸¸é›£çš„å•é¡Œã€‚åƒèˆ‡å ±å‘Šçš„é™¤
äº†ä¸–ç•Œå„åœ°ä¸€æµçš„é ‚å°–å¤§å­¸ä¹‹å¤–ï¼Œä¹ŸåŒ…å«äº†å¾ˆå¤šæ¥­ç•Œçš„ç ”ç©¶æˆæœã€‚é€™è®“è­°é¡Œçš„è¨
è«–ä¸æœƒåªä¾·é™åœ¨ç ”ç©¶é¡Œç›®çš„æ¢è¨ä¸­ï¼Œè€Œèƒ½å¤ è·Ÿæ¥­ç•Œç›®å‰æœ€éœ€è¦è§£æ±ºçš„å›°é›£ç›¸çµ
åˆï¼Œä»¥æœŸå¾…èƒ½å¤ ç™¼å±•å‡ºæ›´ç¬¦åˆç›®å‰éœ€æ±‚çš„ç›¸é—œè¨­è¨ˆè‡ªå‹•åŒ–æŠ€è¡“ã€‚ 
åœ¨ä¸€æ¨“çš„å±•è¦½æœƒå ´ä¸­ï¼Œæœ‰è¶…éæ•¸ç™¾å®¶çš„å» å•†åƒå±•ã€‚åƒå±•çš„å» å•†é™¤äº†è¨­è¨ˆè‡ªå‹•åŒ–
å·¥å…·çš„ä¸€ç·šå¤§å» (å¦‚ Cadence, Synopsys, Mentor ç­‰)ä¹‹å¤–ï¼Œä¹ŸåŒ…å«äº†è¨±å¤šå…·æœ‰å…ˆ
é€²æŠ€è¡“çš„æ–°æˆç«‹å» å•†ã€‚æœƒå ´çš„ä½ˆç½®å’Œå„å€‹å» å•†æ”¤ä½æ´»å‹•çš„å®‰æ’ä¹Ÿååˆ†çš„æ´»æ½‘ï¼Œåœ¨
ä»‹ç´¹å…¬å¸çš„æ–°æŠ€è¡“ä¹‹å‰éƒ½æœƒåˆ©ç”¨è¨±å¤šä¸åŒçš„è¡¨æ¼”ä¾†å¸å¼•äººæ½®ã€‚å€¼å¾—ä¸€æçš„æ˜¯ï¼Œä»Š
å¹´çš„åƒå±•å» å•†ä¸­ï¼Œå°ç©é›»çš„æ”¤ä½å äº†éå¸¸å¤§å€åŸŸã€‚å°ç©é›»ä»Šå¹´ç‰¹åˆ¥å¼·æ‰“æ‰€æå‡ºçš„
æ•´åˆæ€§è¨­è¨ˆç’°å¢ƒ (Open Innovation Platform)ï¼Œå¸Œæœ›è®“æ™¶åœ“ä»£å·¥å» ä¸èƒ½å†å–®ç´”æ
ä¾›è£½é€ æœå‹™ã€‚å°ç©é›»å°‡æ•´åˆæœ¬èº«åŠç¬¬ä¸‰è€…çš„è¨­è¨ˆå·¥å…· EDAé›»å­è¨­è¨ˆè‡ªå‹•åŒ–
ï¼ˆElectronic Design Automationï¼‰åŠçŸ½æ™ºè²¡ï¼ˆIPï¼‰ã€è£½ç¨‹æŠ€è¡“åŠæµç¨‹æœå‹™ç­‰ï¼Œæ¨
è¨ˆç•«ç·¨è™Ÿ NSC 98ï¼ 2218 ï¼E ï¼009  ï¼ 022 ï¼ 
è¨ˆç•«åç¨± å¤šæ ¸å¿ƒç³»çµ±ä¹‹è·¨å±¤ç´šæ•´åˆè¨­è¨ˆç’°å¢ƒåŠæ–¹æ³• 
å‡ºåœ‹äººå“¡
å§“å 
è³´ä¼¯æ‰¿ 
æœå‹™æ©Ÿæ§‹
åŠè·ç¨± 
äº¤é€šå¤§å­¸é›»å­å·¥ç¨‹ç³»åŠ©ç†æ•™æˆ 
æœƒè­°æ™‚é–“ 
99å¹´ 6æœˆ 13æ—¥è‡³ 
99å¹´ 6æœˆ 18æ—¥ 
æœƒè­°åœ°é» 
Anaheim, CA, U.S.A 
æœƒè­°åç¨± 
(ä¸­æ–‡) 2010 è¨ˆç®—æ©Ÿå™¨å­¸æœƒè¨­è¨ˆè‡ªå‹•åŒ–åœ‹éš›æœƒè­° 
(è‹±æ–‡) ACM Design Automation Conference 2010 
ç™¼è¡¨è«–æ–‡
é¡Œç›® 
(ä¸­æ–‡)ç„¡ 
(è‹±æ–‡) 
åœ‹ç§‘æœƒè£œåŠ©è¨ˆç•«è¡ç”Ÿç ”ç™¼æˆæœæ¨å»£è³‡æ–™è¡¨
æ—¥æœŸ:2011/01/26
åœ‹ç§‘æœƒè£œåŠ©è¨ˆç•«
è¨ˆç•«åç¨±: å¤šæ ¸å¿ƒç³»çµ±ä¹‹è·¨å±¤ç´šæ•´åˆè¨­è¨ˆç’°å¢ƒåŠæ–¹æ³•
è¨ˆç•«ä¸»æŒäºº: è³´ä¼¯æ‰¿
è¨ˆç•«ç·¨è™Ÿ: 98-2218-E-009-022- å­¸é–€é ˜åŸŸ: ç©é«”é›»è·¯åŠç³»çµ±è¨­è¨ˆ
ç„¡ç ”ç™¼æˆæœæ¨å»£è³‡æ–™
å…¶ä»–æˆæœ 
(ç„¡æ³•ä»¥ï¥¾åŒ–è¡¨é”ä¹‹æˆ
æœå¦‚è¾¦ï§¤å­¸è¡“æ´»å‹•ã€ç²
å¾—çé …ã€é‡è¦åœ‹éš›åˆ
ä½œã€ç ”ç©¶æˆæœåœ‹éš›å½±éŸ¿
ï¦ŠåŠå…¶ä»–å”åŠ©ç”¢æ¥­æŠ€
è¡“ç™¼å±•ä¹‹å…·é«”æ•ˆï¨—äº‹
é …ç­‰ï¼Œè«‹ä»¥æ–‡å­—æ•˜è¿°å¡«
ï¦œã€‚) 
ç„¡ 
 æˆæœé …ç›® ï¥¾åŒ– åç¨±æˆ–å…§å®¹æ€§è³ªç°¡è¿° 
æ¸¬é©—å·¥å…·(å«è³ªæ€§èˆ‡ï¥¾æ€§) 0  
èª²ç¨‹/æ¨¡çµ„ 0  
é›»è…¦åŠç¶²ï¤·ç³»çµ±æˆ–å·¥å…· 0  
æ•™æ 0  
èˆ‰è¾¦ä¹‹æ´»å‹•/ç«¶è³½ 0  
ç ”è¨æœƒ/å·¥ä½œåŠ 0  
é›»å­å ±ã€ç¶²ç«™ 0  
ç§‘ 
æ•™ 
è™• 
è¨ˆ 
ç•« 
åŠ  
å¡« 
é … 
ç›® è¨ˆç•«æˆæœæ¨å»£ä¹‹ï¥«èˆ‡ï¼ˆé–±è½ï¼‰äººï¥© 0  
