The traditional anamorphosis is divided into 
two types [1-3] perspective and mirror. 
Perspective anamorphosis defines a specific 
viewing point to view the distorted image. A 
classic example of Julian Beeverâ€™s work [4] is 
shown in Fig. 1. Mirror anamorphosis is 
painted as a distorted image in the plane and 
one can see the true image by the common 
shape of the cone tube (conical) or the 
columnar (cylindrical) reflector. The cylindrical 
case of mirror anamorphosis is demonstrated in 
Fig. 2. 
The perspective anamorphosis can provide 
3-D visual effect and doesnâ€™t need extra 
devices. There has been some related research. 
Kent [1] provided two common anamorphic 
videos including rich content. Hunt et al. [2] 
introduced three kinds of common anamorphic: 
flat, conical, and cylindrical. Hansford and 
Collins [3] demonstrated how to make a 3D 
object with anamorphic characteristics. 
Although the perspective anamorphosis has 
been discussed for a long time, there is no 
further extension on other issues. This project 
will reduce restrictions over the traditional 
anamorphosis and adds the new feature.  
This project will use a two-plane 
projection surface to overcome the problem in 
space. The traditional perspective 
anamorphosis is limited to displaying only the 
static content. This project will add the function 
of showing dynamic content by the projector so 
that we can obtain a more rich and diverse 3-D 
visual effect. We will design a viewer tracking 
mechanism to locate the viewerâ€™s position and 
to project the proper pattern on the projection 
surface. 
According to the new concept and design 
in our research, the perspective anamorphosis 
projection methods can be characterized by the 
types of the display content and the viewerâ€™s 
actions. The types of the display content 
projected by the projector can be divided into 
the static image and the dynamic video. The 
action of the viewer is fixed or movable. On the 
whole, the proposed projection-based 
anamorphic imaging system includes the 
following characteristics:  
(i) The displayed content can be the static or 
the dynamic types.  
(ii) The system allows the viewer to change his 
viewing position.  
(iii) The displayed content can be replaced 
quickly.  
3. The Plane Projective Transformation 
This work adopts the World Coordinate 
System (WCS), which is a right-handed 3D 
Euclidean coordinate system in 3D space. The 
three coordinate axes are given by XW, YW, and 
ZW. The camera is modeled as a pinhole camera, 
and defined by another coordinate system, 
called the Camera Coordinate System (CCS) 
whose three coordinate axes are given by XH, 
YH, and ZH. The origin H of CCS is the center 
of projection (COP) of the camera, and ZH is 
superimposed with the optical axis. We will 
employ the CCS to simulate the viewer so that 
the optical axis is the line of sight and H the 
location of the head. Additionally, the image of 
the camera is a plane expressed with a 2D 
coordinate system called the Image Coordinate 
System (ICS), defined with axes U and V. The 
normal vector of image plane parallels to ZH of 
the CCS and passes through the center of image 
plane. The axes U and V are parallel to XH and 
YH, respectively. The distance between the 
image plane and COP is the focal length f.  
Assume the projective plane is the XW-YW 
plane. The point PW(XWP, YWP, 0)WCS is thus on 
the projection plane. From (1), the 
corresponding point of PW on the image plane 
is p(u, v)ICS and can be described as 
' ' ' '
11 12 13 14 11 12 13
' ' ' '
21 22 23 24 21 22 23
' ' ' '
31 32 3331 32 33 34
 
0
 1  1
1
W
W W
W
W W
Xh h h h X Xwu h h h
Y
wv h h h h h h h Y H Y
w h h hh h h h
ïƒ© ïƒ¹ïƒ© ïƒ¹ ïƒ© ïƒ¹ ïƒ© ïƒ¹ïƒ© ïƒ¹ ïƒ© ïƒ¹ïƒª ïƒºïƒª ïƒº ïƒª ïƒº ïƒª ïƒºïƒª ïƒº ïƒª ïƒºïƒª ïƒºï€½ ï‚º ï‚ºïƒª ïƒº ïƒª ïƒº ïƒª ïƒºïƒª ïƒº ïƒª ïƒºïƒª ïƒºïƒª ïƒº ïƒª ïƒº ïƒª ïƒºïƒª ïƒº ïƒª ïƒºïƒª ïƒºïƒ« ïƒ» ïƒ« ïƒ»ïƒ« ïƒ» ïƒ« ïƒ»ïƒ« ïƒ» ïƒ« ïƒ»
ã€€ ã€€ ã€€
ã€€ ã€€ ã€€
ã€€ã€€ ã€€ã€€ã€€ ã€€ ã€€
 (1) 
where w is a scale factor and H is a 3ï‚´3 
homographic matrix. The coordinate of p is 
given by 
4. Geometry Calibration 
In this project, we employ a camera to 
simulate the viewerâ€™s eye which views the 
image on the projective plane. A series of plane 
projections is performed in the following steps: 
(i) Generating the viewing image: the 3-D 
model is projected on the image plane 
that represents the real viewing matter 
for the viewer. 
(ii) Generating the projected image: the 
viewing image is projected on the 
projective plane that simulates the true 
pattern on the projective planes. 
(iii) Generating the input image: the 
projective planes are back-projected to 
the input image of the projector. 
4.1 Generating the Viewing Image  
For providing a realistic 3-D visual effect, 
the 3-D model of the displayed object is 
established first. According to the viewing 
configuration, the object is placed on the front 
of the projective plane and a virtual camera 
located at H takes the image of the virtual 
object. This image represents the viewing result 
of the viewer at H. The viewing image of the 
projected 3-D model is generated by (14). Two 
typical viewing images are shown in Fig. 4. 
4.2 Generating the Projected Image  
For indicating the projection result from 
the projector, the corresponding projection may 
generate the same visual effect that has to be 
made when the viewer views the projective 
plane. Since the viewing image generated in 3.1 
can be regarded as the projection of the 
projected image at H,   the back-projection 
method from the viewing image to the 
projected image on the projective plane is 
designed. Because the projective surface is 
composed of two orthogonal planes, the planes 
have different projective transformation and 
will be processed individually. A set of six 
distinct activities is designed as the flowchart 
shown in Fig. 5.  
4.2.1 Planes segmentation 
In our experiments, two orthogonal planes 
consist of the projective surface. For estimating 
their planar geometric transformation with the 
viewing image, four corresponding features are 
necessary as anchors to calculate the 
homographic matrix. Since the projective plane 
is rectangular, their region and four corners will 
be extracted first.  When the projector shows a 
high intensity image to indicate the projection 
area, two rectangles, denoted as PR1 and PR2, 
on the projective surface are imaged in the 
calibration image by the camera that simulates 
the viewer. We can extract corners formed by 
the rectangle in the calibration image and build 
the corresponding relationship between the 
projective plane and the viewing image. 
In general, the corners can be obtained 
directly with corner detection methods [6-7]. 
However, this method is not sufficiently 
accurate [8]. This work first applies the Hough 
transform [9-10] to find the edge of the 
rectangle, and then computes the coordinates of 
the intersection points defined by the edge lines 
bordering the projection region. The Hough 
transform is an intensive operation, but is only 
applied in the off-line planar homographic 
calculation, and thus does not affect the overall 
efficiency. Following the Hough transform, 
four lines are extracted from the Hough space. 
The corners are the points where the extracted 
lines intersect with the edge lines.  
Two adjacent projective planes will be 
defined by six lines and six corners illustrated 
in Fig. 6. Based on the values of two 
parameters (ï², ï±), a set of simple rules can be 
applied to identify the boundary lines and to 
assign the proper symbol to the corner. For 
projective planes PP1 and PP2, their 
appearances in the calibration image are 
formed by C1:{c1, c2, c3, c4} and C2:{c3, c4, c5, 
c6}, respectively.  
4.2.2 Planar geometric transformation 
Assume that two sets of points S1:{s1, s2, s3, 
s4} and S2:{s3, s4, s5, s6} are applied to define 
the projection rectangles PR1 and PR2, 
respectively. Following the projective 
configuration, the sets C1 and S1 can define the 
planar geometric transformation of PP1 and 
PR1. Using (5), we obtain 
HS1 = C-1(S1, C1) D(C1)  (15) 
In the same way, the planar geometric 
transformation of PP2 and PR2 is  
HS2 = C-1(S2, C2) D(C2).   (16) 
size 1600ï‚´1200 and the projector BenQ MP770 
shown in Fig. 8. 
6.1 The fixed viewer  
In the case of the viewer at the fixed 
position, the projected content can be static or 
dynamic.  The viewing image is made first 
and the input image for projecting by the 
projector is shown in Fig. 9(b). The display 
result is demonstrated in Fig. 9(c) that presents 
a proper 3-D object on the plane. 
6.2 The Brightness Calibration 
Before projecting the input image from 
the projector, the image will adjusted by the 
result of brightness calibration. The process 
makes the perspective anamorphosis more clear 
than is shown in Fig. 10. 
6.3 The movable viewer 
The major feature of the proposed method 
is that the viewer is allowed to move. The 
projection will follow the position of the viewer 
to change the display content.  The projections 
for different viewing positions are 
demonstrated in Fig. 11.  
7. Conclusions 
We have described the method for 
generating static and dynamic perspective 
anamorphosis based on the projection geometry. 
The perspective anamorphosis by our system 
has more characteristics than the traditional 
perspective anamorphosis: (i) The displayed 
content can be the static or the dynamic types, 
(ii) The system allows the viewer to change the 
viewing position, and (iii) The displayed 
content can be replaced quickly. The 
experimental results show the proposed system 
can provide the high quality 3-D display.  
8. Contributions 
(i) For academic:  
(a) A novel projection-based anamorphic 
imaging system is proposed and only 
employs simple hardware such as the 
projector, PC, and the camera. (b) The 
system can show the static or the dynamic 
content. (c) The system still can be worked 
well if the viewer to change the viewing 
position. (d) Two conference papers have 
been accepted and now are prepared to 
submit the international journal. 
(ii) For society: 
(a) It reveals the other way for 3-D display. 
(b) The system can be applied on the 3-D 
display in the advertisement, museums, art 
galleries, and exhibition. (c) To cultivate two 
graduate students for 3-D display industry. 
 REFERENCES 
[1] Kent,P. : Art of anamorphosis. http://www. 
anamorphosis.com, January 2006. 
[2] J. L. Hunt, B. G. Nickel, and C. Gigault, 
â€œAnamorphic images,â€ American Journal 
of Physics, Vol. 68, Issue 3, pp. 232-237, 
March 2000. 
[3] D. Hansford and D. Collins, â€œAnamorphic 
3D geometry,â€ Computing, Vol. 79, No. 
2-4, pp. 211-223, April 2007. 
[4]  Julian Beever: Pavement drawings 
http://users.skynet.be/J.Beever/pave.htm, 
Jane,2009. 
[5] A. Griminisi, Accurate visual metrology 
from single and multiple uncalibrated 
images, Springer, 2001. 
[6] H. Wang and M. Brady, â€œReal-time corner 
detection algorithm for motion estimation,â€ 
Image and Vision Computing, vol. 13, no. 
9, pp. 695-703, Nov. 1995. 
[7] V. Torre and T. Poggio, â€œOn edge 
detection,â€ IEEE Transactions on Pattern 
Analysis and Machine Intelligence, vol. 8, 
no. 2, pp.147-163, March 1986. 
[8] C. H. Huang and T. L. Chia, â€œA fast 
method for virtual advertising based on 
geometric invariant-A tennis match case,â€ 
in Proceeding 2001 Conference on 
Computer Vision, Graphics, and Image 
Processing, 19-21 Aug. 2001. 
[9] R. C. Gonzalez, P. Wintz, and S. L. Eddins, 
Digital Image Processing using MATLAB, 
Addision-Wesley Publishing Company, 
2002. 
          (a
Fig. 6: Lin
extracted li
Fig.7
P
F
)        
es and cor
nes and (b)
: The total 
Camera 
rojector 
Fig. 8: 
ig. 5: Proce
         
ners extrac
six extract
planar geom
The perspe
dure for gen
       (b
tion using
ed corners.
etric trans
ctive anam
erating the
) 
Hough tran
formation.
orphosis pr
 projected 
sformation
Two
proj
ojection 
image.
: (a) six 
-plane 
ection 
åœ‹ç§‘æœƒè£œåŠ©å°ˆé¡Œç ”ç©¶è¨ˆç•«é …ä¸‹å‡ºå¸­åœ‹éš›å­¸è¡“æœƒè­°å¿ƒå¾—å ±å‘Š 
                           
æ—¥æœŸï¼š100 ï¦ 9 æœˆ 01 æ—¥ 
ä¸€ã€ ï¥«åŠ æœƒè­°ç¶“é 
ç¬¬äº”å±†è¤‡é›œæ™ºèƒ½å’Œè»Ÿä»¶å¯†é›†ç³»çµ±åœ‹éš›ç ”è¨æœƒ(The Fifth 
International Conference on Complex, Intelligent, and 
Software Intensive Systems)èˆ‰è¾¦æ–¼éŸ“åœ‹é¦–çˆ¾çš„ Korean 
Bible å¤§å­¸ï¼Œæ­ä¹˜ 6 æœˆ 29 æ—¥ä¸‹åˆ 5é»çš„é£›æ©Ÿé£›å¾€éŸ“åœ‹ï¼Œæ–¼
éŸ“åœ‹æ™‚é–“ 6 æœˆ 29 æ—¥æ™šä¸Š 8é»åˆ°ä»å·åœ‹éš›æ©Ÿå ´ï¼Œéš”å¤©å‰å¾€æœƒ
è­°å ´æ‰€è¾¦ï§¤å ±åˆ°æ‰‹çºŒï¼Œè¾¦å®Œå ±åˆ°æ‰‹çºŒå¾Œï¼Œå¤§æœƒçµ¦æˆ‘å€‘æ¯äººä¸€
ä»½ï¨ç¾ï¦¶ç‰©ï¼Œä¸¦æä¾›èˆ’é©çš„ç’°å¢ƒä¾›æˆ‘å€‘ä¼‘æ¯ï¼Œæˆ‘çš„å ±å‘Šå ´æ¬¡
ç‚ºW-IIBM-S3: IIBM-3ï¼ŒéŸ“åœ‹æ™‚é–“6æœˆ30æ—¥ä¸‹åˆ4:00è‡³5:30
ä¸Šå°é€²ï¨ˆå£é ­å ±å‘Šï¼ŒSession Chairsç‚ºDr. Chen-Kuei Yang, 
Ming ChuanUniversity, Taiwanï¼Œå ±å‘Šéç¨‹ååˆ†ç·Šå¼µï¼Œä¹Ÿè¢«
è½çœ¾å•ï¦ºå¹¾å€‹å•é¡Œï¼Œå ±å‘Šéç¨‹æ•´é«”ï¤­è¬›é‚„ç®—é †ï§ï¼Œæœƒè­°æœŸé–“
ä¹Ÿè½ï¦ºå„å€‹ï¤´å¸«åŠç¢©åšå£«ç”Ÿçš„å„ç¨®ï¥§åŒç ”ç©¶çš„å…§å®¹ï¼Œå—ï¨—ï¥¼
è¨ˆç•«ç·¨è™Ÿ NSC 99ï¼2221ï¼Eï¼130ï¼020ï¼ 
è¨ˆç•«åç¨± é«˜å“è³ªå‹•æ…‹è™›æ“¬ï§·é«”å½±åƒæŠ•å½±ç”¢ç”Ÿä¹‹ç ”ç©¶ 
å‡ºåœ‹äººå“¡
å§“å é»ƒç­‘å¦˜ 
æœå‹™æ©Ÿæ§‹
åŠè·ç¨± 
åœ‹ï§·è‡ºç£æµ·æ´‹å¤§å­¸ 
 â– ç¢©å£«ç­ç ”ç©¶ç”Ÿ 
æœƒè­°æ™‚é–“ 
100 ï¦ 6 æœˆ 30 æ—¥
è‡³ 
100 ï¦ 7 æœˆ 2 æ—¥ 
æœƒè­°åœ°é» 
éŸ“åœ‹é¦–çˆ¾ Korean 
Bible å¤§å­¸ 
æœƒè­°åç¨± 
(ä¸­æ–‡)ç¬¬äº”å±†è¤‡é›œæ™ºèƒ½å’Œè»Ÿä»¶å¯†é›†ç³»çµ±åœ‹éš›ç ”è¨æœƒ 
(è‹±æ–‡) The Fifth International Conference on Complex, 
Intelligent, and Software Intensive Systems 
ç™¼è¡¨ï¥æ–‡
é¡Œç›® 
(ä¸­æ–‡)æ‡‰ç”¨æ¼”åŒ–æ˜¯ç‰¹å¾µæ–¼ Bæ¨¡å‹è¶…éŸ³æ³¢å½±åƒè™•ï§¤ä¹‹è‡ª
å‹•åŒ–è‚è‡Ÿç–¾ç—…è¨ºæ–· 
(è‹±æ–‡) Evolutionary Feature Construction for Ultrasound 
Image Processing and Its Application to Automatic Liver 
Disease Diagnosis 
URL:http://www.ieeeconfpublishing.org/cpir/AuthorKit.asp?Community=CPS&Facil
ity=CPS_June&ERoom=CISIS+2011The proceedings of workshops will be published 
together with CISIS-2011 (in the same proceedings). The Camera Paper deadline in 
the author kit is March 11, 2011.  The registration system is in the following 
URL:https://www.ilcc.com/cisis_imis/ The registration system will be open after 
February 15, 2011. Please be aware that each accepted paper requires a full 
registration.  Other needed information can be found in CISIS-2011 
URL:http://www.takilab.org/conf/cisis/2011/Please note that any delay may prevent 
the inclusion of your paper in the proceedings.   
 
Best regards,  
IIBM 2011 chairs 
 
å…«ã€ï¥æ–‡åŸç¨¿ 
 
for feature extraction is either through manual assessment or 
object segmentation. Automatic selection of effective ROIs 
without image segmentation is an important task for medical 
diagnosis as the shapes of anatomical structures of interest in 
captured ultrasound images are often vague. However, to our 
best knowledge, little work focused on this issue. In contrast, 
in this paper, the self organization properties of genetic 
algorithms are employed to tackle the problem of ROIs 
selection. In the training phase, for each class, the parameters 
to generate effective ROIs are then learned and stored back 
to the database. In the classification phase, the ROIs and then 
their features are extracted from the input image based on 
these parameters. The extracted features provide several 
advantages over other feature extraction techniques which 
include: automatically construct feature set and tune their 
parameters, ability to integrate multiple feature sets to 
improve the diagnosis accuracy, and ability to find local 
ROIs and integrate their local features into effective global 
features. As compared with past approaches, we span a new 
way to unify the processing steps in a clinical application 
using the evolutionary optimization algorithms for 
ultrasound images. Experimental results show the 
effectiveness of the proposed method. 
II. OPTIMIZING ROI SELCTION USING GENETIC
ALGORITHM
SVM Classification
Ranking and 
Diagnosis decision
Classification Phase
Database Image D
Feature Construction
Preprocessing
ROIs Selection
SVM Classifiers
&
Parameters
Preprocessing
ROIs  SelectionParameters
Feature Construction
Training Phase
Fitness Computation 
by Classification Clinical
Information
Optimization by GA
Classifiers
Query Image Q
Figure 1. Block diagram of the proposed ultrasound image 
interpretation system. 
The genetic algorithm (GA) [14] uses a meta-heuristic 
approach for solving hard combinatorial optimization 
problems. The idea of GAs came from an analog to 
biological evolution, in which provides an approach to 
learning. GAs represent hypotheses as chromosomes 
described by bit strings or symbolic expression. Rather than 
search from general-to-specific hypotheses, or from simple-
to-complex, GAs generate an appropriate hypothesis by 
repeatedly mutating and recombining parts of the best 
currently known hypotheses. The search process begins with 
a population, or collection, of initial hypotheses. At each 
iteration, members of current population are evaluated 
relative to a given measure of fitness. The hypotheses of 
most fitness are selected probabilistically as seeds for 
producing the next generation. The process forms a 
generate-and-test beam-search of hypotheses, in which 
variants of the best current hypotheses are most likely to be 
considered next. A threshold defining an acceptable level of 
fitness for terminating the algorithm is used to stop the 
algorithm. Finally, GAs return the hypothesis in up-to-date 
population when the search process converges.  
Figure 1 shows the block diagram of the system which 
involves the training phase and the classification phase. In 
the training phase, we automatically extract ROIs, optimized 
by GA, as speckle templates from ultrasound images in the 
patient database. The set of ROIs with the highest fitness is 
then used to train the SVM classifier for annotating the 
query image the grade of liver cirrhosis in the classification 
phase. 
   The first step, preprocessing, in the training procedure 
consists of three sub-steps: speckle noise filtering, scale-
invariant feature transform (SIFT) [15], and feature 
extraction.   The speckle noise filtering aims at eliminating 
the noise from the speckle template as much as possible 
without destroying the speckle pattern in the template. To 
achieve the goal, we choose the Gaussian filter to filter 
speckle noise. In computer vision, SIFT provides an 
approach to detect extreme feature points from an image to 
construct invariant descriptors with respect to position, scale, 
and rotation for object recognition. Instead of using the 
descriptors provided by SIFT, the feature extraction module 
detects the suitable features for medical diagnosis from the 
smoothed ultrasound images. Every feature point, detected 
by SIFT is indexed by the intensity gradient and defines a 
candidate 64x64 ROI with the feature point as the center. A 
feature vector to represent the speckle pattern of a ROI is 
then extracted from the ROI.  
   The texture features including the contrast, homogeneity, 
entropy, energy, and correlation can be extracted from the 
Grey Level Co-occurrence Matrix (GLCM) [13]. Given a 
specified displacement vector (dx,dy) and a ROI R, for each 
possible pair of grey levels (g1, g2), the GLCM CR(g1, g2) is 
defined as 
},,,),(
,),(|)),(),,{((#),(
2
121
yxR
RR
dyydxxgyxf
gyxfyxyxggC

   (1) 
where ),( yxfR is the grey level of the pixel (x,y) in R and #S
returns the size of the set S. Based on CR, the feature set FR
is used to characterize the content of the ROI R. The 
information in FR includes contrast, total energy, entropy, 
variance, correlation, local homogeneity, cluster shape, 
cluster prominence, and fractal dimension. The 
effectiveness of FR for liver diseases diagnosis based on 
ultrasound images had been reported by the work of Mitrea 
et al. [13]. The details to compute these features from CR
can refer to [13]. Instead of proposing new features for liver 
diseases diagnosis, in this work, we study the scheme to 
optimize the combination of ROIs when multiple ROIs are 
used in the interpretation of ultrasound images. 
566
examples. A fitness score based on classification accuracy 
would favor a SVM classifier to classify everything as 
negative, although it has no ability to discriminate positive 
examples from negative examples, when the negative 
examples are far more than positive examples in the training 
set. Whenever the fitness score of a chromosome is over a 
threshold it is added to a pool from which the selection 
module of the genetic algorithm update the chromosome 
population. 
1
min
P 1max
P
2
min
P 2max
P
Crossover
1
min
C 1max
C
2
min
C 2max
C












21
212
212
211
211
if,
),min(
),max(
),max(
),min(
maxmaxmax
minminmin
maxmaxmax
minminmin
PP
PPC
PPC
PPC
PPC
II
1
min
P 1max
P
2
min
P 2max
P
Crossover
1
min
C 1max
C
2
min
C 2max
C












21
212
212
211
211
if,
),max(
),min(
),max(
),min(
maxmaxmax
maxmaxmin
minminmax
minminmin
PP
PPC
PPC
PPC
PPC
II
(a)
mutatedif,
),max(
),min(
min
maxminmax
maxminmin P
PPC
PPC






)( maxmin
PP 
One-bit mutation
â€¦ â€¦
â€¦ â€¦
)( maxmin
PP   
mutatedif,
),max(
),min(
max
maxminmax
maxminmin P
PPC
PPC






(b)
Figure 2. Evolutionary operators for the genetic algorithm: 
(a) the offspring C1 and C2 are generated by parents P1 and 
P2 by crossover; (b) the parent chromosome P is mutated to 
generate the offspring C.
At each iteration, the genetic algorithm prepares for the 
next generation based the fitness scores of current 
population. A portion of the population is selected to 
continue to the next generation. A tournament selection 
method is used where N chromosomes are selected at 
random and the chromosome with the best fitness score 
continues to the next generation. Currently N is set to 2. 
After selection has taken place the rest of the population is 
composed of new chromosomes created through crossover  
as shown in Fig. 2(a). Once the next generation is filled each 
of the intervals (
minmax  ) in the chromosomes can be 
mutated also shown in Fig. 3(b). This whole process of 
ROIs selection is summarized in Algorithm 1 as below. 
Algorithm 1. Optimization of ROIs Selection 
Initialize P(1) of chromosomes.  
  Evaluate P(1). 
   for t = 1, 2, â€¦, T do
       for every chromosome do
           for every training image do
             Process image with feature construction 
             Train chromosomeâ€™s SVM classifier 
           end for
            for every test image do
                Process image with feature construction 
 Use the output of SVM classifier to update fitness 
score
end for 
            Assign fitness score to the chromosome 
       end for 
        Recombine P(t) to yield C(t) using crossover and 
mutation 
        Evaluate C(t) 
        Select P(t+1) from P(t) and C(t). 
   end while
Let the maximal iteration to stop the genetic algorithm be 
T. The SVM classifiers  with larger fitness scores in current 
population P(T) are returned from the genetic  algorithm to 
construct the classification bank for classifying the query 
image. Based on AdaBoost [17], algorithm 2 outlines how 
to select the SVM classifiers. N represents the maximum 
number of SVM classifiers allowed in the final model, 
which is 5 in our case. The number of SVM classifiers in 
the model can be increased after training if desired. The 
resulting model is a list of SVM classifiers and coefficients 
that indicate how much to trust each classifier. 
Algorithm 2. SVM Classifiers Selection. 
Input: Sequence of M examples S = [(xi, yi))], i = 1, Â·  Â·  Â·  , M
with labels yi  {0, 1,â€¦,C }; SVM classifiers with 
respect to current population P(T); 
Initialize: D1(i) = 1/M, i= 1,..,M.
for t = 1, 2, â€¦, N do 
Remove the SVM classifier, ht with the largest fitness 
score from current population P(T).
Select a training data subset St, drawn from the 
distribution Dt.
Calculate the error of .)(:
)(:
  iit yxh ttt iDh 
if %50t , break.
Set );1/( ttt  
Set );/1log( tt  
Update distribution: 


 



.
otherwise,1
)(if,
)(
)()(1
iitt
i t
t
t
yxh
iD
iDiD

end for 
III. THE CLASSIFICATION METHOD
In the classification phase, shown in Fig. 1, the quality of 
a query image is first slightly improved by a Gaussian filter. 
568
V. CONCLUSIONS 
In this paper, we have presented the method to construct 
an automatic system for liver disease prediction. The 
contributions of the paper include: (1) a preprocessing 
method is proposed to extract effective features from the 
selected ROIs of the input image; (2) using a genetic 
algorithm, a training procedure is proposed to optimize the 
selection of ROIs and to obtain the stable parameters for 
classification; (3) an AdaBoost based classification 
approach is presented to predict the possibility of liver 
cirrhosis for a patient based on the patient database and the 
input ultrasound image. As compared with past approaches, 
we span a new way to unify the processing steps in a 
clinical application using the evolutionary algorithms for 
interpreting ultrasound images.  
Future work would be on increasing the size of patient 
database and generalized the proposed method to deal with 
ultrasound image sequences. Both of them would improve 
the prediction accuracy of the system. 
TABLE 1. PERFORMANCE COMPARISON AMONG CAOâ€™S, YEHâ€™S, 
MITREAâ€™S, AND PROPOSED METHODS FOR TWO CLASS 
CLASSIFICATION IN TERMS OF CCR.
Two classes No cirrhosis
With
cirrhosis Average 
Caoâ€™s method [8] 71 40 56 
Yehâ€™s method [9] 86 76 81 
Mitreaâ€™s method [13] 36 84 60 
Proposed 
method 
Without 
GA 92 80 86 
With GA 93 88 91 
TABLE 2. PERFORMANCE COMPARISON AMONG CAOâ€™S, YEHâ€™S, 
MITREAâ€™S, AND PROPOSED METHODS FOR 6 CLASSES 
CLASSIFICATION IN TERMS OF CCR.
Multi-
classes 
Caoâ€™s 
method 
[8] 
Yehâ€™s 
method 
[9]
Mitreaâ€™s 
method 
[13] 
Proposed method 
Without 
GA
With 
GA
Level 0 64 86 36 71 85 
Level 1 6 36 35 46 79 
Level 2 0 46 69 77 84 
Level 3 14 0 52 31 45 
Level 4 20 10 20 70 50 
Level 5 0 64 76 36 60 
Average 17 41 48 55 67 
Acknowledgement 
This work was supported partially by National Science Council, 
Republic of China under Grant NSC99-2221-E-130-018. Also 
Thanks to Chang Gung Memorial Hospital team members for their 
medical domain knowledge support. 
REFERENCES
[1] J. Stoitsis, S. Golemati, and K. S. Nikita, â€œA Modular 
Software System to Assist Interpretation of Medical Images â€“
Application to Vascular Ultrasound Images,â€ IEEE Trans. 
Instrumentation and Measurement, Vol. 55, No. 6, pp. 1944-
1952, 2006. 
[2] M.I.H. Bhuiyan, M. Omair Ahmad, and M.N.S. Swamy,  
â€œNew Spatially Adaptive Wavelet-based Method for the 
Despeckling of Medical Ultrasound Images,â€ IEEE 
International Symposium on Circuits and Systems (ISCAS 
2007), pp. 2347 â€“ 2350, 2007. 
[3] P. Yang and O.A. Basir,  â€œAdaptive Weighted Median Filter 
Using Local Entropy for Ultrasonic Image Denoising,â€ Proc. 
International Symposium on Image and Signal Processing and 
Analysis, Vol.2, pp. 799 â€“ 803, 2003. 
[4] N. Hiransakolwong, P.S. Windyga, K.A.Hua, and K. Vu, 
â€œFASU: a Full Automatic Segmenting System for Ultrasound 
Images,â€ Proc. IEEE Workshop on Applications of Computer 
Vision, pp. 90 â€“ 94, 2002. 
[5]  J. A. Noble and D. Boukerroui, â€œUltrasound Image 
Segmentation: A Survey,â€ IEEE Trans. Medical Imaging, Vol. 
25, No. 8, pp. 987-1010, 2006.  
[6] C.-M. Wu, Y.-C. Chen, and K.-S. Hsieh, â€œTexture Features for 
Classification of Ultrasonic Liver Images,â€ IEEE Trans. 
Medical Imaging, Vol. 11, 1992. 
[7] O. Basset, F. Duboeuf, B. Delhay, E. Brusseau, C. Cachard, 
and J. P. Tasu,  â€œTexture Analysis of Ultrasound Liver Images 
with Contrast Agent to Characterize the Fibrosis Stage,â€ IEEE 
Symposium on Ultrasonics, pp. 24-27, 2008.  
[8] G. Cao, P. Shi, and B. Hu, â€œLiver Fibrosis Identification Based 
on Ultrasound Images Captured Under Varied Imaging 
Protocols,â€ Journal of Zhejiang University, Science B, 6 (11), 
p. 1107, 2005. 
[9] W.-C. Yeh, S.-W. Huang, and P.-C. Li, â€œLiver Fibrosis Grage 
Classification with B-Mode Ultrasound,â€ Ultrasound in Med. 
& Biol., Vol. 29, No. 9, pp. 1229â€“1235, 2003.  
[10] S. Zhou and J. Wan, â€œA Survey of Algorithms for the 
Analysis of Diffused Liver Disease from B-mode Ultrasound 
Images,â€ Proc. International Conference on Electronic 
Measurement & Instruments, pp. 2-576 - 2-582,  2009.  
[11] S. A. Zaid, M. W. Fakhr, and A. F. A. Mohamed, â€œAutomatic 
Diagnosis of Liver Diseases from Ultrasound Images,â€ Proc. 
International Conference on Computer Engineering and 
Systems, pp. 313 â€“ 319, 2006. 
[12] Y. Fujita, Y. Hamamoto, M. Segawa, S. Terai, and I. Sakaida, 
â€œAn Improved Method for Cirrhosis Detection Using Liverâ€™s 
Ultrasound images,â€ Proc. International Conference on Pattern 
Recognition, 2010.  
[13] D. Mitrea, S. Nedevschi, B. Fratila, and M. Lupsor, â€œTexture-
based Methods in Biomedical Image Recognition of Diffuse 
Liver Diseases,â€ Proc. International Conference on System 
Theory and Software Engineering, Vol. 3,  pp. 629-634, 2005. 
[14] Tom M. Mitchell, Machine Learning, The McGraw-Hill 
Companies, Inc., 1997. 
[15] David G.Lowe, â€œObject Recognition from Local Scale-
invariant Features,â€ Proc. of the International Conference on 
Computer Vision, vol. 2. pp. 1150â€“1157, 1999. 
[16] S.-C. Cheng and C.-K. Yang, È¾A Fast and Novel Technique 
for Color Quantization Using Reduction of Color Space 
Dimensionality,È¿ Pattern Recognition Letters, vol.  22, pp. 
845-856, 2001. 
[17] R. Polikar, â€œEnsemble Based Systems in Decision Making,â€ 
IEEE Circuits and Systems Magazine, Third Quarter, pp. 21-
45, 2006.
570
99 å¹´åº¦å°ˆé¡Œç ”ç©¶è¨ˆç•«ç ”ç©¶æˆæœå½™æ•´è¡¨ 
è¨ˆç•«ä¸»æŒäººï¼šæ¥Šå¥è²´ è¨ˆç•«ç·¨è™Ÿï¼š99-2221-E-130-020- 
è¨ˆç•«åç¨±ï¼šé«˜ç•«è³ªå‹•æ…‹è¦–é»ç«‹é«”å½±åƒæŠ•å½±ç”¢ç”Ÿä¹‹ç ”ç©¶ 
é‡åŒ– 
æˆæœé …ç›® å¯¦éš›å·²é”æˆ
æ•¸ï¼ˆè¢«æ¥å—
æˆ–å·²ç™¼è¡¨ï¼‰
é æœŸç¸½é”æˆ
æ•¸(å«å¯¦éš›å·²
é”æˆæ•¸) 
æœ¬è¨ˆç•«å¯¦
éš›è²¢ç»ç™¾
åˆ†æ¯” 
å–®ä½ 
å‚™ è¨» ï¼ˆ è³ª åŒ– èªª
æ˜ï¼šå¦‚æ•¸å€‹è¨ˆç•«
å…±åŒæˆæœã€æˆæœ
åˆ— ç‚º è©² æœŸ åˆŠ ä¹‹
å° é¢ æ•… äº‹ ...
ç­‰ï¼‰ 
æœŸåˆŠè«–æ–‡ 0 0 100%  
ç ”ç©¶å ±å‘Š/æŠ€è¡“å ±å‘Š 0 0 100%  
ç ”è¨æœƒè«–æ–‡ 1 1 100% 
ç¯‡ 
 
è«–æ–‡è‘—ä½œ 
å°ˆæ›¸ 0 0 100%   
ç”³è«‹ä¸­ä»¶æ•¸ 0 0 100%  å°ˆåˆ© å·²ç²å¾—ä»¶æ•¸ 0 0 100% ä»¶  
ä»¶æ•¸ 0 0 100% ä»¶  
æŠ€è¡“ç§»è½‰ 
æ¬Šåˆ©é‡‘ 0 0 100% åƒå…ƒ  
ç¢©å£«ç”Ÿ 2 2 100%  
åšå£«ç”Ÿ 0 0 100%  
åšå£«å¾Œç ”ç©¶å“¡ 0 0 100%  
åœ‹å…§ 
åƒèˆ‡è¨ˆç•«äººåŠ› 
ï¼ˆæœ¬åœ‹ç±ï¼‰ 
å°ˆä»»åŠ©ç† 0 0 100% 
äººæ¬¡ 
 
æœŸåˆŠè«–æ–‡ 0 0 100%  
ç ”ç©¶å ±å‘Š/æŠ€è¡“å ±å‘Š 0 0 100%  
ç ”è¨æœƒè«–æ–‡ 1 1 100% 
ç¯‡ 
 
è«–æ–‡è‘—ä½œ 
å°ˆæ›¸ 0 0 100% ç« /æœ¬  
ç”³è«‹ä¸­ä»¶æ•¸ 0 0 100%  å°ˆåˆ© å·²ç²å¾—ä»¶æ•¸ 0 0 100% ä»¶  
ä»¶æ•¸ 0 0 100% ä»¶  
æŠ€è¡“ç§»è½‰ 
æ¬Šåˆ©é‡‘ 0 0 100% åƒå…ƒ  
ç¢©å£«ç”Ÿ 0 0 100%  
åšå£«ç”Ÿ 0 0 100%  
åšå£«å¾Œç ”ç©¶å“¡ 0 0 100%  
åœ‹å¤– 
åƒèˆ‡è¨ˆç•«äººåŠ› 
ï¼ˆå¤–åœ‹ç±ï¼‰ 
å°ˆä»»åŠ©ç† 0 0 100% 
äººæ¬¡ 
 
 
