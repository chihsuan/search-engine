demonstrate that the proposed method can effectively 
extract human gaits, in which the extracted feature 
vectors are of high discriminability and stability. 
It turns out that the system still has a relatively 
high recognition rate in a real and unconstraint 
environment. For the application of identity 
recognition, we have 90.0% recognition rate, and for 
group classification, the recognition rate is 81.0%. 
Therefore, the proposed system can work well in real-
world situations. 
è‹±æ–‡é—œéµè©ï¼š pedestrian tracking, gait recognition, gait energy 
image, Fourier descriptor, Gabor wavelet 
 
ä¸­æ–‡æ‘˜è¦ 
ç¾ä»Šç¤¾æœƒç”±æ–¼ç¶“æ¿Ÿçš„é«˜åº¦ç™¼å±•ï¼Œé€ æˆè³¼ç‰©å•†å ´çš„è¦æ¨¡æœ‰æ„ˆä¾†æ„ˆå¤§çš„è¶¨å‹¢ï¼Œç•¶ç„¶äººåŠ›çš„
éœ€æ±‚ä¹Ÿè·Ÿè‘—æ°´æ¼²èˆ¹é«˜ï¼Œé€™æ„è¬‚è‘—äººåŠ›æˆæœ¬äº¦å°‡è·Ÿè‘—æé«˜ã€‚æ­¤å¤–ï¼Œè³¼ç‰©å•†å ´ç‚ºäº†æä¾›é¡§å®¢æ›´
å¥½çš„æœå‹™å“è³ªï¼Œç‰¹åˆ¥æ˜¯å°å¼±å‹¢æ—ç¾¤çš„ç…§é¡§ï¼Œç›¸å°çš„äººåŠ›é…ç½®æ›´æ˜¯ä¸å¯ç¼ºå°‘ï¼Œç•¶ç„¶é€™äº›è²¼å¿ƒ
çš„æœå‹™ä¹Ÿæœƒå¸¶ä¾†ç‡Ÿé‹æˆæœ¬çš„å¢åŠ ã€‚ç‚ºäº†è®“è³¼ç‰©å•†å ´ä¸­çš„äººåŠ›é€²è¡Œæœ€æœ‰æ•ˆç‡çš„èª¿åº¦ï¼Œæœ¬ç ”ç©¶
è—‰ç”±æ­¥æ…‹è­˜åˆ¥æŠ€è¡“æå‡ºå…¨æ–°çš„èº«åˆ†è­˜åˆ¥èˆ‡æ—ç¾¤åˆ†é¡æ–¹æ³•ã€‚æ‰€ææ–¹æ³•åŒ…å«ç”¨æ–¼èº«åˆ†è­˜åˆ¥çš„æ··
å’Œå¼ç‰¹å¾µè¡¨ç¤ºæ³•ï¼Œæ­¤æ–¹æ³•æ¡ç”¨æ­¥æ…‹èƒ½é‡åœ–(Gait energy imageï¼›GEI)èˆ‡è³ˆä¼¯å°æ³¢(Gabor wavelet)
ä¾†é€²è¡Œç‰¹å¾µæ“·å–ï¼Œè—‰æ­¤æå‡èº«åˆ†è­˜åˆ¥çš„æ•ˆç‡ï¼›å¦å¤–ï¼Œåœ¨æ—ç¾¤åˆ†é¡æ–¹æ³•ä¸­ï¼Œå‰‡æ¡ç”¨å‚…ç«‹è‘‰æ
è¿°å­(Fourier descriptors)ä½œç‚ºå…¶ç‰¹å¾µè¡¨ç¤ºæ³•ï¼Œæ­¤ä¸€æ–¹æ³•å…·æœ‰é™ä½ç‰¹å¾µæ•¸é‡èˆ‡ç‰¹å¾µä¸è®Šæ€§ç­‰ç‰¹
é»ï¼Œå¯æœ‰æ•ˆçš„æå‡æ—ç¾¤åˆ†é¡ç‡ã€‚å¯¦é©—çµæœè­‰å¯¦æœ¬ç ”ç©¶æ‰€ææ–¹æ³•èƒ½æœ‰æ•ˆåœ°å°è¡Œäººæ­¥æ…‹ç‰¹å¾µé€²
è¡Œæå–ï¼ŒåŒæ™‚æ‰€æå–çš„ç‰¹å¾µå‘é‡å…·æœ‰é«˜åº¦é‘‘åˆ¥æ€§èˆ‡ç©©å®šæ€§ï¼Œæ•…åœ¨å…·é«˜åº¦ä¸å¯æ§å› ç´ çš„çœŸå¯¦
ç’°å¢ƒä¸­ï¼Œä»ç„¶å…·æœ‰ç›¸å°è¼ƒé«˜çš„è­˜åˆ¥ç‡ï¼›åœ¨èº«åˆ†è­˜åˆ¥ä¸­ï¼Œæœ¬ç ”ç©¶æ‰€æä¹‹æ–¹æ³•å…·æœ‰90.0%çš„é«˜è­˜
åˆ¥ç‡ï¼›è€Œåœ¨æ—ç¾¤åˆ†é¡ä¸­ï¼Œå‰‡å¯é”81.0%ä¹‹åˆ†è¾¨ç‡ã€‚ç”±æ­¤ï¼Œå¯çŸ¥æœ¬ç ”ç©¶æ‰€æä¹‹æ–¹æ³•èƒ½æœ‰æ•ˆçš„é‹
ä½œåœ¨çœŸå¯¦ç’°å¢ƒä¹‹ä¸‹ã€‚ 
 
é—œéµè©ï¼šè¡Œäººè¿½è¹¤ã€æ­¥æ…‹è­˜åˆ¥ã€æ­¥æ…‹èƒ½é‡åœ–ã€å‚…ç«‹è‘‰æè¿°å­ã€è³ˆä¼¯å°æ³¢ 
è‹±æ–‡æ‘˜è¦ 
The shopping malls become large more and more due to the high development of social economics in 
the last decades. It means that manpower requirement and its related personnel cost must increase 
correspondingly. Generally, offering better service to attract the crowds is a commonly used means of 
shopping malls, especially for weak groups such as disabled people, the pregnant and little children so 
on. Of course, such attentive service will inevitably bring the increase in operating costs. To make use 
of the manpower more efficient, we propose a novel method for identity recognition and group 
classification using human gaits with an aid of the shopping malls. The proposed method has twofold 
functions: one is for identity recognition using the hybrid features of gait energy image (GEI) and 
Gabor wavelet, and the other is for group classification using the feature of Fourier descriptor, which 
is invariant with scale, rotation and translation. The experimental results demonstrate that the 
proposed method can effectively extract human gaits, in which the extracted feature vectors are 
of high discriminability and stability. It turns out that the system still has a relatively high 
recognition rate in a real and unconstraint environment. For the application of identity recognition, 
we have 90.0% recognition rate, and for group classification, the recognition rate is 81.0%. 
Therefore, the proposed system can work well in real-world situations. 
Keywords: pedestrian tracking, gait recognition, gait energy image, Fourier descriptor, Gabor 
wavelet 
 
 
 
 
    3 
(äºŒ) ç ”ç©¶ç›®çš„ 
 
ç‚ºäº†è®“è³¼ç‰©å•†å ´ä¸­çš„äººåŠ›é€²è¡Œæœ€æœ‰æ•ˆç‡çš„èª¿åº¦ï¼Œç•¶ç™¼ç¾è³£å ´ä¸­æœ‰éœ€è¦å¹«åŠ©çš„å¼±å‹¢æ—ç¾¤
(åŒ…å«æ®˜éšœäººå£«ã€å­•å©¦èˆ‡å­¸é½¡å¹¼ç«¥ç­‰)æ™‚ï¼Œæ‰æ´¾äººå°±è¿‘æä¾›é©ç•¶çš„æœå‹™ï¼Œé€™ç¨®åšæ³•å¯ä»¥é¿å…åœ¨
åŒå¤§çš„è³£å ´ä¸­åŠƒè¨­å‡ºè¨±è¨±å¤šå¤šçš„è²¬ä»»å€ï¼Œç„¶å¾Œæ¯å€‹è²¬ä»»å€å†ç”±å°ˆè²¬çš„äººå“¡ä¾†è² è²¬ï¼›å¦‚æ­¤ä¸€
ä¾†ï¼Œè³¼ç‰©å•†å ´å°±å¯ä»¥å¤§å¹…åœ°é™ä½ç”¨äººéœ€æ±‚ï¼Œé€²è€Œç¯€çœäººåŠ›æˆæœ¬çš„æ”¯å‡ºï¼ŒåŒæ™‚é”åˆ°æå‡æœå‹™
å“è³ªçš„ç›®çš„ã€‚ 
 
(ä¸‰) æ–‡ç»æ¢è¨ 
 
æ­¥æ…‹è­˜åˆ¥ç”±æ–¼å…·æœ‰éæ¥è§¸æ€§ã€é è·è­˜åˆ¥èˆ‡è‡ªç„¶ç‰¹å¾µæ˜é¡¯ç­‰å„ªé»ï¼ŒæˆåŠŸå¸å¼•è¨±å¤šç ”ç©¶äºº
å“¡çš„çœ¼å…‰ï¼Œæˆç‚ºè¿‘å¹´ä¾†ç ”ç©¶çš„ç†±é»ã€‚åŸºæ–¼é›»è…¦è¦–è¦ºçš„æ­¥æ…‹è­˜åˆ¥æŠ€è¡“åŒ…å«é‹å‹•ç‰©é«”åµæ¸¬ã€é‹
å‹•ç‰©é«”è¿½è¹¤ã€é‹å‹•ç‰©é«”è­˜åˆ¥èˆ‡æ­¥æ…‹è­˜åˆ¥ç­‰é—œéµæŠ€è¡“ã€‚åœ¨é‹å‹•ç‰©é«”åµæ¸¬æ–¹é¢ï¼Œå¸¸è¦‹çš„æ–¹æ³•æœ‰
æ™‚é–“å·®åˆ†æ³•èˆ‡èƒŒæ™¯ç›¸æ¸›æ³•ç­‰å…©ç¨®ï¼Œæˆ–è€…ä»¥æ¬Šé‡çš„æ–¹å¼çµåˆé€™å…©ç¨®æ–¹æ³•çš„å„ªé»ï¼›å…¶ä¸­æ™‚é–“å·®
åˆ†æ³•ä½¿ç”¨ç›¸é„°å…©ç¦æˆ–ä¸‰ç¦å½±åƒç›¸æ¸›å–å…¶å·®å€¼ä½œç‚ºé‹å‹•ç‰©é«”ï¼Œè€ŒèƒŒæ™¯ç›¸æ¸›æ³•å‰‡æ¡ç”¨ç›®å‰å½±åƒ
æ¸›å»ä½¿ç”¨ç–Šä»£æ–¹å¼æˆ–å„ç¨®ä¸åŒçš„èƒŒæ™¯æ›´æ–°ç­–ç•¥æ‰€ç”¢ç”Ÿçš„å›ºå®šèƒŒæ™¯ï¼Œç„¶å¾Œå–å…¶å·®å€¼ä½œç‚ºé‹å‹•
ç‰©é«”ï¼Œé€™ç¨®æ–¹æ³•é›–ç„¶å¯å–å¾—æ¯”è¼ƒå®Œæ•´çš„é‹å‹•ç‰©é«”ï¼Œä½†å»ºç«‹ä¸€å®Œæ•´èƒŒæ™¯å¿…é ˆèŠ±è²»è¼ƒé•·çš„æ™‚é–“ï¼›
ç›¸å°æ–¼èƒŒæ™¯ç›¸æ¸›æ³•ï¼Œæ™‚é–“å·®åˆ†æ³•ä½œæ³•æ¯”è¼ƒå®¹æ˜“ä¸”å¿«é€Ÿï¼Œä½†è‹¥æ‰€ç›£æ§çš„ç‰©é«”ç§»å‹•ç·©æ…¢å¯èƒ½ç„¡
æ³•å°å…¶é€²è¡Œè¿½è¹¤ã€‚ 
åœ¨é‹å‹•ç›®æ¨™è¿½è¹¤æ–¹é¢ï¼Œå¡æ›¼ï¦„æ³¢å™¨(Kalman filter) [1]æ˜¯ä¸€ç¨®è¼ƒå¸¸è¢«ä½¿ç”¨çš„æ–¹æ³•ã€‚å¡æ›¼ï¦„
æ³¢å™¨æ˜¯R. E. Kalmanåœ¨1960å¹´æ‰€æå‡ºä¾†çš„ï¼Œæ˜¯ç›®æ¨™è¿½è¹¤çš„ä¸€å€‹å‚³çµ±æŠ€è¡“ï¼Œå…·æœ‰ç›¸ç•¶å¥½çš„ç©©å®š
æ€§ï¼Œå› æ­¤è¢«å»£æ³›æ‡‰ç”¨æ–¼è¨±å¤šé ˜åŸŸä¸Šã€‚å®ƒçš„åšæ³•æ˜¯é‡å°é‹å‹•ç‰©é«”å»ºç«‹ï§ºæ…‹ä¼°è¨ˆæ¨¡å‹ï¼ŒåŒæ™‚éµ
å¾ªæœ€å°å‡æ–¹å·®åŸå‰‡ï¼Œä¸¦åœ¨æœ€å°å‡æ–¹å·®çš„æº–å‰‡ä¸‹æ‰€å»ºç«‹çš„æœ€ä½³ï¦„æ³¢å™¨ï¼›æ›´ç²¾ç¢ºåœ°ï¥¯ï¼Œå®ƒä½¿å¾—
ç³»çµ±çš„ï§ºæ…‹å‘é‡èˆ‡é æ¸¬å€¼é–“çš„å‡æ–¹èª¤å·®é”æœ€å°ï¼Œé€™å€‹éç¨‹å¯é€éé æ¸¬èˆ‡æ›´æ–°çš„éè¿´æ–¹å¼ä¾†
é”æˆï§ºæ…‹ä¼°è¨ˆä¹‹ç›®çš„ã€‚å› æ­¤å¡æ›¼ï¦„æ³¢å™¨å…·æœ‰å°éå»ï§ºæ…‹ã€ç¾åœ¨ï§ºæ…‹ï¼Œèˆ‡æœªä¾†ï§ºæ…‹çš„ä¼°è¨ˆèƒ½
åŠ›ï¼ŒåŒæ™‚å…·æœ‰åŠŸèƒ½å¼·å¤§ã€è¨ˆç®—é‡å°ï¼Œèˆ‡å³æ™‚é‹ç®—ä¹‹å„ªé»ã€‚ 
å°‡å‰æ™¯ç‰©é«”è‡ªèƒŒæ™¯ä¸­åˆ†é›¢å‡ºä¾†ï¼Œæ˜¯é‹å‹•ç‰©é«”è¿½è¹¤æœ€é‡è¦çš„æ­¥é©Ÿã€‚Wangç­‰äºº[2]å°‡å½±åƒåˆ†
é›¢ç‚ºå‰æ™¯èˆ‡èƒŒæ™¯ç­‰å…©é¡ï¼Œä¸¦é‡å°å‰æ™¯å½±åƒæ“·å–å…¶ä½ç½®åæ¨™ã€å½¢ï§ºå¤§å°ã€ç°åº¦å€¼èˆ‡ç´‹ç†ç­‰å››
å€‹ç‰¹å¾µä½œç‚ºç§»å‹•ç‰©é«”è¿½è¹¤çš„æ ¹æ“šï¼Œè©²æ–¹æ³•å…·æœ‰å¾ˆå¥½çš„ç©©å®šæ€§èˆ‡æ•ˆèƒ½ï¼Œä¸¦ä¸”å¯ä»¥åµæ¸¬åˆ°è¿½è¹¤
å°è±¡é–‹å§‹æˆ–åœæ­¢ç§»å‹•èˆ‡ç¢°æ’ç­‰ï§ºæ…‹ï¼Œé€™å€‹æ–¹æ³•è·Ÿå¤§éƒ¨åˆ†çš„æ–¹æ³•ä¸€æ¨£ï¼Œéƒ½æ˜¯åœ¨ç·šæ€§ç³»çµ±çš„å‰
æä¸‹æå‡ºçš„ã€‚åœ¨2009å¹´æ™‚ï¼ŒIslamç­‰äºº[3]å°‡ç§»å‹•ç‰©é«”çš„é¡è‰²èˆ‡å½¢ï§ºé€éè·é›¢è½‰æ›æ–¹æ³•è½‰æ›æˆ
éç·šæ€§ç²’å­ï¼Œä¸¦é€éå…¶è¨­è¨ˆçš„ç²’å­ï¦„æ³¢è¿½è¹¤å™¨æˆåŠŸçš„æ–¼è¤‡é›œç’°å¢ƒä¸‹å°ç§»å‹•ç‰©é«”é€²è¡Œè¿½è¹¤ã€‚ 
é‹å‹•ç‰¹å¾µçš„æ“·å–èˆ‡è¡¨ç¤ºï¼Œå°æ–¼é‹å‹•è¡Œç‚ºçš„åˆ†æç›¸ç•¶é‡è¦ã€‚Dalalç­‰äºº[4]é¦–å…ˆå°‡å½±åƒåˆ†å‰²
æˆè‹¥å¹²å€‹å­å½±åƒï¼Œç„¶å¾Œè¨ˆç®—å„å­å½±åƒçš„æ ¼é»æ–¹å‘æ¢¯åº¦ç›´æ–¹åœ–(Grids of histogram of oriented 
gradient; G-HOG)ï¼Œä¸¦ç”¨å®ƒä¾†åšç‚ºè¡Œäººåµæ¸¬ä¹‹ç‰¹å¾µã€‚å‚…ç«‹è‘‰æè¿°å­ä¹Ÿå¸¸è¢«ç”¨ä¾†ä½œç‚ºè¡¨ç¤ºå½±åƒ
çš„ç‰¹å¾µ[5][6]ï¼Œå…¶å„ªé»æ˜¯å¯å°‡è¤‡é›œä¸”é«˜ç¶­åº¦çš„å½±åƒè½‰åŒ–ç‚ºç°¡å–®ä¸”ä½ç¶­åº¦çš„ç‰¹å¾µæè¿°ã€‚Liaoç­‰
äºº[7]å‰‡å°‡è¡Œäººå½±åƒåˆ†å‰²ç‚ºé ­éƒ¨ã€è»€å¹¹èˆ‡è…³éƒ¨ç­‰ä¸‰éƒ¨åˆ†ï¼Œåˆ†åˆ¥è¨ˆç®—å…¶é‡å¿ƒä½ç½®èˆ‡å¤¾è§’ï¼Œä¸¦ç”¨
å®ƒä¾†è­˜åˆ¥äººçš„å¥åº·ï§ºæ…‹ã€‚ 
æ­¥æ…‹è­˜åˆ¥çš„æ–¹æ³•å¤§è‡´ä¸Šå¯åˆ†ç‚ºåˆ†é¡å™¨æ³•èˆ‡éš±é¦¬å¯å¤«æ¨¡å‹ç­‰å…©å¤§æ–¹å‘ï¼ŒSuç­‰äºº[8]é¦–å…ˆå°‡
æ­¥æ…‹å½±åƒç‰¹å¾µç¶“ç”±ä¸»å‘é‡åˆ†æ(PCA)é™ä½ç¶­åº¦ï¼Œæ¥è‘—ä½¿ç”¨STC(Spatial-Temporal Correlation)
æ³•ç§»é™¤å¤§éƒ¨åˆ†PCAç‰¹å¾µä¸­éæ–¼ç›¸ä¼¼çš„ç‰¹å¾µå‘é‡ï¼Œæœ€å¾Œä½¿ç”¨æœ€é„°è¿‘æ³•(Nearest Neighbor)ä½œç‚ºåˆ†
    5 
âˆ‘
âˆ‘
=
==
T
t
t
T
t
t
T
yxBP
yxBG
yxBG
1
1
),(
),(
),(           (3) 
 
å°æ–¼å¼(1)ä¸­çš„åƒæ•¸ ( , )tTh x y ï¼Œæœ¬ç ”ç©¶æ¡ç”¨é©æ‡‰æ€§æ–¹æ³•ä¾†æ±ºå®šï¼Œå…¶å¦‚å¼(4)æ‰€ç¤ºã€‚æ¡ç”¨é€™ç¨®åš
æ³•çš„å„ªé»æ˜¯æ¯å€‹åƒç´ é»éƒ½å¯ä»¥æœ‰è‡ªå·±çš„é–¥å€¼(æˆ–å¯å®¹å¿ç¯„åœ)ï¼ŒåŒæ™‚ä¹Ÿå¯ä»¥é¿å…åƒæ•¸èª¿æ•´é€™å€‹
æ“¾äººçš„å•é¡Œï¼Œå…¶ä¸­åˆå€¼ 0),(0 =yxTh ã€‚ä¸‹åœ–2ç‚ºæœ¬ç ”ç©¶æ‰€ææ–¹æ³•åœ¨è‡ªè¡Œæ‹æ”çš„å½±ç‰‡ä¸­å¾—åˆ°çš„çµ•
å°èƒŒæ™¯çµæœã€‚ 
 
1 1( , ) ( 1) ( ( , ) ( , ))( , ) ;  1t t tt
Th x y t F x y F x yTh x y t
t
âˆ’ âˆ’Ã— âˆ’ + âˆ’= â‰¥       (4) 
 
  
(a) (b) 
åœ– 2 å»ºç«‹çµ•å°èƒŒæ™¯ï¼›(a)è¼¸å…¥å½±åƒï¼Œ(b)çµ•å°èƒŒæ™¯ 
 
4.2 é‹å‹•ç‰©é«”åµæ¸¬æ–¹æ³• 
 
æ–¼å»ºç«‹çµ•å°èƒŒæ™¯çš„åŒæ™‚ï¼Œæœ¬ç ”ç©¶æ–¹æ³•å¯å°‡ä¸å±¬æ–¼çµ•å°èƒŒæ™¯ä¸­çš„ç§»å‹•åƒç´ æ¨™ç¤ºå‡ºä¾†ï¼›è‹¥
å½±åƒä¸­åƒç´ é» ( , )tI x y èˆ‡èƒŒæ™¯é» ( , )B x y çš„å·®å€¼å¤§æ–¼é å…ˆè¨­å®šçš„é–¥å€¼ BTh ï¼Œå‰‡è¢«è¦–ç‚ºç§»å‹•åƒç´ 
æˆ–å‰æ™¯é»ã€‚å› æ­¤ï¼Œé€éé€™å€‹æ–¹æ³•å³å¯å¿«é€Ÿä¸”æº–ç¢ºåœ°æ±‚å‡ºç§»å‹•ç›®æ¨™ç‰©ï¼Œå¦‚å¼(5)æ‰€ç¤ºï¼š 
 
1  ( , ) ( , )
( , )
0
t B
t
if I x y B x y Th
D x y
otherwise
ï£± âˆ’ â‰¥
= ï£²
ï£³
        (5) 
 
ç”±æœ¬ç ”ç©¶æ‰€æå‡ºçš„æ–¹æ³•æ‰€å¾—åˆ°ä¹‹äºŒå€¼å½±åƒï¼Œé‚„ç„¡æ³•å°‡é›œè¨Šå®Œå…¨ï¦„é™¤ï¼›å› æ­¤ï¼Œç‚ºäº†ä½¿ç§»
å‹•ç‰©é«”çš„åˆ†å‰²å€å¡Šæ›´åŠ å®Œæ•´ï¼Œæœ¬ç ”ç©¶ä½¿ç”¨å½¢æ…‹å­¸ä¸­çš„ä¾µè•èˆ‡è†¨è„¹æŠ€è¡“ï¼Œä¸€æ–¹é¢å¯ä»¥æ¶ˆé™¤ä¸
æ˜¯ç›®æ¨™å€å¡Šçš„é›œè¨Šï¼Œå¦ä¸€æ–¹é¢å¯ä»¥ä½¿ç›®æ¨™å€å¡Šä¸­çš„ç©ºæ´å¡«è£œèµ·ä¾†ï¼Œä»¥å¾—åˆ°æ›´å®Œæ•´çš„ç§»å‹•ç›®
æ¨™ç‰©å€å¡Šï¼Œä¸‹åœ–3ç‚ºé‹å‹•ç‰©é«”åµæ¸¬ä¹‹çµæœã€‚ 
 
    7 
 
4.4.1 æ··å’Œå¼ç‰¹å¾µæ“·å–æ–¹æ³• 
 
æœ¬ç ”ç©¶ä½¿ç”¨å¿«é€Ÿå…«é€£é€šæ³•[11]ä¾†æ±ºå®šé‹å‹•ç‰©é«”çš„è¿½è¹¤å€å¡Šï¼ŒåŒæ™‚åˆ©ç”¨é€™å€‹å€å¡Šä¾†é€²è¡Œé‹
å‹•ç‰©é«”çš„æå–ï¼Œå› ç‚ºä¸åŒèº«ä»½çš„äººå…¶è¡Œèµ°å§¿æ…‹æœ‰æ‰€ä¸åŒä¸”å…·æœ‰ä¸€å®šçš„å‘¨æœŸæ€§ï¼Œæ‰€ä»¥æˆ‘å€‘èƒ½
åˆ©ç”¨æ­¥æ…‹èƒ½é‡åœ– (Gait energy imageï¼›GEI) [12]çš„æ–¹å¼è£½ä½œå‡ºä¸åŒçš„æ­¥æ…‹ç‰¹å¾µï¼Œå…¶å¯¦ç¾æ–¹æ³•
å¦‚å¼(7)æ‰€ç¤ºï¼š 
 
1
1( , ) ( , )
N
k
k
GEI x y B x y
N =
= âˆ‘         (7) 
 
å…¶ä¸­ ( , )kB x y ç‚ºå¿«é€Ÿå…«é€£é€šæ‰€æå–çš„é‹å‹•ç‰©é«”ï¼ŒNç‚ºç”¢ç”Ÿæ­¥æ…‹èƒ½é‡åœ–æ‰€ä½¿ç”¨çš„å¼µæ•¸ï¼Œåœ–
5å‰‡ç‚ºæ­¥æ…‹å‘¨æœŸç¤ºæ„åœ–ï¼Œå…¶ä¸­æ­¥æ…‹å‘¨æœŸç‚ºN=12ã€‚ 
 
 
åœ– 5 æ­¥æ…‹é€±æœŸåœ–(N=12) 
 
æ¥è‘—æˆ‘å€‘ä½¿ç”¨å¼(8)èˆ‡å¼(9)å°‡æ­¥æ…‹èƒ½é‡åœ–åˆ‡å‰²æˆä¸ŠåŠéƒ¨ UM èˆ‡ä¸‹åŠéƒ¨ LM ç­‰å…©éƒ¨ä»½ï¼Œå…¶
åˆ‡å‰²çµæœå¦‚åœ–6æ‰€ç¤ºã€‚æ–¼å¼(8)èˆ‡(9)ä¸­ï¼Œ ( , )GEI x y è¡¨ç¤ºæ­¥æ…‹èƒ½é‡åœ–ä¸­æ¯å€‹åƒç´ é»çš„ç°éšå€¼ï¼Œ
UM è¡¨ç¤ºæ­¥æ…‹èƒ½é‡åœ–ä¸­ä¸Šæ–¹2/3ä¹‹éƒ¨åˆ†ï¼Œè€Œ LM å‰‡ç‚ºæ­¥æ…‹èƒ½é‡åœ–ä¸­ä¸‹æ–¹1/3ä¹‹éƒ¨åˆ†ï¼Œ 1Î¸ ã€ 2Î¸ ç‚º
é–¥å€¼ï¼Œæœ¬æ–‡ä¾ç…§æ–‡ç»[12]å°‡å…¶è¨­å®šç‚º 1 220Î¸ = èˆ‡ 2 110Î¸ = ã€‚ 
 
( ) 0 ( , )1, 1,
0,
UGEI x yifM x yU Otherwise
Î¸< â‰¤
=
ï£±
ï£²
ï£³
       (8) 
( ) ( , )1, 2,
0,
LGEI x yifM x yL Otherwise
Î¸<
=
ï£±
ï£²
ï£³
       (9) 
 
    9 
 
åœ– 8 è¡Œäººæ­¥æ…‹ä¹‹ Gabor feature 
 
4.4.2 å‚…ç«‹è‘‰æè¿°å­ç‰¹å¾µæè¿°æ–¹æ³• 
 
ä»¤ 0 0 1 1 1 1{( , ), ( , ), , ( , )}T Ts x y x y x yâˆ’ âˆ’= ïŒ ç‚ºæ­¥æ…‹å½±åƒè¼ªå»“é‚Šç•Œåº§æ¨™åºåˆ—ï¼Œç”±åº§æ¨™ 0 0( , )x y é–‹å§‹
é€†æ™‚é‡æ–¹å‘é€²è¡Œç´€éŒ„ï¼Œåœæ­¢æ–¼åº§æ¨™ 1 1( , )T Tx yâˆ’ âˆ’ è™•ã€‚æ›´é€²ä¸€æ­¥ï¼Œå¯å°‡æ­¥æ…‹å½±åƒè¼ªå»“é‚Šç•Œåº§æ¨™åº
åˆ— sè¡¨ç¤ºç‚ºå¼(12)ï¼š 
 
( )       ( ) ( )   0,1, , 1k ks k x jy and s k s k T k T= + = + = âˆ’ï‹     (12) 
 
ç”±æ–¼ ( )s k æ˜¯ä¸€é€±æœŸæ€§è¨Šè™Ÿï¼Œæ•…å¯ç”¨å‚…ç«‹è‘‰åºåˆ—è¡¨ç¤ºæ³•é€²è¡Œè¡¨ç¤ºï¼Œå¦‚å¼(13)æ‰€ç¤ºï¼š 
 
1
2 /
0
1( ) ( )      0,1, , 1
T
j fk T
k
a f s k e f T
T
Ï€
âˆ’
âˆ’
=
= = âˆ’âˆ‘ ï‹      (13) 
 
è¤‡æ•¸ä¿‚æ•¸ ( )a f å³ç‚ºæ­¥æ…‹å½±åƒè¼ªå»“é‚Šç•Œåº§æ¨™å‚…ç«‹è‘‰æè¿°å­ï¼Œä½¿ç”¨åå‚…ç«‹è‘‰æ–¹æ³•å¯å°‡ ( )a f
é‡å»ºç‚ºåŸå§‹çš„æ­¥æ…‹å½±åƒè¼ªå»“é‚Šç•Œåº§æ¨™ï¼Œå…¶æ–¹æ³•å¦‚å¼(14)æ‰€ç¤ºï¼š 
 
1
2 /
0
( ) ( )      0,1, , 1
T
j fk T
f
s k a f e k TÏ€
âˆ’
=
= = âˆ’âˆ‘ ï‹      (14) 
 
ç„¶è€Œï¼Œæˆ‘å€‘å¯ä»¥åƒ…ä½¿ç”¨å‰ nå€‹ä¿‚æ•¸å°æ­¥æ…‹å½±åƒè¼ªå»“é€²è¡Œè¿‘ä¼¼çš„æè¿°ï¼Œå…¶è¿‘ä¼¼æè¿°æ–¹æ³•
å¦‚å¼(15)æ‰€ç¤ºã€‚åœ–9ç‚ºæœ¬ç ”ç©¶æ¡ç”¨ 10,15,20n = å°æ­¥æ…‹å½±åƒè¼ªå»“é€²è¡Œè¿‘ä¼¼æè¿°æ‰€å¾—çš„çµæœã€‚ 
1
2 /
0
Ë†( ) ( )      0,1, , 1
n
j fk T
f
s k a f e k TÏ€
âˆ’
=
= = âˆ’âˆ‘ ï‹      (15) 
    
(a) (b) (c) (d) 
åœ– 9 å‚…ç«‹è‘‰æè¿°å­è¿‘ä¼¼æè¿°çµæœåœ–ï¼›(a)åŸåœ–ï¼Œ(b)n=10ï¼Œ(c)n=15ï¼Œ(d)n=20 
    11 
  
(a) (b) 
åœ– 12 NLPRè¡Œäººåˆ†å‰²å½±åƒ; (a) 0ï¯ï¼Œèˆ‡(b) 90ï¯  
 
(a) 
 
(b) 
 
(c) 
 
(d) 
 
(e) 
åœ– 13 æ¸¬è©¦åŸå½±åƒåºåˆ—ï¼›(a)å­•å©¦ï¼Œ(b)å­©ç«¥ï¼Œ(c)æˆäººï¼Œ(d)ä½¿ç”¨æŸºæ–çš„äººï¼Œèˆ‡(e)è€äºº 
 
æœ¬ç ”ç©¶æ‰€æä¹‹æ–¹æ³•ï¼Œå°æ–¼æ­£é¢èˆ‡å´é¢ç­‰å…©ç¨®è§’åº¦ä¹‹è¡Œäººèº«ä»½æ­£ç¢ºè­˜åˆ¥ç‡ (Correct 
Recognition Rate; CRR)çµæœå¦‚è¡¨1æ‰€ç¤ºã€‚ç”±è¡¨1å¯çŸ¥ï¼Œå°æ–¼å´é¢( 0ï¯ )æ‹æ”çš„è¡Œäººå½±åƒï¼Œå…¶èº«ä»½
è¾¨è­˜ç‡æœ€é«˜å¯é”90%ï¼Œå°æ–¼æ­£é¢æ‹æ”( 90ï¯ )çš„è¡Œäººå½±åƒå‰‡å¯é”åˆ°88.5%ä¹‹æ°´æº–ï¼Œå°æ–¼NLPRä¸­
20å€‹ä¸åŒèº«ä»½çš„è¡Œäººï¼Œå…¶è­˜åˆ¥ç‡é é é«˜æ–¼éš¨æ©ŸçŒœæ¸¬ä¹‹5%ç”šå¤šã€‚åœ–14(a)ã€(b)åˆ†åˆ¥ç‚ºæ­¥æ…‹èƒ½é‡
åœ–çµåˆèˆ‡ä¸çµåˆGabor Featureé€²è¡Œç‰¹å¾µæ“·å–ä¸‹è¡Œäººèº«ä»½è­˜åˆ¥ç‡ä¹‹æ¯”è¼ƒçµæœã€‚è¡¨2ç‚ºè¡Œäººæ—ç¾¤
åœ¨æ¡ç”¨ä¸åŒæ•¸é‡çš„å‚…ç«‹è‘‰æè¿°å­ï§ºæ³ä¸‹æ‰€å¾—çš„è¾¨è­˜ç‡ã€‚ 
    13 
[6] S. Yu, L. Wang, W. Hu, and T. Tan, â€œGait analysis for human identification in frequency 
domain,â€ In: Proc. of the IEEE Int. Conf. on Image and Graphics, Hong Kong, 2004, pp. 
282-285. 
[7] T. Y. Liao, S. G. Miaou, and Y. R. Li, â€œA vision-based walking posture analysis system 
without markers,â€ In: Proc. of the IEEE Int. Conf. on Signal Processing Systems, Dalian, 
China, 2010, Vol. 3, pp. 254-258. 
[8] S. Z. Su, L. Wang, and S. Z. Li, â€œInterframe variation vector-based gait recognition,â€ In: 
Proc. of the IEEE Int. Conf. on Intelligent System and Knowledge Engineering, Xiamen, 
China, 2008, pp.707-712. 
[9] M. H. Cheng, M. F. Ho, and C. L. Huang, â€œGait analysis for human identification through 
manifold learning and HMM,â€ Pattern Recognition, Vol. 41, No. 8, pp. 2541-2553, 2008. 
[10] R. Cucchiara, C. Grana, M. Piccardi, A. Prati, and S. Sirotti, â€œDetecting moving objects, 
ghosts, and shadows in video streams,â€ IEEE Transactions on Pattern Analysis and Machine 
Intelligence, Vol. 25, 2003, pp. 1337-1342. 
[11] D.Y. Huang, C.J. Lin, and W.C. Hu, â€œLearning-based face detection by adaptive switching 
of skin color models and AdaBoost under varying illuminationâ€, Journal of Information 
Hiding and Multimedia Signal Processing (JIHMSP), Vol. 2, 2011, pp. 204-216. 
[12] K. Bashir, T. Xiang, and S. Gong, â€œFeature selection for gait recognition without subject 
cooperationâ€, in: Proc. British Machine Vision Conference (BMVC2008), Leeds, UK, 
September 2008. 
[13] H. Y. Chen, C. L. Huang, and C. M. Fu, â€œHybrid-boost learning for multi-pose face 
detection and facial expression recognition,â€ Pattern Recognition, Vol. 41, 2008, 
pp.1173-1185. 
[14] V.N. Vapnik, â€œStatistical learning theoryâ€, John Wiley and Sons, Sep. 1998. 
[15] The CASIA Gait Database. Available from: <http://www.cbsr.ia.ac.cn/english/ 
Gait%20Databases.asp> 
ç™¼è¡¨è«–æ–‡ 
1. Deng-Yuan Huang, Wu-Chih Hu, Chuan-Wei Chuang, Mu-Song Chen, and Chien-Chuan 
Ko, â€œGait recognition of different people groups based on Fourier descriptor and support 
vector machine,â€ IEEE Proceedings of the 11th International Conference on Hybrid 
Intelligent Systems (HIS2011), Malacca, Malaysia, Dec. 5-8, 2011, pp. 601-604. (EI) 
2. é»ƒç™»æ·µã€æ—å¤§ç‚ºã€é„­è‡³ç¿”ã€ç‹å“²æ°‘ï¼Œâ€œåŸºæ–¼æ··åˆå¼ç‰¹å¾µæ“·å–ä¹‹æ­¥æ…‹è¡Œäººèº«ä»½è­˜åˆ¥æ–¹æ³•,â€
ç¬¬åä¸€å±†é›¢å³¶è³‡è¨ŠæŠ€è¡“èˆ‡æ‡‰ç”¨ç ”è¨æœƒè«–æ–‡é›†(ITAOI2012)ï¼Œæ¾æ¹–ï¼Œå°ç£ï¼ŒMay 25-26, 2012, 
pp. 641-646. 
3. Deng-Yuan Huang, Ta-Wei Lin, Wu-Chih Hu, and Chih-Hsiang Cheng, â€œGait recognition 
based on Gabor wavelet and support vector machine under pedestrian overlapping,â€ 
Proceedings of the 25th Conference on Computer Vision, Graphics and Image Processing 
(CVGIP2012), Nantou, Taiwan, Aug. 12-14, 2012. 
4. Deng-Yuan Huang, Ta-Wei Lin, and Wu-Chih Hu, â€œImplementation of multilevel 
thresholding process by histogram valleys estimation method based on FPGA,â€ Journal of 
Computers, Vol. 23, No. 3, pp. 1-15, October 2012. (EI) 
è¡¨ Y04 
å±•ï¼Œæœ¬äººæœ‰å¹¸èƒ½å¤ å¾—åˆ°åœ‹ç§‘æœƒè£œåŠ©åƒåŠ é€™æ¬¡å¤§æœƒï¼Œä¿ƒæˆæ­¤è¡Œï¼Œåœ¨æ­¤è¡¨é”ç”±è¡·è¬æ„ã€‚ 
  
 æœ¬äººæ–¼ 12æœˆ 4æ—¥æ—©ä¸Šç”±é«˜é›„å°æ¸¯åœ‹éš›æ©Ÿå ´è½‰æ©Ÿè‡³æ¡ƒåœ’åœ‹éš›æ©Ÿå ´å‡ºç™¼ï¼Œç¶“éå››å€‹åŠå°æ™‚çš„
é£›è¡Œåˆ°é”é¦¬ä¾†è¥¿äºå‰éš†å¡åœ‹éš›æ©Ÿå ´(Kuala Lumper Airport)ï¼Œå†æ­ä¹˜æ¥é§è»Šåˆ°é”ä¸‹æ¦»çš„ï¦ƒï¨¬- 
Istana Hotelã€‚è«–æ–‡ç™¼è¡¨æ™‚é–“å®‰æ’åœ¨ 12æœˆ 5æ—¥åˆ° 12æœˆ 8æ—¥èˆ‰è¡Œï¼Œä¸»è¾¦å–®ä½åœ¨è­°ç¨‹çš„å®‰æ’ï¼Œæœƒ
å ´è¨­å‚™çš„ä½ˆç½®ï¼Œå’Œäº¤é€šç­‰å„æ–¹é¢çš„å®‰æ’ï¨¦ç›¸ç•¶ç›¡å¿ƒç›¡ï¦Šï¼Œå› æ­¤æœƒè­°çš„é€²è¡Œå¾ˆé †åˆ©åœ“æ»¿ï¼Œå……ä»½
é”åˆ°ï¦ºè³‡è¨Šäº¤ï§Šå’Œå¢å»£ï¨Šèçš„ç›®çš„ã€‚å¤§æœƒé™¤ï¦ºè«–æ–‡ç™¼è¡¨çš„è­°ç¨‹ä¹‹å¤–ï¼Œä¹Ÿè²»å¿ƒå®‰æ’è¨±å¤šæ´»å‹•ï¼Œ
ä»¥ï¥¥è®“èˆ‡æœƒäººå£«èƒ½é€²ä¸€æ­¥ï¦ºè§£ç›¸é—œï¦´åŸŸç ”ç©¶ä¹‹æ‡‰ç”¨ã€‚ 
 
 å¤§æœƒåœ¨ 12æœˆ 6æ—¥æ™šä¸Šèˆ‰è¡Œæ™šå®´é¤æœƒï¼Œç”±æ–¼åƒåŠ çš„å­¸è€…ä¾†è‡ªä¸–ç•Œå„åœ‹ï¼Œè—‰ç”±æ™šå®´èªè­˜ï¦ºä¾†
è‡ªå—é TshwaneæŠ€è¡“å¤§å­¸(Tshwane University of Technology)çš„å­¸è€… Dr. K. Mpofuï¼Œä»–æ˜¯è©²æ ¡é«˜
ç­‰è£½é€ ä¸­å¿ƒçš„è² è²¬äºº(Advanced Manufacturing Research Leader)ï¼Œèˆ‡éæ´²åœ‹å®¶å¸ƒå‰ç´æ³•ç´¢çš„å­¸
è€… Dr. M. Ouedraogoç­‰äººï¼Œé€éç›¸äº’äº¤ï§Šï¼Œä¹Ÿè®“æˆ‘å€‘ç­è§£åˆ°ä»–å€‘çš„å­¸è¡“ç ”ç©¶èˆ‡é€²æ­¥çš„åœ°æ–¹ï¼Œ
çœŸæ˜¯å—ç›Šè‰¯å¤šï¼Œæœƒå¾Œå¤§å®¶ä¸¦äº¤æ›åç‰‡ä»¥ï¥¥æ—¥å¾Œä¿æŒï¦—ç¹«ã€‚ 
 
äºŒã€èˆ‡æœƒå¿ƒå¾— 
 
 æœ¬æ¬¡æœƒè­°è¨ˆæœ‰ 110å¤šç¯‡è«–æ–‡ç™¼è¡¨ï¼Œæ¶µè“‹çš„ä¸»é¡Œç¯„åœéå¸¸å»£æ³›ï¼ŒåŒ…å«æœ‰æ··åˆæ™ºæ…§ç³»çµ±(hybrid 
intelligent systems)ã€å½±åƒèˆ‡è¨Šè™Ÿè™•ç†è»Ÿæ€§è¨ˆç®—(soft computing)ã€æ™ºæ…§å‹ç¶²è·¯å»ºæ¨¡èˆ‡é€šè¨Šã€æ™ºæ…§
å‹è³‡æ–™æ¡ç¤¦(data mining)ã€æ§åˆ¶èˆ‡è‡ªå‹•åŒ–è»Ÿæ€§è¨ˆç®—ï¼Œèˆ‡å¤šé‡ä»£ç†ç³»çµ±èˆ‡æ‡‰ç”¨(multi agent systems 
and applications)ç­‰ä¸»é¡Œï¼Œæ˜¯ä¸€å€‹æ¢è¨æ··åˆæ™ºæ…§ç³»çµ±çš„åœ‹éš›ç ”è¨æœƒã€‚åœ¨æœ¬æ¬¡å¤§æœƒä¸­ï¼Œæœ¬äººåƒåŠ 
ç”±é«˜æ‡‰å¤§å­¸è€…æ—å¨æˆæ•™æˆæ‰€çµ„çš„ Section: Intelligent data analysis and applicationsã€‚åœ¨æœ¬è­°ç¨‹ä¸­
ç¸½å…±æœ‰ 6 ç¯‡è«–æ–‡ç™¼è¡¨ï¼Œæœ¬äººåœ¨æ­¤æ¬¡å¤§æœƒç™¼è¡¨çš„è«–æ–‡é¡Œç›®ç‚ºã€ŒåŸºæ–¼å‚…åˆ©è‘‰æè¿°å­èˆ‡æ”¯æŒå‘é‡æ©Ÿ
ä¹‹ä¸åŒæ—ç¾¤æ­¥æ…‹è­˜åˆ¥(Gait Recognition of Different People Groups Based on Fourier Descriptor 
and Support Vector Machine)ã€ã€‚å› ç‚ºæœ¬äººç›®å‰çš„ç ”ç©¶ï¦´åŸŸè¼ƒåå‘æ–¼åœ–åƒè­˜åˆ¥èˆ‡åˆ†é¡ã€èšé¡ç­‰ï¦´
åŸŸä¸Šï¼Œæ•…ç­†è€…å¤§å¤šåƒèˆ‡å¤§æœƒä¸­å’Œåœ–åƒè­˜åˆ¥èˆ‡åˆ†é¡ã€èšé¡æœ‰é—œçš„ä¸»è¦å ´æ¬¡ï¼Œä»¥åŠåœ¨æ™ºæ…§å‹è¨ˆç®—
ç›¸é—œä¹‹æ‡‰ç”¨ä¸Šï¼Œé€™äº›å ´æ¬¡å¹³å‡åˆ†ä½ˆæ–¼ 12/5è‡³ 12/8ã€‚ç¶œè§€æœ‰é—œåœ–åƒè­˜åˆ¥èˆ‡åˆ†é¡ã€èšé¡ã€æ™ºæ…§å‹
è¨ˆç®—çš„ä¸»é¡ŒåŠé‡é»ï¼Œå¯ä»¥æ­¸ç´å¦‚ä¸‹ï¼š 
a. ç‰¹å¾µé¸æ“‡åˆ†æ(Feature selection analysis) 
b. æ¨¡ç³Šæ··åˆåŒ–ä¹‹åœ–å½¢è­˜åˆ¥(Fuzzy hybridization for pattern recognition) 
è¡¨ Y04 
 
äº”ã€æ”œå›è³‡æ–™åç¨±åŠå…§å®¹ 
 
ä¸‹åˆ—ç‚ºæ”œå¸¶å›åœ‹ä¹‹è³‡æ–™ï¼Œå…§å®¹çš†ç‚ºæ­¤æ¬¡ç ”è¨æœƒè­°æ‰€ç™¼è¡¨ä¹‹è«–æ–‡ã€‚ 
HIS2011è«–æ–‡å…‰ç¢Ÿä¸€ç‰‡ã€è­°ç¨‹æ‰‹å†Šä¸€æœ¬èˆ‡è«–æ–‡æ‘˜è¦æ‰‹å†Šä¸€æœ¬ 
 
å…­ã€å…¶ä»– 
 
(ç•¥) 
Figure 1. The proposed method of gait recognition for different people 
groups 
A. Background Modeling 
The principle of background modeling is simple in that 
we can consider the pixel to be a background point if the 
change of gray intensity of that pixel between adjacent 
frames is small or approaching to zero. Therefore, the 
temporal difference of frames is utilized to find the pixels 
with small change in gray intensity between consecutive 
frames. The pixel in background is determined as. 
 11 ( , ) ( , ) ( , )( , )     1
0
t t
t
if F x y F x y Th x y
BP x y t
otherwise
Â­  Â° t  Â®
Â°Â¯
where  represents that the pixel of  in 
current frame t  is a background pixel if the intensity change 
is less than the threshold  of which the value is 
different pixel by pixel, and it is determined adaptively, 
t
( , ) 1tBP x y  
)
( , )p x y
( , )Th x y
( ,F x y  and 1( ,t )F x y
t

( , )x y
 are gay intensities in current frame 
t  and previous frame 1 , respectively. Therefore, the gray 
intensity of pixels in background for current frame t , i.e., 
, is calculated as. 

tBG
  ),(),(),( yxFyxBPyxBG ttt u 
The average of T frames for each pixel is further 
carried out to represent the image of absolute background 
.
( , )p x y
( , )TBG x y
  
1 1
( , ) ( , ) / ( , )
T T
T t t
t t
BG x y BG x y BP x y
  
 Â¦ Â¦
Figure 2. Result of background modeling. (a) Original image, and 
modeling absolute background using (b) 5 frames, and (c) 10 frames. 
To determine the threshold  adaptively, 
temporal update of this parameter is given as. 
( , )Th x y
 1 1( , ) ( 1) ( ( , ) ( , ))( , )   1t t tt
Th x y t F x y F x y
Th x y t
t
 u   Âª Âº tÂ« Â»Â« Â»
 
where the initial value is set to 0. The result of 
background modeling is shown in Fig. 2. 
0 ( , )Th x y
B. Motion Detection by Background Subtraction 
The purpose of motion detection is to segment the gait 
silhouette of a walking people from their absolute 
background. The idea of background subtraction is quite 
direct in that the change in gray intensity of pixels is 
noticeable if objects appear rightly in these pixels. Therefore, 
the shape of gait silhouette is detected as. 

1 ( , ) ( , )
( , )
0
t B
t
if F x y B x y Th
D x y
otherwise
Â­  t
 Â®
Â¯
 
where  is a gray level of absolute background at 
pixel ,
( , )B x y
( , )p x y BTh
t
 is a threshold value set to 23 by 
experiments, and D x  is a resulting binary image for 
extracting the gait silhouette of a walking people. However, 
since the segmented clusters in  are not always 
complete, morphological processing, including the methods 
of erosion and dilation, is further performed. The result of 
motion detection using background subtraction is shown in 
Fig. 3. 
( , )y
( , )tD x y
Figure 3. Result of motion detection. (a) Absolute image, (b) current 
image, (c) result of background subtraction, and (d) result after 
morphological processing in (c). 
C. Shadow Removal 
The foreground pixels can be considered as shadow 
pixels if their gray intensities are darker than those in 
background [12], which is primarily caused by non-uniform 
illumination on motion objects.  Shadow often leads to the 
deformation of the shape of human gait silhouette, and thus it 
unavoidably increases the erroneous recognition rate of 
human gait. Hence, the method inspired by [12] is proposed 
to effectively remove the influence of shadow on motion 
objects as. 
602 2011 11th International Conference on Hybrid Intelligent Systems (HIS)
gait silhouettes. The highest CRR of 81.0% in the case of 
n=20 were obtained, indicating the feasibility of the 
proposed method. 
Figure 5. Video sequences of 5 different people groups. (a) The pregnant, 
(b) the child, (c) the adult, (d) people with a walking stick, and (e) the aged. 
To analyze the misclassification of gait silhouettes for the 
5 different people groups, a confusion matrix of CRR is 
analyzed, as listed in Table I, from which the three groups of 
the adult, the people with a walking stick, and the aged are 
most confused of having the highest misclassification rate of 
16.6% due to their similar silhouettes in shape. For the 
people group with a walking stick, when the walking stick is 
occluded by walkerâ€™s body, this group can be easily 
recognized as the groups of the adult and the aged. Thus, 
high misclassification rates can arise. Moreover, the two 
groups of the adult and the children are similar in shape but 
different in scale. This result causes a misclassification rate 
of 13.3% between them since the shape of the two groups is 
similar described by the FDs that has the favorable property 
of scale invariance. 
TABLE I. CONFUSION MATRIX OF CORRECT RECOGNITION RATE FOR 
THE CASE OF n=20 FOURIER DESCRIPTORS
The 
pregnant 
The 
children
The 
adult
People/w
walking
stick
The aged
The 
pregnant 
93.4% 0 6.6% 0 0 
The 
children
0 86.7% 13.3% 0 0 
The 
adult
0 0 75.1% 16.6% 8.3% 
People/w
walking
stick
0 0 16.6% 66.8% 16.6% 
The aged 5.0% 0 11.6% 0 83.4% 
IV. CONCLUSION AND FUTURE WORK
In this paper, we have proposed a novel method of 
recognizing the gait silhouettes for different people groups. 
The correct recognition rate of 81% is obtained using only 
the first 20 coefficients of FDs, indicating the feasibility of 
the proposed method. However, the three groups of the adult, 
the people with a walking stick, and the aged for the test 
video sequences have a similar shape, especially when the 
walking stick is occluded by walkerâ€™s body, to cause an 
erroneous recognition rate of 20% between them. Hence, the 
increase of discriminability between the three groups can 
leave as the future work to improve the recognition rate of 
gait silhouettes for different people groups. 
ACKNOWLEDGMENT
This work is partly supported by a grant from National 
Science Council, Taiwan, under contract NSC-100-2221-E-
212-020. 
REFERENCES
[1] Z. Hong, Z. Jun, and Zhijing, â€œA new method of pedestrian gait 
classification,â€ in: Proc. IEEE Int. Conf. on Educational and 
Information Technology, Chongqing, China, 2010, Vol. 3, pp. 268-
272. 
[2] E.H. Zhang, H.B. Ma, J.W. Lu, and Y.J. Chen, â€œGait recognition 
using dynamic gait energy and PCA+LPP methodâ€, in: Proc. IEEE Int. 
Conf. on Machine Learning and Cybernetics, Baoding, China, 2009, 
pp. 50-53. 
[3] X.T. Chen, Z.H. Fan, H. Wang, and Z.Q. Li, â€œAutomatic gait 
recognition using kernel principal component analysisâ€, in: Proc. 
IEEE Int. Conf. on Biomedical Engineering and Computer Science, 
Wuhan, China, 2010. 
[4] S.D. Mowbray, and M.S. Nixon, â€œAutomatic gait recognition via 
Fourier descriptors of deformable objects,â€ LNCS 2688, pp. 566â€“573, 
2003. 
[5] Z. Ling, C. Zhao, Q. Pan, Y. Wang, and Y. Cheng, â€œAnalyzing 
human movements from silhouettes via Fourier descriptor,â€ in: Proc. 
IEEE Int. Conf. on Automation and Logistics, Jinan, China, 2007, pp. 
231-236. 
[6] D. Xiao, and L. Yang, â€œGait recognition using Zernike moments and 
BP neural network,â€ in: Proc. IEEE Int. Conf. on Networking, 
Sensing and Control, Sanya, China, 2008, pp. 418-423. 
[7] B. Ye, and Y.M. Wen, â€œGait recognition based on DWT and SVM,â€ 
in: Proc. IEEE Int. Conf. on Wavelet Analysis and Pattern 
Recognition, Beijing, China, 2007, Vol. 3, pp. 1382-1387. 
[8] X. Yang, J. Dai, Y. Zhou, and J. Yang, â€œGabor-based discriminative 
common vectors for gait recognition,â€ in: Proc. IEEE Int. Conf. on  
Image and Signal Processing, Sanya, China, 2008, Vol. 4, pp. 191-
195. 
[9] J. Wu, J. Wang, and L. Liu, â€œFeature extraction via KPCA for 
classification of gait patterns,â€ Human Movement Science, Vol. 26, 
No. 3, June 2007, pp. 393-411. 
[10] J. Wu, â€œA novel approach for discrimination of human gait using 
kernel learning algorithm,â€ in: Proc. IEEE Int. Conf. on Natural 
Computation, Fuzhou, China, 2010, Vol. 6, pp. 3253-3256. 
[11] P.R.G. Harding, and T.J. Ellis, â€œRecognizing hand gesture using 
Fourier descriptors,â€ in: Proc. IEEE Int. Conf. on Pattern Recognition, 
Cambridge, UK, 2004, Vol. 3, pp. 286-289. 
[12] R. Cucchiara, C. Grana, M. Piccardi, A. Prati, and S. Sirotti, 
â€œDetecting moving objects, ghosts, and shadows in video streams,â€ 
IEEE Transactions on Pattern Analysis and Machine Intelligence, Vol. 
25, Oct. 2003, pp 1337-1342. 
[13] R.E. Fan, P.H. Chen, and C.J. Lin. â€œWorking set selection using 
second order information for training SVM,â€ Journal of Machine 
Learning Research, Vol. 6, 2005, pp. 1889-1918. 
604 2011 11th International Conference on Hybrid Intelligent Systems (HIS)
100ï¦ï¨å°ˆé¡Œç ”ç©¶è¨ˆç•«ç ”ç©¶æˆæœå½™æ•´è¡¨ 
è¨ˆç•«ä¸»æŒäººï¼šé»ƒç™»æ·µ è¨ˆç•«ç·¨è™Ÿï¼š100-2221-E-212-020- 
è¨ˆç•«åç¨±ï¼šå¤šåŠŸèƒ½æ•´åˆå¼è¦–è¨Šç›£æ§ç³»çµ±æ–¼è³¼ç‰©å•†å ´ä¹‹æ‡‰ç”¨ 
ï¥¾åŒ– 
æˆæœé …ç›® å¯¦éš›å·²é”æˆ
ï¥©ï¼ˆè¢«æ¥å—
æˆ–å·²ç™¼è¡¨ï¼‰
é æœŸç¸½é”æˆ
ï¥©(å«å¯¦éš›å·²
é”æˆï¥©) 
æœ¬è¨ˆç•«å¯¦
éš›è²¢ç»ç™¾
åˆ†æ¯” 
å–®ä½ 
å‚™ è¨» ï¼ˆ è³ª åŒ– ï¥¯
æ˜ï¼šå¦‚ï¥©å€‹è¨ˆç•«
å…±åŒæˆæœã€æˆæœ
ï¦œ ç‚º è©² æœŸ åˆŠ ä¹‹
å° é¢ æ•… äº‹ ...
ç­‰ï¼‰ 
æœŸåˆŠï¥æ–‡ 1 1 100%  
ç ”ç©¶å ±å‘Š/æŠ€è¡“å ±å‘Š 0 0 100%  
ç ”è¨æœƒï¥æ–‡ 2 2 100% 
ç¯‡ 
 
ï¥æ–‡è‘—ä½œ 
å°ˆæ›¸ 0 0 100%   
ç”³è«‹ä¸­ä»¶ï¥© 0 0 100%  å°ˆï§ å·²ç²å¾—ä»¶ï¥© 0 0 100% ä»¶  
ä»¶ï¥© 0 0 100% ä»¶  
æŠ€è¡“ç§»è½‰ 
æ¬Šï§ï¤Š 0 0 100% åƒå…ƒ  
ç¢©å£«ç”Ÿ 1 1 100%  
åšå£«ç”Ÿ 1 1 100%  
åšå£«å¾Œç ”ç©¶å“¡ 0 0 100%  
åœ‹å…§ 
ï¥«èˆ‡è¨ˆç•«äººï¦Š 
ï¼ˆæœ¬åœ‹ç±ï¼‰ 
å°ˆä»»åŠ©ï§¤ 0 0 100% 
äººæ¬¡ 
 
æœŸåˆŠï¥æ–‡ 0 0 100%  
ç ”ç©¶å ±å‘Š/æŠ€è¡“å ±å‘Š 0 0 100%  
ç ”è¨æœƒï¥æ–‡ 1 1 100% 
ç¯‡ 
 
ï¥æ–‡è‘—ä½œ 
å°ˆæ›¸ 0 0 100% ç« /æœ¬  
ç”³è«‹ä¸­ä»¶ï¥© 0 0 100%  å°ˆï§ å·²ç²å¾—ä»¶ï¥© 0 0 100% ä»¶  
ä»¶ï¥© 0 0 100% ä»¶  
æŠ€è¡“ç§»è½‰ 
æ¬Šï§ï¤Š 0 0 100% åƒå…ƒ  
ç¢©å£«ç”Ÿ 0 0 100%  
åšå£«ç”Ÿ 0 0 100%  
åšå£«å¾Œç ”ç©¶å“¡ 0 0 100%  
åœ‹å¤– 
ï¥«èˆ‡è¨ˆç•«äººï¦Š 
ï¼ˆå¤–åœ‹ç±ï¼‰ 
å°ˆä»»åŠ©ï§¤ 0 0 100% 
äººæ¬¡ 
 
åœ‹ç§‘æœƒè£œåŠ©å°ˆé¡Œç ”ç©¶è¨ˆç•«æˆæœå ±å‘Šè‡ªè©•è¡¨ 
è«‹å°±ç ”ç©¶å…§å®¹èˆ‡åŸè¨ˆç•«ç›¸ç¬¦ç¨‹ï¨ã€é”æˆé æœŸç›®æ¨™æƒ…æ³ã€ç ”ç©¶æˆæœä¹‹å­¸è¡“æˆ–æ‡‰ç”¨åƒ¹
å€¼ï¼ˆç°¡è¦æ•˜è¿°æˆæœæ‰€ä»£è¡¨ä¹‹æ„ç¾©ã€åƒ¹å€¼ã€å½±éŸ¿æˆ–é€²ä¸€æ­¥ç™¼å±•ä¹‹å¯èƒ½æ€§ï¼‰ã€æ˜¯å¦é©
åˆåœ¨å­¸è¡“æœŸåˆŠç™¼è¡¨æˆ–ç”³è«‹å°ˆï§ã€ä¸»è¦ç™¼ç¾æˆ–å…¶ä»–æœ‰é—œåƒ¹å€¼ç­‰ï¼Œä½œä¸€ç¶œåˆè©•ä¼°ã€‚
1. è«‹å°±ç ”ç©¶å…§å®¹èˆ‡åŸè¨ˆç•«ç›¸ç¬¦ç¨‹ï¨ã€é”æˆé æœŸç›®æ¨™æƒ…æ³ä½œä¸€ç¶œåˆè©•ä¼° 
â– é”æˆç›®æ¨™ 
â–¡æœªé”æˆç›®æ¨™ï¼ˆè«‹ï¥¯æ˜ï¼Œä»¥ 100å­—ç‚ºé™ï¼‰ 
â–¡å¯¦é©—å¤±æ•— 
â–¡å› æ•…å¯¦é©—ä¸­æ–· 
â–¡å…¶ä»–åŸå›  
ï¥¯æ˜ï¼š 
2. ç ”ç©¶æˆæœåœ¨å­¸è¡“æœŸåˆŠç™¼è¡¨æˆ–ç”³è«‹å°ˆï§ç­‰æƒ…å½¢ï¼š 
ï¥æ–‡ï¼šâ– å·²ç™¼è¡¨ â–¡æœªç™¼è¡¨ä¹‹æ–‡ç¨¿ â–¡æ’°å¯«ä¸­ â–¡ç„¡ 
å°ˆï§ï¼šâ–¡å·²ç²å¾— â–¡ç”³è«‹ä¸­ â– ç„¡ 
æŠ€è½‰ï¼šâ–¡å·²æŠ€è½‰ â–¡æ´½è«‡ä¸­ â– ç„¡ 
å…¶ä»–ï¼šï¼ˆä»¥ 100å­—ç‚ºé™ï¼‰ 
3. è«‹ä¾å­¸è¡“æˆå°±ã€æŠ€è¡“å‰µæ–°ã€ç¤¾æœƒå½±éŸ¿ç­‰æ–¹é¢ï¼Œè©•ä¼°ç ”ç©¶æˆæœä¹‹å­¸è¡“æˆ–æ‡‰ç”¨åƒ¹
å€¼ï¼ˆç°¡è¦æ•˜è¿°æˆæœæ‰€ä»£è¡¨ä¹‹æ„ç¾©ã€åƒ¹å€¼ã€å½±éŸ¿æˆ–é€²ä¸€æ­¥ç™¼å±•ä¹‹å¯èƒ½æ€§ï¼‰ï¼ˆä»¥
500å­—ç‚ºé™ï¼‰ 
æœ¬ç ”ç©¶è¨ˆç•«åŸç”³è«‹ä¸‰å€‹å­è¨ˆç•«ï¼Œé è¨ˆæ–¼ä¸‰ï¦å…§å®Œæˆï¼Œåˆ†åˆ¥ç‚ºã€Œå¼±å‹¢æ—ç¾¤ï§¼åˆ¥ç³»çµ±è¼”åŠ©è³¼ç‰©
å•†å ´æ–¼æœå‹™äººï¦Šä¹‹èª¿ï¨ã€ã€ã€Œæ€§åˆ¥ï§¼åˆ¥ç³»çµ±è¼”åŠ©è³¼ç‰©å•†å ´æ–¼äº’å‹•å¼å‹•æ…‹å»£å‘Šæ’­æ”¾ç³»çµ±ä¹‹é–‹
ç™¼ã€èˆ‡ã€Œæ‰‹å‹¢ï§¼åˆ¥ç³»çµ±è¼”åŠ©è³¼ç‰©å•†å ´æ–¼äº’å‹•å¼å‹•æ…‹å»£å‘Šæ’­æ”¾ç³»çµ±ä¹‹æ“æ§ã€ï¼Œä½†å› åªæ ¸å®šé€š
éç¬¬ä¸€å€‹å­è¨ˆç•«ï¼Œå› æ­¤å°‡åƒ…å°±è©²è¨ˆç•«ä¹‹åŸ·ï¨ˆæˆæœï¤­é€²ï¨ˆè‡ªè©•ã€‚æœ¬è¨ˆç•«åŸç›®æ¨™è¨­å®šåœ¨å»ºï§·ä¸€
å…·æœ‰ï¨ˆäººæ—ç¾¤åˆ†ï§èƒ½ï¦Šä¹‹æ–¹æ³•ï¼Œä½†ç¶“éå¯¦éš›ç ”ç©¶éç¨‹ç™¼ç¾ï¼Œï¥´åƒ…å°‡ï¨ˆäººç‰¹å¾µé‹ç”¨åœ¨æ—ç¾¤åˆ†
ï§ä¹‹ä¸Šï¼Œä¸¦ç„¡æ³•å¾¹åº•ä¸”æœ‰æ•ˆçš„ç™¼æ®æ­¥æ…‹ç‰¹å¾µæ‰€æœ‰çš„ç‰¹æ€§ã€‚æ•…æœ¬ç ”ç©¶é€²ä¸€æ­¥å°‡æ­¥æ…‹ç‰¹å¾µé‹ç”¨
åœ¨ï¨ˆäººèº«åˆ†ï§¼åˆ¥ä¹‹ä¸Šï¼Œè‡´ï¦Šæ–¼å°‡æ­¥æ…‹ç‰¹å¾µæ‰€å…·æœ‰çš„ç‰¹è‰²ç™¼æ®åˆ°æ¥µé™ã€‚ 
 
å› ä¸Šè¿°ï§¤ç”±ï¼Œæ•…å¯¦éš›å¯¦ç¾æ­¤ç³»çµ±æ™‚ï¼Œæœ¬ç ”ç©¶å°‡æ­¥æ…‹ç‰¹å¾µåŒæ™‚é‹ç”¨åœ¨æ—ç¾¤åˆ†ï§èˆ‡èº«ä»½ï§¼åˆ¥ï¥¸
éƒ¨åˆ†ï¼›åœ¨æ—ç¾¤åˆ†ï§ä¸­ï¼Œç‚ºèƒ½æœ‰æ•ˆçš„å°‡å„æ—ç¾¤é€²ï¨ˆåˆ†ï§ï¼Œæœ¬ç ”ç©¶æ¡ç”¨å‚…ï§·ï¥®æè¿°å­æ–¹æ³•åšç‚º
å„æ—ç¾¤çš„æ­¥æ…‹ç‰¹å¾µè¡¨ç¤ºæ–¹æ³•ã€‚å› å‚…ï§·ï¥®æè¿°å­å…·æœ‰å°ºï¨ã€æ—‹è½‰èˆ‡å¹³ç§»ï¥§è®Šçš„ç‰¹æ€§ï¼Œæ•…èƒ½æœ‰
æ•ˆçš„å°ï¥§åŒæ”å½±æ©Ÿè·ï§ªçš„ï¨ˆäººé€²ï¨ˆï§¼åˆ¥ï¼ŒåŒæ™‚èƒ½è§£æ±ºå…’ç«¥èˆ‡æˆäººä¹‹é–“å·®ï¥¢éå°çš„å•é¡Œã€‚åœ¨
èº«åˆ†ï§¼åˆ¥æ–¹é¢ï¼Œæœ¬ç ”ç©¶æ¡ç”¨ä¸€è¤‡åˆå¼ç‰¹å¾µè¡¨ç¤ºæ–¹æ³•ï¼ŒæˆåŠŸçš„å°å„ç¨®è§’ï¨ä¸‹çš„ï¨ˆäººé€²ï¨ˆèº«åˆ†
çš„è¾¨ï§¼ã€‚ç”±å¯¦é©—çµæœï¤­è©•ä¼°ç•¶åˆåŸè¨ˆç•«æ‰€è¨­å®šä¹‹ç›®æ¨™ï¼Œæ‡‰å·²å®Œå…¨é”åˆ°é æœŸä¹‹ç›®æ¨™ã€‚ 
 
æœ¬ç ”ç©¶æ‰€æä¹‹æ­¥æ…‹ç‰¹å¾µèº«åˆ†ï§¼åˆ¥èˆ‡æ—ç¾¤åˆ†ï§æ–¹æ³•ï¼Œå…·æœ‰ï¨ˆäººè§’ï¨è®ŠåŒ–é©æ‡‰æ€§èˆ‡ç‰¹å¾µï¥§è®Šæ€§
ä¹‹èƒ½ï¦Šï¼Œæ‰€ä»¥æœ¬ç ”ç©¶æˆæœå¯æ‡‰ç”¨æ–¼ä»»ä½•çœŸå¯¦ã€ç„¡é™åˆ¶æ¢ä»¶ä¸‹ä¹‹æ¸¬è©¦ç’°å¢ƒã€‚æ ¹æ“šä»¥ä¸Šï¥é»ï¼Œ
æœ¬ç ”ç©¶æ–¹æ³•æ¥µå…·å­¸è¡“èˆ‡æ‡‰ç”¨åƒ¹å€¼ï¼Œå…¶æˆæœç•¶ç„¶é©åˆæ–¼åœ‹éš›ç ”è¨æœƒèˆ‡åœ‹éš›æœŸåˆŠï¤­é€²ï¨ˆç™¼è¡¨ã€‚
