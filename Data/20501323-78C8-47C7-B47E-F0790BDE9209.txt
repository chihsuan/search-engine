retrieved results. Following the first step, we then 
continue to conduct the Support Vector Regression 
(SVR) training on the pairs of documents with Same 
Rank and Different Category (SRDC). That is, starting 
with the output values of the first classification 
model, the second step performs SVR on the SRDC 
pairsï¼› therefore, this practice will result in 
pulling the pairs of documents in the different 
categories as close as possible, which directly put 
the concept of diversity into the learned model. In 
addition, we also propose a novel retrieval model 
based on Post-modern Portfolio Theory. The proposed 
model also has the ability of diversifying retrieval 
results, and we attempt to combine the model with the 
learning-to-ranking techniques for the diversity 
task. 
è‹±æ–‡é—œéµè©ï¼š Information Machine Learning, Diversified Retrieval, 
Support Vector Machine, Portfolio Theory 
 
a document being relevant conditioned on the other documents in its front. They propose an objective
function capable of considering the diversification of retrieved results, and the function can also focus
on retrieving at least one relevant document for all users. In [12], Radlinski et al. propose a learning
algorithm to compute a set of retrieved results from a diverse set of orderings. By iterating through
all documents in each of the positions while holding fixed the documents in the other positions, they
attempt to learn a best ranking of documents using user click-through data. By means of the ability
that the user click-through data can diminish the value of similar documents, their approach can
naturally produces a diverse set of results. In [3], Clarke et al. study diversification in the context
of answering questions. They focus on developing a framework of evaluation that takes into account
both novelty and diversity. In this work, questions and answers are treated as sets of â€œinformation
nuggets,â€ and relevance is a function of the nuggets contained in the questions and the answers. In
addition, they also propose a novel metrics, Î±-DCG, capable of taking into account both diversity and
relevance, thereby can better reflect the ranking quality and diversity within the retrieved results. We
also use this metric for the assessment of our proposed approach.
2 Methodology
ç ”ç©¶æ–¹æ³•
In Ranking SVM [9], the ranking problem for document retrieval can be represented as the following
constrained optimization problem:
min
1
2
~Ï‰ Â· ~Ï‰ + C
âˆ‘
Î¾i,j,k
s.t.
{ âˆ€(di, dj) âˆˆ râˆ—k : ~Ï‰Î¦(qk, di) â‰¥ ~Ï‰Î¦(qk, dj) + 1âˆ’ Î¾i,j,k
âˆ€iâˆ€jâˆ€k : Î¾i,j,k â‰¥ 0
, (1)
where Î¦(q, d) is a feature vector obtained from document d with respect to query q. If we rearrange
the constraints as:
~Ï‰(Î¦(qk, di)âˆ’ Î¦(qk, dj)) â‰¥ 1âˆ’ Î¾i,j,k, (2)
the above optimization problem can be casted as the classification problem of SVM on all document
pairs (di, dj) with different ranks râˆ—.
Unlike the conventional Ranking SVM, the proposed two-step Ranking SVM consists of two
training phases: In the first step, with the taxonomy information, Support Vector Classification (SVC)
is carried on the document pairs with Different Ranks but the Same Category (DRSC) to produce a
ranking model. In the second step, to diversify ranking results, the ranking model continues to be
trained by Support Vector Regression (SVR) on the document pairs with the Same Rank but Different
Categories (SRDC). With the aid of taxonomy information, the proposed approach focuses on differ-
ent types of pairs in different steps for the goal of diversification. Below we describe the intuition
behind our method in details.
Instead of conducting SVC training on all different-rank pairs, the first step performs SVC training
on DRSC pairs only. This practice is due to the following benefits: First, this way indirectly includes
diversity by separating documents in the same category. Because of the margin-maximization spe-
cialty of SVM, conducting SVC on DRSC pairs will permit the learned model to not only separate the
documents with different ranks, but also keep the documents in the same category as away as possible.
Second, this way is consistent with the nature of comparison that under the same category, objects
are more reasonable for comparison. Third, this way leads to more efficient training time because the
number of DRSC pairs is fewer than that of all different-rank pairs.
Once a ranking model has been obtained in the first step, the second step continues to conduct
SVR training on the ranking model by using the SRDC pairs. Specifically, starting with the output
values of the first-step model, the second step performs -SVR on the SRDC pairs. This step is mainly
2
Table 1: Performances of NDCG@15, CR@15, Î±-DCG@15, and MAP: All numbers are average
values over 5 folds. Numbers in brackets indicate the p-value from a paired one-tailed t-test. Bold
faced numbers indicate that the entry is statistically significant from the run of Ranking SVM at 95%
confidence level.
Methods NDCG@15 CR@15 Î±-DCG@15 MAP
Ranking SVM 0.423 0.535 4.294 0.433
SVC only 0.446 (0.01) 0.543 (0.21) 4.614 (0.01) 0.450 (2e-4)
SVC+SVR 0.440 (0.05) 0.554 (0.04) 4.562 (0.04) 0.445 (0.01)
3.2 Experimental Results
In addition to NDCG and MAP, we also use Category Recall (CR) and Î±-DCG to evaluate the diversity
within the retrieved results. Among these four metrics, NDCG and MAP are mainly for the evaluation
of ranking quality, CR is for diversity, and Î±-DCG is an in-between version. Since diversity cannot
just be presented in a few top ranks, we focus on the performance at position 15. Notice that the value
of CR is 5
15
if there are 5 different categories within top 15 results. For Î±-DCG, the parameter of Î± is
set to 0.5; for more details about Î±-DCG, please refer to [3].
Table 1 lists the performance of three referenced approaches including Ranking SVM, SVC only,
and SVC+SVR. Note that the parameters of the three methods are all tuned on the validation datasets
provided in LETOR. The method of SVC only, as indicated in the table, indeed improves diversity in
terms of CR@15 because of the indirect injection of diversity by separating DRSC pairs; however, the
improvement is not significant. By further retraining the ranker, the method of SVC+SVR eventually
enhances diversity significantly while maintaining the ranking quality in terms of all criteria. These
results are consistent with the discussions in Section 2.
3.3 Summary
This work proposes a two-step Ranking SVM for diversifying ranking results. With the aid of tax-
onomy information, the proposed method focuses on different types of pairs in different steps for the
goal of diversification. According to our experimental results, the two-step method of SVC+SVR not
only improves ranking quality, but also diversifies the retrieved results with varied categories. In the
following section, we attempt to use another retrieval model based on portfolio theory to deal with
the problem.
4 Extension Work:
Post-Modern Portfolio Theory for Information Retrieval
å»¶ä¼¸å·¥ä½œï¼šå¾Œç¾ä»£æŠ•è³‡çµ„åˆç†è«–ä¹‹æª¢ç´¢æ¨¡å‹
4.1 Introduction
In general, the process of retrieving information consists of two phases. In the first phase, probabilistic
retrieval models [13] compute the relevance between a given userâ€™s information need (query) and each
of the documents in a collection. The second phase focuses on how to rank the calculated documents;
the classic Probability Ranking Principle (PRP) [4] forms the theoretical basis of this phase, which
ranks the documents with the order of decreasing probabilities of relevance to the query. However, the
ranking principle neglects the uncertainty associated with the relevance of the documents to the query;
the uncertainty may result from various sources, such as specific user preferences and ambiguity
within a query. Take the query â€œjaguarâ€ as an example. This query may refer to the Jaguar Cars
company, the Apple Jaguar operation system, the Fender Jaguar electric guitar, or the felines. For
4
where V arâˆ’(Rn) (V ar+(Rn)) denotes the downside (upside, respectively) variance of the overall rel-
evance. Unlike the variance defined in Eq. (3), which can be calculated exogenously, the semivariance
is endogenous. As a result, we use the approximation proposed by [5] to calculate V arQ(Rn):
V arQ(Rn) â‰ˆ
nâˆ‘
i=1
nâˆ‘
i=1
wiwj cË†i,j,
where
cË†i,j =
{
E [Min (ri âˆ’ E[ri], 0)Ã—Min(rj âˆ’ E[rj], 0)] , if Q = âˆ’,
E [Max (ri âˆ’ E[ri], 0)Ã—Max(rj âˆ’ E[rj], 0)] , if Q = +.
(4)
Optimization for the Ranking List
To optimize the effectiveness of a ranking list with the summary statistics, mean and semivariance,
the objective function for the optimization is
max An = E[Rn]âˆ’ aÃ— V arQ(Rn), (5)
where a denotes the risk preference parameter and Q â‰¡ sgn[a]. Note that for a risk-averse solution,
a < 0 and for a risk-loving solution, a > 0; additionally, with a = 0, documents are ranked by the
PRP.
Since the weight wi for each document is a discrete variable, it is hard to directly optimize the
objective function in Eq. (5). Therefore, the greedy algorithm in [14] is adopted to optimize the
objective function. The difference of the objective function from the position k âˆ’ 1 to k is
Ak âˆ’ Akâˆ’1 = E[Rk]âˆ’ aÃ— V arQ(Rk)âˆ’ E[Rkâˆ’1] + aÃ— V arQ(Rkâˆ’1)
=
kâˆ‘
i=1
wiE[ri]âˆ’ a
kâˆ‘
i=1
kâˆ‘
i=1
wiwj cË†i,j âˆ’
kâˆ’1âˆ‘
i=1
wiE[ri] + a
kâˆ‘
i=1
kâˆ’1âˆ‘
i=1
wiwj cË†i,j
= wk(E[rk]âˆ’ awkcË†kk âˆ’ 2a
kâˆ’1âˆ‘
i=1
wicË†i,k). (6)
The i-th ranked document for i âˆˆ {2, 3, Â· Â· Â· , n} is selected to maximize the difference Ai âˆ’ Aiâˆ’1 in
Eq. (6). (Note that the first document (i = 1) is set to the document with the highest relevance score.)
Calculation of Means and Semicovariance Matrix
Different retrieval models generate different estimators of E[Rn] and V arQ(Rn). In the following
experiments, the probabilistic language models with Dirichlet and Jelinek-Mercer (JM) smoothing
are adopted [15]. In a multinomial language model with parameter y = (y1, Â· Â· Â· , yi, Â· Â· Â· , y|V |), given
a document d â‰¡ (d1, Â· Â· Â· , di, Â· Â· Â· , d|V |), the posterior probability can denoted as p(y |d, Î±), and
p(y |d, Î±) âˆ p(d |y)p(y |Î±) =
âˆ
i
(yi)
di
âˆ
i
(yi)
Î±iâˆ’1
=
âˆ
i
(yi)
di+Î±iâˆ’1
âˆ¼ Dir(d + Î±), (7)
where p(w|Î±) is the Dirichlet prior on y with parameter Î± = (Î±1, Â· Â· Â· , Î±i, Â· Â· Â· , Î±|V |).
The mean of yi is chosen to be the estimator of yi; i.e.,
yË†i =
di + Î±iâˆ‘n
i=1 di + Î±i
. (8)
6
MAP MRR MAP
5
MAP
100 P@5 P@1
00
NDC
G@5
NDC
G@1
00
Evaluation Metrics
2
0
2
4
6
8
10
Im
pr
ov
em
en
ts
 (%
)
Roubust04 Hard Topics (Dirichlet Smoothing)
PMPT vs. PRP
PMPT vs. MPT
MAP MRR MAP
5
MAP
100 P@5 P@1
00
NDC
G@5
NDC
G@1
00
Evaluation Metrics
2
0
2
4
6
8
10
Im
pr
ov
em
en
ts
 (%
)
Roubust04 Hard Topics (Jelinek-Mercer Smoothing)
PMPT vs. PRP
PMPT vs. MPT
(a) (b)
Figure 2: Comparison of our approach (PMPT) against the MPT and the PRP on Robust2004
hard topics.
over the baseline, PRP, and MPT; this improvement shows that the PMPT method can better rank
retrieved documents via the mean-semivariance framework. For the performance at top positions, the
PMPT method, especially, can gain about 2.5%, 1.5%, and 1.0% improvements in terms of MAP5,
P@5, and NDCG@5, respectively; this leap demonstrates that the PMPT method can boost the top-
position ranking quality even further, no matter with either the Dirichlet or JM smoothing techniques.
Similarly, as shown in Figure 2, the proposed PMPT method improves over the PRP baseline in terms
of most of IR evaluation metrics on the Robust04 dataset. However, since the topics we used for
the Robust04 track are hard topics only, in terms of some metrics, the PMPT method can only get
minor improvements, or even cannot outperform over the MPT method. This phenomenon shows
that, when operating on hard topics, these two approaches based on Portfolio Theory might obtain
similar performance. As shown in Figure 2(b), compared with the PRP baseline, the PMPT method
with the JM smoothing still gains about 7%, 5%, and 3% improvements in terms of MAP5, P@5, and
NDCG@5, respectively. Furthermore, with respect to the different smoothing techniques, we observe
that the JM smoothing generally performs better than the Dirichlet smoothing does; this phenomenon
may be due to the big variances caused by the JM smoothing in our experiments. This observation
is also consistent with that in [19], which suggests that it might be more preferable to apply the
â€œrisk-sensitiveâ€œ approach with the JM smoothing technique.
5 Conclusions and Future Work
This extension work proposes a general mean-semivariance framework to study document ranking un-
der uncertainty, which also implies the diversity of retrieved results. In the framework, the downside
uncertainty can be distinguished with the upside uncertainty when optimizing a ranking list. Ex-
periments on two TREC datasets with the different smoothing techniques validate that the proposed
framework improves the ranking quality over the PRP baseline and the MPT approach. In particu-
lar, the proposed framework obtains about 1%-7% improvements over the PRP baseline in terms of
MAP5, P@5, and NDCG@5. Future directions include how to use learning-to-rank techniques to find
out the optimal parameters of the proposed framework, and how to adapt the framework for diversi-
fied information retrieval. We will also study how to combine the two-step ranking SVM technique
with the mean-semivariance framework.
8
[16] ChengXiang Zhai. Risk Minimization and Language Modeling in Information Retrieval. PhD
thesis, Carnegie Mellon University, 2002.
[17] ChengXiang Zhai, William W. Cohen, and John Lafferty. Beyond independent relevance: meth-
ods and evaluation metrics for subtopic retrieval. In SIGIR â€™03: Proceedings of the 26th annual
international ACM SIGIR conference on Research and development in informaion retrieval,
pages 10â€“17, New York, NY, USA, 2003. ACM.
[18] ChengXiang Zhai and J. Lafferty. A risk minimization framework for information retrieval.
Information Processing and Management, 42(1):31â€“55, 2006.
[19] J. Zhu, J. Wang, I.J. Cox, and M.J. Taylor. Risky business: modeling and exploiting uncertainty
in information retrieval. In Proceedings of the 32nd international ACM SIGIR conference on
Research and development in information retrieval, pages 99â€“106. ACM, 2009.
[20] J. Zhu, J. Wang, M. Taylor, and I. Cox. Risk-aware information retrieval. Advances in Informa-
tion Retrieval, pages 17â€“28, 2009.
10
Ã«qÂ¤kÂ·Â´?RÂ–Ã¡Â‹Ã‡Ä´0Â´ÄÂƒÄ—ÃˆÅ‚ÃƒÄªÃ“Ä
:q0Â´ÂµÂ‹Â£Âˆ/#:Â“K 
 	 
Â¤kÂ‹qÂ•ÅšÄÂƒ:~Â˜ÄÂƒÄ—ÃˆÅ‚ÃƒÄªÃ“Â‹Â¢Å•}\Â¤k
RÂ¢Ä‘Â‹Ä¿azÃŸÃ¼T8		 ÃÃœz 
 Â¤kÂ·jÂœÅŠÄ³:~Â˜Â¨RÄºÄ4/w  Â€Âœ
ZÃ,Â¤kÃŒÃ¨Ã‘Â¤kÃ«qÅ–Ã™Â‹ÄºÄjÂœÅ :RÄ¡
ÄƒTYÂ‹Ä‹Å™	
 
  TSÄÅšÂ‹ Â‹Ä ÅˆÂ¡"Ä£ÂÃ­
"BÅ‡M

 


	

		
	
	
â€¢ 	Ä Åˆ Â¹"Ä£Â.ÂªÃ¥M[Ã–ÂŒ
Ä“Ä¤Ä˜Ä€ÄŸ
	 	
 

Ä¥Ä—ÃˆÅ
y
	
	 
	^Ä€HpÄŒÃŠ

	 tÃ¦Ã£Ä‘Ä—Â¼Ä…ÅœÂ½Â‹Å‚ÃƒÃ
eÃ‘Å
	

   
 
	
		
			
â€¢  Â¤kÂ·.ÂªÃ¥M[`;r;ÂÂ‹
r;Ä…Ä—Ãˆ
 
	
tiÄ‚r;
ÂKÄ¤Ä˜ÄÃƒÂ‹r;ÂÄ’Å
 
Ã¹Ä´ÂœÄÃƒÄ€Â‡ÃeÂ€ÂœÄÃƒÂ¯Â‹ÃªÂ«KTÃ¯
Ä ÅˆÃ´w`;r;Ä…Ä—ÃˆtiÄ‚Ä¤Ä˜ÄÃƒ
4Ã†Â¯Å†wÂ‹Â­xzÂ±Ä¾Ã¿
 
  Ã/Ä ÅˆÄÅšu0Ä¶ÂÂ‹Ä´'Ã°b?"Ä£ÂÅ :
TYQÅ’mL/BÅ‡Ã³Ä‰CÄ„+Ä™Ã¡vÂ‹Ä Åˆ
 
 			


			
	


â€¢ TÄ°Ä´'Ã´1ÂµÄÂ‹ÄÃƒÂ¯
	
Ã‹ÄÄ¤Ä˜+Ä™Å–Å‚ÃƒÂ‹Ã‘64/Ã´sÃ&Ãµ
  
 
March 5, 2012 
To: Ming-Feng Tsai 
Assistant Professor 
Department of Computer Science 
National Chengchi University, 
Taiwan. 
 
Dear Dr. Tsai, 
 
On behalf of the Organizing Committee, I would like to extend a formal invitation  
for you to attend the upcoming ECIR 2012 Conference as Program Committee Member, 34th 
European Conference on Information Retrieval, to be held in Barcelona, Spain, 1-5 April 
2012. 
 
This letter can be used by the person stated in the letter, Dr. Ming-Feng Tsai, 
who is an Assistant Professor in the Department of Computer Science at  the National Chengchi 
University, Taiwan, for a Visa application to cover the stay in Barcelona, Spain, for the 
conference, in the stated period. 
 
Dr. Ming-Feng Tsai 
Assistant Professor 
Department of Computer Science 
National Chengchi University, 
Taiwan. 
 
 
Yours sincerely, 
 
 
 
Mrs. Mari-Carmen Marcos  
Chair, Local Organizing Committee 
 
 
 
 
 
 
 
Department of Information Technology  
and Communications,  
Pompeu Fabra University, 
Tanger, 122-140  
08018 Barcelona, Spain. 
Tel: +34  93 542 25 00 
Fax: + 34  93 542 25 17 
Email: mcmarcos@upf.edu 
100ï¦ï¨å°ˆé¡Œç ”ç©¶è¨ˆç•«ç ”ç©¶æˆæœå½™æ•´è¡¨ 
è¨ˆç•«ä¸»æŒäººï¼šè”¡éŠ˜å³° è¨ˆç•«ç·¨è™Ÿï¼š100-2218-E-004-001- 
è¨ˆç•«åç¨±ï¼šæ”¹å–„å¤šæ¨£æ€§æª¢ï¥ªä¹‹æœï¥ªçµæœ 
ï¥¾åŒ– 
æˆæœé …ç›® å¯¦éš›å·²é”æˆ
ï¥©ï¼ˆè¢«æ¥å—
æˆ–å·²ç™¼è¡¨ï¼‰
é æœŸç¸½é”æˆ
ï¥©(å«å¯¦éš›å·²
é”æˆï¥©) 
æœ¬è¨ˆç•«å¯¦
éš›è²¢ç»ç™¾
åˆ†æ¯” 
å–®ä½ 
å‚™ è¨» ï¼ˆ è³ª åŒ– ï¥¯
æ˜ï¼šå¦‚ï¥©å€‹è¨ˆç•«
å…±åŒæˆæœã€æˆæœ
ï¦œ ç‚º è©² æœŸ åˆŠ ä¹‹
å° é¢ æ•… äº‹ ...
ç­‰ï¼‰ 
æœŸåˆŠï¥æ–‡ 0 0 100%  
ç ”ç©¶å ±å‘Š/æŠ€è¡“å ±å‘Š 0 0 100%  
ç ”è¨æœƒï¥æ–‡ 0 0 100% 
ç¯‡ 
 
ï¥æ–‡è‘—ä½œ 
å°ˆæ›¸ 0 0 100%   
ç”³è«‹ä¸­ä»¶ï¥© 0 0 100%  å°ˆï§ å·²ç²å¾—ä»¶ï¥© 0 0 100% ä»¶  
ä»¶ï¥© 0 0 100% ä»¶  
æŠ€è¡“ç§»è½‰ 
æ¬Šï§ï¤Š 0 0 100% åƒå…ƒ  
ç¢©å£«ç”Ÿ 3 0 100%  
åšå£«ç”Ÿ 1 0 50%  
åšå£«å¾Œç ”ç©¶å“¡ 0 0 100%  
åœ‹å…§ 
ï¥«èˆ‡è¨ˆç•«äººï¦Š 
ï¼ˆæœ¬åœ‹ç±ï¼‰ 
å°ˆä»»åŠ©ï§¤ 0 0 100% 
äººæ¬¡ 
 
æœŸåˆŠï¥æ–‡ 0 1 100% 
ç ”è¨æœƒï¥æ–‡ä¹‹å»¶
ä¼¸æœŸåˆŠç‰ˆæœ¬ä»åœ¨
é€²ï¨ˆä¸­ã€‚ 
ç ”ç©¶å ±å‘Š/æŠ€è¡“å ±å‘Š 0 0 100%  
ç ”è¨æœƒï¥æ–‡ 1 1 100% 
ç¯‡ International 
Neural Network 
Society Winter 
Conference 
(INNS-WC2012), 
Thailand 2012. 
ï¥æ–‡è‘—ä½œ 
å°ˆæ›¸ 0 0 100% ç« /æœ¬  
ç”³è«‹ä¸­ä»¶ï¥© 0 0 100%  å°ˆï§ å·²ç²å¾—ä»¶ï¥© 0 0 100% ä»¶  
ä»¶ï¥© 0 0 100% ä»¶  
æŠ€è¡“ç§»è½‰ 
æ¬Šï§ï¤Š 0 0 100% åƒå…ƒ  
ç¢©å£«ç”Ÿ 0 0 100%  
åšå£«ç”Ÿ 0 0 100%  
åšå£«å¾Œç ”ç©¶å“¡ 0 0 100%  
åœ‹å¤– 
ï¥«èˆ‡è¨ˆç•«äººï¦Š 
ï¼ˆå¤–åœ‹ç±ï¼‰ 
å°ˆä»»åŠ©ï§¤ 0 0 100% 
äººæ¬¡ 
 
