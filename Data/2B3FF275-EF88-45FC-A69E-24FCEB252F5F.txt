3. Memory Mapping 
DRAM is usually used as main memory for 
program execution. The thermal behavior of a 
memory block in a 3D SIP is affected not 
only by the power behavior but also the heat 
dissipating ability of that block. The power 
behavior of a block is related to the 
applications run on the system while the heat 
dissipating ability is determined by the 
number of tier and the position the block 
locates. Therefore, a thermal-aware memory 
allocator should consider the following two 
points. First, allocator should consider not 
only the power behavior of a logic block but 
also the physical location during memory 
mapping, second, the changing temperature 
of a physical block during execution of 
programs. In this paper, we will propose a 
memory mapping algorithm taking into 
consideration the above-mentioned two 
points. Our technique can be classified as 
static thermal management to be applied to 
embedded software designs. 
 
é—œ éµ å­— (Keywords) ï¼š SiP ã€ leadframe 
routing ã€ memory mapping ã€ thermal 
management 
 
äºŒã€ ç ”ç©¶è¨ˆåŠƒä¹‹èƒŒæ™¯ã€ç›®çš„åŠæ–‡ç»è¨è«– 
 
éš¨è‘—è£½ç¨‹çš„é€²æ­¥ï¼Œæ™¶ç‰‡(Chip)é–“çš„åŒ¯æµ
æ’(Bus)æ‰€éœ€è¦çš„é€Ÿåº¦åŠé »å¯¬è¶Šä¾†è¶Šå¤§ï¼Œè€Œ
ç³»çµ±çš„åŒ¯æµæ’çš„é€Ÿåº¦åŠé »å¯¬å‰‡æ˜¯å–æ±ºæ–¼å°
è£(Package)çš„æŠ€è¡“ã€‚ç„¶è€Œå°è£æŠ€è¡“çš„æˆé•·
ç›¸å°æ–¼æ™¶ç‰‡è£½ç¨‹é€²æ­¥æ…¢äº†è¨±å¤šï¼Œä»¥è‡´æ–¼å…©
è€…ä¹‹é–“ç”¢ç”Ÿäº†è¶Šä¾†è¶Šå¤§çš„é´»æºï¼Œå‚³çµ±çš„å°
è£æŠ€è¡“è¶Šä¾†è¶Šä¸èƒ½æ»¿è¶³æ–°è£½ç¨‹æ™¶ç‰‡å°æ–¼é »
å¯¬çš„éœ€æ±‚ã€‚ 
 
ç‚ºäº†è§£æ±ºè¨Šè™Ÿ on-chipåŠ off-chipå‚³é
é€Ÿåº¦æ„ˆä¾†æ„ˆå¤§çš„å·®ç•°ï¼Œ  å› æ­¤æœ‰æ‰€è¬‚
System-on-Chipï¼ˆSOCï¼‰çš„è¨­è¨ˆæ–¹æ³•ç”¢ç”Ÿã€‚
ç„¶è€Œéš¨è‘—ç³»çµ±çš„è¤‡é›œåº¦å¢åŠ ï¼Œå°‡è¨±å¤šä¸åŒ
è£½ç¨‹çš„æ™¶ç‰‡å¦‚è¨˜æ†¶é«”æ™¶ç‰‡ã€é‚è¼¯æ™¶ç‰‡æ•´åˆ
åœ¨åŒä¸€æ™¶ç‰‡ï¼Œæ‰€éœ€è¦çš„æˆæœ¬æˆè·³èºçš„å¢
åŠ ã€‚å› æ­¤å¦ä¸€æ–¹é¢ï¼Œç‚ºäº†è€ƒé‡æˆæœ¬å› ç´ ï¼Œ
æœ‰æ‰€è¬‚ System-in-Package çš„è¨­è¨ˆæ–¹æ³•ã€‚æ‰€
è¬‚ System-in-Package æ˜¯æŒ‡å°‡ä¸åŒè£½ç¨‹çš„æ™¶
ç‰‡ï¼Œå„è‡ªè£½é€ ã€‚ä¹‹å¾Œï¼Œå†åˆ©ç”¨è£½ç¨‹åŒ…è£çš„
æŠ€è¡“å°‡æ™¶ç‰‡å †ç–Šã€‚ 
 
è¨­è¨ˆ System-in-Packageæ‰€é¢è‡¨çš„æŒ‘æˆ° 
 
 ç”±æ–¼ System-in-Package ç‰½æ¶‰äº†ç³»çµ±æ•´
åˆã€å°è£æŠ€è¡“ã€æ™¶åœ“è£½ç¨‹ç­‰æ–°æŠ€è¡“çš„çµ±æ•´ï¼Œ
ç ”ç™¼ä¸Šå‹¢å¿…é¢è‡¨å‚³çµ±è¨­è¨ˆæ‰€æ²’æœ‰çš„å•é¡Œèˆ‡
æŒ‘æˆ°ï¼Œå°¤å…¶åœ¨è¨­è¨ˆè»Ÿé«”ä¸Šï¼Œæœ‰ä¸‹åˆ—çš„å•é¡Œï¼š 
ï¬ è¨­è¨ˆå¦‚ä½•åˆ†å‰²ï¼Œå°‡ä¸åŒ moduleåˆ†æ”¾åœ¨
ä¸åŒä¹‹æ™¶ç‰‡ä¸Šã€‚ 
ï¬ Pad assignmentï¼ŒFloorplanningï¼ŒRouting
ä»¥æ¸›å°‘ leadframeä¹‹ costã€‚ 
ï¬ æ™¶ç‰‡å †ç–Šæˆ–è€…æ˜¯ä¸¦æ’çš„é¸æ“‡åŠå–æ¨ 
ï¬ å¦‚ä½•é é˜²å †ç–Šç”¢ç”Ÿçš„éç†±å•é¡Œ 
ï¬ å¦‚ä½•å»ºç«‹æ¸¬è©¦çš„æ¨¡å¼ï¼Œä½¿å¾— SiPçš„ç¸½é«”
æ¸¬è©¦æˆæœ¬é™ä½ 
ï¬ åœ¨å‚³çµ±çš„Memory mappingä¸­ï¼Œä¸»è¦åˆ©
ç”¨ Sequential mappingï¼›ç”±æ–¼ä½¿ç”¨ data
ä¹‹ localityï¼Œå¸¸æœƒå°è‡´ hot spot moduleï¼Œ
å¦‚ä½•åˆ©ç”¨ memory mappingï¼Œä½¿å¾—
performanceåŠ hot spot å•é¡Œçš†èƒ½åŒæ™‚
è§£æ±ºã€‚ 
 
System-in-Packageè¨­è¨ˆæµç¨‹ 
 
    ç‚ºäº†è§£æ±ºä»¥ä¸Šå•é¡Œï¼Œæˆ‘å€‘è¦åŠƒäº†å®Œæ•´
çš„è¨­è¨ˆæµç¨‹èˆ‡ç ”ç©¶è¨ˆç•«ï¼Œä»¥è§£æ±ºä¸Šè¿°å•é¡Œã€‚ 
æœ¬è¨ˆç•«å°‡æ¢è¨æœ‰é—œ Chip Stackingï¼Œ
Leadframe RoutingåŠ Memory Mappingä¹‹
å•é¡Œã€‚ 
 
åœ¨ Chip Stackingæ–¹é¢ï¼Œéå»ä¸¦æœªæœ‰å®Œå…¨é¡
ä¼¼è«–æ–‡æ¢è¨ã€‚ç„¶è€Œï¼Œæœ‰é—œæ–¼ 3D floor 
planning[12] ï¼Œ 3D routing[13] ï¼Œ 3D via 
assignment[14]çš„å•é¡Œçš†æœ‰ç™¼è¡¨åœ¨æœ€è¿‘æœƒè­°
ä¸­ã€‚åœ¨ Leadframe ç¹ç·šæ–¹é¢ï¼Œéå»æœ‰è¨±å¤š
Routingçš„è«–æ–‡æ¢è¨ PCB routingï¼ŒåŠç›®å‰æ–°
ç™¼è¡¨çš„æœ‰é—œ routing for flip-chip design[15]
æ–°è«–æ–‡ï¼Œç„¶è€Œé‡å° SiP leadframeç¹ç·šç‰¹æ€§
ä¹‹ç›¸é—œç ”ç©¶ä¸¦æ²’æœ‰è«–æ–‡ç™¼è¡¨ã€‚åœ¨ Memory 
Mappingæ–¹é¢ï¼Œéå»åƒ…æœ‰å°‘æ•¸è«–æ–‡æ¢è¨ï¼Œä¸»
è¦é‡å° memoryèˆ‡ logicå¦‚ä½•æ•´åˆ[16][17]ã€‚ 
 
 
ä¸‰ã€ ç ”ç©¶æ–¹æ³•åŠé€²è¡Œæ­¥é©Ÿ 
 
åŠç†±èƒ½è¡¨ç¾ã€‚è‹¥ä»¥å‚³çµ±çš„æ–¹å¼åš sequential
çš„ mappingï¼Œå¯èƒ½æœƒå°è‡´ä¸€äº›å­˜å–é »ç‡è¼ƒ
é«˜çš„è¨˜æ†¶é«”å€æ®µï¼Œè¢« mapåˆ°æ•£ç†±æ•ˆç‡åŠç†±
èƒ½è¡¨ç¾è¼ƒä¸å¥½çš„ memory moduleä¸Šï¼Œè€Œå°
è‡´æ•´å€‹ç³»çµ±çš„æº«åº¦éé«˜ã€‚é‡å°ç…§é€™æ¨£çš„æƒ…
å½¢ï¼Œæˆ‘å€‘æå‡ºçš„ä¸€å¥—å®Œæ•´çš„ç¨‹å¼åˆ†æåŠè¨˜
æ†¶é«”æ˜ æˆæ–¹æ³•ï¼Œä»¥é™ä½æ•´é«”ç³»çµ±çš„æœ€é«˜æº«
åº¦ã€‚ 
 
é¦–å…ˆï¼Œåœ¨ç¡¬é«”éƒ¨åˆ†ï¼Œé‡å°è¨˜æ†¶é«”çš„å †
ç–Šæ–¹å¼åŠå­˜å–ç‰¹æ€§ï¼Œæˆ‘å€‘å…ˆåˆ—èˆ‰å‡ºå¹¾çµ„åœ¨
ç†±èƒ½è¡¨ç¾ä¸Šè¼ƒå…·å„ªå‹¢çš„å­˜å–çµ„åˆã€‚åœ¨è»Ÿé«”
éƒ¨åˆ†ï¼Œæˆ‘å€‘è§€å¯Ÿæ‡‰ç”¨ç¨‹å¼å°è¨˜æ†¶é«”çš„å­˜å–
æƒ…å½¢ï¼Œå°‡è¨˜æ†¶é«”ç©ºé–“ä¾ç…§å­˜å–é »ç‡ï¼Œåˆ‡æˆ
æ•¸å€‹å€é–“ã€‚æœ€å¾Œï¼Œæˆ‘å€‘åˆ©ç”¨æ•´æ•¸å‹ç·šæ€§è¦
åŠƒ(integer linear programming)çš„æ–¹æ³•ï¼Œå»
æ‰¾å‡ºç¡¬é«”ä¸Šæœ€åˆé©çš„å­˜å–çµ„åˆï¼Œä»¥åŠå„è¨˜
æ†¶é«”å€é–“å° memory moduleçš„æ˜ æˆæƒ…å½¢ã€‚ 
 
å››ã€ çµæœèˆ‡è¨è«– 
 
æœ¬å¹´åº¦ä¸»è¦çš„ç ”ç©¶æˆæœï¼Œåœ¨æ–¼é‡å° SiP
è¨­è¨ˆä¸­ memory mappingçš„éƒ¨åˆ†ï¼Œåœ¨åŒæ™‚è€ƒ
æ…®è»Ÿé«”åŠç¡¬é«”ç‰¹æ€§çš„æƒ…å½¢ä¸‹ï¼Œæå‡ºä¸€å¥—å®Œ
æ•´çš„è¨­è¨ˆæµç¨‹ï¼Œä»¥ä¸å½±éŸ¿æ•ˆèƒ½è¡¨ç¾ç‚ºå‰
æï¼Œæå‡ç³»çµ±çš„ç†±èƒ½è¡¨ç¾ï¼Œä¸¦é™ä½ç³»çµ±çš„
æœ€é«˜æº«åº¦ã€‚ 
 
æˆ‘å€‘çš„å¯¦é©—çµæœé¡¯ç¤ºï¼šèˆ‡å‚³çµ±
sequentialçš„ mappingæ–¹å¼ç›¸æ¯”ï¼Œåœ¨å–®æ ¸å¿ƒ
çš„å¹³å°ç’°å¢ƒä¸‹ï¼Œæˆ‘å€‘æ‰€æå‡ºçš„æ–¹æ³•ï¼Œæœ€å¤š
å¯ä»¥å°‡è¨˜æ†¶é«”ç³»çµ±çš„æœ€é«˜æº«åº¦é™ä½ 17.1
â„ƒã€‚å¹³å‡ä¾†èªªï¼Œæœ€é«˜æº«åº¦çš„é™å¹…ç‚º 13.3â„ƒã€‚
åŒæ™‚ï¼Œæˆ‘å€‘é€²ä¸€æ­¥å°‡æˆ‘å€‘æ‰€æå‡ºçš„æ–¹æ³•æ“´
å±•åˆ°å¤šæ ¸å¿ƒçš„ç’°å¢ƒã€‚å¯¦é©—é¡¯ç¤ºï¼Œåœ¨å››æ ¸å¿ƒ
çš„å¹³å°ç’°å¢ƒä¸‹ï¼Œæˆ‘å€‘æ‰€æå‡ºçš„æ–¹æ³•å¯ä»¥å°‡
æœ€é«˜æº«åº¦é™ä½ 9.9â„ƒï½11.6â„ƒã€‚ 
 
æˆ‘å€‘çš„ç ”ç©¶æˆæœï¼Œå·²å…ˆæ–¼ 2009å¹´ï¼Œåœ¨
è¨­è¨ˆã€è‡ªå‹•åŒ–æš¨æ¸¬è©¦å…¨æ­æœƒè­° (DATE)ä¸­ç™¼
è¡¨ã€‚åœ¨ 2010å¹´åˆï¼Œæˆ‘å€‘é€²ä¸€æ­¥çš„å°‡æ›´å®Œæ•´
çš„ç ”ç©¶æˆæœæŠ•ç¨¿è‡³ ACM Transaction on 
Embedded Computing Systems (TECS)ï¼Œ
ç›®å‰æ­£åœ¨å¯©æŸ¥éšæ®µä¸­ã€‚é™„ä»¶ä¸€åŠé™„ä»¶äºŒï¼Œ
åˆ†åˆ¥ç‚ºæˆ‘å€‘åœ¨ DATE æœƒè­°ä¸­ç™¼è¡¨çš„è«–æ–‡ä»¥
åŠæŠ•ç¨¿è‡³ TECS åœ‹éš›æœŸåˆŠä¹‹æ–‡ç¨¿ã€‚é—œæ–¼æˆ‘
å€‘æ‰€æå‡ºæ–¹æ³•çš„è©³ç´°ä»‹ç´¹ï¼Œä»¥åŠå®Œæ•´çš„å¯¦
é©—æµç¨‹ï¼Œå¯åƒè€ƒé™„ä»¶ä¸€åŠé™„ä»¶äºŒã€‚ 
 
 
äº”ã€ åƒè€ƒæ–‡ç» 
 
[1] Rao R. Tummala, "Fundamentals of 
microsystems packageing," international 
edition 2001. 
[2] Joe Adam, â€œSystem-in-Package 
Roadmap,â€1st workshop on 3S (SOP, SIP, 
SOC) Electronics Technologies . 
[3] W. R. Davis,J. Wilson,S. Mick,J. Xu,H. 
Hua,C. Mineo,A. M. Sule,M. Steer,and P. D. 
Franzon, "Demystifying 3D ICs: The Pros 
and Cons of Going Vertical," IEEE Design & 
Test of Computers, pp. 498-510, 2005. 
[4] Juergen Wolf, and IZMJoe Adams,"2005 
Packaging Roadmap Overview," 2005. 
[5] Bryan Black , Donald W. Nelson, Clair 
Webb, and Nick Samra, â€œ3D Processing 
Technology and its Impact on iA32 
Microprocessors,â€ Proc. of ICCDâ€™04. 
[6] R. M. Lea, I. P. Jalowiecki, D. K. 
Boughton,, J. S. Yamaguchi,A. A. Pepe,V. H. 
Ozguz, and J. C. Carson, â€œA 3-D Stacked 
Chip Packaging Solution for Miniaturized 
Massively Parallel Processing,â€IEEE 
Transactions On Advanced Packaging , 
pp.424-432,  1999. 
[7] Rao R. Tunmala,V. Sundaram,F. Liu,G. 
White, S. Bhattacharya, R. M. Pulugurtha,M. 
Swaminathan,S. Dalmia,J. Laskar,N. M. 
Jokerst,S. Y. Chow, "High Density Packaging 
in 2010 and Beyond", International 
Symposium On Electronic Materials and 
Packaging , 2002.   
[8] V.N. Johnson, J. Jozwiak, and A. 
Moll,  â€œThrough Wafer Interconnects on 
Active pMOS Devices,â€ Proceedings IEEE 
Workshop on Microelectronics and Electron 
Devices,  pp. 82-84,  2004. 
[9] "SiP (System in Package)", Toshiba 
corporation 
http://www.semicon.toshiba.co.jp/eng/ 
[10]Jordan Tsai , â€œSystem In Package 
Technology & Development,â€ ASE TECH 
FORUM 2003. 
[11] Jayson Hsu,"Multi-Chip Packaging for 
Lead Frame,â€ Ase Inc. 2004. 
[12] J. Cong and Y. Zhang, â€œA Thermal 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
é™„ä»¶ä¸€ï¼š 
(ç ”ç©¶æˆæœ) 
æ–¼ DATEåœ‹éš›æœƒè­°ä¸­æ‰€ç™¼è¡¨çš„è«–æ–‡ 
 
 
 
 
 
 
 
 
 
TSV TSV
TSV TSV
Upper Tier
Lower Tier
Fig. 1. Bonding between TSVs and Bond Pads
for each TSV [9][10]. In addition to misalignments, TSVs
can also fail in the soldering process [11]. For example, short
circuits between two distinct TSVs or open circuits between a
TSV and its corresponding bonding pad may be formed. Other
failure mechanisms such as dislocation, process variations or
mechanical stress also decrease the fabrication yield of TSVs.
Above all, misalignment and failures on bonding are pri-
mary failure mechanisms for TSVs [11]. Both of the tech-
nologies used for alignment and bonding are very similar
to the packaging methods used in current IC industry [5].
Although the exact failure rate of TSVs is still not clear, it
is possible to use the failure rates of alignment and bonding
to perform a failure rate analysis for TSV. Considering the
TSV diameter and the size of bond pads, the failure rate of
a single TSV may ranges between 10âˆ’4 and 10âˆ’5 based on
current packaging technology. This assumption roughly meets
the yields of TSVs from the process technologies of HRI,
IMEC and IBM [12][13][14].
According to the applications and network styles, the num-
ber of TSVs in each tier can be quite different. For many-core
processors or NoC-based designs, thousands of TSVs may be
required in each tier. On the contrary, hundreds of TSVs may
be sufcient for smaller IP-based designs. In this work, we
focus on IP-based designs where TSVs are mainly used for
connections between modules on different tiers. Considering
the area of bond pads and oorplan problems, we assume that
the number of TSVs to be placed in a tier ranges from 300
to 500.
An analysis between failure rate and yield is given in
Figure 2. Assume that all dies to be stacked are known-good-
dies. Thus, only the failure rate of TSV bonding needs to be
considered. Let f stands for the failure rate of bonding one
TSV and #tier stands for the number of tiers to be stacked.
Note that the actual number of tiers that contain TSVs to be
bonded is equal to #tier - 1. For example, when #tier = 2, only
the top tier contains TSVs to be bonded. The x-axis represents
the number of TSVs to be placed in each tier (#TSV). Since a
good chip stack requires all TSVs to be successfully bonded,
the binding yield can be computed as (1âˆ’ğ‘“)#ğ‘‡ğ‘†ğ‘‰Ã—(#ğ‘¡ğ‘–ğ‘’ğ‘Ÿâˆ’1).
The analysis results for ğ‘“ = {0.0001, 0.00002} and #ğ‘¡ğ‘–ğ‘’ğ‘Ÿ =
{2 , 5} are shown in Figure 2. Without any redundant TSVs,
the average yield is 94.35%. And when #ğ‘‡ğ‘†ğ‘‰ = 500 and
#ğ‘¡ğ‘–ğ‘’ğ‘Ÿ = 5, the yield degrades to 81.8%. Note that dies to
be stacked are all known-good-dies. Therefore, the cost of
discarding chip stacks that are failed due to TSV bonding is
very expensive. In fact, in most failed chip stacks, only a very
80 00%
85.00%
90.00%
95.00%
100.00%
p 
St
ac
ks
 w
ith
 n
o 
Fa
ile
d 
TS
V
f = 0 0001 #tier = 2
70.00%
75.00%
.
300 350 400 450 500
%
of
 C
hi
p 
St
ac
ks
 w
ith
 n
o 
Fa
ile
d 
TS
V
#TSV
  . ,  
f=0.0001,#tier=5
f=0.00002,#tier=2
f=0.00002,#tier=5
Fig. 2. Yield Analysis
small portion of TSVs are failed. If these failed TSVs can be
recovered with circuits of reasonable cost, the yield can be
largely improved. The redundant TSV design to be proposed
in this paper provides a solution to this problem.
III. REDUNDANT TSV ARCHITECTURE
In this section, the architecture of our proposed redundant
TSV design is introduced in Section III-A. Next, a brief
introduction to the oorplan of 3D IC and its relation to our
proposed architecture are given in Section III-B.
A. Architecture Design
The proposed architecture for redundant TSV is depicted
in Figure 3. For each TSV, 2 MUXs are added to shift the
signal to neighboring TSV when one TSV is failed. To reduce
the timing effect caused by the loading capacitance of the
additional wires used for signal shifting, a pair of buffers are
added to each TSV. The TSVs are connected as a chain where
the redundant TSV is placed at the last position of the chain.
When no TSV is failed, all signals are transferred by original
TSVs as shown in Figure 4(a). When a TSV is failed, the
signal of the failed TSV needs to be shifted. This in term
causes all signals between the failed TSV and the redundant
TSV to be shifted. For example, let TSV 1 be failed. The
signal paths after shifting are shown in Figure 4(b). When a
signal is shifted, larger delay is introduced due to larger wire
length and buffers. For signals that are timing critical, this
may become a problem. We will discuss it in Section V-A.
In this architecture, only one failed TSV can be recovered in
each chain. If two or more TSVs are failed in a chain, only
one of them can be recovered. Therefore, how to determine the
number of TSVs in a chain so that an acceptable recovery rate
can be achieved is an important design issue. This issue will
be discussed in Section IV. For simplicity, the term TSV-chain
is used to refer to the structure of the proposed redundant TSV
architecture.
The MUXs in the proposed architecture are connected to an
e-fuse array which can be programmed by a scan-chain. By
default, all signals connect to MUXs are set to 0. When the
testing for TSV connectivity is done, signals are scanned in to
program the e-fuses so that each MUX receives an appropriate
control signal.
TABLE I
ğ‘ƒğ‘“ ğ‘¡ğ‘ ğ‘£=ğ‘› AND ğ¶ ğ‘…ğ‘ğ‘¡ğ‘–ğ‘œğ‘› WHEN ğ¹ = 0.0001
ğ‘ ğ‘› ğ‘ƒğ‘“ ğ‘¡ğ‘ ğ‘£=ğ‘› ğ¶ ğ‘…ğ‘ğ‘¡ğ‘–ğ‘œğ‘›
300
0 97.0444% 97.0444%
1 2.9116% 99.9560%
2 0.0435% 99.9996%
400
0 96.0788% 96.0788%
1 3.8435% 99.9223%
2 0.0767% 99.9990%
500
0 95.1227% 95.1227%
1 4.7566% 99.8793%
2 0.1187% 99.9980%
Table I shows that, when ğ‘› = 2, the values of ğ¶ ğ‘…ğ‘ğ‘¡ğ‘–ğ‘œğ‘› for
ğ‘ = {300, 400, 500} are all greater than 99.998%. A smaller
ğ¹ will result in a larger ğ¶ ğ‘…ğ‘ğ‘¡ğ‘–ğ‘œğ‘›. This means, as long as
the failure rate ğ¹ is no greater than 0.0001, the probability
that three or more TSVs are failed is less than 0.002%.
Therefore, when designing TSV-chains, we can assume that
the maximum number of failed TSVs in a tier is 2. This
assumption covers 99.998% of all possible faulty free and
faulty situations.
B. Analysis on Recovery Rate
As mentioned in Section III, each TSV-chain is capable of
recovering at most one failed TSV in a TSV block. As the
number of TSVs in a TSV block increases, the probability
that all failed TSVs can be recovered decreases. To achieve
an expected recovery rate, the number of TSVs in each TSV
block must be limited. To simplify the analysis, we assume
that the number of TSVs in all TSV blocks are identical. Let
#ğµ ğ‘‡ğ‘†ğ‘‰ stand for the number of TSVs in each TSV block
and ğ‘› stand for the number of failed TSVs. For a given value
of ğ‘›, we want to analyze the relation between #ğµ ğ‘‡ğ‘†ğ‘‰ and
recovery rate. The discussion in Section IV-A indicates that
assuming ğ‘› â‰¤ 2 is sufcient to covers 99.998% of all possible
faulty free and faulty situations. Therefore, we will perform
the analysis for ğ‘› = 1 and ğ‘› = 2 only.
Let ğ‘ stand for the number of TSVs in a tier. The
number of combinations of ğ‘ TSVs with ğ‘› failed TSVs can
be computed as ğ¶ğ‘ğ‘› . The number of combinations that all
failed TSVs can be recovered by TSV-chains is referred as
#ğ‘…ğ‘’ğ‘ğ‘œğ‘£ğ‘’ğ‘Ÿğ‘ğ‘ğ‘™ğ‘’ ğ¶ğ‘œğ‘šğ‘ğ‘–ğ‘›ğ‘ğ‘¡ğ‘–ğ‘œğ‘›ğ‘ . The recovery rate discussed
in this section is dened as
#ğ‘…ğ‘’ğ‘ğ‘œğ‘£ğ‘’ğ‘Ÿğ‘ğ‘ğ‘™ğ‘’ ğ¶ğ‘œğ‘šğ‘ğ‘–ğ‘›ğ‘ğ‘¡ğ‘–ğ‘œğ‘›ğ‘ 
ğ¶ğ‘ğ‘›
.
When ğ‘› = 1, only one failed TSV needs to be recovered.
Since one TSV block contains one redundant TSV, regardless
of the number of TSVs in each TSV block, one failed TSV can
always be recovered. Therefore, the recovery rate for ğ‘› = 1
is 100%.
The recovery rate analysis for ğ‘› = 2 is more complicated.
Let the term #ğµğ‘™ğ‘œğ‘ğ‘˜ represent the number of TSV blocks in
a tier. Under our assumptions, #ğµğ‘™ğ‘œğ‘ğ‘˜ can be computed as
ğ‘
#ğµ ğ‘‡ğ‘†ğ‘‰ . To successfully recover all failed TSVs, each failed
TSVs must be located in different TSV blocks. That is, ğ‘› TSV
blocks are selected from #ğµğ‘™ğ‘œğ‘ğ‘˜ TSV blocks. Each selected
TSV block contains exactly one failed TSV. The number of
40.00%
50.00%
60.00%
70.00%
80.00%
90.00%
100.00%
ec
ov
er
y 
R
at
e
0.00%
10.00%
20.00%
30.00%
25 26 27 29 31 33 35 38 41 45 50 55 62 71 83 100 125 166 250
R
ec
ov
er
y 
R
at
e
Number of TSVs in a TSV Block
Fig. 6. Recovery Rate when ğ‘ = 500, ğ‘› = 2
combinations that satises this requirement can be computed
as
ğ¶#ğµğ‘™ğ‘œğ‘ğ‘˜ğ‘› .
Inside each TSV block that contains one failed TSV, the
failed TSV can be located at #ğµ ğ‘‡ğ‘†ğ‘‰ possible positions.
Therefore, the #ğ‘…ğ‘’ğ‘ğ‘œğ‘£ğ‘’ğ‘Ÿğ‘ğ‘ğ‘™ğ‘’ ğ¶ğ‘œğ‘šğ‘ğ‘–ğ‘›ğ‘ğ‘–ğ‘œğ‘›ğ‘  for ğ‘› = 2 can
be computed as
ğ¶#ğµğ‘™ğ‘œğ‘ğ‘˜2 â‹… (#ğµ ğ‘‡ğ‘†ğ‘‰ )2.
The relation between #ğµ ğ‘‡ğ‘†ğ‘‰ and recovery rate for ğ‘ =
500 and ğ‘› = 2 is shown in Figure 6. For different values of
#ğµ ğ‘‡ğ‘†ğ‘‰ that result in the same #ğµğ‘™ğ‘œğ‘ğ‘˜, only the smallest
#ğµ ğ‘‡ğ‘†ğ‘‰ is shown in the gure since the recovery rates of
them are the same.1
According to Figure 6, to achieve 90% recovery rate,
#ğµ ğ‘‡ğ‘†ğ‘‰ needs to be no greater than 50. By limiting the
number of TSVs in each TSV block to be less than or equal
to 50, the recovery rate is greater than 90%. To achieve a
higher recovery rate, the gure shows that with 95% recovery
rate, the number of TSVs in each TSV block cannot be greater
than 25. In realistic ASIC designs, the number of TSVs in a
TSV block is usually less than 50. Therefore, in most cases,
TSV block partitioning is not required.
A further analysis is to compute the overall yield. In
Table I, when ğ‘ = 500, ğ‘ƒğ‘“ ğ‘¡ğ‘ ğ‘£=0, ğ‘ƒğ‘“ ğ‘¡ğ‘ ğ‘£=1, and ğ‘ƒğ‘“ ğ‘¡ğ‘ ğ‘£=2
are 95.1227%, 4.7566%, and 0.1187%, respectively. The dis-
cussion above indicates that the recovery rate for ğ‘› = 1 is
always 100% based on our proposed architecture. Thus, let
the recovery rate for ğ‘› = 2 be set to 90%. The overall yield
can be computed as
ğ‘ƒğ‘“ ğ‘¡ğ‘ ğ‘£=0+ğ‘ƒğ‘“ ğ‘¡ğ‘ ğ‘£=1Ã—100%+ğ‘ƒğ‘“ ğ‘¡ğ‘ ğ‘£=2Ã—90% = 99.98613%.
This value is high enough for most applications.
V. DESIGN FLOW AND TSV-Chain DESIGN
The discussion in Section IV focuses on the recovery of
failed TSVs in terms of connectivity. Timing issues are not
concerned. As mentioned in Section III-A, when a signal is
shifted in a TSV-chain, extra delay will be incurred. For signals
that are timing critical, the delay caused by signal shifting may
1The actual computation of#ğ‘…ğ‘’ğ‘ğ‘œğ‘£ğ‘’ğ‘Ÿğ‘ğ‘ğ‘™ğ‘’ğ¶ğ‘œğ‘šğ‘ğ‘–ğ‘›ğ‘ğ‘–ğ‘œğ‘›ğ‘  is a little more
complicated since sizes of TSV blocks may differ by one due to the division
operation to compute #ğµğ‘™ğ‘œğ‘ğ‘˜
Corner of a TierBoundary of a Tier
(a) Spiral-Style (b) Snake-Style (c) Hybrid
Fig. 9. Chaining Styles
probabilities to be routed through for minimum wire length.
These TSVs should be assigned as head parts of TSV-chains.
A spiral-style chaining policy is proposed for TSV-chain
design. In a TSV block, by picking a TSV in the central
position to be the starting point, spiral-style chaining results
in a routing path where all TSVs on the boundary are at one
end. The starting TSV is assigned as redundant TSV while the
other end becomes the head of a TSV-chain. An example for a
4 Ã— 5 TSV block is shown in Figure 9(a) where TSVs in grey
are head and good for timing critical signals. In routing stage,
routers can choose to assign timing-critical signals to TSVs
that are on the boundary of a TSV block. This can reduce the
probability for a timing critical signal to be shifted.
The spiral-style chaining policy is appropriate for a TSV
block that is not on the boundary or the corner of a tier.
For a TSV block located on the boundary of a tier, most
signals assigned to that TSV block are connected from the
opposite side of the tier boundary. In this case, a snake-style
chaining policy satises the requirement. The result is shown
in Figure 9(b). For a TSV block located on the corner, most
signals assigned to that TSV block are connected from the
counter direction of the tier corner. In this case, a hybrid
chaining policy as shown in Figure 9(c) becomes the best
candidate. Based on the position of each TSV block, one of
these three chaining policies can be applied to determine the
structure of a TSV-chain.
C. Physical Design Flow Considering TSV-Chain
In current design ow for 3D ICs , 3D partitioning rst
takes place to determine which tier each design blocks to be
placed. The number of required TSVs for signals between two
consecutive tiers is determined in this stage. Next, in oorplan
stage, blocks with x area but unknown dimensions are placed
in each tier. To provide communication links between blocks
in different tiers, TSV blocks are placed. The number of sig-
nals to be assigned to each TSV block as well as the position
of each TSV block are roughly determined in this stage. Based
on the discussion in Section IV, the number of TSVs in each
TSV block should be limited. Partitioning may be required
for large TSV blocks. Based on the position of each TSV
block, the structure of each TSV-chain is determined. In place
and route stage, routers should be aware of the TSV-chain
structure in each TSV block. Based on design constraints and
requirements, router needs to decide whether to assign timing
critical signals to TSVs that are located at the head of TSV-
chains. The overall design ow for TSV-chain is shown in
Figure 10.
3D Partitioning:
TSVs required for signal on each tier is determined
Placement
3D Routing:
Assignment of signals to TSVs
Considering the structure of each TSV-chain
when perform the assignment of signals to TSVs
3D Floorplanning:
TSV Block are determined
1. Partitioning is required for large TSV blocks
2. The size of each TSV block is limited
Based on the position of each TSV block, determine 
the structure of each TSV-chain
Fig. 10. Proposed Design Flow for TSV-Chain
VI. CONCLUSION
In this paper, a new redundant TSV architecture with
reasonable cost for ASICs has been proposed. Design issues
including recovery rate and timing problem have been inves-
tigated. Required modications on the design ow has been
explained. Based on probabilistic models, the new design can
successfully recover most of the failed chips and increase the
yield of TSV bonding to 99.99%. This can effectively reduce
the cost of manufacturing 3D designs.
REFERENCES
[1] W. R. Davis, J. Wilson, S. Mick, davis demystifying 3D et al.,
â€œDemistifying 3D ICs: The Pros and Cons of Going Vertical,â€ IEEE
Design Test of Computer, vol. 22, no. 6, pp. 498-510, Nov./Dec., 2005.
[2] J. Burns, L. Mcllrath, C. Keast, et al., â€œThree-Dimensional Integrated
Circuit for Low Power, High-Bandwidth Systems on a Chip,â€ ISSCC
Dig. of Tech. Papers, pp. 268-269, Feb., 2001.
[3] S. Siesshoefer and et al., â€œZ-axis Interconnect Using Fine Pitch,
Nanoscale Through Silicon Vias: Process Development,â€ ECTC, 2004.
[4] P. Morrow, M. J. Kobrinsky, S. Ramanathan, et al., â€œWafer-Level 3D
Interconnects via Cu Bonding,â€ Proceedings of the Advanced Metalliza-
tion Conference, pp. 125-130, 2004.
[5] Philip Garrou, Christopher Bower, and Peter Ramm, â€œHandbook of
3D Integration: Technology and Application of 3D Integrated Circuits
Volume 1 & 2,â€ poblished by WILEY-VCHVerlag GmbH& Co. KGaA,
Weinheim, 2008, ISBN: 978-3-527-32034-9.
[6] Uksong Kang, Hoe-Ju Chung, Seongmoo Heo, et al., â€œ8Gb 3D DDR3
DRAM Using Through-Silicon-Via Technology,â€ ISSCC Dig. of Tech.
Papers, pp. 130-131, Feb., 2009.
[7] Igor Loi, Subhasish Mitra, Thomas H. Lee, Shinobu Fujita and Luca
Benini, â€œA Low-Overhead Faule Tolerance Scheme for TSV-Based 3D
Network on Chip Links,â€ ICCAD, 2008.
[8] Hsien-Hsin S. Lee and Krishnendu Chakrabarty, â€œTest Challenges for
3D Integrated Circuits,â€ IEEE Design & Test of Computers, vol. 26, no.
5, pp. 26-35, Sep./Oct., 2009.
[9] R. Patti, â€œThree-Dimensional Integrated Circuits and the Future of
System-on-Chip Designs,â€ Proc. of the IEEE, vol. 84, no. 6, June 2006.
[10] A. W. Topol, J. D. C. La Tulipe, L. Shi, et al., â€œThree Dimensional
Integrated Circuits,â€ IBM Journal of Research and Development, vol.
50, no. 4/5, pp. 491-506, July/Sepetember 2006.
[11] R. Patti, â€œImpact of Wafer-Level 3D Stacking on the Yield of ICs,â€
Future Lab Intl., issue 23, July 2007.
[12] N. Miyakawa, â€œA 3D Prototyping Chip based on a Wafer-Level Stacking
Technology,â€ ASP-DAC, Jan. 2009.
[13] B. Swinnen, W. Ruythooren, et al., â€œ3D Integration by Cu-Cu Thermo-
Compression Bonding of Extremely Thinned Bulk-Si Die Containing
10 ğœ‡m Pitch Through-Si Vias,â€ IEDM, Dec. 2006.
[14] A. W. Topol, et al., â€œEnabling SOI-Based Assembly Technology for
Three-Dimensional Integrated Circuits,â€ IEDM, Dec. 2005.
Thermal-Aware Memory Mapping in 3D Designs
ANG-CHIH HSIEH and TINGTING HWANG
Department of Computer Science, National Tsing Hua University
DRAM is usually used as main memory for program execution. The thermal behavior of a memory
block in a 3D SIP is aï¬€ected not only by the power behavior but also the heat dissipating ability
of that block. The power behavior of a block is related to the applications run on the system
while the heat dissipating ability is determined by the number of tier and the position the block
locates. Therefore, a thermal-aware memory allocator should consider the following two points.
First, allocator should consider not only the power behavior of a logic block but also the physical
location during memory mapping, second, the changing temperature of a physical block during
execution of programs. In this paper, we will propose a memory mapping algorithm taking into
consideration the above-mentioned two points. Our technique can be classiï¬ed as static thermal
management to be applied to embedded software designs. Experiments show that, for single-core
systems, our method can reduce the temperature of memory system by 17.1âˆ˜C as compared to a
straightforward mapping in the best case, and 13.3âˆ˜C in average. For systems with 4 cores, the
temperature reductions are 9.9âˆ˜C and 11.6âˆ˜C in average when L1 cache of each core is set to 4KB
and 8KB, respectively.
Categories and Subject Descriptors: B.7.1 [Integrated Circuits]: Types and Design Stylesâ€”
VLSI (Very Large Scale Integration); B.3.1 [Memory Structures]: Semiconductor Memories;
B.8.1 [Performance and Reliability]: Reliability, Testing, and Fault-Tolerance
General Terms: Design, Reliability
Additional Key Words and Phrases: System in package (SIP), thermal management, memory
mapping
1. INTRODUCTION
System in package (SIP) provides a cost-eï¬€ective solution for large-scale integration
[1]. This technology has been widely used in mobile devices and embedded systems.
Current technology allows more than twenty chips to be stacked in one package [2].
With the capacity provided by SIP technology, integrating memory chips into pack-
age has become popular in recent years. Several researches on memory integration
based on SIP have been studied [3][4][5][6][7]. Though SIP technology provides
extremely high capacity for circuit integration, it suï¬€ers severe thermal stress be-
cause of three dimensional stacking of ICs [8]. Thermal stress will induce variation
of DRAM retention time and reliability problem [9].
Many temperature-aware researches have been conducted. They can be classi-
ï¬ed into two categories, dynamic and static thermal managements. The former
techniques detect the temperature information at run-time, and stop hot units op-
erating till their temperature cools down. Examples such as voltage scaling [10],
throttling techniques [11], and non-DVS localized thermal management [12] are in
this category. Dynamic thermal management schemes can precisely monitor tem-
perature value and guarantee that the system temperature will never be higher
than a predeï¬ned constraint, however, at the cost of slowdown of the processor ex-
ecution. As to static thermal management, the proï¬ling data is generated ï¬rst and
then used to analyze the temperature distribution of the program. [13] proposes a
ACM Journal Name, Vol. V, No. N, Month 20YY, Pages 1â€“0??.
Preparing Articles for the ACM Transactions â‹… 3
Dual Die DRAM Packages on PCB Module
DRAM Die
DRAM Die
DRAM 
Die
DRAM 
Die
DRAM 
Die
DRAM 
Die
DRAM 
Die
DRAM 
Die
DRAM 
Die
DRAM 
Die
DRAM 
Die
DRAM 
Die
DRAM 
Die
DRAM 
Die
DRAM 
Die
DRAM 
Die
DRAM 
Die
DRAM 
Die
DRAM Dies in SIP
Fig. 1. DRAM Packages on PCB and DRAM Dies in SIP Design
have quite diï¬€erent access frequencies. For example, instructions of an application
are all loaded to a consecutive memory space. But segments for instructions of
diï¬€erent loops or diï¬€erent functions are accessed with diï¬€erent frequencies. This
situation can also be found in memory blocks for data, heap and stack. In tra-
ditional on-board DRAM chips, the mapping between these memory blocks and
physical DRAM chips can be simple since all DRAM chips are identical. However,
for SIP designs, the mapping problem becomes complicated because the behavior
of each memory block and the heat dissipating ability of each DRAM chip need to
be considered simultaneously for thermal management.
Figure 2 gives an example to present our motivation. Assume that a program is
executed with 4 stages. 4 functions named funcA(), funcB(), funcC() and funcD()
are called in each stage, as shown in Figure 2(a). When a function is called, its
corresponding memory segment is accessed. Since diï¬€erent function has diï¬€erent
behavior, each segment has diï¬€erent access frequency. Let the access frequency
of each segment be given in Figure 2(b) where access frequency is deï¬ned as the
number of accesses to a memory segment divided by the total cycle counts of that
stage. In this simpliï¬ed example, we assume each memory die has only two banks.
Due to design constraints, for each memory die, only one bank can be accessed
at a time. Let a wider memory word be composed of bits from two dies. Then
2 memory dies are required to be triggered simultaneously for each access. This
means an address will map to 2 banks of 2 diï¬€erent memory dies. Three mapping
policies are shown in Figure 2(c)-(e). Figure 2(c) shows a straightforward map-
ping (Mapping A) where two banks at the same relative position denoted as ğ´, ğµ,
ğ¶, ğ· are accessed simultaneously. Figure 2(d) shows a mapping (Mapping B) to
avoid stacking eï¬€ect where banks accessed at the same tier are not in the same
vertical position and Figure 2(e) a mapping (Mapping C ) consider stacking eï¬€ect
ACM Journal Name, Vol. V, No. N, Month 20YY.
Preparing Articles for the ACM Transactions â‹… 5
32-bit Processor
Memory Controller
System Bus
DRAM 
Die 0
DRAM
Die 1
DRAM
Die 2
DRAM 
Die 3
DRAM 
Die 4
DRAM
Die 5
DRAM
Die 6
DRAM 
Die 7
DRAM 
Die 8
DRAM
Die 9
DRAM
Die 10
DRAM
Die 11
DRAM 
Die 12
DRAM
Die 13
DRAM
Die 14
DRAM 
Die 15
Group 1
Group 2
Group 3
Group 4
8-bit 8-bit 8-bit 8-bit
Fig. 3. Memory System
that mappings considering stacking eï¬€ect but banks located at bottom tiers (Map-
ping C ) sometimes has higher temperature than straightforward mapping. But in
both stages, the temperature is relative low because of low access frequency. The
maximum temperature occurs in Stage IV because of the highest access frequency.
Stage IV (funcD()) shows that a mapping considering stacking eï¬€ect (Mapping C )
and program behavior can reduce the maximum temperature by 18âˆ˜C and 12âˆ˜C as
compared to Mappings A and B respectively.
3. SYSTEM MODEL AND PROBLEM DEFINITION
In this section, we will ï¬rst give our system model. Based on the model, we will
deï¬ne our problem and propose an overall design ï¬‚ow. The data width of a modern
DRAM chip often ranges between 20-bit to 24-bit while processors have a 32-bit,
64-bit, or more data lines. Therefore, to read or write a 32-bit, 64-bit or more
bit word from memory, multiple DRAM chips need to be accessed. Figure 3 gives
an example of a system containing 32-bit processor, system bus, memory controller
and 8-bit DRAM chips. To access a 32-bit data, 4 DRAM chips need to be activated
simultaneously. Let the DRAM chips activated simultaneously form a group. Then,
in the example, DRAM Die 0 to DRAM Die 3 are in the same group. To increase
the number of words (address space) in the system, multiple groups are assembled.
In the example, there are 4 groups. Hence, the total address space is 4 times the
word capacity of one group.
In a stacked SIP system, memory dies are stacked one tier on another. In one tier,
there will be one or more dies packed. Due to intra-tier package routing constraint,
the number of dies packed in one tier is rarely greater than 4. Figure 4(a) shows
a system that has 8 tiers and 2 dies packed in one tier. Within a die, there are
multiple banks in it. The ï¬‚oorplan of a typical DRAM chip with 4 banks is shown in
Figure 4(b). For each memory access, Control & Pre-charge Circuits block is always
triggered. This block contains control, error correction and pre-charge circuits. The
ACM Journal Name, Vol. V, No. N, Month 20YY.
Preparing Articles for the ACM Transactions â‹… 7
Parameters of the memory 
system
Determination of 
Candidate Configurations
Memory reference records 
for all applications
Application Behavior 
Analysis
Segments of all 
applications
ILP Formulation for 
Segments Mapping
Mapping decisions for all 
segments
Configurations of the 
memory ststem
Candidate configurations
Fig. 6. Overall Flow
high power density due to their small area size. In general, more than 30% power
of a DRAM chip is consumed by Sense Ampliï¬er block while the area of a block is
usually less than 5% of the total area. Sense Ampliï¬er blocks are usually candidates
for hotspot. If continuous addresses in a bank are accessed, Sense Ampliï¬er blocks
stacked at the same relative position in 3D space will result in high temperature.
On the other hand, Figure 5(b) shows another access mapping where the same
dies form a group but banks in diï¬€erent relative positions are selected to form a set.
In this mapping, lower temperature can be expected because the activated banks
are not in the same vertical location.
In this paper, we will study a memory mapping problem to minimize the max-
imum temperature in a stacked 3D memory system. The problem is deï¬ned as
follows. Given parameters of a memory system and the proï¬ling of memory refer-
ences for all application programs, the objective is to ï¬nd a memory conï¬guration
and a mapping from logical address to physical location so that the maximum
temperature is minimized.
To solve this problem, the ï¬‚ow depicted in Figure 6 is proposed. The ï¬rst step,
Determination of Candidate Conï¬gurations is, for given parameters of a memory
system, to ï¬nd candidate memory conï¬gurations (in Section 4.1). Then, behav-
iors of applications run on the system are analyzed in the second step, Application
Behavior Analysis, where logical memory blocks that have the similar behaviors
are grouped in a segment (in Section 4.2). According to the candidate conï¬gura-
tions and segments obtained, the last step, ILP Formation for Segments Mapping,
is an ILP formulation to perform mapping so that the maximum temperature is
minimized (in Section 4.3).
ACM Journal Name, Vol. V, No. N, Month 20YY.
Preparing Articles for the ACM Transactions â‹… 9
Tier n
Tier n + 1
(a)
Set 0
Set 1
Set 2
Set 3 (b)
Tier n
Tier n + 1
Fig. 9. (a) Conï¬guration I ; (b) Conï¬guration II
a group. However, most of combinations of dies are not required to be considered.
Because dies in a group are accessed simultaneously, thermal behavior of a group is
determined by the die that has the worst behavior. For example, if die 7, die 6, die
5 and die 4 in Figure 4(a) are deï¬ned as a group, though die 7 is on the top tier
and has the best heat dissipating ability, the actual thermal behavior of the group
is bounded by die 4. No matter how low the temperature of die 7 is, the memory
space provided by the group would not be functional if die 4 is overheated. Thus,
dies in a group should have similar environmental conditions.
Based on the discussion above, how to form a group becomes straightforward.
We should group dies on consecutive tiers into a group. In our example, because
the number of dies in a group = 4 and #ğ‘‘ğ‘–ğ‘’ ğ‘œğ‘› ğ‘¡ğ‘–ğ‘’ğ‘Ÿ = 2, dies on 2 neighboring
tiers forms a group. That is, die 0, die 1, die 8, and die 9 form a group, and die 2,
die 3, die 10, and die 11 form a group,...etc.
Next, we show how to determine the banks in a set. First, banks on the same
tier have diï¬€erent heat dissipating abilities when #ğ‘‘ğ‘–ğ‘’ ğ‘œğ‘› ğ‘¡ğ‘–ğ‘’ğ‘Ÿ â‰¥ 2. For example,
suppose there are two dies on a tier as shown in Figure 8. Banks 1, 3, 4 and 6 are in
the middle area of the tier and therefore have worse thermal behavior than banks
0, 2, 5 and 7. Second, accessing banks of diï¬€erent dies at the same vertical position
will result in undesirable thermal eï¬€ect. For example, banks 0, 8 are at the same
vertical position. If they are accessed simultaneously, heat will be generated in a
small area and cannot be dissipated in vertical directions. This situation should
be avoided. Based on the discussion above, possible sets combinations for a group
can be deï¬ned through enumeration. The term conï¬guration is used to refer to a
deï¬nition of all sets in a group. We use the example in Figure 8 to explain how to
determine possible conï¬gurations where dies on two neighboring tiers form a group.
We start with deï¬ning a set with best thermal behavior. As mentioned earlier,
the thermal behavior of a set is determined by the bank with the worst thermal
behavior. Therefore, to deï¬ne a set with best thermal behavior, two rules should be
followed. Rule 1 is that banks in the middle area should not be grouped in the same
set and rule 2 is that banks in the same vertical position should not be grouped in
the same set. Following these two rules, Figure 9 shows two resultant conï¬gurations,
Conï¬guration I and Conï¬guration II, where banks drawn in the same patterns are
deï¬ned as a set. Two conï¬gurations have their own characteristics. In Conï¬guration
I, set 0 and set 1 have good heat dissipating ability because the banks in these two
sets are all in the boundary. However, the environmental conditions of set 2 and
set 3 are worse than those of set 0 and set 1 because banks in set 2 and set 3 are
all located in the middle positions with less heat dissipating abilities. On the other
ACM Journal Name, Vol. V, No. N, Month 20YY.
Preparing Articles for the ACM Transactions â‹… 11
address lines connected to BA 0 and BA 1 doubles the mapping space. Table in
Figure 10(b) enumerates all mappings supported by the proposed circuit. The ï¬rst
column of the table speciï¬es whether the address lines are swapped, and the second
and third columns represent whether INV BA 0 and INV BA 1 are set to 1 or 0.
The forth column gives the address of each bank after re-mapping. Though only one
thirds of all possible mappings are supported by our proposed circuit, it is suï¬ƒcient
to implement most of desired conï¬gurations. Figure 10(c) shows the settings for
Conï¬gurations I & II as examples.
Next, we should determine the cost of each conï¬guration under diï¬€erent access
frequency to each set. In each conï¬guration and in each set, we deï¬ne the relation
between temperature and access frequency by simulation. This relation can be used
to determine the cost of mapping a memory segment with given access frequency to
a set. For a set, the average power is deï¬ned as follows. First, the access to memory
is divided to read access and write access. And operating power in Equation (1)
considers diï¬€erent ratios of read and write access where ğ›¼ represents the ratio of
read access to total access and (1âˆ’ ğ›¼) the ratio of write access to total access.
ğ‘ƒğ‘œğ‘¤ğ‘’ğ‘Ÿğ‘‚ğ‘ğ‘’ğ‘Ÿğ‘ğ‘¡ğ‘–ğ‘›ğ‘” = ğ‘ƒğ‘œğ‘¤ğ‘’ğ‘Ÿğ‘…ğ‘’ğ‘ğ‘‘ Ã— ğ›¼+ ğ‘ƒğ‘œğ‘¤ğ‘’ğ‘Ÿğ‘Šğ‘Ÿğ‘–ğ‘¡ğ‘’ Ã— (1 âˆ’ ğ›¼) (1)
Next, with diï¬€erent access frequency to a ğ‘ ğ‘’ğ‘¡, ğ‘“ , Equation (2) is deï¬ned for the
average power.
ğ‘ƒğ‘œğ‘¤ğ‘’ğ‘Ÿğ´ğ‘£ğ‘” = ğ‘ƒğ‘œğ‘¤ğ‘’ğ‘Ÿğ‘‚ğ‘ğ‘’ğ‘Ÿğ‘ğ‘¡ğ‘–ğ‘›ğ‘” Ã— ğ‘“ + ğ‘ƒğ‘œğ‘¤ğ‘’ğ‘Ÿğ‘†ğ‘¡ğ‘ğ‘›ğ‘‘ğ‘ğ‘¦ Ã— (1âˆ’ ğ‘“) (2)
Finally, the simulation of each set is done as follows. For each ğ‘“ , the average power
is calculated. Then, the hardware blocks of the target set for simulation are set with
the average power while all other blocks with standby power. Next, thermal simu-
lation tool is called to obtain the steady state temperature. In this paper, HotSpot
4.0 [16] is used as our thermal simulation tool. The temperature obtained will be
used to evaluate the eï¬€ect of mapping a memory segment with access frequency ğ‘“
to a set. Notice that this temperature computed may be underestimated since all
other surrounding blocks are assumed to be idle. That means, the interaction eï¬€ect
of blocks in the model is ignored. However, this underestimation is acceptable since
the temperature can still reï¬‚ect the thermal behavior of a set under a given access
frequency. We use the term,
ğ‘‡ (ğ‘—, ğ‘“)
to represent the steady state temperature when set ğ‘— is accessed with frequency ğ‘“ .
This term will be used to deï¬ne the cost function in Section 4.3.
4.2 Application Behavior Analysis
For each program runs on the system, the memory requirement is varying over the
time. We can partition a programâ€™s logical address space to a number of segments
each with diï¬€erent access frequencies and then based on access frequency, map
each segment to diï¬€erent physical locations in a 3D memory to minimize maximum
temperature.
An algorithm, Behavior Analysis Algorithm, is developed for this purpose as
shown in Figure 11. First, proï¬ling of memory references for application programs
is recorded. For each cycle, whether memory is accessed and if yes, which memory
ACM Journal Name, Vol. V, No. N, Month 20YY.
Preparing Articles for the ACM Transactions â‹… 13
1 Algorithm : Program Behavior Analysis Algorithm()
2 Input : Memory reference record
3 Output : Memory segments
4
5 ğ‘ğ‘œğ‘¢ğ‘›ğ‘¡ğ‘’ğ‘Ÿ = 0;
6 While(end of record is not reached)
7 {
8 ğ‘Ÿğ‘’ğ‘“ = ReadNextReference();
9 If(ğ‘Ÿğ‘’ğ‘“ is TRUE)
10 {
11 ğ‘ ğ‘’ğ‘”ğ‘šğ‘’ğ‘›ğ‘¡ = FindSegmentFor(ğ‘Ÿğ‘’ğ‘“);
12 If(ğ‘ ğ‘’ğ‘”ğ‘šğ‘’ğ‘›ğ‘¡ == NULL)
13 CreateNewSegmentFor(ğ‘Ÿğ‘’ğ‘“);
14 Else
15 AddInfoTo(ğ‘ ğ‘’ğ‘”ğ‘šğ‘’ğ‘›ğ‘¡, ğ‘Ÿğ‘’ğ‘“);
16 }
17 ğ‘ğ‘œğ‘¢ğ‘›ğ‘¡ğ‘’ğ‘Ÿ++;
18 If(ğ‘ğ‘œğ‘¢ğ‘›ğ‘¡ğ‘’ğ‘Ÿ == ğ‘ğ‘’ğ‘Ÿğ‘–ğ‘œğ‘‘)
19 {
20 ğ‘ğ‘œğ‘¢ğ‘›ğ‘¡ğ‘’ğ‘Ÿ = 0;
21 UpdateAllSegments();
22 MergeNeighboringSegmentsWithSimilarBehavior();
23 }
24 }
25 UpdateAllSegments();
26 MergeNeighboringSegmentsWithSimilarBehavior();
Fig. 11. Algorithm for Behavior Analysis Algorithm
subject to
âˆ‘
ğ‘¥
ğ¶ğ‘œğ‘›ğ‘“ğ‘–ğ‘”ğ‘¥,ğ‘¦ = 1, âˆ€ ğ‘¦ (4)
âˆ‘
ğ‘¥,ğ‘¦,ğ‘§
ğ‘†ğ‘’ğ‘”ğ‘šğ‘’ğ‘›ğ‘¡ğ‘–,ğ‘†ğ‘’ğ‘¡ğ‘¥,ğ‘¦,ğ‘§ = 1, âˆ€ ğ‘– (5)
UNIT SET SIZEÃ— ğ¶ğ‘œğ‘›ğ‘“ğ‘–ğ‘”ğ‘¥,ğ‘¦ = ğ‘†ğ‘’ğ‘¡ğ‘†ğ‘–ğ‘§ğ‘’ğ‘†ğ‘’ğ‘¡ğ‘¥,ğ‘¦,ğ‘§ ,
âˆ€ ğ‘¥, ğ‘¦, ğ‘§ (6)
âˆ‘
ğ‘– ğ‘†ğ‘’ğ‘”ğ‘šğ‘’ğ‘›ğ‘¡ğ‘†ğ‘–ğ‘§ğ‘’ğ‘–Ã— ğ‘†ğ‘’ğ‘”ğ‘šğ‘’ğ‘›ğ‘¡ğ‘–,ğ‘†ğ‘’ğ‘¡ğ‘¥,ğ‘¦,ğ‘§ â‰¤ ğ‘†ğ‘’ğ‘¡ğ‘†ğ‘–ğ‘§ğ‘’ğ‘†ğ‘’ğ‘¡ğ‘¥,ğ‘¦,ğ‘§ ,
âˆ€ ğ‘¥, ğ‘¦, ğ‘§ (7)
The ğ¶ğ‘œğ‘ ğ‘¡ğ‘–,ğ‘†ğ‘’ğ‘¡ğ‘¥,ğ‘¦,ğ‘§ (the detail of computing ğ¶ğ‘œğ‘ ğ‘¡ğ‘–,ğ‘†ğ‘’ğ‘¡ğ‘¥,ğ‘¦,ğ‘§ will be explained later)
represents the temperature cost when ğ‘†ğ‘’ğ‘”ğ‘šğ‘’ğ‘›ğ‘¡ ğ‘– is mapped to ğ‘†ğ‘’ğ‘¡ğ‘¥,ğ‘¦,ğ‘§. The ob-
jective is to minimize the mapping cost. Equation (4) guarantees each group has
exactly one conï¬guration. Equation (5) is required to make sure each segment maps
to only one set. Equation (6) ensures that if ğ¶ğ‘œğ‘›ğ‘“ğ‘–ğ‘”ğ‘¥,ğ‘¦ = 1 (conï¬guration ğ‘¥ is se-
lected for ğ‘¦ group), the size of all sets under ğ‘¥ conï¬guration for ğ‘¦ group is equal to
ACM Journal Name, Vol. V, No. N, Month 20YY.
Preparing Articles for the ACM Transactions â‹… 15
Table I. Parameters for Experiments
System Parameter Value
#ğ‘¡ğ‘–ğ‘’ğ‘Ÿ 8
#ğ‘‘ğ‘–ğ‘’ ğ‘œğ‘› ğ‘¡ğ‘–ğ‘’ğ‘Ÿ 2
#ğ‘ğ‘ğ‘›ğ‘˜ 4
#ğ‘ğ‘ğ‘›ğ‘‘ğ‘¤ğ‘–ğ‘‘ğ‘¡â„ ğ‘‘ğ‘–ğ‘’ 8
#ğ‘ğ‘ğ‘›ğ‘‘ğ‘¤ğ‘–ğ‘‘ğ‘¡â„ ğ‘ ğ‘¦ğ‘ ğ‘¡ğ‘’ğ‘š 32
DRAM Chip Parameter Value
Capacity 512 Mb
Internal Clock Rate 200 MHz
Voltage 2.5 V
Max. Power 0.75 W
Standby Power 0.34 W
Total Memory Size 1 GB
L1 Cache Architecture
Single-Core
Size: 512B
Organization: Direct-Mapped
Line Size: 16-byte
(32 Sets)
Multi-Core
Size: 4KB/8KB
Organization: Direct-Mapped
Line Size: 32-byte/64-byte
(128 Sets)
Power Values (mW)
Mode Sense Ampliï¬er Cell Bank Control & Pre-charge
Standby 36.5 18.2 121.2
Active Read 186.4 94.9 211.6
Active Write 217.6 114.6 245.7
5. EXPERIMENTAL RESULTS
In this section, experimental results for diï¬€erent execution conditions are presented.
The system parameters are listed in Table I where the power values are estimated
based on the ğ¼ğ·ğ· values of a Hynix DDR400 512 Mb SDRAM chip [17]. We
assume the system supports multiprogramming with Round-Robin scheduling and
all programs run on the system are pre-loaded to memory. In Section 5.1, the
program set is composed of MediaBench [18], PowerStone [19] benchmark suites and
JM H.264/AVC CODEC [20]. The programs are duplicated to multiple instances
to simulate systems with diï¬€erent memory utilization ratio. For experiments in
Section 5.2, programs from SPEC CPU2000 benchmark suite are also included.
SimpleScalar 3.0 [22] is used to generate memory reference records. lp solve 5.5
[23] is used as our ILP solver. HotSpot 4.0 [16] is used as our thermal simulation
tool. To demonstrate the eï¬ƒciency of our method, two straightforward mappings
are tested for comparison. The ï¬rst one selects 4 DRAM dies at the same relative
positions of 4 consecutive tiers as a group and the second selects all 4 dies of 2
consecutive tiers as a group. Notice that no additional re-mapping circuits are
added in these two mappings and therefore stacking eï¬€ect among banks cannot
be avoided. These two mappings are referred as M 1 and M 2 while our proposed
mapping is referred as M ours in the following discussion.
In Section 5.1, a single-core system with 512B cache size is used to examine the
eï¬€ectiveness of our proposed memory mapping ï¬‚ow. Next, in Section 5.2, a multi-
core system with 4KB/8KB cache size is used for experiment. For both experiments
in Section 5.1 and Section 5.2, the cache architectures are direct-mapped and the
value of ğ¿ is set to 12. The tradeoï¬€ between the value of ğ¿ and the quality of
mapping result is discusses in Section 5.3.
ACM Journal Name, Vol. V, No. N, Month 20YY.
Preparing Articles for the ACM Transactions â‹… 17
Table II. Workload Combinations
Core 1 Core 2 Core 3 Core 4
W1 MediaBench PowerStone JM H.264 gzip
W2 MediaBench + PowerStone JM H.264 gzip gcc
W3 JM H.264 gzip gcc mcf
near saturated frequency and increasing the clock rate of processor will only lead
to limited increase in access frequency. However, for segments accessed with low
frequency, the increase in access frequency will be proportional to the increase ra-
tio of processorâ€™s clock rate. Since maximum temperature is usually observed on
tiers with less heat dissipating ability and M ours maps segments with low access
frequency to these tiers, access frequency of these tiers is increased signiï¬cantly as
compared to other tiers. Therefore, M ours cannot provide the same temperature
reduction when clock rate of processor is increased. Still, our method reduces the
temperature by 14.5âˆ˜C and 11.9âˆ˜C as compared to M 1 and M 2 (75%, 800 MHz).
Finally, when the clock rate of processor is set to 1.2 GHz under 95% memory uti-
lization (the rightmost column), the temperature is reduced by 12.2âˆ˜C and 9.3âˆ˜C
as compared to M 1 and M 2 (95%, 800 MHz). Also, notice that in all experiments,
M 2 is consistently better than M 1, which conï¬rms our observations to form dies
in adjacent tiers in a group.
5.2 Experiments for Multi-Core System
A multi-core system is assumed in this section. The objective of experiments in this
section is to demonstrate the eï¬€ectiveness of our proposed method when the mem-
ory system is accessed by multiple cores running diï¬€erent applications. Increasing
the number of cores leads to higher access rate to memory system. To make the
overall access rate to the memory system more reasonable, the cache memory size
(L1 Cache) of each core is increased to 4KB in the ï¬rst experiment of this section.
In this paper, the applications run on diï¬€erent cores are assumed to be independent
to each other and hence data consistency is not considered. For each core, a set
of programs are assigned as its workload. To avoid the memory access behavior of
each core to be similar, 3 more programs (gcc, gzip, mcf) from SPEC CPU2000
are added to our program set. In terms of program behavior, these three programs,
as well as JM H.264/AVC CODEC, are much more complicated than other pro-
grams in our program set. Therefore, when a core is assigned with one of these
programs as its workload, it will not be assigned with any other programs. Also
note that these four complicated programs contain many consecutive memory reads
and writes. Increasing the number of cores executing these complicated programs
will largely increase the number of segments with high access frequencies. Since
SimpleScalar does not support multi-core simulation, the memory access behavior
of each core is ï¬rst recorded individually. Then, the memory access behaviors of all
cores are multiplexed to create the workload to the memory system. The system is
set to contain 4 cores, and three types of workloads, ğ‘Š1, ğ‘Š2 and ğ‘Š3, are used in
the experiments as listed in Table II.
The experimental results are shown in Figure 13. In these experiments, the fre-
quencies of the cores are set to 800 MHz. Similar to Section 5.1, for each workload
ACM Journal Name, Vol. V, No. N, Month 20YY.
Preparing Articles for the ACM Transactions â‹… 19
M_1
M_2
Fig. 15. The Highest Temperature for Diï¬€erent Values of ğ¿
each core. When L1 cache size of each core is set to 8KB, the experimental results
are shown in Figure 14. Similar to Figure 13, the maximum temperature of the
system increases and the average improvements degrades as the workload combina-
tion contains more complicated programs. However, the improvement degradation
becomes more stable. The average improvements of our proposed mapping ï¬‚ow for
W1, W2, and W3 are 13.58âˆ˜C, 11.23âˆ˜C, and 9.88âˆ˜C respectively. The experiments
indicate that the design of cache architecture is very important to 3D memory
designs since it directly aï¬€ects the memory access behavior.
5.3 Experiments for Segment Merging
In this section, the tradeoï¬€ between the value of ğ¿ and the quality of mapping
result is discussed. The single-core system model introduced in Section 5.1 is used
in this section. The frequency of the processor and memory utilization ratio are set
to 800 MHz and 75% respectively. Diï¬€erent values of ğ¿ are tested. Experiments are
performed on a Linux workstation with Intel Pentium 4 3.4 GHz CPU and 2 GB
memory. For diï¬€erent values of ğ¿, the highest temperature and the computation
time are summarized in Figure 15 and Table III.
Two dash lines which represent the highest temperatures of M 1 andM 2 (straight-
forward mappings) are depicted in Figure 15 for comparison. When the values of ğ¿
are set to 4 and 6, little improvement is observed. This is because the granularity of
the merging scheme is too coarse-grained. Segments that have high access frequen-
cies are merged with segments with relatively low access frequencies. Our proposed
mapping ï¬‚ow can not accurately map all segments that have high access frequencies
to physical locations with better heat dissipation. Therefore, the improvement is
limited. As the value of ğ¿ increases, only segments with less diï¬€erence in access
frequency are allowed to be merged. Better mapping results can be obtained. When
the value of ğ¿ is set to 12, segments are merged with suï¬ƒciently ï¬ne granularity.
According to Figure 15, increasing the value of ğ¿ to be greater than 12 results in
ACM Journal Name, Vol. V, No. N, Month 20YY.
Preparing Articles for the ACM Transactions â‹… 21
Table III. Computation Time
L #segment #var. Computation Time
4 93 2980 9 min 27 sec
6 102 3268 12 min 3 sec
8 117 3748 18 min 46 sec
10 133 4260 25 min 19 sec
12 157 5028 33 min 54 sec
14 179 5732 45 min 12 sec
16 204 6532 1 hr 3 min 7 sec
6. CONCLUSION
In this paper, we have proposed a static thermal management scheme for DRAM
dies in stacked 3D designs. Both physical and software level issues are considered
in our method. In physical level, the ï¬‚oorplan of DRAM die and power behavior
of bank access are analyzed to generate candidate conï¬gurations. In software level,
the memory space of the programs run on the system are partitioned to segments
based on access frequency. The conï¬guration decision and the mapping segments
to physical locations are formulated as an ILP problem. For single-core systems,
experiments show that our method can reduce temperature of memory system by
17.1âˆ˜C as compared to a straightforward mapping in the best case, and 13.3âˆ˜C
in average. For systems with 4 cores, the temperature reductions are 9.9âˆ˜C and
11.6âˆ˜C in average when L1 cache of each core is set to 4KB and 8KB, respectively.
REFERENCES
K. L. Tai, â€œSystem-In-Package (SIP): Challenges and Opportunities,â€ Asia and South Paciï¬c
Design Automation Conference, pp. 191-196, 2000.
Alexandru Pancescu, â€œHynix Storms The NAND Industry - 24 nand memory chips only 1.4mm
thick,â€ SOFTPEDIA, Sep. 7, 2007.
K. L. Tai, R. C. Frye, B. J. Han, M. Y. Lau, and D. Kossives, â€œA chip-on-chip DSP/SRAM
multichip module,â€Intâ€™l Conf. on Multi-chip Modules, pp 466-471, 1995.
Y. L Low, R.C Frye, and K. J OConner, â€œDesign methodology for chip-on-chip applications,â€
IEEE Trans. on Components, Packaging, and Manufacturing Technology Part B, vol. 21, pp.
298-301, Aug. 1998.
M. X. Wang, K. Suzuki, W. Dai, Yee L. Low, K. J. Oconner and K. L. Tai, â€œIntegration of
Large-Scale FPGA and DRAM in a Package Using Chip-on-Chip Technologyâ€, Asia and South
Paciï¬c Design Automation Conference, pp. 205- 210, 2000.
Michael Wang, Katsuharu Suzuki, Wayne Dai, Atsushi Sakai, Kiwamu Watanabe, â€œConï¬g-
urable Area-IO Memory for System-in-a-Package (SiP),â€ 27th European Solid-State Circuits
Conference, September, 2001.
Michael Wang, Katsuharu Suzuki, Wayne Dai, â€œMemory and Logic Integration for System-in-
a-Package,â€ 4th Intâ€™l Conf. on ASIC, October, 2001.
Kiran Puttaswamy and Gabriel H. Loh, â€œThermal Analysis of a 3D Die-Stacked High-
Performance Microprocessor,â€ ACM/IEEE Great Lakes Symposium on VLSI, pp 19-24, 2006.
Y. I. Kim, K. H. Yang, W. S. Lee, â€œThermal Degradation of DRAM Retention Time: Charac-
terization and improving techniques,â€ Proceedings of the 42nd IEEE Intâ€™l Reliability Physics
Symp., pp. 667-668, April 2004.
D. Brooks and M. Martonosi, â€œDynamic Thermal Management for High-Performance Micropro-
cessors,â€ Proceedings of the Seventh International Symposium on High-Performance Computer
Architecture, February 2001.
K. Skadron, T. Abdelzaher and M. R. Stan, â€œControl Theoretic Techniques and Thermal-RC
Modeling for Accurate and Localized Dynamic Thermal Management,â€ Proceedings of the
Eighth International Symposium on High-Performance Computer Architecture, February 2002.
ACM Journal Name, Vol. V, No. N, Month 20YY.
 
åœ‹ç§‘æœƒè£œåŠ©å°ˆé¡Œç ”ç©¶è¨ˆç•«é …ä¸‹å‡ºå¸­åœ‹éš›å­¸è¡“æœƒè­°å¿ƒå¾—å ±å‘Š 
                                æ—¥æœŸï¼š   ï¦   æœˆ   æ—¥ 
ä¸€ã€ï¥«åŠ æœƒè­°ç¶“é 
æœ¬æ¬¡æœƒè­°çš„ç›®çš„ç‚ºå ±å‘Šç ”ç©¶çš„æˆæœã€‚æˆ‘å€‘çš„ï¥æ–‡ä¸»è¦æ˜¯åœ¨æ¢è¨ 3D IC redundant TSV è¨­
è¨ˆï¼Œä»¥è§£æ±º TSV failure çš„ recoveryã€‚é™¤ï¦ºï¥æ–‡å ±å‘Šå¤–ï¼Œäº¦ï¨Šåˆ°è¨±å¤šç›¸é—œï¦´åŸŸæ•™æˆï¼Œè¨ï¥
ç”šä½³ã€‚ 
 
äºŒã€èˆ‡æœƒå¿ƒå¾— 
DATE æœƒè­°åŒ…å«è¼ƒå¤š system åŠ software æ–¹é¢çš„ç ”ç©¶ï¦´åŸŸï¼Œå…¶ submission paper çš„ï¥©ç›®
åŠï¥«åŠ äººï¥©ï¼Œï¨¦å¤§å¹…æˆé•·ï¼Œä»Šï¦ï¤è¶…è¶Š DAC åŠ ICCADã€‚ï¥«åŠ æ­¤æœƒè­°ï¼Œå…¶å„ªé»æ˜¯å¯ç¢°åˆ°
è¼ƒå¤šæ­æ´²çš„å­¸è€…ï¼Œvisibility ä¹Ÿè¶Šï¤­è¶Šé«˜ã€‚ 
ä¸‰ã€è€ƒå¯Ÿï¥«è§€æ´»å‹•(ç„¡æ˜¯é …æ´»å‹•è€…ï¥¶) 
å››ã€å»ºè­° 
äº”ã€æ”œå›è³‡ï¦¾åç¨±åŠå…§å®¹ 
ï§‘ã€å…¶ä»– 
 
è¨ˆç•«ç·¨è™Ÿ NSC 98ï¼2220ï¼Eï¼007ï¼014ï¼ 
è¨ˆç•«åç¨± 
åœ¨ System-in-Package è¨­è¨ˆä¸‹ä¹‹è‡ªå‹•åŒ–å·¥å…·ç ”ç™¼â”€å­è¨ˆç•«ä¸‰ï¼šåœ¨ SiP
è¨­è¨ˆä¸‹ä¹‹æ•£ç†±ç´„æŸæ™¶ç‰‡å †ç–Š, Leadframe ç¹ç·šåŠè¨˜æ†¶é«”æ˜ æˆä¹‹ç ”
ç©¶(3/3) 
å‡ºåœ‹äºº
å“¡å§“å é»ƒå©·å©· 
æœå‹™æ©Ÿæ§‹
åŠè·ç¨± æ¸…è¯å¤§å­¸è³‡è¨Šå·¥ç¨‹å­¸ç³»   æ•™æˆ 
æœƒè­°æ™‚é–“ 99 ï¦ 03 æœˆ 04 æ—¥è‡³99 ï¦ 03 æœˆ 13 æ—¥ æœƒè­°åœ°é» å¾·åœ‹ Dresdon 
æœƒè­°åç¨± (ä¸­æ–‡) (è‹±æ–‡)2010 DATE 
ç™¼è¡¨ï¥
æ–‡é¡Œç›® 
(ä¸­æ–‡) 
(è‹±æ–‡) TSV Redundancy: Architecture and Design Issues 
TSV TSV
TSV TSV
Upper Tier
Lower Tier
Fig. 1. Bonding between TSVs and Bond Pads
for each TSV [9][10]. In addition to misalignments, TSVs
can also fail in the soldering process [11]. For example, short
circuits between two distinct TSVs or open circuits between a
TSV and its corresponding bonding pad may be formed. Other
failure mechanisms such as dislocation, process variations or
mechanical stress also decrease the fabrication yield of TSVs.
Above all, misalignment and failures on bonding are pri-
mary failure mechanisms for TSVs [11]. Both of the tech-
nologies used for alignment and bonding are very similar
to the packaging methods used in current IC industry [5].
Although the exact failure rate of TSVs is still not clear, it
is possible to use the failure rates of alignment and bonding
to perform a failure rate analysis for TSV. Considering the
TSV diameter and the size of bond pads, the failure rate of
a single TSV may ranges between 10âˆ’4 and 10âˆ’5 based on
current packaging technology. This assumption roughly meets
the yields of TSVs from the process technologies of HRI,
IMEC and IBM [12][13][14].
According to the applications and network styles, the num-
ber of TSVs in each tier can be quite different. For many-core
processors or NoC-based designs, thousands of TSVs may be
required in each tier. On the contrary, hundreds of TSVs may
be sufcient for smaller IP-based designs. In this work, we
focus on IP-based designs where TSVs are mainly used for
connections between modules on different tiers. Considering
the area of bond pads and oorplan problems, we assume that
the number of TSVs to be placed in a tier ranges from 300
to 500.
An analysis between failure rate and yield is given in
Figure 2. Assume that all dies to be stacked are known-good-
dies. Thus, only the failure rate of TSV bonding needs to be
considered. Let f stands for the failure rate of bonding one
TSV and #tier stands for the number of tiers to be stacked.
Note that the actual number of tiers that contain TSVs to be
bonded is equal to #tier - 1. For example, when #tier = 2, only
the top tier contains TSVs to be bonded. The x-axis represents
the number of TSVs to be placed in each tier (#TSV). Since a
good chip stack requires all TSVs to be successfully bonded,
the binding yield can be computed as (1âˆ’ğ‘“)#ğ‘‡ğ‘†ğ‘‰Ã—(#ğ‘¡ğ‘–ğ‘’ğ‘Ÿâˆ’1).
The analysis results for ğ‘“ = {0.0001, 0.00002} and #ğ‘¡ğ‘–ğ‘’ğ‘Ÿ =
{2 , 5} are shown in Figure 2. Without any redundant TSVs,
the average yield is 94.35%. And when #ğ‘‡ğ‘†ğ‘‰ = 500 and
#ğ‘¡ğ‘–ğ‘’ğ‘Ÿ = 5, the yield degrades to 81.8%. Note that dies to
be stacked are all known-good-dies. Therefore, the cost of
discarding chip stacks that are failed due to TSV bonding is
very expensive. In fact, in most failed chip stacks, only a very
80 00%
85.00%
90.00%
95.00%
100.00%
p 
St
ac
ks
 w
ith
 n
o 
Fa
ile
d 
TS
V
f = 0 0001 #tier = 2
70.00%
75.00%
.
300 350 400 450 500
%
of
 C
hi
p 
St
ac
ks
 w
ith
 n
o 
Fa
ile
d 
TS
V
#TSV
  . ,  
f=0.0001,#tier=5
f=0.00002,#tier=2
f=0.00002,#tier=5
Fig. 2. Yield Analysis
small portion of TSVs are failed. If these failed TSVs can be
recovered with circuits of reasonable cost, the yield can be
largely improved. The redundant TSV design to be proposed
in this paper provides a solution to this problem.
III. REDUNDANT TSV ARCHITECTURE
In this section, the architecture of our proposed redundant
TSV design is introduced in Section III-A. Next, a brief
introduction to the oorplan of 3D IC and its relation to our
proposed architecture are given in Section III-B.
A. Architecture Design
The proposed architecture for redundant TSV is depicted
in Figure 3. For each TSV, 2 MUXs are added to shift the
signal to neighboring TSV when one TSV is failed. To reduce
the timing effect caused by the loading capacitance of the
additional wires used for signal shifting, a pair of buffers are
added to each TSV. The TSVs are connected as a chain where
the redundant TSV is placed at the last position of the chain.
When no TSV is failed, all signals are transferred by original
TSVs as shown in Figure 4(a). When a TSV is failed, the
signal of the failed TSV needs to be shifted. This in term
causes all signals between the failed TSV and the redundant
TSV to be shifted. For example, let TSV 1 be failed. The
signal paths after shifting are shown in Figure 4(b). When a
signal is shifted, larger delay is introduced due to larger wire
length and buffers. For signals that are timing critical, this
may become a problem. We will discuss it in Section V-A.
In this architecture, only one failed TSV can be recovered in
each chain. If two or more TSVs are failed in a chain, only
one of them can be recovered. Therefore, how to determine the
number of TSVs in a chain so that an acceptable recovery rate
can be achieved is an important design issue. This issue will
be discussed in Section IV. For simplicity, the term TSV-chain
is used to refer to the structure of the proposed redundant TSV
architecture.
The MUXs in the proposed architecture are connected to an
e-fuse array which can be programmed by a scan-chain. By
default, all signals connect to MUXs are set to 0. When the
testing for TSV connectivity is done, signals are scanned in to
program the e-fuses so that each MUX receives an appropriate
control signal.
TABLE I
ğ‘ƒğ‘“ ğ‘¡ğ‘ ğ‘£=ğ‘› AND ğ¶ ğ‘…ğ‘ğ‘¡ğ‘–ğ‘œğ‘› WHEN ğ¹ = 0.0001
ğ‘ ğ‘› ğ‘ƒğ‘“ ğ‘¡ğ‘ ğ‘£=ğ‘› ğ¶ ğ‘…ğ‘ğ‘¡ğ‘–ğ‘œğ‘›
300
0 97.0444% 97.0444%
1 2.9116% 99.9560%
2 0.0435% 99.9996%
400
0 96.0788% 96.0788%
1 3.8435% 99.9223%
2 0.0767% 99.9990%
500
0 95.1227% 95.1227%
1 4.7566% 99.8793%
2 0.1187% 99.9980%
Table I shows that, when ğ‘› = 2, the values of ğ¶ ğ‘…ğ‘ğ‘¡ğ‘–ğ‘œğ‘› for
ğ‘ = {300, 400, 500} are all greater than 99.998%. A smaller
ğ¹ will result in a larger ğ¶ ğ‘…ğ‘ğ‘¡ğ‘–ğ‘œğ‘›. This means, as long as
the failure rate ğ¹ is no greater than 0.0001, the probability
that three or more TSVs are failed is less than 0.002%.
Therefore, when designing TSV-chains, we can assume that
the maximum number of failed TSVs in a tier is 2. This
assumption covers 99.998% of all possible faulty free and
faulty situations.
B. Analysis on Recovery Rate
As mentioned in Section III, each TSV-chain is capable of
recovering at most one failed TSV in a TSV block. As the
number of TSVs in a TSV block increases, the probability
that all failed TSVs can be recovered decreases. To achieve
an expected recovery rate, the number of TSVs in each TSV
block must be limited. To simplify the analysis, we assume
that the number of TSVs in all TSV blocks are identical. Let
#ğµ ğ‘‡ğ‘†ğ‘‰ stand for the number of TSVs in each TSV block
and ğ‘› stand for the number of failed TSVs. For a given value
of ğ‘›, we want to analyze the relation between #ğµ ğ‘‡ğ‘†ğ‘‰ and
recovery rate. The discussion in Section IV-A indicates that
assuming ğ‘› â‰¤ 2 is sufcient to covers 99.998% of all possible
faulty free and faulty situations. Therefore, we will perform
the analysis for ğ‘› = 1 and ğ‘› = 2 only.
Let ğ‘ stand for the number of TSVs in a tier. The
number of combinations of ğ‘ TSVs with ğ‘› failed TSVs can
be computed as ğ¶ğ‘ğ‘› . The number of combinations that all
failed TSVs can be recovered by TSV-chains is referred as
#ğ‘…ğ‘’ğ‘ğ‘œğ‘£ğ‘’ğ‘Ÿğ‘ğ‘ğ‘™ğ‘’ ğ¶ğ‘œğ‘šğ‘ğ‘–ğ‘›ğ‘ğ‘¡ğ‘–ğ‘œğ‘›ğ‘ . The recovery rate discussed
in this section is dened as
#ğ‘…ğ‘’ğ‘ğ‘œğ‘£ğ‘’ğ‘Ÿğ‘ğ‘ğ‘™ğ‘’ ğ¶ğ‘œğ‘šğ‘ğ‘–ğ‘›ğ‘ğ‘¡ğ‘–ğ‘œğ‘›ğ‘ 
ğ¶ğ‘ğ‘›
.
When ğ‘› = 1, only one failed TSV needs to be recovered.
Since one TSV block contains one redundant TSV, regardless
of the number of TSVs in each TSV block, one failed TSV can
always be recovered. Therefore, the recovery rate for ğ‘› = 1
is 100%.
The recovery rate analysis for ğ‘› = 2 is more complicated.
Let the term #ğµğ‘™ğ‘œğ‘ğ‘˜ represent the number of TSV blocks in
a tier. Under our assumptions, #ğµğ‘™ğ‘œğ‘ğ‘˜ can be computed as
ğ‘
#ğµ ğ‘‡ğ‘†ğ‘‰ . To successfully recover all failed TSVs, each failed
TSVs must be located in different TSV blocks. That is, ğ‘› TSV
blocks are selected from #ğµğ‘™ğ‘œğ‘ğ‘˜ TSV blocks. Each selected
TSV block contains exactly one failed TSV. The number of
40.00%
50.00%
60.00%
70.00%
80.00%
90.00%
100.00%
ec
ov
er
y 
R
at
e
0.00%
10.00%
20.00%
30.00%
25 26 27 29 31 33 35 38 41 45 50 55 62 71 83 100 125 166 250
R
ec
ov
er
y 
R
at
e
Number of TSVs in a TSV Block
Fig. 6. Recovery Rate when ğ‘ = 500, ğ‘› = 2
combinations that satises this requirement can be computed
as
ğ¶#ğµğ‘™ğ‘œğ‘ğ‘˜ğ‘› .
Inside each TSV block that contains one failed TSV, the
failed TSV can be located at #ğµ ğ‘‡ğ‘†ğ‘‰ possible positions.
Therefore, the #ğ‘…ğ‘’ğ‘ğ‘œğ‘£ğ‘’ğ‘Ÿğ‘ğ‘ğ‘™ğ‘’ ğ¶ğ‘œğ‘šğ‘ğ‘–ğ‘›ğ‘ğ‘–ğ‘œğ‘›ğ‘  for ğ‘› = 2 can
be computed as
ğ¶#ğµğ‘™ğ‘œğ‘ğ‘˜2 â‹… (#ğµ ğ‘‡ğ‘†ğ‘‰ )2.
The relation between #ğµ ğ‘‡ğ‘†ğ‘‰ and recovery rate for ğ‘ =
500 and ğ‘› = 2 is shown in Figure 6. For different values of
#ğµ ğ‘‡ğ‘†ğ‘‰ that result in the same #ğµğ‘™ğ‘œğ‘ğ‘˜, only the smallest
#ğµ ğ‘‡ğ‘†ğ‘‰ is shown in the gure since the recovery rates of
them are the same.1
According to Figure 6, to achieve 90% recovery rate,
#ğµ ğ‘‡ğ‘†ğ‘‰ needs to be no greater than 50. By limiting the
number of TSVs in each TSV block to be less than or equal
to 50, the recovery rate is greater than 90%. To achieve a
higher recovery rate, the gure shows that with 95% recovery
rate, the number of TSVs in each TSV block cannot be greater
than 25. In realistic ASIC designs, the number of TSVs in a
TSV block is usually less than 50. Therefore, in most cases,
TSV block partitioning is not required.
A further analysis is to compute the overall yield. In
Table I, when ğ‘ = 500, ğ‘ƒğ‘“ ğ‘¡ğ‘ ğ‘£=0, ğ‘ƒğ‘“ ğ‘¡ğ‘ ğ‘£=1, and ğ‘ƒğ‘“ ğ‘¡ğ‘ ğ‘£=2
are 95.1227%, 4.7566%, and 0.1187%, respectively. The dis-
cussion above indicates that the recovery rate for ğ‘› = 1 is
always 100% based on our proposed architecture. Thus, let
the recovery rate for ğ‘› = 2 be set to 90%. The overall yield
can be computed as
ğ‘ƒğ‘“ ğ‘¡ğ‘ ğ‘£=0+ğ‘ƒğ‘“ ğ‘¡ğ‘ ğ‘£=1Ã—100%+ğ‘ƒğ‘“ ğ‘¡ğ‘ ğ‘£=2Ã—90% = 99.98613%.
This value is high enough for most applications.
V. DESIGN FLOW AND TSV-Chain DESIGN
The discussion in Section IV focuses on the recovery of
failed TSVs in terms of connectivity. Timing issues are not
concerned. As mentioned in Section III-A, when a signal is
shifted in a TSV-chain, extra delay will be incurred. For signals
that are timing critical, the delay caused by signal shifting may
1The actual computation of#ğ‘…ğ‘’ğ‘ğ‘œğ‘£ğ‘’ğ‘Ÿğ‘ğ‘ğ‘™ğ‘’ğ¶ğ‘œğ‘šğ‘ğ‘–ğ‘›ğ‘ğ‘–ğ‘œğ‘›ğ‘  is a little more
complicated since sizes of TSV blocks may differ by one due to the division
operation to compute #ğµğ‘™ğ‘œğ‘ğ‘˜
Corner of a TierBoundary of a Tier
(a) Spiral-Style (b) Snake-Style (c) Hybrid
Fig. 9. Chaining Styles
probabilities to be routed through for minimum wire length.
These TSVs should be assigned as head parts of TSV-chains.
A spiral-style chaining policy is proposed for TSV-chain
design. In a TSV block, by picking a TSV in the central
position to be the starting point, spiral-style chaining results
in a routing path where all TSVs on the boundary are at one
end. The starting TSV is assigned as redundant TSV while the
other end becomes the head of a TSV-chain. An example for a
4 Ã— 5 TSV block is shown in Figure 9(a) where TSVs in grey
are head and good for timing critical signals. In routing stage,
routers can choose to assign timing-critical signals to TSVs
that are on the boundary of a TSV block. This can reduce the
probability for a timing critical signal to be shifted.
The spiral-style chaining policy is appropriate for a TSV
block that is not on the boundary or the corner of a tier.
For a TSV block located on the boundary of a tier, most
signals assigned to that TSV block are connected from the
opposite side of the tier boundary. In this case, a snake-style
chaining policy satises the requirement. The result is shown
in Figure 9(b). For a TSV block located on the corner, most
signals assigned to that TSV block are connected from the
counter direction of the tier corner. In this case, a hybrid
chaining policy as shown in Figure 9(c) becomes the best
candidate. Based on the position of each TSV block, one of
these three chaining policies can be applied to determine the
structure of a TSV-chain.
C. Physical Design Flow Considering TSV-Chain
In current design ow for 3D ICs , 3D partitioning rst
takes place to determine which tier each design blocks to be
placed. The number of required TSVs for signals between two
consecutive tiers is determined in this stage. Next, in oorplan
stage, blocks with x area but unknown dimensions are placed
in each tier. To provide communication links between blocks
in different tiers, TSV blocks are placed. The number of sig-
nals to be assigned to each TSV block as well as the position
of each TSV block are roughly determined in this stage. Based
on the discussion in Section IV, the number of TSVs in each
TSV block should be limited. Partitioning may be required
for large TSV blocks. Based on the position of each TSV
block, the structure of each TSV-chain is determined. In place
and route stage, routers should be aware of the TSV-chain
structure in each TSV block. Based on design constraints and
requirements, router needs to decide whether to assign timing
critical signals to TSVs that are located at the head of TSV-
chains. The overall design ow for TSV-chain is shown in
Figure 10.
3D Partitioning:
TSVs required for signal on each tier is determined
Placement
3D Routing:
Assignment of signals to TSVs
Considering the structure of each TSV-chain
when perform the assignment of signals to TSVs
3D Floorplanning:
TSV Block are determined
1. Partitioning is required for large TSV blocks
2. The size of each TSV block is limited
Based on the position of each TSV block, determine 
the structure of each TSV-chain
Fig. 10. Proposed Design Flow for TSV-Chain
VI. CONCLUSION
In this paper, a new redundant TSV architecture with
reasonable cost for ASICs has been proposed. Design issues
including recovery rate and timing problem have been inves-
tigated. Required modications on the design ow has been
explained. Based on probabilistic models, the new design can
successfully recover most of the failed chips and increase the
yield of TSV bonding to 99.99%. This can effectively reduce
the cost of manufacturing 3D designs.
REFERENCES
[1] W. R. Davis, J. Wilson, S. Mick, davis demystifying 3D et al.,
â€œDemistifying 3D ICs: The Pros and Cons of Going Vertical,â€ IEEE
Design Test of Computer, vol. 22, no. 6, pp. 498-510, Nov./Dec., 2005.
[2] J. Burns, L. Mcllrath, C. Keast, et al., â€œThree-Dimensional Integrated
Circuit for Low Power, High-Bandwidth Systems on a Chip,â€ ISSCC
Dig. of Tech. Papers, pp. 268-269, Feb., 2001.
[3] S. Siesshoefer and et al., â€œZ-axis Interconnect Using Fine Pitch,
Nanoscale Through Silicon Vias: Process Development,â€ ECTC, 2004.
[4] P. Morrow, M. J. Kobrinsky, S. Ramanathan, et al., â€œWafer-Level 3D
Interconnects via Cu Bonding,â€ Proceedings of the Advanced Metalliza-
tion Conference, pp. 125-130, 2004.
[5] Philip Garrou, Christopher Bower, and Peter Ramm, â€œHandbook of
3D Integration: Technology and Application of 3D Integrated Circuits
Volume 1 & 2,â€ poblished by WILEY-VCHVerlag GmbH& Co. KGaA,
Weinheim, 2008, ISBN: 978-3-527-32034-9.
[6] Uksong Kang, Hoe-Ju Chung, Seongmoo Heo, et al., â€œ8Gb 3D DDR3
DRAM Using Through-Silicon-Via Technology,â€ ISSCC Dig. of Tech.
Papers, pp. 130-131, Feb., 2009.
[7] Igor Loi, Subhasish Mitra, Thomas H. Lee, Shinobu Fujita and Luca
Benini, â€œA Low-Overhead Faule Tolerance Scheme for TSV-Based 3D
Network on Chip Links,â€ ICCAD, 2008.
[8] Hsien-Hsin S. Lee and Krishnendu Chakrabarty, â€œTest Challenges for
3D Integrated Circuits,â€ IEEE Design & Test of Computers, vol. 26, no.
5, pp. 26-35, Sep./Oct., 2009.
[9] R. Patti, â€œThree-Dimensional Integrated Circuits and the Future of
System-on-Chip Designs,â€ Proc. of the IEEE, vol. 84, no. 6, June 2006.
[10] A. W. Topol, J. D. C. La Tulipe, L. Shi, et al., â€œThree Dimensional
Integrated Circuits,â€ IBM Journal of Research and Development, vol.
50, no. 4/5, pp. 491-506, July/Sepetember 2006.
[11] R. Patti, â€œImpact of Wafer-Level 3D Stacking on the Yield of ICs,â€
Future Lab Intl., issue 23, July 2007.
[12] N. Miyakawa, â€œA 3D Prototyping Chip based on a Wafer-Level Stacking
Technology,â€ ASP-DAC, Jan. 2009.
[13] B. Swinnen, W. Ruythooren, et al., â€œ3D Integration by Cu-Cu Thermo-
Compression Bonding of Extremely Thinned Bulk-Si Die Containing
10 ğœ‡m Pitch Through-Si Vias,â€ IEDM, Dec. 2006.
[14] A. W. Topol, et al., â€œEnabling SOI-Based Assembly Technology for
Three-Dimensional Integrated Circuits,â€ IEDM, Dec. 2005.
98ï¦ï¨å°ˆé¡Œç ”ç©¶è¨ˆç•«ç ”ç©¶æˆæœå½™æ•´è¡¨ 
è¨ˆç•«ä¸»æŒäººï¼šé»ƒå©·å©· è¨ˆç•«ç·¨è™Ÿï¼š98-2220-E-007-014- 
è¨ˆç•«åç¨±ï¼šåœ¨ System-in-Package è¨­è¨ˆä¸‹ä¹‹è‡ªå‹•åŒ–å·¥å…·ç ”ç™¼--å­è¨ˆç•«ä¸‰ï¼šåœ¨ SiP è¨­è¨ˆä¸‹ä¹‹æ•£ç†±ç´„æŸæ™¶
ç‰‡å †ç–Š, Leadframe ç¹ç·šåŠè¨˜æ†¶é«”æ˜ æˆä¹‹ç ”ç©¶(3/3) 
ï¥¾åŒ– 
æˆæœé …ç›® å¯¦éš›å·²é”æˆ
ï¥©ï¼ˆè¢«æ¥å—
æˆ–å·²ç™¼è¡¨ï¼‰
é æœŸç¸½é”æˆ
ï¥©(å«å¯¦éš›å·²
é”æˆï¥©) 
æœ¬è¨ˆç•«å¯¦
éš›è²¢ç»ç™¾
åˆ†æ¯” 
å–®ä½ 
å‚™ è¨» ï¼ˆ è³ª åŒ– ï¥¯
æ˜ï¼šå¦‚ï¥©å€‹è¨ˆç•«
å…±åŒæˆæœã€æˆæœ
ï¦œ ç‚º è©² æœŸ åˆŠ ä¹‹
å° é¢ æ•… äº‹ ...
ç­‰ï¼‰ 
æœŸåˆŠï¥æ–‡ 0 0 100%  
ç ”ç©¶å ±å‘Š/æŠ€è¡“å ±å‘Š 0 0 100%  
ç ”è¨æœƒï¥æ–‡ 0 0 100% 
ç¯‡ 
 
ï¥æ–‡è‘—ä½œ 
å°ˆæ›¸ 0 0 100%   
ç”³è«‹ä¸­ä»¶ï¥© 0 0 100%  å°ˆï§ å·²ç²å¾—ä»¶ï¥© 0 0 100% ä»¶  
ä»¶ï¥© 0 0 100% ä»¶  
æŠ€è¡“ç§»è½‰ 
æ¬Šï§ï¤Š 0 0 100% åƒå…ƒ  
ç¢©å£«ç”Ÿ 3 3 100%  
åšå£«ç”Ÿ 3 3 100%  
åšå£«å¾Œç ”ç©¶å“¡ 0 0 100%  
åœ‹å…§ 
ï¥«èˆ‡è¨ˆç•«äººï¦Š 
ï¼ˆæœ¬åœ‹ç±ï¼‰ 
å°ˆä»»åŠ©ï§¤ 0 0 100% 
äººæ¬¡ 
 
æœŸåˆŠï¥æ–‡ 0 0 100%  
ç ”ç©¶å ±å‘Š/æŠ€è¡“å ±å‘Š 0 0 100%  
ç ”è¨æœƒï¥æ–‡ 1 1 100% 
ç¯‡ 
 
ï¥æ–‡è‘—ä½œ 
å°ˆæ›¸ 0 0 100% ç« /æœ¬  
ç”³è«‹ä¸­ä»¶ï¥© 0 0 100%  å°ˆï§ å·²ç²å¾—ä»¶ï¥© 0 0 100% ä»¶  
ä»¶ï¥© 0 0 100% ä»¶  
æŠ€è¡“ç§»è½‰ 
æ¬Šï§ï¤Š 0 0 100% åƒå…ƒ  
ç¢©å£«ç”Ÿ 0 0 100%  
åšå£«ç”Ÿ 0 0 100%  
åšå£«å¾Œç ”ç©¶å“¡ 0 0 100%  
åœ‹å¤– 
ï¥«èˆ‡è¨ˆç•«äººï¦Š 
ï¼ˆå¤–åœ‹ç±ï¼‰ 
å°ˆä»»åŠ©ï§¤ 0 0 100% 
äººæ¬¡ 
 
 
