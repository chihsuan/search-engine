drivenï¼‰çš„æ™‚é–“åºï¦œï¦„æ³¢å™¨ï¼›å…¶ä¸»è¦æ–¹æ³•æ˜¯å…ˆçµ±è¨ˆåŸ
å§‹èªéŸ³çš„ç‰¹å¾µï¥«ï¥©åœ¨æ™‚é–“ä¸Šå…¶çµ±è¨ˆç‰¹æ€§ï¼Œï¦µå¦‚æ¯ä¸€ï§
åˆ¥çš„å¹³å‡å€¼ï¼ˆmeanï¼‰æˆ–è®Šï¥¢ï¥©ï¼ˆvarianceï¼‰ï¼Œç„¶å¾Œé…
åˆæŸä¸€äº›æœ€ä½³åŒ–æº–å‰‡ï¼Œï¦µå¦‚æ—©æœŸä½¿ç”¨çš„ç·šæ€§é‘‘åˆ¥åˆ†æ
æ³•ï¼ˆlinear discriminant analysisï¼ŒLDAï¼‰ï¼Œæ±‚å–ï¦„æ³¢å™¨
ä¹‹ä¿‚ï¥©ï¼Œä¿¾ä½¿å¾—ï¦„æ³¢å™¨ä¹‹è¼¸å‡ºæœ‰æœ€å¤§çš„åˆ†ï§é‘‘åˆ¥å€¼ï¼Œ
åœ¨éå»æ–‡ç»ä¸­è­‰å¯¦æ­¤ï§è³‡ï¦¾å°å‘ï¦„æ³¢å™¨æ•ˆèƒ½ç¢ºå¯¦è¶…è¶Š
å‚³çµ±èˆ‡è³‡ï¦¾ç„¡é—œä¹‹ï¦„æ³¢å™¨ï¼Œå¸¶ï¤­ï¤é«˜çš„èªéŸ³è¾¨ï§¼ï¨ç¢º
ï¨ã€‚åœ¨ä»¥ä¸Šé€™äº›æ–¹æ³•ä¸­ï¼Œé›–ç„¶æˆ‘å€‘æœ€å¸¸è¨ï¥çš„æ˜¯æ‰€æ±‚
å¾— ä¹‹ ï¦„ æ³¢ å™¨ åœ¨ èª¿ è®Š é » åŸŸ ï¼ˆ modulation frequency 
domainï¼‰ä¸Šçš„é »ï¥¡éŸ¿æ‡‰ï¼ˆfrequency responseï¼‰ç‰¹åˆ¥æ˜¯
å¼·ï¨éŸ¿æ‡‰ï¼ˆmagnitude responseï¼‰ï¼Œï¤­åˆ†ææ¯å€‹é »å¸¶å°
æ–¼è¾¨ï§¼ï¨ç¢ºï¨ä¹‹ï§å¼Šï¼Œç„¶è€Œï¼Œåœ¨è¨­è¨ˆï¦„æ³¢å™¨éç¨‹ä¸­ï¼Œ
æˆ‘å€‘å»æ˜¯ï§ç”¨ç‰¹å¾µï¥«ï¥©åœ¨æ™‚åŸŸï¼ˆtemporal domainï¼‰ä¸Š
å…¶çµ±è¨ˆç‰¹æ€§ï¼Œè€Œå¾ˆå°‘ç›´æ¥ï§ç”¨èª¿è®Šé »åŸŸä¹‹æ€§è³ªï¼Œé€™æ¨£
å¯èƒ½å°è‡´ç™¼ç”Ÿæœ‰ä¸‹ï¦œï¥¸é …ç¼ºé»ï¼šï¼ˆä¸€ï¼‰åœ¨æ™‚åŸŸä¸Šæœ€ä½³
åŒ–å…¶ï¦„æ³¢å™¨ï¼Œæœªå¿…äº¦èƒ½åœ¨èª¿è®Šé »åŸŸä¸Šä¹Ÿæ˜¯æœ€ä½³åŒ–ï¼Œå¯
èƒ½åªæ˜¯é–“æ¥åœ°ï§ç”¨èªéŸ³ç‰¹å¾µåœ¨æ™‚åŸŸä¸Šå…¶ç‰¹æ€§ï¼Œï¤­æ¨æ•²
åœ¨èª¿è®Šé »åŸŸä¸Šå…¶ç‰¹æ€§ã€‚ï¼ˆäºŒï¼‰æ‰€æ±‚å¾—çš„ï¦„æ³¢å™¨é›–ç„¶åœ¨
å¼·ï¨éŸ¿æ‡‰ï¼ˆmagnitude responseï¼‰ä¸Šé¡¯ç¤ºï¦ºä»¥èªéŸ³ç‚ºä¸»
çš„é »å¸¶è¢«éï¦„å‡ºï¤­ï¼Œä½†æ˜¯åœ¨ç›¸ä½éŸ¿æ‡‰ï¼ˆ phase 
responseï¼‰ä¸Šçš„ç‰¹æ€§é€šå¸¸è¢«å¿½ï¥¶ï¥§æï¼Œè€Œé€™äº›æ‰€æ±‚å¾—
ä¹‹ï¦„æ³¢å™¨ä¿‚ï¥©ï¼Œé€šå¸¸ï¥§å…·æœ‰å°ç¨±ï¼ˆsymmetricï¼‰æˆ–åå°
ç¨±ï¼ˆanti-symmetricï¼‰ä¹‹ç‰¹æ€§ï¼Œä¹Ÿå› æ­¤é®®å°‘å…·å‚™ï¦ºç·šæ€§
ç›¸ä½ï¼ˆ linear phaseï¼‰ä¹‹ï¥¼å¥½æ€§è³ªï¼Œå› æ­¤å¯æƒ³è€ŒçŸ¥çš„
æ˜¯ï¼Œåœ¨ï¦„æ³¢å™¨é€šå¸¶ï¼ˆpass-bandï¼‰ä¹‹ï¥§åŒçš„é »ï¥¡æˆåˆ†å› 
ç‚ºéç·šæ€§ç›¸ä½æ‰€å½±éŸ¿è€Œé€ æˆï¥§ä¸€è‡´çš„ç¾¤å»¶é²ï¼ˆgroup 
delayï¼‰ä¹‹å¤±çœŸï¼Œå¯èƒ½é€²è€Œé™åˆ¶ï¦ºï¦„æ³¢å™¨å…¶æœ€ä½³æ•ˆèƒ½ã€‚ 
   æ ¹æ“šä¸Šè¿°ç¬¬äºŒå€‹æ½›åœ¨ç¼ºé»ï¼Œæˆ‘å€‘åœ¨æ±‚å–ï¦„æ³¢å™¨ä¹‹å¼·
ï¨éŸ¿æ‡‰å¾Œï¼Œå†ï§ç”¨ï¦„æ³¢å™¨è¨­è¨ˆä¹‹æŠ€è¡“ï¼Œè¨­è¨ˆå‡ºæ–°çš„ï¦„
æ³¢å™¨ä¿‚ï¥©ï¼Œä½¿æ–°çš„ï¦„æ³¢å™¨ä¿‚ï¥©èƒ½å¤ å…·å‚™æœ‰ç·šæ€§ç›¸ä½ï¼Œ
åŒæ™‚åˆèƒ½å¤ é€¼è¿‘åŸï¦„æ³¢å™¨å…¶å¼·ï¨éŸ¿æ‡‰ã€‚è€Œç‚ºï¦ºæ”¹å–„å…¶
ç¬¬ä¸€å€‹ç¼ºé»ï¼Œæˆ‘å€‘æ¡ç”¨èªéŸ³ç‰¹å¾µï¥«ï¥©æ™‚é–“åºï¦œä¹‹èª¿è®Š
é »è­œï¼ˆè€Œéæ™‚åŸŸï¼‰ï¤­æ±‚å–å…¶çµ±è¨ˆæ€§è³ªï¼Œå†é€²ä¸€æ­¥æ±‚å–
æ™‚é–“åºï¦œä¹‹ï¦„æ³¢å™¨çš„æœ€ä½³å¼·ï¨éŸ¿æ‡‰ï¼›å› æ­¤æˆ‘å€‘ç”±èª¿è®Š
é »è­œæ‰€æ±‚å¾—ä¹‹æ™‚é–“åºï¦œï¦„æ³¢å™¨å…¼å…·æœ‰ï¥¼å¥½çš„å¼·ï¨éŸ¿æ‡‰
ä»¥åŠç·šæ€§ç›¸ä½ä¹‹ï¥¼å¥½çš„ç‰¹è³ªã€‚ä»¥ä¸‹ï¼Œæˆ‘å€‘å°±é‡å°å¦‚ä½•
ï§ç”¨èª¿è®Šé »è­œï¤­è¨­è¨ˆæ™‚é–“åºï¦œï¦„æ³¢å™¨çš„æ–¹æ³•åŠ ä»¥ä»‹
ç´¹ã€‚ 
    ï¦¨æŸä¸€ç¶­èªéŸ³ç‰¹å¾µä¹‹æ™‚é–“åºï¦œç‚º { }( )x n ï¼Œè€Œæˆ‘å€‘æ‰€
è¦è¨­è¨ˆä¹‹ï¦„æ³¢å™¨éŸ¿æ‡‰ç‚º { }( ), 0,1, ..., - 1h n n L= ï¼Œå‰‡ï¦„æ³¢
å™¨ä¹‹è¼¸å‡ºç‚ºï¥¸è€…ä¹‹é–“çš„æ‘ºç©ï¼ˆconvolutionï¼‰ï¼Œå…¶è¡¨ç¤º
å¦‚(1)å¼æ‰€ç¤ºï¼š 
1
0
( ) ( ) ( - )
L
u
y n h u x n u
âˆ’
=
= âˆ‘                                                 ï¼ˆ1ï¼‰ 
åœ¨é€™ï§¨æˆ‘å€‘å°‡è™•ï§¤çš„ï¦´åŸŸç”±æ™‚åŸŸï¼ˆtemporal domainï¼‰
è½‰æ›è‡³èª¿è®Šé »åŸŸï¼ˆmodulation frequency domainï¼‰ï¼Œæ­¤
æ™‚å…¶è¼¸å‡ºèª¿è®Šé »è­œ ( )jY e Ï‰ ä»¥åŠè¼¸å…¥èª¿è®Šé »è­œ ( )jX e Ï‰ èˆ‡
ï¦„æ³¢å™¨ä¹‹é »ï¥¡éŸ¿æ‡‰ ( )jH e Ï‰ ï¼Œä¹‹é—œä¿‚å¦‚(2)å¼æ‰€ç¤ºï¼š 
( ) ( ) ( )j j jY e H e X eÏ‰ Ï‰ Ï‰=                                                ï¼ˆ2ï¼‰ 
ç”±æ–¼èª¿è®Šé »è­œé€šå¸¸æ˜¯ä¸€è¤‡ï¥©ï¼ˆcomplex numberï¼‰ï¼Œäº¦
å³åŒ…å«å¯¦éƒ¨èˆ‡è™›éƒ¨æˆ–æ˜¯æŒ¯å¹…èˆ‡ç›¸ä½ï¼Œäº¦å³æˆ‘å€‘å¿…é ˆåŒ
æ™‚è™•ï§¤ï¥¸å€‹è®Šï¥©ä¹‹å•é¡Œï¼Œç‚ºï¦ºç°¡åŒ–è¨ˆç®—å…¶è¤‡é›œï¨ï¼Œæˆ‘
å€‘å°‡åŸæœ¬æœ€ä½³åŒ–è¼¸å‡ºèª¿è®Šé »è­œç°¡åŒ–æˆæœ€ä½³åŒ–è¼¸å‡ºèª¿è®Š
é »è­œåŠŸï¥¡çš„å•é¡Œï¼Œå…¶å®šç¾©å¦‚(3)å¼æ‰€ç¤ºï¼š 
2 2
2 22
0 0
( ) ( ) ( )
K K
T
Y
k k
P Y k H k X k
â¢ â¥ â¢ â¥â¢ â¥ â¢ â¥â£ â¦ â£ â¦
= =
=âˆ‘ âˆ‘ H X                 ï¼ˆ3ï¼‰ 
å…¶ä¸­ 
22 2
(0) (1) ( ) ,  2
T
KH H Hâ¡ â¤â¢ â¥= â¢ â¥â¢ â¥â£ â¦â£ â¦H "  
22 2
(0) (1) ( )2
T
KX X Xâ¡ â¤â¢ â¥= â¢ â¥â¢ â¥â£ â¦â£ â¦X " ã€‚ 
Hç›¸ç•¶æ–¼ï¦„æ³¢å™¨å¹³æ–¹å¼·ï¨éŸ¿æ‡‰ï¼Œå› æ­¤ï¼Œæˆ‘å€‘å¯ä»¥ï§ç”¨
ä¸€æœ€ä½³åŒ–æº–å‰‡ï¼Œè—‰ç”±æœ€ä½³åŒ–æŸä¸€è¼¸å‡ºåŠŸï¥¡ YP çš„ç›®æ¨™å‡½
ï¥©(objective function) ï¤­æ±‚å–æœ€ä½³çš„Hã€‚æ ¹æ“š(3)å¼ï¼Œåœ¨
æ±‚å–æœ€ä½³çš„Hä¹‹éç¨‹ä¸­ï¼Œæœƒï§ç”¨åˆ°è¼¸å…¥ä¿¡è™Ÿèª¿è®Šé »è­œ
Xçš„çµ±è¨ˆç‰¹æ€§ã€‚åœ¨æœ¬ï¥æ–‡ä¸­ï¼Œæ‰€ï§ç”¨çš„æœ€ä½³åŒ–æº–å‰‡åŒ…
æ‹¬ ï¦º å— é™ ä¹‹ ç·š æ€§ é‘‘ åˆ¥ åˆ† æ (constrained linear 
discriminant analysis, C-LDA)ã€å—é™ä¹‹ä¸»è»¸æˆåˆ†åˆ†æ
(constrained principal component analysis, C-PCA) åŠå—
é™ä¹‹æœ€å¤§åˆ†ï§è·ï§ª(constrained maximum class distance, 
C-MCD)ï¼Œé€™ä¸‰ç¨®æœ€ä½³åŒ–æº–å‰‡å°‡æ–¼å¾Œé¢çš„ç« ç¯€ä¸­è©³åŠ 
ä»‹ç´¹ã€‚æ­¤å¤–ï¼Œç‚ºï¦ºå¾—åˆ°è¼¸å…¥ä¿¡è™Ÿèª¿è®Šé »è­œXçš„çµ±è¨ˆç‰¹
æ€§ï¼Œæˆ‘å€‘å¯ä»¥è’é›†è¨“ï¦–èªï¦¾åº«ä¸­æ¯ä¸€å€‹æ™‚é–“åºï¦œçš„ç‰¹
å¾µï¥«ï¥©ï¼Œè¨ˆç®—å…¶å¹³æ–¹å¼·ï¨é »è­œå¾Œï¼Œé€™äº›å¹³æ–¹å¼·ï¨é »è­œ
å³å¯è¦–ç‚º Xçš„æ¨£æœ¬(samples)ï¼Œè—‰ç”±é€™äº›æ¨£æœ¬æˆ‘å€‘ï¥¥èƒ½
ä¼°æ¸¬Xçš„çµ±è¨ˆç‰¹æ€§ã€‚ 
é™„å¸¶ä¸€æï¼Œåœ¨é€™ï§¨æˆ‘å€‘é¸æ“‡è¼¸å‡ºåŠŸï¥¡ YP ä½œç‚ºæœ€ä½³åŒ–ï¦„
æ³¢å™¨éç¨‹ä¸­çš„ï¥«ï¥©ï¼Œå…·å‚™ï¦ºè¨±å¤šå„ªé»ï¼Œé¦–å…ˆï¼Œè©•ä¼°ä¸€
å€‹å–®ä¸€è®Šï¥© YP çš„è¡¨ç¾å¥½å£æ¯”è©•ä¼°ä¸€ï¦šï¤…è®Šï¥©ï¼Œå¦‚è¼¸å‡º
é »è­œ ( ){ }Y k æˆ–å…¶å¹³æ–¹å¼·ï¨ ( ){ }2Y k  ç›¸å°è€Œè¨€ç°¡å–®çš„
å¤šï¼›å…¶æ¬¡ï¼Œ YP æœ¬èº«ä»£è¡¨ï¦ºï¦„æ³¢å™¨è¼¸å‡ºçš„åŠŸï¥¡ï¼Œå› æ­¤ç›¸
å°æ–¼è¼¸å‡ºé »è­œä¹‹å¼·ï¨å’Œ ( )
1
1
K
k
Y k
âˆ’
=
âˆ‘ ï¤å…·æœ‰ç‰©ï§¤æ„ç¾©ï¼›ç¬¬
ä¸‰ï¼Œç”±(3)å¼å¯çŸ¥ï¼Œ YP ç›´æ¥é—œï¦šæ–¼ï¦„æ³¢å™¨å¹³æ–¹å¼·ï¨éŸ¿
æ‡‰ ( ){ }2H k  è€Œéï¦„æ³¢å™¨çš„é »ï¥¡éŸ¿æ‡‰ ( ){ }H k ï¼Œå¦‚å‰æ‰€
æï¼Œ ( ){ }2H k æ˜¯éè² å¯¦ï¥©ï¼Œä½†æ˜¯ ( ){ }H k å»é€šå¸¸æ˜¯è¤‡
ï¥©ï¼Œå› æ­¤è™•ï§¤ ( ){ }2H k ç›¸å°è€Œè¨€æ¯” ( ){ }H k ï¤­çš„ç°¡ï§ ã€‚ 
ç•¶æˆ‘å€‘è—‰ç”±æœ€ä½³åŒ–ä¸€å€‹ YP çš„ç›®æ¨™å‡½ï¥©ï¼Œå¾—åˆ°æœ€ä½³ä¹‹ï¦„
æ³¢å™¨å¹³æ–¹å¼·ï¨éŸ¿æ‡‰ ( ){ }2H k ï¼Œå¾Œï¼Œçš†ä¸‹ï¤­æˆ‘å€‘å¯ä»¥ï§
ç”¨ï¥©ä½ï¦„æ³¢å™¨è¨­è¨ˆä¹‹æŠ€è¡“ï¼Œå°‡æœ€ä½³çš„ï¦„æ³¢å™¨å¹³æ–¹å¼·ï¨
éŸ¿æ‡‰ï¼Œè½‰æ›ç‚ºç·šæ€§ç›¸ä½ä¹‹ï¦„æ³¢å™¨ï¼Œé¦–å…ˆå°æ–¼ä¸€é•·ï¨ L
çš„ FIRï¦„æ³¢å™¨ä¹‹è„ˆè¡éŸ¿æ‡‰å¦‚(4)å¼æ‰€ç¤ºï¼š 
{ }( ), 0 1h n n Lâ‰¤ â‰¤ âˆ’ ï¼Œ                                            ï¼ˆ4ï¼‰ 
( ) ( )
( )
1 LDAJ
Î¸
Î¸ Î¸ Îµ+ =
âˆ‚= + âˆ‚ H HH H H                                       (15ï¼‰ 
å…¶ä¸­ Îµç‚ºæ­¥éšï¥¾ï¼ˆstep-sizeï¼‰ï¼Œè€Œä¸” 
LDA LDAJ Jâˆ‚ âˆ‚âˆ‚=âˆ‚ âˆ‚ âˆ‚
H
H H H
                                                 ï¼ˆ16ï¼‰ 
å…¶ä¸­çŸ©é™£ âˆ‚âˆ‚
H
H
çš„ç¬¬ ,i jé …ç‚º 
( )
( )
1
1
2
0
exp1
exp
P
jj
K
iij
m
m
HH
H P
H
âˆ’
â¢ â¥â¢ â¥â£ â¦
=
â› ââŸâœ âŸâœ âŸâœ âŸâœâˆ‚ âŸâ› ââˆ‚ âœ âŸâŸâœ âŸ= = âœâŸâœ âŸâŸâœ âœâ â  âŸâˆ‚ âˆ‚ âœ âŸâœ âŸâœ âŸâŸâœ âŸâœâ â âˆ‘
H
H
 
( ) ( ) ( )
( )
2
0
2
2
0
exp exp exp
exp
K
j m i jij
m
K
m
m
H H H H
H
Î´
â¢ â¥â¢ â¥â£ â¦
=
â¢ â¥â¢ â¥â£ â¦
=
â› ââŸâœ âŸâœ âŸâœ âŸâœ âŸâˆ’ +âœ âŸâŸâœ âŸâœÃ— âŸâœ âŸâœ âŸâ› ââœ âŸâŸâœ âŸâœ âŸâœ âŸâœ âŸ âŸâœâœ âŸ âŸâœ âŸâœ âŸâŸâœ âŸâœ â â â â 
âˆ‘
âˆ‘
 ï¼ˆ17ï¼‰ 
è€Œä¸” 
( ) ( )
( )
2 - 2T TW B B WLDA
T
W
Jâˆ‚ =âˆ‚
H S H S H H S H S H
H H S H
          ï¼ˆ18ï¼‰ 
ç•¶Hæ”¶æ–‚æ™‚ç”±(8)å¼æ‰€æ±‚å¾—ä¹‹Häº¦å³æ˜¯æˆ‘å€‘æ‰€è¦æ±‚çš„å—
é™ä¹‹ç·šæ€§é‘‘åˆ¥æœ€ä½³çš„ï¦„æ³¢å™¨å¹³æ–¹å¼·ï¨éŸ¿æ‡‰ã€‚ 
 
III.2 å—é™ä¹‹ä¸»è»¸æˆåˆ†åˆ†ææ³• 
ä¸»è»¸æˆåˆ†åˆ†ææ³•æ˜¯åœ¨ï¥©ä½è¨Šè™Ÿè™•ï§¤ã€å½±åƒè™•ï§¤ä»¥åŠåœ–
å½¢è¾¨ï§¼ä¸­å¾ˆå¸¸ï¨Šä¹‹æŠ€è¡“ï¼Œå…¶ä¸»è¦ç›®çš„åœ¨æ–¼æ±‚å–æœ€å…·ä»£
è¡¨æ€§ï¼ˆrepresentativeï¼‰çš„ç‰¹å¾µå€¼ï¼Œå› å®ƒå¯å°‡å½¼æ­¤ç›¸é—œ
çš„ä¸€ç¾¤ç‰¹å¾µå‘ï¥¾æ¡ç”¨è¼ƒå°‘ç¶­ï¨çš„å‘ï¥¾ï¤­ä»£è¡¨ï¼Œä¸¦ä¸”å¯
ä»¥å°‡ç‰¹å¾µå‘ï¥¾ç¶­ï¨èˆ‡ç¶­ï¨ä¹‹é–“ç›¸é—œæ€§å»é™¤ã€‚åœ¨æ­¤æˆ‘å€‘
ï§ç”¨ä¸»è»¸æˆåˆ†åˆ†ææ³•ä½œç‚ºæœ€ä½³åŒ–æº–å‰‡ï¼Œï¤­å¹«åŠ©æˆ‘å€‘æ±‚
å–æ™‚é–“åºï¦œï¦„æ³¢å™¨çš„å¼·ï¨éŸ¿æ‡‰ã€‚ 
é¦–å…ˆå¿…é ˆå…ˆå°æ–¼è¨“ï¦–èªï¦¾ä¹‹ç‰¹å¾µï¥«ï¥©åšå€æ®µçš„ï¨€å‰²ï¼Œ
å°æ–¼æŸä¸€ç¶­ç‰¹å¾µï¥«ï¥©æ™‚é–“åºï¦œè€Œè¨€ï¼Œæˆ‘å€‘å°‡å…¶åˆ†æˆå›º
å®šé•·ï¨çš„å€æ®µï¼Œå°‡é€™äº›å€æ®µå–å…¶å¹³æ–¹å¼·ï¨é »è­œ
( ) ( ) ( ) 22 2( ) ,1 , 2 , 2 Tn X n X n X n Kâ¡ â¤â¢ â¥â¢ â¥= â¢ â¥â£ â¦â¢ â¥â£ â¦X " ï¼Œ å…¶ ä¸­
( ),X n k ä»£è¡¨ï¦ºç¬¬ n æ™‚é–“å€æ®µçš„é »è­œï¼Œè€Œ k ç‚ºé »ï¥¡ï¥ª
å¼•ã€‚ï¥§åŒæ–¼å‰ä¸€ç¯€çš„ C-LDA çš„ä½œæ³•ï¼Œåœ¨æ­¤æˆ‘å€‘ç„¡é ˆ
å°æ–¼é€™äº›å€æ®µåšåˆ†ï§ã€‚æ¥è‘—ï¼Œå°‡é€™äº›å€æ®µä¹‹å¹³æ–¹å¼·ï¨
é »è­œå–å…¶å„ï§ä¹‹å¹³å‡å€¼ Î¼ä»¥åŠå…±è®Šï¥¢ï¥©Î£ï¼Œå¦‚(19)å¼
ä»¥åŠ(20)å¼æ‰€ç¤ºï¼Œ 
( )
1
1 N
n
n
N =
= âˆ‘XÎ¼                                                         ï¼ˆ19ï¼‰ 
( )( ) ( )( )
1
1 N T
n
n n
N =
= âˆ’ âˆ’âˆ‘ X XÎ£ Î¼ Î¼                            ï¼ˆ20ï¼‰ 
å…¶ä¸­N ç‚ºå€æ®µçš„ç¸½ï¥©ã€‚ 
    åœ¨æ­¤æˆ‘å€‘ä»¥ 2Ïƒ ï¤­è¡¨ç¤ºç‚ºï¦„æ³¢å™¨è¼¸å‡ºåŠŸï¥¡ä¹‹ç¸½é«”è®Šï¥¢
ï¥©ï¼ˆglobal varianceï¼‰ï¼Œå‰‡å—é™ä¹‹ä¸»è»¸æˆåˆ†åˆ†ææ³•æ‰€å¾—
åˆ°æœ€ä½³ï¦„æ³¢å™¨å¹³æ–¹å¼·ï¨éŸ¿æ‡‰å¦‚(21)å¼æ‰€ç¤ºï¼š 
* 2arg max ( ), ( ) TPCA PCAH
J J Ïƒ= = =H H H H HÎ£            (21) 
ï§ä¼¼å‰ä¸€ç¯€ï¼Œå—åˆ°Hå¿…é ˆç‚ºéè² ä¹‹é™åˆ¶ï¼Œæˆ‘å€‘å¼•é€²ä¸€
å€‹æ²’æœ‰å—é™çš„ä¸­ä»‹å‘ï¥¾Hï¼Œä¸¦ï¦¨Hèˆ‡Hä¹‹é—œä¿‚å¦‚å‰ä¹‹
(8)å¼æ‰€ç¤ºï¼Œæ¥ä¸‹ï¤­ï¼Œæˆ‘å€‘ï¥¥å¯ä½¿ç”¨æ¢¯ï¨ï¨‰ä½æ³•
ï¼ˆgradient-descent algorithmï¼‰ï¤­åè¦†æ±‚å–è¿‘ä¼¼æœ€ä½³ä¹‹
Hèˆ‡Hï¼Œå¦‚(22)å¼æ‰€ç¤ºï¼š 
( ) ( )
( )
1 PCAJ
Î¸
Î¸ Î¸ Îµ+ =
âˆ‚= + âˆ‚ H HH H H                                     ï¼ˆ22ï¼‰ 
å…¶ä¸­ Îµç‚ºæ­¥éšï¥¾ï¼ˆstep-sizeï¼‰ï¼Œè€Œä¸” 
PCA PCAJ Jâˆ‚ âˆ‚âˆ‚=âˆ‚ âˆ‚ âˆ‚
H
H H H
                                                 ï¼ˆ23ï¼‰ 
å…¶ä¸­çŸ©é™£ âˆ‚âˆ‚
H
H
çš„ç¬¬ ,i jé …å¯ç”±(17)å¼è¡¨ç¤ºï¼Œ 
è€Œ 
2PCA
Jâˆ‚ =âˆ‚ HH Î£                                                          ï¼ˆ24ï¼‰ 
ç•¶Hæ”¶æ–‚æ™‚ç”±(8)å¼æ‰€æ±‚å¾—ä¹‹Hç‚ºå—é™ä¹‹ä¸»è»¸æˆåˆ†åˆ†æ
æ³•æº–å‰‡ä¸‹æœ€ä½³ä¹‹ï¦„æ³¢å™¨å¹³æ–¹å¼·ï¨éŸ¿æ‡‰ã€‚ 
 
III.3 å—é™ä¹‹æœ€å¤§ï§åˆ¥è·ï§ªæ³• 
æœ€å¤§ï§åˆ¥è·ï§ªæ³•æ˜¯æœ€å°åˆ†ï§éŒ¯èª¤æ³•ï¼ˆMinimum 
Classification Errorï¼ŒMCEï¼‰ä¹‹è®Šå½¢ï¼Œå…¶ç›®çš„åœ¨æ–¼æœ€å¤§
åŒ–ï¥§åŒï§åˆ¥é–“ä¹‹è·ï§ªï¤­æå‡åˆ†ï§æ­£ç¢ºï¥¡ä¸¦ä¸”å¯ä»¥ç°¡åŒ–
å‚³çµ±ä¹‹æœ€å°åˆ†ï§éŒ¯èª¤æ³•ä¹‹è¤‡é›œé‹ç®—ä»¥åŠå¤šè®Šï¥©ä¹‹å•
é¡Œï¼Œä»¥ä¸‹æˆ‘å€‘å°‡ä»‹ç´¹å—é™ä¹‹æœ€å¤§ï§åˆ¥è·ï§ªæ³•ï¼š 
    é¦–å…ˆå¦‚åŒå—é™ä¹‹ç·šæ€§é‘‘åˆ¥åˆ†ææ³•ï¼Œå…ˆå°‡è¨“ï¦–èªï¦¾æ¯
ä¸€ç¶­ç‰¹å¾µå‘ï¥¾åšå€æ®µçš„ï¨€å‰²ï¼Œä¸¦åŠ ä»¥åˆ†ï§ï¼Œæ±‚å–æ¯ä¸€
å€æ®µçš„å¹³æ–¹å¼·ï¨é »è­œå¾Œï¼Œå°‡é€™äº›åˆ†ï§å¾Œçš„å€æ®µä¹‹å¹³æ–¹
å¼·ï¨é »è­œå–å…¶å„ï§ä¹‹å¹³å‡å€¼ ( )jÎ¼ ä»¥åŠå…±è®Šï¥¢ï¥© ( )jÎ£ ï¼Œå¦‚
(10)å¼ä»¥åŠ(11)å¼æ‰€ç¤ºã€‚é¦–å…ˆæˆ‘å€‘å‡è¨­æ¯ä¸€ï§åˆ¥ä¹‹å¹³æ–¹
å¼·ï¨é »è­œç‚ºä¸€éš¨æ©Ÿå‘ï¥¾ ( )jX ï¼Œä¸”ç‚ºé«˜æ–¯åˆ†ä½ˆ
ï¼ˆmultivariate Gaussian distributedï¼‰ï¼Œå…¶å¹³å‡å€¼ç‚º ( )jÎ¼
ä»¥åŠå…±è®Šï¥¢çŸ©é™£ç‚º ( )jÎ£ ï¼Œå› æ­¤ï¦„æ³¢å™¨è¼¸å‡ºä¹‹åŠŸï¥¡å¯è¦–
ç‚ºä¸€é«˜æ–¯éš¨æ©Ÿè®Šï¥©ï¼Œå…¶å¹³å‡å€¼ç‚º ( )T jH Î¼ ï¼Œè®Šï¥¢ï¥©ç‚º
( )T jH HÎ£ ï¼Œå‰‡å…¶æ©Ÿï¥¡å¯†ï¨å‡½ï¥©ï¼ˆ probability density 
functionï¼‰ ( )( )jg x å¯ç”±(25)å¼æ‰€ç¤ºï¼š 
( )( ) ( ) ( )( ) ; ,j T j T jg x x= H H HÎ¼ Î£N  
( )
( )2( )
( )( )
1
exp
22
T j
T jT j
x
Ï€
â› ââˆ’ âŸâœ âŸâœ âŸ= âˆ’âœ âŸâœ âŸâœ âŸâŸâœâ â 
H
H HH H
Î¼
Î£Î£
                     ï¼ˆ25ï¼‰ 
ç„¶å¾Œè¨ˆç®—å…¶è¼¸å‡ºåŠŸï¥¡ä¹‹ç¬¬ i ï§èˆ‡åŠç¬¬ j ï§ä¹‹è·ï§ªï¼Œæ¡
ç”¨ Kullback-Leibler distanceï¼Œå…¶å®šç¾©å¦‚(26)å¼æ‰€ç¤ºï¼š 
( )
( ) log
( )
i
ij i
j
g x
d g x dx
g x
âˆ
âˆ’âˆâˆ«                                         ï¼ˆ26ï¼‰ 
å‰‡ï§ç”¨(25)å¼ï¼Œ(26)å¼åˆå¯è¡¨ç¤ºæˆ(27)å¼ 
( )( )( ) ( ) ( ) ( )( )
( ) ( )
- -
log
TT i j i jT j T
ij T i T T j T
d = + H HH H
H H H H
Î¼ Î¼ Î¼ Î¼Î£
Î£ Î£  
 
è¡¨ 2.å—é™ä¹‹ç·šæ€§é‘‘åˆ¥åˆ†ææ³•è¾¨ï§¼ï¥¡ï¼ˆï¼…ï¼‰ï¼ˆ Set Bï¼‰ 
 
 
è¡¨ 3. å—é™ä¹‹ç·šæ€§é‘‘åˆ¥åˆ†ææ³•è¾¨ï§¼ï¥¡ï¼ˆï¼…ï¼‰ï¼ˆSet Cï¼‰ 
 
åœ– 1. å—é™ä¹‹ç·šæ€§é‘‘åˆ¥åˆ†ææ³•å…¶ 13ç¶­å¹³æ–¹å¼·ï¨éŸ¿æ‡‰åœ– 
 
é€éå—é™ä¹‹ä¸»è»¸æˆåˆ†åˆ†ææ³•åœ¨èª¿è®Šé »åŸŸè¨­è¨ˆä¹‹æ™‚
é–“åºï¦œï¦„æ³¢å™¨ä¹‹å¯¦é©—çµæœï¼Œå¦‚è¡¨ 4ã€è¡¨ 5 èˆ‡è¡¨ 6 æ‰€
ç¤ºï¼Œç‚ºï¦ºæ¯”è¼ƒï¼Œæˆ‘å€‘å°‡åœ¨æ™‚åŸŸä¸­ï§ç”¨ä¸»è»¸æˆåˆ†åˆ†ææ³•
è¨­è¨ˆä¹‹æ™‚é–“ï¦„æ³¢å™¨[9]çš„çµæœé™„æ–¼æ¯ä¸€è¡¨çš„æœ€å¾Œä¸€ï¦œï¼Œ
ä»¥ Temporal PCA è¡¨ç¤ºã€‚åŒæ™‚ï¼Œé€™äº›ï¦„æ³¢å™¨æ‰€å°æ‡‰ä¹‹
å¹³æ–¹å¼·ï¨éŸ¿æ‡‰å¦‚åœ– 2æ‰€ç¤ºã€‚ 
ç”±è¡¨ 4ã€è¡¨ 5èˆ‡è¡¨ 6æ‰€ç¤ºï¼Œå—é™ä¹‹ä¸»è»¸æˆåˆ†åˆ†ææ³•
ç›¸è¼ƒæœªè™•ï§¤ä¹‹ç‰¹å¾µï¥«ï¥© MFCCï¼Œåœ¨æ¸¬è©¦çµ„åˆ¥ Aã€B èˆ‡
æ¸¬è©¦çµ„åˆ¥ C å¹¾ä¹ï¨¦æœ‰é€²æ­¥ï¼Œå…¶æ•´é«”å¹³å‡è¾¨ï§¼ï¥¡é”
62.76ï¼…ï¼ŒåŒæ™‚ï¼Œå¯¦é©—ï¥©æ“šä¹Ÿé¡¯ç¤ºï¦ºä»–å€‘çš„æ•ˆæœå„ªæ–¼å‚³
çµ±åœ¨æ™‚åŸŸä¸Šï§ç”¨ä¸»è»¸æˆåˆ†åˆ†ææ³•æ‰€å¾—çš„ï¦„æ³¢å™¨ï¼Œä½†æ˜¯
å®ƒå€‘çš„è¡¨ç¾å»æ˜é¡¯ï¥§å¦‚å‰ä¸€ç¯€çš„å—é™ä¹‹ç·šæ€§é‘‘åˆ¥åˆ†æ
æ‰€å¾—ï¦„æ³¢å™¨ï¼Œå¯èƒ½åŸå› åœ¨æ–¼ï¼Œé€™äº›ï¦„æ³¢å™¨å¤§å¤šç‚ºä½é€š
ï¼ˆlowpassï¼‰ï¦„æ³¢å™¨ï¼Œå¦‚åœ– 2 æ‰€ç¤ºï¼Œå› æ­¤å®ƒå€‘ç„¡æ³•æœ‰æ•ˆ
å°‡ç›´ï§Šéƒ¨åˆ†ç§»é™¤ã€‚ 
 
è¡¨ 4 .å—é™ä¹‹ä¸»è»¸æˆåˆ†åˆ†ææ³•è¾¨ï§¼ï¥¡ï¼ˆï¼…ï¼‰ï¼ˆSet Aï¼‰ 
 
 
è¡¨ 5. å—é™ä¹‹ä¸»è»¸æˆåˆ†åˆ†ææ³•è¾¨ï§¼ï¥¡ï¼ˆï¼…ï¼‰ï¼ˆSet Bï¼‰ 
 
 
åœ– 3. å—é™ä¹‹æœ€å¤§ï§åˆ¥è·ï§ªæ³•å…¶ 13ç¶­å¹³æ–¹å¼·ï¨éŸ¿æ‡‰åœ– 
 
V.çµï¥ 
ç”±å‰ç« ä¹‹å¯¦é©—çµæœé¡¯ç¤ºï¼Œæˆ‘å€‘æ¡ç”¨ç”±èª¿è®Šé »è­œï¤­
è¨­è¨ˆæ™‚é–“åºï¦œï¦„æ³¢å™¨ç¢ºå¯¦èƒ½å¤ é”åˆ°èªéŸ³å¼·å¥æ€§ï¼Œé€™äº›
æ–¹æ³•åŒ…å«å—é™ä¹‹ç·šæ€§é‘‘åˆ¥åˆ†ææ³•ï¼ˆC-LDAï¼‰ã€å—é™ä¹‹
æœ€å¤§ï§åˆ¥è·ï§ªæ³•ï¼ˆC-MCDï¼‰ã€å—é™ä¹‹ä¸»è»¸æˆä»½åˆ†ææ³•
ï¼ˆC-PCAï¼‰ï¼Œå…¶ä¸­å‰ï¥¸è€…å…¶æ‰€è¨­è¨ˆå‡ºï¤­ä¹‹ï¦„æ³¢å™¨ç‚ºå¸¶
é€šï¦„æ³¢å™¨ï¼Œå°æ–¼è¾¨ï§¼ï¥¡è€Œè¨€è¼ƒæœ‰é¡¯è‘—ä¹‹æ•ˆæœè¡¨ç¾ï¼Œè€Œ
å¾Œè€…ç”±æ–¼æ‰€è¨­è¨ˆå‡ºï¤­ä¹‹ï¦„æ³¢å™¨ç‚ºä½é€šï¦„æ³¢å™¨ï¼Œå› æ­¤é€ 
æˆå…¶é€²æ­¥ï¥¡æœªæœ‰è¼ƒé¡¯è‘—ä¹‹æ•ˆæœï¼›ç„¶è€Œä»–å€‘ï¨¦æ˜é¡¯å„ªæ–¼
ç›´æ¥åœ¨æ™‚åŸŸä¸Šæ‰€è¨­è¨ˆä¹‹ï¦„æ³¢å™¨ï¼Œé€™å¯èƒ½æ„å‘³ï¦ºé™¤ï¦ºä»–
å€‘æœ‰è¼ƒï§¤æƒ³çš„å¼·ï¨éŸ¿æ‡‰å¤–ï¼Œç·šæ€§ç›¸ä½çš„ï¥¼å¥½æ€§è³ªä¹Ÿæ˜¯
åŸå› ä¹‹ä¸€ï¼Œå› æ­¤æˆ‘å€‘æ‰€æå‡ºä¹‹ç”±èª¿è®Šé »è­œï¤­è¨­è¨ˆä¹‹æ™‚
é–“åºï¦œï¦„æ³¢å™¨å…¼å…·æœ‰æœ€ä½³å¹³æ–¹å¼·ï¨éŸ¿æ‡‰èˆ‡ç·šæ€§ç›¸ä½ä¹‹
å„ªé»ï¼Œå¯æé«˜å…¶èªéŸ³è¾¨ï§¼æ•ˆæœã€‚ 
 
ï¥«è€ƒæ–‡ç» 
[1] Jeih-weih Hung and Wei-Yi Tsai, "Optimization of 
Temporal Filters in the Modulation Frequency Domain for 
Constructing Robust Features in Speech Recognition", 
accepted by IEEE Transactions on Audio, Speech and 
Language Processing, 2007 
[2] Jeih-weih Hung, " Optimization of Temporal Filters in 
the Modulation Frequency Domain via Constrained Linear 
Discriminant Analysis (C-LDA) for Constructing Robust 
Features in Speech Recognition", 2007 International 
Conference on Acoustics, Speech and Signal Processing 
(ICASSP 2007) 
[3] Jeih-weih Hung, "Optimization of Temporal Filters in 
the Modulation Frequency Domain for Constructing 
Robust Features in Speech Recognition", 2007 
International Conference on Spoken Language Processing 
(Interspeech 2007 â€” ICSLP) 
[4] N. Kanedera, T. Aria, H. Hermansky and M. Pavel. 
"On The Importance of Various Modulation Frequencies 
for Speech Recognition", Proceedings of Eurospeech, 
1997 
[5] H. Hermansky and N. Morgan, "RASTA processing of 
speech", IEEE Transactions on Speech and Audio 
Processing, 2, 578-589, 1994 
[6] J. W. Hung and L. S. Lee, "Comparative Analysis for 
Data-Driven Temporal Filters Obtained Via Principal 
Component Analysis(PCA) and Linear Discriminant 
Analysis(LDA) In Speech Recognition", Proceedings of 
Eurospeech 2001 
[7] S. V. Vuuren and H. Hermansky, "Data-Driven Design 
of RASTA-Like Filters", Proceedings of ICSLP 1996 
[8] L. Markus and H. U. Reinhold, "LDA Derived 
Cepstral Trajectory Filters in Adverse Environmental 
Conditions", Proceedings of ICASSP 2000 
[9] J. W. Hung and L. S. Lee, "Optimization of Temporal 
Filters for Constructing Robust Features in Speech 
Recognition", IEEE Transactions on Speech and Audio 
Processing 2006 
[10] S. Tiberewala and H. Hermansky, "Multiband and 
adaptation approaches to robust speech recognition", 
Proceedings of  Eurospeech 1997 
[11] Sanjit K. Mitra, "Digital Signal Processing, a 
computer-Based Approach", second version, McGraw-
Hill 
Silence Energy Normalization for Robust Speech Rec
Chung-fu Tai and Jeih-w
Dept of Electrical Engineering, Natio
Taiwan, Republic of
e-mail : s3323542@ncnu.edu.tw, jw
Abstract 
The energy parameter has been widely used as an 
extension to the basic features of mel-frequency cepstral 
coefficients (MFCCs) to improve the recognition 
accuracy in speech recognition. In this paper, a simple 
and effective approach for energy normalization for 
silence (non-speech) portions in an utterance is proposed. 
This approach, named as silence energy normalization 
(SEN), uses the high-pass filtered log-energy as the 
feature for speech/non-speech classification, and then the 
log-energy of non-speech frames is set to be a small 
constant while that of speech frames is kept unchanged. 
In the experiments conducted on AURORA2 database, 
we showed that SEN provides an averaged word error 
rate reduction of 34.9% and 44.6% for Test Sets A and B, 
respectively, when compared with the baseline 
processing. It was also shown that SEN outperforms 
similar approaches like energy subtraction (ES) and 
feature vector selection (FVS). Finally, we showed that 
SEN can be integrated with cepstral mean and variance 
normalization (CMVN), to achieve further improved 
recognition performance.  
Index Terms: silence energy normalization, frame 
vector selection, energy subtraction 
1. Introduction 
The performance of a speech recognition system is often 
severely degraded in the presence of noise. A variety of 
approaches have been proposed to mitigate this 
degradation, and they can be roughly divided into three 
classes: utilization of a noise robust representation of 
speech signals, enhancement of the speech features 
before they are fed to the recognizer, and adaptation of 
the speech models in the recognizer to make them better 
match the noise conditions. The main difference between 
the first two classes of approaches is that, for the first 
class, the noise robust speech features are used for both 
model training and testing, and for the second, 
enhancement procedures are often performed only on the 
noise corrupted speech features for testing, while the 
speech features for training are kept unchanged. In this 
paper, our proposed approach belongs to the first class. A 
new feature normalization scheme called silence energy 
normalization (SEN) is introduced.  
As we know, the energy of speech signal contains 
important information regarding the phonetic content of 
speech, and therefore we have used it directly or the 
variation of it (for example, log-energy, delta energy, etc.) 
to be one of the speech features for recognition. However, 
these energy features are often vulnerable to noise and 
thus their discriminating capability is limited. Recently, 
some approaches have been proposed to enhance these 
energy features [1-5]. For example, in [1] the speech 
energy contour is extracted from the high-pass filtered 
signal so as to reduce the distortion in the delta energy, 
and 
both
targe
whe
fram
ones
fram
rate 
the f
norm
fram
valu
class
Part
pape
norm
utter
(sile
high
for 
norm
the s
the 
be p
nois
labe
that 
nois
corr
the 
utter
is a 
easil
for 
(CM
The 
secti
The 
secti
othe
addi
the 
brief
    
2.1 B
Whe
utter
Figu
non-
high
by n
On 
INTERSPEECH 2006 - ICSLP
2558ognition in Additive Noise Environments 
eih Hung 
nal Chi Nan University 
 China 
hung@ncnu.edu.tw
in [2] the dynamic range of log-energy sequences for 
 training and testing utterances is normalized to a 
t one in order to reduce the environmental mismatch, 
re the normalization function indicates lower-energy 
es are more affected by noise than higher-energy 
. On the other hand, [6] introduces the method of 
e vector selection (FVS) based on variable frame 
processing or voice activity detection (VAD), where 
rame-to-frame variation (for example, the Euclidean 
 of the delta feature) or the log-energy of each 
e is used as an indicator for frame selection. If its 
e is below a predefined threshold, this frame is 
ified as silence or noise-only and is then discarded.  
ly motivated by the concepts in [2] and [6], in this 
r we propose the approach of silence energy 
alization (SEN). In SEN, every frame vector of an 
ance is first classified as speech or non-speech 
nce). The classifier is based on the output of a 
-pass filter with the log-energy being the input. Then 
each of the silence frames the log-energy is 
alized to a small constant, while the log-energy of 
peech frames remains unchanged. Note that in SEN, 
classification and normalization procedures need to 
erformed on the utterances in both clean training and 
y testing databases, and unlike FVS, the frames 
lled as non-speech are not discarded. We will show 
by SEN the normalized log-energy sequence of a 
e corrupted utterance is quite close to that of the 
esponding clean version. Also, the threshold used in 
classifier for SEN is determined by the input 
ance and needs not to be tuned heuristically, which 
particular benefit of SEN. Furthermore, SEN can be 
y integrated with cepstral compensation techniques, 
example, cepstral mean and variance normalization 
VN) [7], to obtain further improved performance. 
remainder of the paper is organized as follows.  In 
on 2, the proposed approach of SEN is described. 
experimental environment setup is described in 
on 3, and the recognition results of SEN and some 
r approaches are given and discussed in section 4. In 
tion, section 4 also contains the recognition results of 
combination of SEN and CMVN. Finally, section 5 
ly contains some concluding remarks.  
 2. Silence Energy Normalization 
asic idea 
n observing the log-energy contours of a clean 
ance and its noise-corrupted counterparts as in 
re 1(a), some differences between the speech and 
speech portions may be found. For example, the 
-energy speech portions are relatively less influenced 
oise and sometimes keep the ripple characteristics. 
the other hand, the low-energy non-speech portions 
September 17-21, Pittsburgh, Pennsylvania
cepstral coefficients (MFCCs) plus log-energy. Then the 
log-energy sequence for each utterance was processed by 
the proposed SEN algorithm described in section 2 or 
some other approaches that will be described in section 4. 
The original 12-dimensional MFCCs (c1~c12) and the 
updated log-energy, plus their delta and delta-delta were 
the components in the finally used 39-dimensional 
feature vectors. Since the proposed algorithm only 
involves the front-end feature extraction, all the 
following procedures for training and recognition are 
identical to the reference experiments stated in the 
AURORA2 documentation [8]. 
4 Experimental Results 
4.1 The results of the energy-processed approaches 
In this subsection, we compare the recognition 
performance of several energy-processing approaches 
including the proposed SEN, Energy Subtraction (ES) [3] 
and two versions of Feature Vector Section (FVS). In 
FVS here, the frames classified as silence are directly 
removed from the utterance without any normalization. 
The first version of FVS uses the speech/silence 
classifier in SEN, and is thus denoted as SEN-FVS, 
while the second makes use of the output of ES method, 
and is thus denoted as ES-FVS. The ES and ES-FVS are 
briefly introduced here. 
The approach of energy subtraction (ES) is quite similar 
to the typical spectral subtraction (SS), and the algorithm 
is stated as follows, 
< > \ if  if  ESESn E n N E n TE n E n TE BC Â  Â¯ Â  Â¯Â¡ Â° Â¡ Â°Â¢ Â± Â¢ Â±Â  Â¯ Â  Â¯Â¡ Â° Â¡ Â°Â¢ Â± Â¢ Â± p ,   (4) 
where E nÂ  Â¯Â¡ Â°Â¢ Â±  and < >nE  are the original and updated 
energy values of the n-th frame, respectively, TES is a 
threshold , N  is the noise energy estimate, D is the 
over-subtracting factor and C is the flooring factor. In the 
following experiments, both N and TES are set to be the 
average of energy values for the first five frames of each 
utterance, and D and C are set to be 0.95 and 0.05, 
respectively. 
For the approach of ES-FVS, a simple rule based on the 
updated energy values < >\ ^E n  from ES is used for 
frame vector selection. If the two consecutive energy 
values, < >E n  and < >1E n  , are both smaller than a 
threshold TES-FVS, then the n-th frame is classified as 
silence and then discarded. The threshold is determined 
by the following equation, 
	 
 < >
1
1
1
N
ES FVS ES
n
T wT w E n
N 
   Âœ  ,           (5) 
where N is the number of total frames in an utterance, 
TES is the threshold used in Eq. (4), and 0 1w  . In 
our experiments, w  is set to be 0.4. 
Table 1 shows the averaged recognition accuracy for the 
baseline processing and several approaches stated 
previously for Test Set A (four types of stationary noise), 
and Test Set B (four types of non-stationary noise) of 
AUR
phen
1. Th
th
no
ca
SE
ac
re
fo
be
al
fo
an
2. Th
sim
ab
w
as
ou
ac
no
he
no
an
sim
to
3. W
af
SE
de
Su
po
er
th
(a
re
ve
sil
m
4. Fi
fra
fo
ca
cl
SE
en
fil
so
is 
be
th
w
un
de
th
From
prop
cond
case
INTERSPEECH 2006 - ICSLP
2560ORA2 database. From this table, several 
omena can be observed: 
e proposed approach SEN significantly improves 
e recognition accuracy for both stationary and 
n-stationary noise conditions in almost every SNR 
se. For example, compared with the baseline results, 
N gives 13.57% and 19.28% of absolute word 
curacy improvements for Test Sets A and B, 
spectively. Furthermore, it performs particularly well 
r non-stationary noise conditions since it gives the 
st recognition performance among all approaches in 
most all SNR cases in Test Set B. On the other hand, 
r Test Set A, SEN is especially well for the median 
d low SNR (10dB~0dB) cases.  
e approach ES also performs quite well and very 
ilarly to SEN for Test Set A, and it gives 11.98% of 
solute word accuracy improvement when compared 
ith the baseline result. However, it does not perform 
 well as SEN for Test Set B, although it still 
tperforms the baseline processing by 14.32% of 
curacy rate. One of the possible reasons is that under 
n-stationary noise cases, the noise estimate in ES 
re (simply the average of the first several frames) is 
t very accurate. In addition, the two parameters, D
d C in eq. (4), are set to be constants here for 
plicity, which in fact should be updated according 
 different noise conditions.  
hen implementing frame-vector-selection (FVS) 
ter the classification procedure of SEN (denoted as 
N-FVS in the table), the recognition performance is 
teriorated when compared with that of SEN alone. 
ch results probably tell us that the â€œdetectedâ€ silence 
rtions do not always provide us with redundant or 
roneous information for recognition. Modifying 
ese portions (as in SEN) instead of discarding them 
s in FVS) may be a better choice. Another possible 
ason is that the classifier used here does not perform 
ry well, and thus some portions like the 
ence-to-speech or speech-to-silence transitions are 
isclassified as silence and are then discarded.  
nally, observing the results of ES-FVS, where the 
me selection is based on the results of ES, it is 
und that ES-FVS is better than SEN-FVS for all 
ses, which possibly shows that the speech/silence 
assifier in ES-FVS is more reliable than that in 
N-FVS since it depends on the noise-reduced 
ergy sequence < >\ ^E n  in eq. (4) rather than the 
tered log-energy sequence < >\ ^y n . These results 
mewhat coincide those obtained in [6], where FVS 
performed on the noise-reduced features to obtain a 
tter recognition accuracy. Furthermore, we also find 
at ES-FVS outperforms ES only when the SNR is 
orse (0dB and 5dB). One possible reason is that 
der worse SNR conditions, ES is less capable of 
aling with the silence frames, and thus dropping 
em directly as in FVS may be more beneficial. 
 the above, we can roughly conclude that the 
osed SEN performs excellently for almost all 
itions. For example, under high and median SNR 
s, it preserves the energy contour of speech portions 
