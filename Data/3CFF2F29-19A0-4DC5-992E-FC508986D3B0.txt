a criterion such as minimum squared errors and maximum canon-
ical correlation [26]. While the kernels in most multiple kernel
learning differ in parameters and types, they share a common
information resource (or a feature set); moreover, they may have
distinct inputs. The study in [27] divides the input feature set into
subsets of local features to construct multiple kernels. Summing
the kernels will reduce the incorrect recognition rate caused by
partially contaminated features (e.g., the object of interest is par-
tially occluded). A related method, KPCA plus LDA [28], shares
the similarity of needing decision fusion for more than one resul-
tant feature space, though the work is, strictly speaking, not in
the catalog of multiple kernels. KPCA plus LDA maps one input
onto two feature spaces. Rather than in the input feature space,
the division for features occurs in the kernel feature space (which
is produced by KPCA), in which LDA is applied individually to two
orthogonal complement subspaces, resulting in two feature spaces.
When data carry auxiliary information, it is worth exploring
such information as a resource for discrimination. In applications
with images, the spatial context is often embedded with abundant
discriminative information [29,30]. The spatial context information
can thus be deÔ¨Åned as another input to a kernel function, which
forms multiple resources. A composite kernel is constructed by
combining a polynomial kernel and an RBF kernel based on spec-
tral and spatial features, respectively [31]. The spatial features
are expressed in terms of the mean and the standard deviation in
the neighborhood of a pixel.
The main focus of this study is related to a new design of the
kernel function suitable for classiÔ¨Åcation of image data. The pro-
posed kernel function is a composite kernel that integrates two
additional resources of information ‚Äì class membership and spatial
context ‚Äì while preserving the concept of the kernel trick. Spatial
context information is explored by means of Markov random Ô¨Åeld
models (MRFs) [32,33]. Two pixels are compared based on the
characteristics of the spatial neighborhood. Class membership is
taken into account in terms of the mutual closeness deÔ¨Åned in this
study. Two samples are deemed similar if they belong to same
class with a high probability. The proposed kernel function allows
two samples to be distinguished based on dissimilar spatial con-
texts and low mutual closeness in class membership, even if they
are close in the Euclidean distance measure. A function is said to
be a valid kernel function if it obeys Mercer‚Äôs conditions [34‚Äì36].
We give a proof to show that the proposed kernel function is a
Mercer kernel.
The rest of the paper is organized as follows. Section 2 reviews
the kernel trick and its application to feature extraction. Section 3
describes the proposed kernel function and proves its validity as a
Mercer kernel. Section 4 presents the experimental results. Finally,
conclusions are presented in Section 6.
2. Kernel trick and kernel-based feature extraction
A kernel-based feature extraction is, conceptually, composed of
two transformations: a nonlinear mapping / from an input space
X to the kernel space H, / : X! H, and a linear projectionL from
H onto a lower dimensional space Y, L : H ! Y . The objective of
the mapping / is to transform data in X to a much higher dimen-
sional kernel space H [9] that possesses possibly higher data sepa-
rability than the original space. If m features, v1; . . . ; vm, are
involved in the linear projection L, the kernel-based feature
extraction for a given input data sample x 2 X can be expressed
as s
L√∞/√∞x√û√û ¬º
hv1;/√∞x√ûi
..
.
hvm;/√∞x√ûi
2
664
3
775: √∞1√û
The linear mappingL, such as PCA and LDA, is basically derived
based on the training samples. Given n observation training sam-
ples x1; . . . ;xn 2 Xn > dim√∞X√û, any resulting feature vj will be in
span f/√∞x1√û; . . . ;/√∞xn√ûg and can be expressed in matrix form as
vj ¬º Uaj; √∞2√û
where U ¬º ¬Ω/√∞x1√û   /√∞xn√û. Let
A ¬º ¬Ωa1    am; √∞3√û
then
L√∞/√∞x√û√û ¬º AT
h/√∞x1√û;/√∞x√ûi
..
.
h/√∞xn√û;/√∞x√ûi
2
664
3
775: √∞4√û
Note that there is a relationship between the distance metric and
the inner products,
k/√∞xi√û  /√∞xj√ûk2 ¬º h/√∞xi√û;/√∞xi√ûi  2h/√∞xi√û;/√∞xj√ûi
√æ h/√∞xj√û;/√∞xj√ûi: √∞5√û
While the distance metric is often used as a similarity measure, this
relationship implies that inner products are highly associated with
the similarity between two samples. By introducing
K√∞xi;xj√û ¬º h/√∞xi√û;/√∞xj√ûi; √∞6√û
the kernel trick implicitly computes an inner product in H based on
resubstitution with a kernel function K that represents a similarity
measure between two mapped vectors in H but can be executed
explicitly in the input space X [22]. Hence, L√∞/√∞x√û√û can be carried
out based on an a priori chosen kernel function,
L√∞/√∞x√û√û ¬º AT
K√∞x1; x√û
..
.
K√∞xn;x√û
2
664
3
775: √∞7√û
Prior to performing the kernel-based feature extraction, one needs
to consider (i) the choice of k√∞x1;x2√û and (ii) the determination of
A. Once a kernel function has been chosen, the kernel matrix
K ¬º hU;Ui can be constructed from K√∞xi;xj√û; i; j ¬º 1; . . . ;n, based
on the given n training samples, x1; . . . ;xn. Next, a linear feature
extraction algorithm L whose criterion can be expressed in terms
of inner products is chosen as the base algorithm for the derived
kernel method. If PCA is used as the base algorithm, the derived cri-
terion for KPCA is
J√∞a√û ¬º a
TMa
aTa
; √∞8√û
where
M ¬º K 1
n
1nK 1nK1n √æ
1
n2
1nK1n; √∞9√û
and 1n is an n nmatrix of all ones. Solving the eigenvalue problem
Ma ¬º ka √∞10√û
yields the m most signiÔ¨Åcant eigenvectors to form A ¬º ¬Ωa1    am for
KPCA.
If LDA is considered as the base algorithm, the criterion for KDA
is derived as
J√∞a√û ¬º a
TMba
aTMwa
; √∞11√û
where Mb; Mw are associated with the between-class and within-
class scatter matrices in H,
P.-F. Hsieh et al. / Image and Vision Computing 28 (2010) 502‚Äì517 503
PF√∞xT√û ¬º 1Z exp 
1
T0
X
c
Vc√∞xT√û
( )
; √∞25√û
where Vc√∞xT√û denotes the potential function of clique c, T0 is the
temperature, and Z is the normalizing constant for the sum-to-
one constraint. For the sake of simplicity, Vc is deÔ¨Åned herein using
the pair-wise multi-level logistic (MLL) model [42], with a level for
a label. Assume that the MRF is a homogeneous and isotropic Ô¨Åeld,
then Vc is independent of site and orientation. For a pair-wise clique
c ¬º fs; tg;Vc√∞xT√û ¬º bcd√∞xs‚Äìxt√û, where bc is the neighborhood inÔ¨Çu-
ence associated with the clique type. It follows thatX
c
Vc√∞xT√û ¬º
X
s2T
X
t2Hs
bcd√∞xs‚Äìxt√û: √∞26√û
By substituting (26) into (25), and (25) into (24), the potentials of
the cliques not containing site s will be cancelled from the denom-
inator and the numerator. It follows that the conditional probability
P xsjxTfsg
	 

depends only on the cliques containing site s as
follows:
P xsjxTfsg
	 
 ¬º P√∞xsjxHs √û
¬º
exp  1T0
P
t2Hsbcd√∞xs‚Äìxt√û
n o
PL
~xs¬º1 exp  1T0
P
t2Hsbcd ~xs‚Äìxt√∞ √û
n o : √∞27√û
3.3. Formulation of the MRF-based kernel function
Let us deÔ¨Åne a contextual vector, r√∞s√û ¬º ¬Ωr1√∞s√û    rx√∞s√û    rL√∞s√ûT ,
where rx√∞s√û conveys the spatial context information of site sassoci-
ated with class x. rx√∞s√û is deÔ¨Åned by
rx√∞s√û ¬º
X
t2Hs
bcp√∞xjxt;xHt √û; x 2 f1; . . . ; Lg; √∞28√û
where p√∞xjxt;xHt √û is the a posteriori probability as given in (22).
Furthermore, consider a contextual distance dC√∞si; sj√û representing
the similarity of spatial context between the samples at sites
si and sj. Let us deÔ¨Åne the contextual distance dC√∞si; sj√û as
dC√∞si; sj√û ¬º kr√∞si√û  r√∞sj√ûk: √∞29√û
In addition to spatial context information, we exploit the discrimi-
native resource from the class memberships of samples. Let
xj ¬º argmax
x¬º1;...;L
p√∞xjxj;xHsi √û be the optimum label assigned to the
sample xj at site sj. The value of p√∞xj jxi;xHsi √û reÔ¨Çects how closely
a sample xi is related to another sample xj with respect to class
membership. The mutual closeness in class membership is deÔ¨Åned
by
g√∞xi;xj√û ¬º p√∞xj jxi;xHsi √ûp xi jxj;xHsj
  1=2
: √∞30√û
In an L-class problem, a sample is assigned an optimum label with
p√∞xjx;xH√ûP 1=L. If two samples xi and xj are classiÔ¨Åed into the
same class, p√∞xj jxi;xHsi √û¬ºp√∞xi jxi;xHsi √ûP1=L, and p√∞xi jxj;xHsj √û¬º
p√∞xj jxj;xHsj √ûP1=L. This leads to 1=L 6 g√∞xi;xj√û 6 1. Otherwise, if
two samples xi and xj are assigned with different class labels, we
have 0 6 g√∞xi;xj√û 6 1=L. A pair of samples assigned with the same
class label enjoys a larger value of class-membership similarity than
those with different class labels.
By combining the resources from the spatial context and class
membership, a new kernel function for samples xi and xj at sites
si and sj is designed as
K√∞xi;xj√û ¬º g√∞xi; xj√ûq
 exp  1
r2
ad2E√∞xi;xj√û √æ √∞1 a√ûd2C√∞si; sj√û
  
; √∞31√û
where dE√∞xi; xj√û ¬º kxi  xjk is the Euclidean distance, r controls the
width of kernel, 0 6 q 6 1 controls the signiÔ¨Åcance of the class-
membership similarity, and a is a parameter to balance between
the Euclidean distance and the contextual distance. When the
class-membership similarity is not signiÔ¨Åcant and negligible, one
can set q to be 0. In image applications, we often see
g√∞xi; xj√û and dC render a similar effect, since both are related to
the MRF-based contextual information. In this case, one can choose
a small number for q to reduce the redundancy. This kernel function
can be generally applied to classiÔ¨Åcation problems, not limited to
the applications of image data. If spatial context information is
not available, labels are simply assigned by xi ¬º argmax
x¬º1;...;L
p√∞xjxi√û.
The kernel function for samples x and y degenerates to
K√∞xi;xj√û ¬º g√∞xi;xj√û exp  d
2
E√∞xi;xj√û
r2E
( )
; √∞32√û
where g√∞xi; xj√û ¬º P√∞xj jxi√ûP√∞xi jxj√û
 1=2
.
Since a kernel function can be viewed as a measure of similarity
between samples, two samples xi and xj are said to be of high sim-
ilarity if K√∞xi;xj√û is close to 1, and of low similarity if K√∞xi; xj√û takes
on a value near 0. Consider the following scenario: two samples
xi and xj of distinct classes are withdrawn from an image. Suppose
that the samples are located near the boundary between classes in
the original feature space. They are misclassiÔ¨Åed by a pixel-wise
classiÔ¨Åer. Also, suppose that each of the samples is surrounded
by samples of its own class in the image. Thus, they can be cor-
rectly relabeled by using an MRF-based classiÔ¨Åer. If the samples
are separated by a small Euclidean distance, dE, the basic RBF ker-
nel in (17) will fail to discriminate between the samples. However,
their spatial contexts are quite different, leading to a large contex-
tual distance dC . The probability of a sample belonging to the class
of the other sample tends to be low, resulting in a small value of
class-membership similarity g√∞xi;xj√û. In this case, either a large
dC or a small g√∞xi;xj√û will force the value of K√∞xi;xj√û to approach
zero, thus properly representing the dissimilar relationship be-
tween the samples.
3.4. Proof of a mercer kernel
The RBF kernel has been proven to be a positive deÔ¨Ånite kernel
[43], and therefore it is a Mercer kernel according to Mercer‚Äôs the-
orem. Similarly, we will prove in the following that the proposed
kernel is a Mercer kernel because of the positive deÔ¨Åniteness. A
real symmetric matrix ¬ΩAij is called almost negative deÔ¨Ånite pro-
vided that
Xn
i¬º1
Xn
j¬º1
cicjAij 6 0 √∞33√û
whenever
P
i¬º1;...;nci ¬º 0 [43]. Note that if
Aij ¬º 1r2E
kxi  xjk2 √æ 1r2C
XL
x¬º1
krx√∞si√û  rx√∞sj√ûk2 √∞34√û
for some training sample set f√∞x1; s1;x1√û; . . . ; √∞xn; sn;xn√ûg;xi 2
X; si 2 T;xi 2 f1; . . . ; Lg, then the matrix ¬ΩAij is almost negative def-
inite because
Xn
i¬º1
Xn
j¬º1
cicjAij ¬º  2r2E
Xn
j¬º1
cjxj


2
 2
r2C
XL
x¬º1
Xn
j¬º1
cjrx√∞sj√û


2
6 0 √∞35√û
whenever
P
i¬º1;...;nci ¬º 0. Furthermore, let
Bij ¬º 12 ln p√∞xjjxi√û 
1
2
ln p√∞xijxj√û: √∞36√û
P.-F. Hsieh et al. / Image and Vision Computing 28 (2010) 502‚Äì517 505
Theproposedkernel functionprovides away to improvediscrim-
ination based on spatial context information. If yi and yj have the
same Euclidean distance to a training sample x, the RBF kernel func-
tion fails to distinguish yi and yj. If yi and yj have different contex-
tual distances tox, the degree of discrimination between yi and yj
can be increased. In the worst case, classes are severely overlapped
in the input feature space. The proposed method can overcome the
overlapping problem if discriminative information about the spatial
context is present in the image. Dataset 3 is characterized by high
class separability in the spatial domain, but low class discrimination
in theoriginal three-dimensional feature space, as shown in Fig. 6(a).
Two classes are normally distributed with slightly different mean
vectors, ¬Ω0 0 0T and ¬Ω0:1 0 0T , and a common identity covariance
matrix. Fig. 6(b) shows that methods such as PCA, LDA, KPCA and
KDA give rather poor classiÔ¨Åcation accuracy, even using the original
three features, due to low discrimination in the original feature
space. In contrast, the resulting distributions of MrfKPCA and
MrfKDAbecomeseparable. Using classmembership and spatial con-
text information leads to an improvement of 45% in classiÔ¨Åcation
accuracy over other feature extraction methods.
Fig. 3. Distributions of Dataset 1 resulting from various feature extraction methods. (a) KPCA; (b) KDA; (c) MrfKPCA; and (d) MrfKDA.
Fig. 4. (a) Distribution of Dataset 2. (b) Performance of feature extraction.
P.-F. Hsieh et al. / Image and Vision Computing 28 (2010) 502‚Äì517 507
4. For the chosen base feature extraction algorithm, the eigen-
value problem is solved. m √∞m 6 d√û optimum features are
selected to form a transform matrix A.
5. For each sample x in the image, the corresponding feature vec-
tor, w ¬º ¬Ωk√∞x1;x√û    k√∞xn;x√ûT , is obtained by pairing x with each
training sample xi. Feature extraction is performed by using
z ¬º ATw to generate an m-variate image data set.
6. In the test stage, the resulting m-variate image is classiÔ¨Åed
using a pixel-wise or an MRF-based ML classiÔ¨Åer. The classiÔ¨Åca-
tion accuracy is assessed based on test samples.
7. The above steps are repeated for the new m-variate image data
set if iteration is requested. The iteration terminates if the test
accuracy becomes stable.
4. Experimental results
4.1. Data description
We used synthetic and natural images to perform a comparative
study. Synthetic images are composed of texture patterns selected
from the Brodatz album [45]. The experiment aims to separate tex-
ture patterns from each other and to extract an animal silhouette
(Zebra, Squirrel, and Tiger) from a natural image. In these cases,
classes cannot be described appropriately by unimodal distribu-
tions. An overlap of the distributions between classes in the origi-
nal feature space makes it difÔ¨Åcult to separate one class from the
others, as seen in Fig. 7(a). It is quite difÔ¨Åcult to separate the
Fig. 7. Color image Zebra and the classiÔ¨Åcation maps based on various methods: (a) Image and its distribution in the RGB space (Class1: Zebra. Class2: Background, x1:R, x2:G,
x3:B). (b) kNN-MRF; (c) LDA; (d) KDA; (e) SVM; (f) MKL; (g) CKFD; (h) C-KDA; and (i) MrfKDA. Methods LDA, KDA, CKFD, C-KDA, and MrfKDA are followed by a kNN and an
MRF-based contextual classiÔ¨Åer. (For interpretation of the references to color in this Ô¨Ågure legend, the reader is referred to the web version of this paper.)
P.-F. Hsieh et al. / Image and Vision Computing 28 (2010) 502‚Äì517 509
provides a common ground for comparison of SVM to KDA and
LDA. Tables 3 and 4 show that SVM and KDA outperform LDA, thus
conÔ¨Årming the feasibility of the basic RBF kernel.
Multiple kernel learning (MKL) is basically an extension of SVM.
The MKL [26] used in this comparative study combines a linear
kernel, a polynomial kernel, and a Gaussian RBF kernel based on
a minimum-error criterion regularized by maximizing correlation
among multiple kernels (called canonical correlation analysis).
However, under the constraint of agreement among kernels, a
poorly operated kernel will likely cause the overall performance
of MKL to deteriorate. The correlation-based MKL sometimes pro-
duces poorer results than SVM (Table 3) because the MKL includes
an incompetent linear kernel. In the design of multiple kernels,
requirements should be set to highlight the kernels of good perfor-
mance and to suppress the kernels of poor performance. We thus
slightly modiÔ¨Åed the MKL formulation in [26] by loosening the
constraint of full agreement among kernels and assigning small
weights to poorly operated kernels. For example, the linear, the
polynomial, and the Gaussian RBF kernels were assigned a weight
of 0, 0.3, and 0.7, respectively, for the image Tiger. Table 3 shows
Table 4
kNN classiÔ¨Åcation accuracy of various feature extraction algorithms in the reduced (L  1) dimensional space.
Image Reduced
dimension, L  1
LDA Standard
deviation
KDA Standard
deviation
CKFD Standard
deviation
Mrf
CKFD
Standard
deviation
C-
KDA
Standard
deviation
Mrf
KDA
Standard
deviation
Zebra 1 86.6 0.9 86.7 2.0 89.5 1.4 89.3 2.1 94.1 2.1 97.2 1.4
Tiger 1 87.0 4.3 93.9 0.6 92.1 2.2 94.1 2.6 99.0 1.0 98.7 1.0
Squirrel 3 94.9 0.5 95.5 0.6 94.8 1.2 94.7 1.0 99.5 0.5 97.6 0.6
Rocks 1 88.0 0.4 87.8 1.3 89.0 0.6 89.9 1.1 93.7 1.2 97.7 0.9
T5 4 86.1 0.7 86.4 0.6 86.5 1.0 87.9 3.5 93.3 1.1 97.2 0.6
Average 88.5 90.1 90.4 91.2 95.9 97.7
Table 5
kNN-MRF contextual classiÔ¨Åcation accuracy of various feature extraction algorithms.
Image Reduced
dimension, L  1
LDA Standard
deviation
KDA Standard
deviation
CKFD Standard
deviation
Mrf
CKFD
Standard
deviation
C-
KDA
Standard
deviation
Mrf
KDA
Standard
deviation
Zebra 1 90.6 1.4 91.6 2.2 91.3 1.7 91.3 2.5 95.5 1.6 96.0 3.4
Tiger 1 95.7 1.9 96.9 1.4 96.2 2.2 97.5 1.3 99.1 1.0 98.6 1.3
Squirrel 3 97.8 0.6 97.7 0.6 98.9 0.3 99.1 0.4 100.0 0.0 98.3 0.3
Rocks 1 94.4 1.0 92.6 1.3 94.7 1.3 94.5 1.1 96.2 1.2 98.4 0.9
T5 4 91.6 1.1 91.7 0.7 92.5 1.3 93.2 2.5 95.8 0.6 97.6 0.6
Average 94.0 94.1 94.7 95.1 97.3 97.8
Fig. 8. Image Tiger and the classiÔ¨Åcation maps based on various methods: (a) Image; (b) kNN-MRF; (c) LDA; (d) KDA; (e) SVM; (f) MKL; (g) CKFD; (h) C-KDA; and (i) MrfKDA.
Methods LDA, KDA, CKFD, C-KDA, and MrfKDA are followed by a kNN and an MRF-based contextual classiÔ¨Åer.
P.-F. Hsieh et al. / Image and Vision Computing 28 (2010) 502‚Äì517 511
discriminant features from the nullspace of the within-class
covariance matrix. In Table 4, CKFD does not consistently perform
better than KDA. That is probably because the summed normalized
distance for fusing two sets of features is not appropriate in some
cases. Like the canonical correlation analysis used in MKL, the
summed normalized distance used in CKFD tends to suffer from
an ineffective feature set.
Table 3 shows that using an MRF-based classiÔ¨Åer exhibits an in-
crease in classiÔ¨Åcation accuracy, compared to that of using a kNN
classiÔ¨Åer. With the aid of spatial context information, a misclassi-
Ô¨Åed pixel is correctly relabeled if it is surrounded by pixels of the
same class. This establishes the role of the spatial context as an
auxiliary discriminative resource for the test images. The methods,
MrfKDA and C-KDA, additionally incorporate spatial context
Fig. 11. Image T5 and the classiÔ¨Åcation maps based on various methods: (a) Image T5 is synthesized from Ô¨Åve Brodatz texture patterns √∞300 300√û. The gray image is
combined with six wavelet features to generate a seven-dimensional image. The lowpass Ô¨Åltered seven-dimensional image is used for textual classiÔ¨Åcation. (b) kNN-MRF; (c)
LDA; (d) KDA; (e) SVM; (f) CKFD; (g) C-KDA; and (h) MrfKDA. Methods LDA, KDA, CKFD, C-KDA, and MrfKDA are followed by a kNN and an MRF-based contextual classiÔ¨Åer.
Fig. 12. The results obtained by using various window widths to deÔ¨Åne the neighborhood in MrfKDA and the MRF-based classiÔ¨Åer. The test classiÔ¨Åcation accuracy for various
window widths: (a) 91.4% for window width 3; (b) 95.9% for window width 7; and (c) 97.3% for window width 15.
P.-F. Hsieh et al. / Image and Vision Computing 28 (2010) 502‚Äì517 513
Fig. 14. ClassiÔ¨Åcation accuracy using the MRF-based contextual classiÔ¨Åer. (a) Dataset 1; (b) Dataset 2; and (c) Dataset 3.
Fig. 15. Performance of the iterative MrfKDA for image T5. (a) 94.3% for the Ô¨Årst iteration; (b) 96.1% for three iterations; (c) 95.7% for Ô¨Åve iterations; (d) 96.9% for seven
iterations; and (e) 97.3% for nine iterations.
P.-F. Hsieh et al. / Image and Vision Computing 28 (2010) 502‚Äì517 515
