  2
è¡Œæ”¿é™¢åœ‹å®¶ç§‘å­¸å§”å“¡æœƒå°ˆé¡Œç ”ç©¶è¨ˆç•«æˆæœå ±å‘Š 
è¨ˆç•«ç·¨è™Ÿï¼šNSC 95-2221-E-150-091 
åŸ·è¡ŒæœŸé™ï¼š95 å¹´ 8 æœˆ 1 æ—¥è‡³ 96 å¹´ 7 æœˆ 31 æ—¥ ä¸»æŒäººï¼šé»ƒæƒ ä¿   
åŸ·è¡Œæ©Ÿæ§‹åŠå–®ä½åç¨±ï¼šåœ‹ç«‹è™å°¾ç§‘æŠ€å¤§å­¸è³‡è¨Šå·¥ç¨‹ç³» 
   è¨ˆç•«åƒèˆ‡äººå“¡ï¼šé­å°è»(åœ‹ç«‹ä¸­æ­£å¤§å­¸è³‡å·¥æ‰€) 
 
 
ä¸€ã€ä¸­æ–‡æ‘˜è¦ 
 
ç”±æ–¼æ•¸ä½ç§‘æŠ€è³‡è¨Šç”¢æ¥­çš„éµ¬å‹ƒç™¼å±•ï¼Œäºº
æ°‘å°ç”Ÿæ´»å“è³ªåŠç”Ÿæ´»å‘¨é­ç’°å¢ƒçš„å®‰å…¨æœ‰
äº†æ›´åŠ çš„é‡è¦–ã€‚å› è€Œæ•¸ä½ç›£æ§æ”å½±å™¨ææ›´
æ˜¯æœ€ä½³çš„å™¨å…·ï¼Œç„¶å…¶å“è³ªä¸æ–·çš„æé«˜ä¸”åƒ¹
æ ¼ä¹Ÿæ˜¯ç›¸ç•¶å¹³æ˜“è¿‘äººçš„ã€‚æ•¸ä½è¦–è¨Šæ”å½±å™¨
æé™¤äº†æä¾›çš„å¨›æ¨‚å¤–æ›´æ˜¯å”åŠ©å‘¨é­ç’°å¢ƒ
å®‰å…¨ç›£æ§çš„å¥½å·¥å…·ï¼Œå…·å³æ™‚æ€§æ“æ§æ€§ä½³ã€‚
å¦ä¹Ÿæä¾›çš„ç›£éŒ„ã€ç¶²è·¯è¦–è¨Šæ•™å­¸ç­‰æ‡‰ç”¨ã€‚
ç¶“ç”±ç¶²éš›ç¶²è·¯çš„è³‡è¨Šäº¤æ›åŠåˆ†äº«ï¼Œæˆ‘å€‘å¸Œ
æœ›ç ”ç©¶ä¸€å€‹èƒ½å¤ å°ç›¸åŒç’°å¢ƒæˆ–æ˜¯å»ºç¯‰ç‰©
å‘¨é­ç’°å¢ƒåšæè¿°çš„æ•¸ä½é¡¯åƒï¼Œä¸¦é€éç’°å ´
æ¥åœ–æŠ€è¡“çš„å”åŠ©ï¼Œåˆæ­¥å»ºç«‹å‡ºç”±é€™ç³»åˆ—æ‰€
å–å¾—çš„å…¨æ™¯å½±åƒï¼Œå½¢æˆä¸€çµ„2Dçš„å½±åƒè³‡
è¨Šã€‚åŒæ™‚æ›´é€²ä¸€æ­¥çš„åˆ©ç”¨é›»è…¦è¦–è¦ºåŠè™›æ“¬
å¯¦å¢ƒä¸Šçš„æŠ€è¡“ï¼Œå»ºç«‹å‡ºæ­¤å»ºç¯‰ç‰©æˆ–æ˜¯ç’°å¢ƒ
çš„3D modelï¼Œä¸¦å°‡3D modelèˆ‡2Dçš„å½±åƒè³‡
è¨ŠåŠ ä»¥çµåˆï¼Œå½¢æˆä¸€å€‹ååˆ†é€¼è¿‘å¯¦ç‰©çš„3D
çš„è¦–è¦ºç’°å¢ƒï¼Œä¸¦ä¸”é€éå»ºç«‹å‡ºçš„3Dç’°å¢ƒï¼Œ
é€²è¡Œä¸€ç³»åˆ—å»¶ä¼¸çš„æ‡‰ç”¨é–‹ç™¼ï¼Œä½¿å¾—ä½¿ç”¨è€…
å¯åœ¨é™é çš„å½¼ç«¯ï¼Œä¹Ÿèƒ½æœ‰èº«æ­·å…¶å¢ƒçš„æ„Ÿ
è¦ºã€‚     
æœ¬è¨ˆåŠƒä¸»è¦ä¹‹ç›®çš„æ˜¯ç ”ç™¼ä¸€å€‹ä»¥ç’°å ´
æ¥åœ–æŠ€è¡“ç‚ºåŸºç¤ä¹‹è¦–è¨Šå½±åƒç›£æ§è¼”åŠ©ç³»çµ±
(An Auxiliary Surveillance System based on 
Image Mosaic, ASSIM)ï¼Œå¯æ‡‰ç”¨æ–¼å¦‚å¤è¹Ÿ
ä¿®å¾©ã€æ•¸ä½å…¸è—ã€å®¤å…§è¨­è¨ˆã€è™›æ“¬å¯¦å¢ƒã€
3D éŠæˆ²ç­‰ç›¸é—œæ‡‰ç”¨ä¸Šã€‚ 
 
é—œéµè©ï¼šå½±åƒé‘²åµŒ,å½±åƒæ¥åˆ,ç‰©ä»¶åµæ¸¬,
è¦–è¨Šé‘²åµŒã€‚ 
Abstract 
 
As the speed growing of the Information 
technology advance, the digital camera 
becomes more powerful in the quality or the 
capability and cheaper in the prices recently. 
However, humans are most important them 
life quality and environment security, the 
digital surveillance device is the best tool. 
Hence, we can observe more and more 
applications in digital image filed are 
achieved. For example, the reservation of 
memory in the past time and e-learning via 
the multimedia information shared in the 
internet. Because of the information 
exchanged or shared in the internet, we want 
to investigate these image sequences that 
relate to other images. Then, we reconstruct 
the 2D panorama information by image 
mosaic technology. We adopt the related 
technology in computer vision and the 
virtual technology to build a 3D model of 
the building or the environment. The 
approximate 3D vision environment will be 
formed by the 2D and 3D information. 
Finally, the system will support the extended 
applications that are operating in our system. 
Regardless of time or space, they will be 
stay in the scene when the users are 
executing our system. 
The main goal of our approach is to 
develop a system that called an auxiliary 
surveillance system based on image mosaic 
technique (named ASSIM). This system can 
support some applications, such as the 
reconstruction of historic interest, the digital 
book reservation, interior design, virtual 
reality, 3D game, and etc.  
 
Keywords: 3D environment reconstruction, 
virtual reality, image mosaic, interaction. 
  4
ä¸‰ã€çµæœèˆ‡è¨è«– 
 
I. ç ”ç©¶æ–¹æ³•æ­¥é©Ÿï¼š 
æœ¬ç ”ç©¶ç³»çµ±è™•ç†æµç¨‹ä¸»è¦æœ‰å¤šæ”å½±æ©Ÿ
ç›£æ§ç’°å¢ƒå…¨æ™¯åœ–å»ºç½®ã€ç‰©ä»¶åˆ†æè™•ç†èˆ‡å³
æ™‚ç‰©ä»¶è¡Œç‚ºåˆ†æã€ç‰©ä»¶ä¿®æ­£ã€è­¦è¨Šç³»çµ±è™•
ç†ã€‚åœ¨åœ–ä¸€ç³»çµ±æµç¨‹åœ–ä¸­å·¦é‚Šæ”¯ç·šéƒ¨åˆ†è¡¨
ç¤ºå¤šæ”å½±æ©Ÿç›£æ§ç’°å¢ƒå…¨æ™¯åœ–å»ºç½®ï¼Œè€Œå³é‚Š
æ”¯ç·šå‰‡è¡¨ç¤ºç‰©ä»¶åˆ†æè™•ç†èˆ‡å³æ™‚ç‰©ä»¶è¡Œç‚º
åˆ†æã€ç‰©ä»¶ä¿®æ­£ã€è­¦è¨Šç³»çµ±è™•ç†ã€‚é¦–å…ˆï¼Œ
æˆ‘å€‘å°‡å°æ–¼ç›£æ§ç’°å¢ƒæ¶è¨­é©ç•¶å€‹æ•¸ä¹‹ç›£æ§
æ”å½±æ©Ÿé€²è¡Œå°è©²ç’°å¢ƒè¦–è¨Šå½±åƒè³‡æ–™çš„æ”¶é›†
çµ±æ•´ï¼Œä¸¦å°æ‰€æ‹æ”å¾—çŸ¥çš„å½±åƒè³‡æ–™é€²è¡Œå½±
åƒé‚Šç·£èª¿æ•´ï¼Œä»¥é¿å…ä¸‹ä¸€æ­¥å½±åƒæ¥åˆæŠ€è¡“
è™•ç†æ™‚ï¼Œæ¥åœ–æ•ˆæœåŠæº–ç¢ºæ€§å—åˆ°å…·æœ‰æ›²åº¦
ä¹‹å½±åƒé‚Šç·£å¹²æ“¾ã€‚è€Œåœ¨è¦–è¨Šå½±åƒå‰ç½®èª¿æ•´
å®Œç•¢å¾Œï¼Œå‰‡æ˜¯å°‡å‰å¹¾å€‹ Cycle æ™‚é–“å…§ä¹‹ç›£
æ§ç’°å¢ƒå½±åƒï¼Œä»¥æˆ‘å€‘å…ˆè¡ŒåŸ·è¡Œ(94)åœ‹ç§‘æœƒ
è¨ˆç•«æ‰€æå‡ºä¹‹å½±åƒæ¥åˆ(image registration)
æŠ€è¡“[1]ï¼Œå°‡æ‰€æœ‰æ”å½±æ©Ÿæ‰€å–å¾—ä¹‹å½±åƒé€²è¡Œ
æ¥åˆè™•ç†ï¼Œä¸¦ç¶“éç´°éƒ¨èª¿æ•´å¾Œå–å¾—å°è©²ç›£
æ§ç’°å¢ƒä¹‹å…¨æ™¯åœ–ï¼›åŒæ™‚ï¼Œæˆ‘å€‘ä¹Ÿå°‡åœ¨è©²æ®µ
æ™‚é–“å…§ï¼Œé€²è¡Œå–å¾—æ¸¬è©¦ä¹‹ç›£æ§è¦–è¨Šå½±åƒè³‡
æ–™çš„è’é›†åŠæ•´ç†ï¼Œä¸¦å°‡é€éèƒŒæ™¯ç›¸æ¸›æ³•ï¼Œ
å³æ™‚åˆ¤æ–·å‡ºæ–¼é‚£å€‹æ™‚é–“é»ã€é‚£å€‹æ”å½±æ©Ÿç›£
æ§ç•«é¢å‡ºç¾äº†å…¥ä¾µç‰©é«”ï¼Œå› è€Œå°‡è©²æ®µå‡ºç¾
å…¥ä¾µç‰©é«”æ™‚æ®µä¹‹è¦–è¨Šå½±åƒï¼Œå¦è¡Œå„²å­˜æ–¼æ‰€
è¨­ç½®ä¹‹ç›£æ§è¦–è¨Šå½±åƒè³‡æ–™åº«ä¸­ï¼Œç·Šæ¥è‘—é€²
è¡Œå°æ­¤æ®µæ™‚é–“å…§ä¹‹å…¥ä¾µç‰©é«”ï¼Œåšç‰©é«”å‰ç½®
è™•ç†ï¼ŒåŒ…å«ç‰©é«”å€‹æ•¸åˆ¤æ–·ï¼Œç‰©é«”å¤–è§€å–å¾—ã€
ç‰©é«”æ–¹ä½ç­‰é€²è¡Œè™•ç†ï¼Œä»¥æä¾›å¾ŒçºŒä¹‹ç‰©é«”
è¡Œç‚ºåˆ†æç­‰ç¨‹åºä½¿ç”¨ã€‚ 
åœ¨å…¥ä¾µç‰©é«”åµæ¸¬åŠè¡Œç‚ºåˆ†ææ–¹é¢ï¼Œå°‡
é€éç‰©é«”è¡Œç‚ºåˆ†ææ¨¡çµ„èˆ‡å»ºè­°é˜²å µç­–ç•¥æ¨¡
çµ„çš„å”åŠ©ï¼Œä½¿å¾—ç›£æ§äººå“¡å¾—ä»¥æ–¼ç›£æ§è¢å¹•
ä¸Šæ›´æ¸…æ™°ä¸”å…·æœ‰æ›´ä½³çš„è§€çœ‹è§’åº¦ä¸‹è§€çœ‹å…¥
ä¾µç‰©é«”çš„ä¸€èˆ‰ä¸€å‹•ã€‚åŒæ™‚ï¼Œè©²ç‰©é«”è¡Œç‚ºåˆ†
ææ¨¡çµ„ä¹Ÿå°‡æœƒæ–¼çŸ­æš«æ™‚é–“å…§åˆ¤æ–·å‡ºè©²å…¥ä¾µ
ç‰©é«”ä¹‹æœªä¾†å¯èƒ½çš„èµ°å‘ï¼Œä¸¦å»ºè­°é˜²å µç­–ç•¥
æ¨¡çµ„æºé€šï¼Œç™¼å‡ºä¸€æé†’ç›£çœ‹äººå“¡æ³¨æ„åŠå»º
è­°é˜²å µç­–ç•¥çš„è­¦å ±è¨Šæ¯ã€‚æœ€å¾Œï¼Œç”±ç›£æ¸¬ä¸­
å¿ƒä¹‹ç›£æ§äººå“¡æ–¼ç¬¬ä¸€æ™‚é–“å…§åšå‡ºæœ€é©ç•¶çš„
æ‡‰å°è™•ç†æ–¹å¼ï¼Œä»¥é”æˆæœ¬ç ”ç©¶è¨ˆç•«æ‰€è¿½æ±‚
ä¹‹ç›®æ¨™â€“æ›´åŠ äººæ€§åŒ–çš„å³æ™‚ç›£æ§è¼”åŠ©ç³»
çµ±ã€‚ 
ä»¥ä¸‹ç‚º [2]æ‰€æå‡º Video Alignment 
Algorithm æ­¥é©Ÿæ•˜è¿°ã€‚ 
Video Alignment Algorithm: 
{ 1. For each frame: 
z Extract the invariant features at 
the interest points  
z Match to the previous frame 
z Match to the previous key frame 
z Estimate the overlap with the 
previous key frame  
z Mark as a key frame if the 
overlap is too low 
{ 2. For each frame: 
z Match to the next or the 
â€œforwardâ€ key frame 
{ 3. For each key frame: 
z Match to all other key frames 
{ 4. Compress the matched measurements  
{ 5. Estimate the image orientations from 
the compressed matches using the 
bundle adjustment 
 
æ ¹æ“šä¸Šè¿°çš„æ­¥é©Ÿæˆ‘å€‘å…ˆè™•ç†æœ‰é—œ key 
frames çš„æŒ‘é¸å‹•ä½œ: 
(1) Frames clusterï¼šæˆ‘å€‘å°‡æ”¶é›†ä¹‹å½±åƒï¼Œå…¶
å¤§å°ç‚º 720Ã—480ï¼Œé‡å°ä¸€æ®µæ™‚é–“å…§çš„å½±
åƒé€²è¡Œ cluseter çš„å‹•ä½œï¼Œä¾‹å¦‚ä¸€æ®µ 5 åˆ†
é˜çš„è¦–è¨Šå½±åƒï¼Œåªè™•ç†ç•¶ä¸­ I frames çš„
åˆ†é¡ï¼Œå› ç‚ºéå¤š frames è‹¥æ˜¯çš†éœ€é€²è¡Œ
æ¥åˆè™•ç†ï¼Œæ•¸é‡éæ–¼é¾å¤§ï¼Œå› è€ŒåªæŒ‘å‡º
I frames çš„éƒ¨ä»½è™•ç†åˆ†é¡ã€‚ç”±çœ¾å¤šç›¸ä¼¼
çš„ I frames æ­¸é¡æˆä¸€å€‹ groupï¼Œæ¯å€‹
  6
çš„é¡åˆ¥ç•¶ä¸­ã€‚ 
æˆ‘å€‘æ¡ç”¨ä»¥ä¸Šä¹‹è™•ç†ç¨‹åºè—‰ä»¥ç²å¾—æ­£
ç¢ºçš„ frames cluster çµæœï¼Œä»¥åˆ©å¾ŒçºŒé€²è¡Œå½±
åƒçš„æ¥åˆæ™‚é¿å…å¤§é‡çš„ frames æ¥åˆï¼Œä»¥å°‘
æ•¸å…·æœ‰ä»£è¡¨æ€§çš„ framesæ¥åˆå–ä»£ç„¡æ„ç¾©ä¸”
è¨ˆç®—é‡å¤§ä¹‹å…¨éƒ¨ frames æ¥åœ–å‹•ä½œï¼Œè—‰ä»¥æ
æ˜‡æ•´é«”è¨ˆç®—æ•ˆèƒ½ã€‚ 
 
II. å¯¦é©—çµæœå’Œè¨è«–ï¼š 
 
æˆ‘å€‘ä»¥å°‡æ‰€æ”å½±åˆ°è¦–è¨Šå½±ç‰‡é€²è¡Œåˆ†æ
å¾Œï¼Œå› ç‚ºæ‰€æœ‰çš„ç‰‡æ®µæ‰€åˆ†æå‡ºçš„æ›²ç·šå¤§å¤š
ç›¸è¿‘ï¼Œæˆ‘å€‘ä»¥å…¶ä¸­ä¹‹ä¸€å€‹ 5 åˆ†é˜çš„ç‰‡æ®µå½±
ç‰‡ä½œç‚ºåˆ†æçµæœä¹‹ä¾‹ï¼Œå¦‚åœ–ä¸‰æ‰€ç¤ºï¼Œæ©«è»¸
ä»£è¡¨ç›¸ä¼¼åº¦å€åŸŸæ‰€ä½”çš„æ¯”ä¾‹ï¼Œç¸±è»¸ç‚º
frames æ•¸ç›®çš„å¤šå¯¡æ„æŒ‡è¡¨ç¤ºåœ¨æ­¤ç›¸ä¼¼åº¦çš„
é–€æª»å€¼ä¸‹æœƒæœ‰å¤šå°‘ framesã€‚ 
 
 
åœ–ä¸‰ è¦–è¨Šå½±åƒç›¸ä¼¼åº¦é–€æª»åˆ†æåœ– 
 
ç”±ä¸Šé¢å¯¦é©—å¯ä»¥æ˜é¡¯çœ‹å‡ºï¼Œç•¶åœ¨ç›¸ä¼¼
åº¦é–€æª»å€¼ç‚º 45 æ™‚ï¼Œé–‹å§‹æœ‰è‘—å¤§å¹…ä¸‹æ»‘çš„è¶¨
å‹¢ï¼ŒåŒæ™‚åœ¨ 65 ä»¥ä¸Šä¹Ÿæœƒæœ‰è‘—é€™æ¨£çš„ç¾è±¡ï¼Œ
é€™æ¨£çš„ç¾è±¡èªªæ˜äº†ç•¶ä½¿ç”¨éä½æˆ–æ˜¯éé«˜çš„
é–€æª»å€¼æ™‚ï¼Œç”±æ–¼é–€æª»å€¼çš„æ¢ä»¶ä¸æ˜“é”åˆ°æˆ–
æ˜¯éæ–¼å®¹æ˜“é”åˆ°ï¼Œè€Œé€ æˆåˆ†é¡æ•ˆæœä¸ä½³çš„
ç‹€æ³ã€‚ 
ä¾‹å¦‚éå°çš„é–€æª»å€¼æ™‚ï¼Œæ‰€åˆ†é¡å‡ºçš„çµ
æœå°‡æœƒæ˜¯æ¯”è¼ƒå°‘çš„ groupsï¼Œå› ç‚ºè¦é–“éš”å¾ˆ
å¤šå€‹ I frame æ‰æœƒé€ æˆç„¡æ³•é€šéé–€æª»å€¼é€²
è€Œåˆ†é¡åˆ°å¦å€‹åˆ†é¡ï¼Œå› æ­¤æ¯å€‹ groups ä¸­
æ‰€ä»£è¡¨çš„ key frame åè€Œæœƒæœ‰è‘—å·®ç•°æ€§é
å¤§ä¸åˆ©æ–¼å¾ŒçºŒæ¥åœ–è™•ç†ã€‚ç›¸å°çš„ï¼Œåœ¨éé«˜
çš„é–€æª»å€¼ä¸­æœƒé€ æˆå¾ˆçŸ­çš„é–“éš”å°±å¿…é ˆåˆ†
é¡ï¼Œä½¿å¾— groups å€‹æ•¸éå¤šï¼Œé€£å¸¶ä½¿ key 
frames å€‹æ•¸è®Šå¤šï¼Œåœ¨æœ€å·®çš„ç‹€æ³ä¸‹å¹¾ä¹æ²’
æœ‰åˆ†é¡ã€‚æ‰€ä»¥ç„¡è«–éä½æˆ–æ˜¯éé«˜çš„é–€æª»å€¼
éƒ½ä¸æ˜¯å€‹é©ç•¶çš„çµæœã€‚å¾åœ–äº”åˆ°åœ–å…«ç‚ºå¯¦
é©—ä¸åŒé–€æª»å€¼æ‰€å±•ç¤ºå‡ºçš„åˆ†é¡çµæœåœ–ã€‚ 
å¦å¤–ä½¿ç”¨ç‰¹å¾µé»åµæ¸¬çš„æ–¹å¼å¯¦é©—çµæœ
å¦‚åœ–å››(a)èˆ‡(b)æ‰€ç¤ºã€‚ 
 
 
(a) 
 
(b) 
åœ–å›› è¦–è¨Šå½±åƒç‰¹å¾µé»åœ–(a)èˆ‡(b) 
  
å¾åœ–å››(a)å’Œ(b)çš„çµæœä¸­å¯ä»¥çœ‹å‡ºç‰¹å¾µé»
éæ•¸éå°‘ï¼Œé€™æ˜¯ç”±æ–¼è¦–è¨Šå½±ç‰‡æœ¬èº«å°æ¯”ä»¥
åŠå½±åƒå…§å®¹é€²è¡Œ edge è™•ç†æ™‚æ‰€å¯æ¡ç”¨çš„
è³‡è¨Šä¸¦éååˆ†å……è¶³ï¼Œå› è€Œç„¡æ³•æœ‰è‘—è¼ƒå¤šçš„
ç‰¹å¾µé»å¯ç”¨å°è‡´æº–ç¢ºç‡ä¸‹æ»‘ã€‚åœ–äº”è‡³å…«åˆ† 
  8
    
    
    
 
åœ–å…« é–€æª»å€¼ 70%ä¸‹æ‰€åˆ†é¡çµæœåœ– 
 
åˆ¥åœ¨ä¸åŒçš„é–€æª»å€¼ä¸‹æ‰€ç²å¾—çš„åˆ†é¡çµæœã€‚ 
 
å››ã€æˆæœè‡ªè©• 
 
æœ¬ç ”ç©¶è¨ˆç•«ä¹‹æœ€çµ‚ç›®æ¨™æ˜¯ç‚ºå»ºæ§‹å‡ºä¸€
å€‹æ›´å…·äººæ€§åŒ–ä¸”å…·æœ‰è°æ˜çš„å»ºè­°é˜²å µç­–ç•¥
ä¹‹ç›£æ§è¼”åŠ©ç³»çµ±ç‚ºä¸»è¦çš„ç ”ç©¶ä¸»è»¸ï¼Œç ”ç™¼
å¦‚ä½•å¾ç¾å­˜æ”å½±æ©Ÿæ‰€æ‹æ”å‡ºä¹‹å…·é—œè¯æ€§çš„
å½±åƒ/è¦–è¨Šè³‡æ–™ï¼Œåˆ©ç”¨ Image Mosaic æŠ€è¡“
å¯¦ä½œç›£æ§ç’°å¢ƒå…¨æ™¯é‡å»ºï¼Œä¸¦ä¸”æ­é…å…¶å¾ŒçºŒ
ä¹‹ç‰©ä»¶è¡Œç‚ºåˆ†ææ¨¡çµ„èˆ‡è­¦å ±ç™¼ä½ˆæ¨¡çµ„ï¼Œå°‡
é€™äº›æœ‰æ•ˆä¸”è±å¯Œçš„è¨Šæ¯ç²¾ç¢ºåœ°é¡¯ç¤ºæ–¼ç›£æ§
è¢å¹•ä¸Šï¼Œå»ºæ§‹å‡ºäººæ€§åŒ–çš„ç›£æ§è¼”åŠ©ç³»çµ±ã€‚
è—‰ç”±æ¢è¨ç›¸é—œç†è«–åŠæŠ€è¡“é–‹ç™¼ï¼Œå¦‚å‰æ™¯ã€
èƒŒæ™¯å€åˆ†ã€èƒŒæ™¯ç›¸æ¸›æ³•ã€ç‰©ä»¶å‹•æ…‹å‘é‡ç­‰
æŠ€è¡“ï¼Œçµ±æ•´å‡ºèƒ½å¤ æä¾›ç²¾ç¢ºã€å…·æœ‰ç›£æ§ç’°
å¢ƒå…¨æ™¯åœ–ï¼Œå³æ™‚é€šå ±å…¥ä¾µç‰©é«”å‹•å‘ä¸”å¸¶æœ‰
å»ºè­°é˜²å µç­–ç•¥çš„è¦–è¨Šå½±åƒç›£æ§è¼”åŠ©ç³»çµ±ï¼Œ
ä¸¦ä¸”æä¾›æœªä¾†å¦‚å‹•æ…‹ç‰©é«”åµæ¸¬åŠè¿½è¹¤ã€ç¤¾
å€å®‰å…¨ç­‰ç›¸é—œå¾ŒçºŒå»¶ä¼¸çš„è¨­è¨ˆæ‡‰ç”¨ã€é–‹ç™¼
ç ”ç©¶ç­‰æŠ€è¡“ä¹‹åŸºç¤ã€‚ 
ç›®å‰å·²å°‡æœ‰é—œ key frames æŒ‘é¸éƒ¨ä»½é€²
è¡Œè™•ç†ï¼Œçµæœå‘ˆç¾å¦‚å‰è¿°çš„åœ–äº”è‡³å…«ä¸­ï¼Œ
éƒ¨åˆ†çµæœä¸¦ä¸æ˜¯è®“äººæ»¿æ„ï¼Œæ­£è©¦è‘—çµåˆå…¶
ä»–ä¸åŒçš„ä½œæ³•é€²è¡Œæ”¹å–„ï¼Œä½†ç³»çµ±å°šå­˜åœ¨ä¸€
äº›å›°é›£é»ï¼Œä¹Ÿæ­£ç©æ¥µå…‹æœä¸­ï¼Œç‚ºæœŸèƒ½å»ºæ§‹
å®Œæ•´çš„ç’°å ´ç›£æ§åœ–ã€‚æœªä¾†å°‡æ›´é€²ä¸€æ­¥çš„æ”¹
è‰¯æŠ€è¡“åŠæ”¹å–„ç³»çµ±æ•ˆèƒ½ï¼Œä»¥å»ºæ§‹å®Œå–„çš„äºº
æ€§åŒ–ç›£æ§è¼”åŠ©ç³»çµ±ã€‚ 
 
äº”ã€åƒè€ƒæ–‡ç» 
 
[1] H. Y. Huang and T. C. Wei, "Fast 
Locating Detection of Covering Region 
in Image Mosaic," in Proc. of the 2nd 
European Workshop on the Integration 
of Knowledge, Semantic and digital 
Media Technologies, PP. 301-308, IEE 
Savoy Place, 
London,  UK,  Nov.30~Dec. 1, 2005 
[2] D. Steedly, C. Pal and R. Szeliski, 
An effective watermark embedding algorithm for high JPEG compression 
Hui-Yu Huang 
Department of Computer Science and Information 
Engineering, National Formosa University, Taiwan 
E-mail: hyhuang@nfu.edu.tw 
Chi-Hung Fan, and Wen-Hsing Hsu 
Department of Electrical Engineering,  
National Tsing Hua University,  Taiwan 
Abstract 
Digital watermarking is an important technology that has 
been widely applied many applications. In this paper, we 
present an effective embedding watermark method for JPEG 
image which can resist high compression attack and retain a 
good image quality. The proposed algorithm consists of 
three parts which are searching the optimal embedded 
position, embedded value, and embedded/extracted 
processing for watermark in images.  First, the embedded 
position search, which performed in DCT domain, are
achieved the optimal watermark embedding position by
means of finding the number of zero in low frequency region 
after compressing. Next, according to above result, we 
calculate the distortion difference between the original 
image and compressed image to decide the best tolerant 
range and assign the embedded value. Last, based on
quantization index modulation (QIM), the embedded 
processing can further achieve effectively to inset the 
watermark in images. Thus this approach can effectively 
resist high JPEG compression and protect the embedded 
information and media ownership. The experimental results 
are presented to demonstrate the effectiveness of our 
approach. 
1. Introduce 
Owing to the quickly evolvement of networked multi media 
systems in last few years, the protection of digital media has 
been necessitated and more important scheme, especially the 
protection and enforcement of intellectual property rights. 
Copyright protection involves the authentication of data 
(text/image/video) ownership and the identification of illegal 
behavior such as copies. Techniques are needed to prevent 
the copying, forgery and unauthorized distribution of images 
and video.  However, digital watermarking technology is 
usually applied to protect the intellectual property of digital 
data which are freely available on the WWW and transmitted 
over network. 
A large number of watermarking systems address the 
problems of implementing invisible watermarks. There have 
been a number of corresponding works [1-3] dedicated to 
image/video/audio watermarking. These scholars define a 
digital watermark as an identification code which carrying 
information about the copyright owner, the creator of the 
work, the authorized consumer, etc. It is permanently 
embedded into digital data for copyright protection and may 
be used for checking whether the data have been modified 
illegally [1]. Cox et al. [3] proposed a secure (tamper-
resistant) algorithm to construct the watermark as an 
independent and identically distributed Gaussian random 
vector which is inserted in a spread-spectrum-like fashion 
into spectral component of the data. It can effectively 
resisted against the transformed watermarked image. Owing 
to the time-consuming computation for spread-spectrum 
method, Chen [4] proposed the quantization index 
modulation (QIM) and distortion-compensated (DC-QIM) 
methods to embed the watermark in order to improve this 
program. By using of the (QIM) algorithm, it can achieve 
against arbitrary bounded and fully informed attacks and 
further arise to currently popular spread-spectrum method. 
Wong [5] used the human visual system (HVS) model to 
estimate the JEPG-to-JEPG data hiding capacity of JPEG 
image and the maximum number of bits embedded in JPEG-
compressed images. Wong et al. [6] proposed three 
techniques which include single watermark embedding, 
multiple watermark embedding, and iterative watermark 
embedding to embedded watermarks in order to remain good 
image quality and robust in varying degree to JPEG 
compression. This algorithm can successively embedded 
watermark when the quality factor is low, but when the 
quality factor is low. However, this approach makes high 
computation complexity of the iterative loop. These methods 
are also existed the problems of either complexity or time-
consuming computation. 
Generally, the watermark scheme hopes the abilities of 
resisting some attacks such as noise, copying, rotation, 
scaling, lossy compression, etc. However, we find out that 
many researches do not have an effective method to solve 
this problem well. Although, a lot of watermarking systems 
designed for compression have been proposed, most of them 
may not make a balance point between image quality and 
compression intensity. Therefore, we design an optimal 
method in order to solve this problem between image quality 
and compression intensity. In this paper, our proposed 
system will concern with resisting high lossy compression 
for JPEG to protect the intellectual property rights of owner 
against the illegal infringement.  
256
MVA2007 IAPR Conference on Machine Vision Applications, May 16-18, 2007, Tokyo, JAPAN
8-8
2.3 Embedded and extracted processing 
2.3.1 Embedded processing 
In order to obtain the optimal positions to embed 
watermark, we have to further find out the embedded
watermarking positions ),( nmEWP and values 
),( nmEWV corresponding the coordinates ),( nm of 
watermark. According to above processing, all of the optimal 
embedded points ),( qpOEP can be found which can 
tolerant higher JPEG compression ratio corresponding to the 
pth row and qth column of block location and have the 
relatively number of zero coefficient by compression 
processing. Now we use this information to decide 
the ),( nmEWP . The searching rule is that the number of 
zero coefficient for ),( nmEWP  must be greater than a 
threshold value and the searching path is started at the 
threshold to 100. In our experiment, this threshold is set to 
30, namely, searching the ),( nmEWP  position is started 
from 30 to 100. While the number of ),( nmEWP  are 
equal to the number of embedded watermark, the searching 
process is stopped. Every ),( nmEWP  has the 
corresponding ),( nmEWV  value that can easy to obtain 
by means of the optimal embedded value ),( qpOEP . Here, 
our system will not search ),( nmEWP  from 0 to 100, it is 
because that if the threshold is set to 0, it will cause the 
serious distortion of watermark image. Actually, it is a 
reasonable situation; a point which is the low number of zero 
coefficient can serve as a sensitive point under JPEG 
compression. 
Figure 2 is shown in the embedded method based on 
improved quantization index modulation mechanism. All of 
the embedded procedures will be distributed as follows.
Figure 2 The diagram of the proposed embedded method.
Step1: Load the information of ),( nmEWP  to know where 
is the embedded point and also read-out its original 
host image DCT value ( ),( yxQi ) in this point. 
Step2: Find out the positive index range )(iPIR  and 
negative index range )(iNIR  for the ith point that 
will be used to extracted process and this information 
serves as secure key. 
Â®Â¯Â­  
  
),(),()(
),(),()(
)(
iMDRyxOiiPIR
iMDRyxOiiNIR
IIR         (2) 
where ),( yxQi  is the DCT value of the original host 
image corresponding to the embedded point. 
Step3: Define the index range (IR).
Â®Â¯Â­ dt
dd 
),,()(),()(here,1
),(),()(here,0
)(
yxWiPIRoryxWiNIRw
iPIRyxWiNIRw
iIR
ii
i       (3) 
where ),( yxWi  is the DCT value of embedded point 
for watermark image. 
Step4:  Insert the watermark in the host image. 
Â®Â¯Â­
u 
0,embedif),,(
1,embedif),(2),(
),(
yxO
iEWVyxO
yxW
i
i
i
        (4) 
If we want to embed index (=0), we don't need to 
change its value. If we want to embed index (=1), we
need to move the original DCT value out of the index 
range. 
Step5: Repeat step1 to step4 until all of the watermarks are 
embedded. 
2.3.2 Extracted processing 
In extracted method, we must make use of the secure key 
obtained by the embedded process which is denoted the 
negative index range )(iNIR  and positive index 
range )(iPIR  information. By above the information, then it 
is easy to detect the embedded watermark. And its procedure 
is expressed by 
Â®Â¯Â­ dt
dd 
),,()(),()(,1
,)(),()(,0
)(
yxWiPIRoryxWiNIRif
iPIRyxWiNIRif
iIR
ii
i (5)
where ),( yxWi  is the DCT value of embedded point of the 
watermark image. 
3. Experimental Results and Discussion 
In this section, we show some experimental results by our 
proposed algorithm. Here we use the size 720Ã—480 of
Mandrill standard image to be our host image and the 30Ã—20 
size of the watermark shown in Figure 3. A similarity 
measurement (NC) of the extracted and the referenced 
watermarks is defined as: 
,
)],([
),(Ë†),(
0 0
2
0 0
Â¦Â¦
Â¦Â¦
  
   
m
i
n
j
m
i
n
j
jiw
jiwjiw
NC           (5) 
where ),( jiw and ),(Ë† jiw denote the original watermark 
and the extracted watermark corresponding to the 
coordinates ),( ji  respectively. 
Figure 4 shows the NC value in the different QFactor 
value. From the Figure 4, it is obvious that the NC value can 
258
è¡¨ Y04 1
è¡Œæ”¿é™¢åœ‹å®¶ç§‘å­¸å§”å“¡æœƒè£œåŠ©åœ‹å…§å°ˆå®¶å­¸è€…å‡ºå¸­åœ‹éš›å­¸è¡“æœƒè­°å ±å‘Š 
                                                     ä¹åå…­å¹´äº”æœˆäºŒåäºŒæ—¥ 
å ±å‘Šäººå§“å é»ƒæƒ ä¿ 
Hui-Yu Huang 
 
æœå‹™æ©Ÿæ§‹
åŠè·ç¨± 
åœ‹ç«‹è™å°¾ç§‘æŠ€å¤§å­¸ 
è³‡è¨Šå·¥ç¨‹å­¸ç³» 
åŠ©ç†æ•™æˆ 
    æ™‚é–“ 
æœƒè­° 
     åœ°é» 
2007 å¹´ 05 æœˆ 16 æ—¥è‡³ 05 æœˆ
18 æ—¥  
æ—¥æœ¬åœ‹ æ±äº¬  
æœ¬æœƒæ ¸å®š
è£œåŠ©æ–‡è™Ÿ
NSC95-2221-E-150-091 
æœƒè­° 
åç¨± 
 (ä¸­æ–‡) ç¬¬åå±†æ©Ÿå™¨è¦–è¦ºåŠæ‡‰ç”¨ç ”è¨æœƒ 
 (è‹±æ–‡) 2007 Machine Vision and Applications, Tokyo, Japan 
ç™¼è¡¨ 
è«–æ–‡ 
é¡Œç›® 
 (ä¸­æ–‡) é«˜ JPEG å£“ç¸®ä¸‹ä¸€å€‹æœ‰æ•ˆçš„æµ®æ°´å°åµŒå…¥æ¼”ç®—æ³• 
 (è‹±æ–‡) An effective watermark embedding algorithm for high JPEG compression
å ±å‘Šå…§å®¹æ‡‰åŒ…æ‹¬ä¸‹åˆ—å„é …ï¼š 
ä¸€ã€åƒåŠ æœƒè­°ç¶“é 
æˆ‘çš„è«–æ–‡è¢«é¸ç‚ºä»¥æµ·å ±æ–¹å¼é€²è¡Œç™¼è¡¨ï¼Œä¸¦å®‰æ’åœ¨ 5æœˆ 17 æ—¥ä¸­åˆçš„ poster sectionï¼Œèˆ‰è¡Œçš„
æ™‚é–“å¾ 13ï¼š00ï½14ï¼š30ã€‚æœ¬æ¬¡ä»¥è£½ä½œ A0 å¤§å°ä¹‹æµ·å ±è³‡æ–™æ”œè‡³å¤§æœƒæœƒå ´ã€‚æ–¼æœƒè­°èˆ‰è¡Œå‰æ­ä¹˜
é•·æ¦®èˆªç©ºé£›æŠµé–‹æœƒåœ°é»æ—¥æœ¬åœ‹æ±äº¬æˆç”°(Narita Airport)åœ‹éš›æ©Ÿå ´ã€‚æœƒè­°èˆ‰è¡Œä¹‹åœ°é»æ˜¯ä½æ–¼æ±äº¬
å¤§å­¸ä¹‹ç”Ÿç”¢ç§‘æŠ€ç ”ç©¶æ‰€å…§(Institute of Industrial Science)ã€‚æœƒè­°é–‹å¹•å¼æº–æ™‚é–‹å§‹æ–¼åå…­æ—¥(ä¸‰)
æ—©ä¸Š 9:00ï¼Œä¸»å¸­ Mr. Johji TAJIMA åƒ…ç°¡å–®è‡´æ­¡è¿è©ä¸¦ä»‹ç´¹æœ¬æ¬¡ç ”è¨æœƒç‰¹è‰²ä¸¦åŒæ™‚å°‡å‰ä¹å±†çš„
MAV è«–æ–‡é›†çµæˆä¸€ç‰‡ç´€å¿µ DVD ç‰‡è´ˆæ–¼æ¯ä½èˆ‡æœƒçš„ä¾†è³“ã€‚éš¨å³é€²è¡Œç¬¬ä¸€å ´çš„ oral presentation åŠ
ç›¸é—œçš„ poster presentationã€‚æ­¤æ¬¡å¤§æœƒè­°ç¨‹å®‰æ’æ¯å¤©æœ‰ä¸‰å ´ sectionsã€ä¸€å ´ poster sectionã€åŠæ¯
å¤©çš†æœ‰ä¸€å ´çš„ invited talk é€²è¡Œï¼Œæ•´å€‹æœƒè­°ç›¸ç•¶å……å¯¦ä¸”ç·Šæ¹Šã€‚ 
 
äºŒã€èˆ‡æœƒå¿ƒå¾— 
é€™æ¬¡å‡ºåœ‹æ˜¯æˆ‘ç¬¬äº”æ¬¡æ¥å—è£œåŠ©å‡ºåœ‹åƒåŠ åœ¨åœ‹éš›æœƒè­°ï¼Œè€Œç‰¹åˆ¥çš„æ˜¯é€™ MAV æœƒè­°æ˜¯æˆ‘ç¬¬äºŒæ¬¡
åƒåŠ ï¼Œåœ°é»çš†åœ¨æ—¥æœ¬èˆ‰è¡Œï¼Œæ­¤æœƒè­°ç‚ºæœŸä¸‰å¤©(äº”æœˆåå…­è™Ÿè‡³åå…«æ—¥)ã€‚æˆ‘çš„è«–æ–‡åœ¨æœƒè­°ä¸­æ˜¯ä»¥
æµ·å ±å½¢å¼é€²è¡Œè«–æ–‡å ±å‘Šã€‚èˆ‡æœƒçš„äººå“¡æœ‰ä¾†è‡ªä¸–ç•Œå„åœ°åœ¨é€™æ©Ÿå™¨è¦–è¦ºæ–¹é¢çš„å…ˆé€²ã€ç§‘æŠ€äººæ‰åŠ
å­¸è€…ç­‰ï¼Œä¸€èµ·åœ¨é€™æœƒè­°ä¸­é€²è¡Œäº¤æµåŠç¶“é©—åˆ†äº«ã€‚ 
 
é™„ä»¶ä¸‰
 
è¡¨ Y04 3
çš„å¿ƒå¢ƒåƒèˆ‡æ­¤æ¬¡æœƒè­°ã€‚åœ¨é€™å°‡è¿‘å…©å°æ™‚çš„ poster representation æ™‚é–“ç²ç›Šè‰¯å¤šï¼Œå› èˆ‡æœƒä¾†è³“æœ‰
å­¸è€…ã€å°ˆå®¶æˆ–æ¥­ç•Œç­‰ï¼ŒåŸºæ–¼ä»–å€‘çš„å°ˆæ¥­çŸ¥è­˜è€Œæå‡ºä¸åŒè¦‹è§£åŠç–‘å•ï¼Œå› è€Œçµ¦äº†ä¸åŒè§’åº¦çš„æ€
è€ƒæ€ç·’ï¼Œå°å•é¡Œæˆ–ç ”ç©¶æœ‰äº†æ›´æ–°çš„æ€è€ƒã€‚æ¯ä¸€ä½å‰ä¾†è¨è«–ä¾†è³“åšè©³ç›¡çš„å ±å‘ŠåŠè§£èªªä¹‹å¤–ï¼ŒåŒ
æ™‚ä¹Ÿäº¤æ›å½¼æ­¤åœ¨é€™æ–¹é¢çš„å¿ƒå¾—åŠçœ‹æ³•ï¼Œäº¦åŒæ™‚ç²å¾—è‰¯å¥½çš„å»ºè­°åŠå°æˆ‘ç ”ç©¶çš„è®šè³ç­‰ã€‚å°æˆ‘è€Œ
è¨€ï¼Œé€™åˆæ˜¯å†ä¸€æ¬¡éå¸¸é›£å¾—æ—¢å¯¶è²´çš„å­¸ç¿’ç¶“é©—ï¼Œå¾€å¾Œå°‡æ›´åŠ åŠªåŠ›æ–¼ç ”ç©¶æ–¹é¢åŠå¤šåƒåŠ åœ‹éš›é–“
ç›¸é—œç ”ç©¶èˆ‰è¡Œä¹‹æœƒè­°ï¼Œæ‹“å±•è‡ªå·±çš„è¦–é‡ï¼Œå¢å»£è‡ªå·±çš„ç ”ç©¶é ˜åŸŸï¼Œä¹Ÿé©æ™‚çš„å°‡è‡ªå·±çš„ç ”ç©¶åˆ†äº«
æ–¼å¤–ã€‚å› æœƒè­°èˆ‰è¡Œåœ°é»åœ¨æ±äº¬å¤§å­¸å…§ï¼Œæ–¼åƒåŠ æœƒè­°æœŸé–“ä»”ç´°è§€å¯Ÿäº†æ ¡åœ’è£¡çš„ç’°å¢ƒï¼Œè¨­å‚™ï¼Œå­¸
ç”Ÿå€‘çš„äº’å‹•ç­‰ï¼Œåšäº†ä¸€æ¬¡æ ¡åœ’å°‹è¨ªã€‚ 
   
ä¸‰ã€è€ƒå¯Ÿåƒè§€æ´»å‹•(ç„¡æ˜¯é …æ´»å‹•è€…çœç•¥) 
ç„¡ 
å››ã€å»ºè­° 
ç„¡ 
äº”ã€æ”œå›è³‡æ–™åç¨±åŠå…§å®¹ 
æœ¬æ¬¡æœƒè­°ä¸»è¦æ”œå›è«–æ–‡é›†ä¸€æœ¬ (proceedings)åŠæœƒè­°å…‰ç¢Ÿç‰‡æœ‰å…©ç‰‡,å…¶ä¸€æ˜¯å°‡éå»
(1988~2005)æ‰€æœ‰ MAV çš„è«–æ–‡æ•´ç†æˆä¸€ç‰‡ DVD ç‰‡ã€‚å¦ä¸€å‰‡æ˜¯æœ¬æ¬¡æœƒè­°çš„æ‰€æœ‰è³‡æ–™åŒ…å«å¤§æœƒè­°
ç¨‹æ™‚é–“è¡¨ï¼ˆprogramï¼‰ã€invited talks(3 ç¯‡)ã€oral papers ( 43 ç¯‡) and poster papers (96 ç¯‡)ç­‰å…¨æ–‡
è«–æ–‡ã€‚å…¶ä¸»è¦ç›®éŒ„ä¾æ—¥æœŸåˆ†åˆ—å¦‚ä¸‹: 
3-22 A Comparison of New Generic Camera Calibration 
with the Standard Parametric Approach 
Aubrey K. Dunne, John Mallon and Paul F. Whelan, 
Ireland 
3-23 Pre-processing Algorithms on Digital Mammograms 
Hengameh Mirzaalian, Mohammad Reza Ahmadzadeh, 
Saeed Sadri and Mehdi Jafari, Iran 
3-24 License Plate Recognition from Low-Quality Videos 
Chih-Chiang Chen and Jun-Wei Hsieh, Taiwan 
3-25 Adaptive Modified PCA for Face Recognition 
Youness Aliyari Ghassabeh, Hamid Abrishami 
Moghaddam and Mohammad Teshnehlab, Iran 
3-26 Fingerprint Core and Delta Detection by Candidate 
Analysis 
Tomohiko Ohtsuka, Daisuke Watanabe and Hiroyuki 
Aoki, Japan 
3-27 Japanese Phone Recognition Using Lip Image In-
formation 
Takeshi Saitoh, Mitsugu Hisagi and Ryosuke Konishi, 
Japan 
3-28 A SVM Based Method to Detect Color Shift Defects 
in IC Packages 
R.M.C.B. Ratnayake, Craig Hicks and M.A. Akbari, 
Japan 
3-29 Object Type Classification Using Structure-based 
Feature Representation 
Tomoyuki Nagahashi, Hironobu Fujiyoshi and Takeo 
Kanade, Japan 
3-30 A Review of Tracking Methods under Occlusions 
Zui Zhang and Massimo Piccardi, Australia 
3-31 Fast Graph Segmentation Based on Statistical Ag-
gregation Phenomena 
Frank Nielsen and Richard Nock, Japan 
3-32 Tracking Features with Global Motion Compensa-
tion for Drone Camera Servoing 
BenoÃ®t Louvat, Laurent Bonnaud, Nicolas Marchand 
and Gerard Bouvier, France 
 
Session 4: Invited Talk 1 (14:30 ï£§ 15:30) 
Chair: Katsushi Ikeuchi 
4-1 Computational Cameras 
Prof. Shree K. Nayar, Columbia University, USA 
 
Break (15:30 ï£§ 15:50) 
 
Session 5: Motion and Image Sequence Analysis 
(15:50 ï£§ 17:50) 
Chairs: Bjorn Stenger and Atsuto Maki 
5-1 A Method for Estimating Rigid Object Motion Us-
ing Regularized Scene Flow 
Hiroki Mizuno and Hironobu Fujiyoshi, Japan 
5-2 Probabilistic Motion Segmentation of Videos for 
Temporal Super Resolution 
Arasanathan Thayananthan, Masahiro Iwasaki and 
Roberto Cipolla, UK 
5-3 Robust and Efficient 3-D Reconstruction by 
Self-Calibration 
Hanno Ackermann and Kenichi Kanatani, Japan 
5-4 Linear Tracking of Pose and Facial Features 
Jose Alonso Ybanez Zepeda, Franck Davoine and 
Maurice Charbit, France 
5-5 A Video Motion Capture System for Interactive 
Games 
Ryuzo Okada, Nobuhiro Kondoh and Bjorn Stenger, UK 
5-6 Using Space-Time Interest Points for Video Se-
quence Synchronization 
Daniel Wedge, Du Huynh and Peter Kovesi, Australia 
 
 
 
 
Thursday, May 17, 2007 
 
Session 6: Image Processing & Graphics (9:00 ï£§ 10:20) 
Chairs: Chu-song Chen and Hiroaki Nakai 
6-1 Real-time Soft Shadows in Mixed Reality Using 
Shadowing Planes 
Tetsuya Kakuta, Takeshi Oishi and Katsushi Ikeuchi, 
Japan 
6-2 A High-Speed and Compact Vision System Suitable 
for Wearable Man-machine Interfaces 
Takashi Komuro, BjÃ¶rn Werkmann, Takashi Komai, 
Masatoshi Ishikawa and Shingo Kagami, Japan 
6-3 Synthesis Arbitrary Views from Two Images Based 
on Improved View Morphing Technique 
Huagang Liang, Shogo Tokai and Hiroyuki Hase, 
Japan 
6-4 Noisy Image Segmentation Based on a Level Set 
Evolution 
Khaled Issa and Hiroshi Nagahashi, Japan 
 
Break (10:20 ï£§ 10:40) 
 
Session 7: Multimedia (10:40 ï£§ 12:00) 
Chairs: Massimo De Gregorio and Shuji Senda 
7-1 Patch Based Localization of Visual Object Class 
Instances 
Alexandra Teynor and Hans Burkhardt, Germany 
7-2 Correction of Geometric and Photometric Distor-
tion of Document Images Using a Stereo Camera 
System 
Yusuke Suzuki, Atsushi Yamashita and Toru Kaneko, 
Japan 
7-3 A Local Keypoint Matching Technique for Transi-
tion Detection 
Chun-Rong Huang, Huai-Ping Lee and Chu-Song Chen, 
Taiwan 
7-4 New Image Encryption Method Based on ICA 
Ayman Alfalou and Ali Mansour, France 
 
Lunch (12:00 ï£§ 13:00) 
 
Session 8: Poster Session 2 (13:00 ï£§ 14:30) 
8-1 View-invariant Human Action Recognition Based on 
Factorization and HMMs 
Xi Li and Kazuhiro Fukui, Japan 
8-2 Gesture Recognition Using Temporal Templates 
with Disparity Information 
Kazunori Onoguchi and Masaaki Sato, Japan 
8-3 Vision-based UAV Navigation in Mountain Area 
Jihwan Woo, Kilho Son, Teng Li, Gwansung Kim and In 
So Kweon, Korea 
8-4 Identifying Hand Gesture Images by Using Genetic 
Algorithms 
Tetsuji Kobayashi and Norifumi Machida, Japan 
8-5 Enhanced Blood Vessels in Laparoscopy by Using 
Narrow-Band Imaging 
Hamed Akbari, Yukio Kosugi, Kazuyuki Kojima, 
Toshiaki Ohya, Hideki Akamatsu and Naofumi Tanaka, 
Japan 
8-6 An Iris Image Quality Assessment Method Based on 
Laplacian of Gaussian Operation 
Jing Wan, Xiaofu He and Pengfei Shi, China 
8-7 Calculation of Bedding Angles Inclination from Drill 
Core Digital Images 
Thomas Quiniou, Nazha Selmaoui, Christine 
Laporte-Magoni and Michel Allenbach, New Caledonia 
8-8 An Effective Watermark Embedding Algorithm for 
High JPEG Compression 
Hui-Yu Huang, Chi-Hung Fan and Wen-Hsing Hsu, 
Taiwan 
Friday, May 18, 2007 
 
Session 11: Industrial Applications (9:00 ï£§ 10:20) 
Chairs: Naoufel Werghi and Akio Nakamura 
11-1 Goniometric Imaging of Paper Gloss 
Tomi Kauppi, Albert Sadovnikov, Lasse Lensu, 
Joni-Kristian KÃ¤mÃ¤rÃ¤inen, Pertti Silfsten and Heikki 
KÃ¤lviÃ¤inen, Finland 
11-2 One Fish, Two Fish, Butterfish, Trumpeter: Recog-
nizing Fish in Underwater Video 
Andrew Rova, Greg Mori and Lawrence M. Dill, 
Canada 
11-3 Machine Vision Based Lumber Grain Measurement 
Matti Niskanen and Olli Silven, Finland 
11-4 Geometrical and Statistical Visual Inspection of 
Imprinted Tablets 
Marko Bukovec, Ziga Spiclin, Franjo Pernus and 
Bostjan Likar, Slovenia 
 
Break (10:20 ï£§ 10:40) 
 
Session 12: Medical Image Analysis & Biometrics 
(10:40 ï£§ 12:00) 
Chairs: AurÃ©lio Campilho and Yasuyo Kita 
12-1 An Unsupervised Learning Approach Based on 
Hopfield-like Network for Assessing Posterior Cap-
sule Opacification 
Naoufel Werghi, Rachid Sammouda and Fatma AlKirbi, 
UAE 
12-2 Microscopic Image Segmentation with 
Two-dimensional Exponential Entropy Based on 
Hybrid Microcanonical Annealing 
Amir Nakib, Hamouche Oulhadj and Patrick Siarry, 
France 
12-3 Fingerprint Verification Using Perturbation Method 
Satoshi Otaka, Yoshihisa Nishiyama, Takahiro Hatano 
and Toru Wakahara, Japan 
12-4 Automatic Cell Image Segmentation Using a 
Shape-Classification Model 
Shishir Shah, USA 
 
Lunch (12:00 ï£§ 13:00) 
 
Session 13: Poster Session 3 (13:00 ï£§ 14:30) 
13-1 Evaluation of Stereo Matching Systems for Real 
World Applications Using Structured Light for 
Ground Truth Estimation 
Martin Humenberger, Daniel Hartermann and Wilfried 
Kubinger, Austria 
13-2 Stabilizing Illumination Chromaticity Estimation 
Using the Illumination Line Segment 
Rei Kawakami and Katsushi Ikeuchi, Japan 
13-3 Probabilistically Semantic Labeling of IR Image for 
UAV 
Teng Li, Jihwan Woo and In So Kweon, Korea 
13-4 Shadow Elimination in Traffic Video Segmentation 
Hong Liu, Jintao Li, Qun Liu and Yueliang Qian, China 
13-5 3D Precise Inspection of Electronic Devices by Sin-
gle Stereo Vision 
Takashi Watanabe, Akira Kusano, Takayuki Fujiwara 
and Hiroyasu Koshimizu, Japan 
13-6 Facial Expression Recognition by SVM-based 
Two-stage Classifier on Gabor Features 
Fan Chen and Kazunori Kotani, Japan 
13-7 Vehicle Orientation Detection Using Vehicle Color 
and Normalized Cut Clustering 
Jui-Chen Wu, Jun-Wei Hsieh, Yung-Sheng Chen and 
Cheng-Min Tu, Taiwan 
13-8 Human Tracking Based on Particle Filter in Out-
door Scene 
Mototsugu Muroi and Heitoh Zen, Japan 
13-9 Extracting Object Regions Using Locally Estimated 
Probability Density Functions 
Hidenori Takeshima, Takashi Ida and Toshimitsu 
Kaneko, Japan 
13-10  A Three Resolution Framework for Reliable Road 
Obstacle Detection Using Stereovision 
Mathias Perrollaz, Raphael Labayrade, Romain Gallen 
and Didier Aubert, France 
13-11 Human Body Region Extraction from Photos 
Yi Hu, Japan 
13-12 A Fast Surface-Based Visual Hull Reconstruction 
Sofiane Yous and Masatsugu Kidode, Japan 
13-13 Automatic Detection of Anatomical Structures in 
Digital Fundus Retinal Images 
Anantha Vidya Sagar, S. Balasubramanian and V. 
Chandrasekaran, India 
13-14 Illumination-robust Change Detection Using Tex-
ture Based Features 
Kentaro Yokoi, Japan 
13-15 Feature Extraction from Biological Motion of Hu-
man Gait Patterns for Emotion Discrimination 
Hidenori Maruta and Masahiro Ishii, Japan 
13-16 Robust Real Time Multi-Layer Foreground Seg-
mentation 
Simon Denman, Vinod Chandran and Sridha Sridharan, 
Australia 
13-17 Tumor Detection Based on Spatial and Inter-Slice 
Analyses for MRI Breast Imaging 
Guo-Shiang Lin, Sin-Kuo Daniel Chai, Wei-Cheng Yeh 
and Lin-Jie Cheng, Taiwan 
13-18 Appearance Manifold with Embedded Covariance 
Matrix for Robust 3D Object Recognition 
Lina, Tomokazu Takahashi, Ichiro Ide and Hiroshi 
Murase, Japan 
13-19 A Robust Coarse-to-Fine Method for Pupil Local-
ization in Non-ideal Eye Images 
Xiaoyan Yuan and Pengfei Shi, China 
13-20 Facial Caricaturing Robot COOPER Exhibited at 
EXPO2005 and Its Improvements 
Naoya Tokuda, Takayuki Hoshino, Takashi Watanabe, 
Takuma Funahashi, Takayuki Fujiwara and Hiroyasu 
Koshimizu, Japan 
13-21 Extraction of Corresponding Points from Stereo 
Images by Using Intersections of Segments 
Hiroshi Unno, Keikichi Hayashibe and Hitoshi Saji, 
Japan 
13-22 Rat Mammary Gland Analysis in T1 Weighted MR 
Images 
Bin Wang, Jianhua Xuan, Matthew T. Freedman, Peter 
G. Shields and Yue Wang, USA 
13-23 A Lawn Weed Detection in Winter Season Based on 
Color Information 
Ukrit Watchareeruetai, Yoshinori Takeuchi, Tetsuya 
Matsumoto, Hiroaki Kudo and Noboru Ohnishi, Japan  
13-24 A Novel Approach of 3D Face Reconstruction Using 
Ellipse Fitting 
Charoenpong Theekapun, Hiroyuki Hase and Shogo 
Tokai, Japan 
13-25 A Facial Sketch Animation Generator for Mobile 
Communication 
Yuehu Liu, Yuanqi Su, Yang Yang, Fengjuan Wang, 
Maojun Yuan and Zhen Ren, China 
13-26 Lane Detection and Tracking through Affine Recti-
fication 
Qiang He and Chee-Hung Henry Chu, USA 
13-27 Statistical Background Subtraction Based on the 
Exact Per-pixel Distributions 
Youngbae Hwang, Hanbyul Joo, Jun-Sik Kim and In-So 
Kweon, Korea 
13-28 Periodic Pattern Inspection Using Convolution 
Masks 
Y. S. Weng and M. H. Perng, Taiwan 
