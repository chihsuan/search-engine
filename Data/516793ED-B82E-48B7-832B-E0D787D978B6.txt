 1 
è¡Œ æ”¿ é™¢ åœ‹ å®¶ ç§‘ å­¸ å§” å“¡ æœƒ å°ˆ é¡Œ ç ” ç©¶ è¨ˆ ç•« æˆ æœ å ± å‘Š 
ä»¥è¦–è¦ºç‚ºåŸºç¤ä¹‹å…¨å¤©å€™è»Šè¼›åµæ¸¬ç³»çµ±è¨­è¨ˆåŠå¯¦ç¾ 
Vision-Based All-Weather Preceding Vehicle Detection System 
è¨ˆåŠƒç·¨è™Ÿï¼šNSC 98-2221-E-167-018  
åŸ·è¡ŒæœŸé–“ï¼š98å¹´ 08æœˆ 01 æ—¥è‡³ 99å¹´ 10æœˆ 31æ—¥ 
è¨ˆ ç•« ä¸»æŒäººï¼šéƒ­è‹±å“² åœ‹ï§·å‹¤ç›Šç§‘æŠ€å¤§å­¸é›»æ©Ÿç³» E-MAIL: kuoyc@ncut.edu.tw 
 
ä¸€ã€ä¸­æ–‡æ‘˜è¦ 
æœ¬è¨ˆç•«æ‰€æå‡ºçš„å…¨æ—¥è»Šè¼›å½±åƒåµæ¸¬ç³»çµ±
ä¸»è¦æ‡‰ç”¨åœ¨å…ˆé€²é§•é§›è€…è¼”åŠ©ç³»çµ±(Advanced 
Driver Assistance Systems, ADAS)åŠŸèƒ½ä¸­çš„å‰
æ–¹è»Šè¼›è¿½æ’é è­¦(Forward Collision Warning, 
FCW)ã€‚è€ƒé‡äº†è»Šå…§çš„ç©ºé–“ã€æ”œå¸¶æ€§ä»¥åŠå•†å“
åŒ–çš„å¯è¡Œæ€§ï¼Œä½¿ç”¨ INTEL XScale PXA270 
SOC-Based åµŒå…¥å¼é–‹ç™¼å¹³å°å¯¦ä½œæ­¤ç³»çµ±ã€‚æ‰€
ä½¿ç”¨åˆ°çš„ç¡¬é«”å‘¨é‚Šè¨­å‚™åŒ…å«(1) USB ç¶²è·¯æ”å½±
æ©Ÿï¼šå½±åƒæ“·å–è¨­å‚™ï¼›(2)è§¸æ§å¼è¢å¹•ï¼šä½¿ç”¨è€…
æ“ä½œèˆ‡é¡¯ç¤ºä¹‹ä»‹é¢ï¼›(3)éŸ³æºè¼¸å‡ºç”¨å–‡å­ï¼šèª
éŸ³è­¦å‘Šä¹‹è¼¸å‡ºè¨­å‚™ã€‚æ‰€ä½¿ç”¨ä¹‹è»Ÿé«”åŒ…å«
Embedded Linux 2.6.15.3 ä½œæ¥­ç³»çµ±ã€ç¶²è·¯æ”å½±
æ©Ÿ çš„ è®€ å– èˆ‡ æ§ åˆ¶ ç”¨ ä¹‹ Video for Linux 
Two(V4L2)å‡½å¼åº«ã€è§¸æ§å¼è¢å¹•ä½¿ç”¨è€…åœ–å‹ä»‹
é¢è¨­è¨ˆç”¨ä¹‹ MiniGUI çš„å‡½å¼åº«ã€èªéŸ³æ’­æ”¾ç”¨
ä¹‹ madplay æ‡‰ç”¨ç¨‹å¼ã€‚ 
æœ¬è¨ˆç•«å®Œæˆä¹‹é …ç›®åŒ…å«ä»¥å¯æ‹“ç†è«–ç‚ºåŸº
ç¤çš„æ—¥é–“èˆ‡å¤œé–“è»Šè¼›åµæ¸¬æ¼”ç®—æ³•çš„ä½¿ç”¨é¸æ“‡ã€
æ—¥é–“èˆ‡å¤œé–“çš„å‰æ–¹è»Šè¼›åµæ¸¬ã€è¿½è¹¤ã€è·é›¢ä¼°
æ¸¬ã€è»Šé“ç·šåµæ¸¬ã€å±éšªæƒ…æ³æ™‚çš„èªéŸ³è­¦ç¤ºèˆ‡
å½±åƒè³‡è¨Šè¨˜éŒ„ã€‚å…¶ä¸­ï¼Œå½±åƒè³‡è¨Šè¨˜éŒ„è£¡é™¤äº†
å½±åƒä¹‹å¤–ï¼Œä¹Ÿä½¿ç”¨æ–‡å­—è¨˜è¼‰äº†ç•¶æ™‚çš„æ™‚é–“ã€
æ—¥æœŸèˆ‡è»Šè¼›ä¹‹é–“çš„è·é›¢ï¼Œä»¥åˆ©ä¸å¹¸ç™¼ç”Ÿäº‹æ•…
æ™‚çš„èª¿æŸ¥èˆ‡è²¬ä»»æ­¸å±¬çš„é‡æ¸…ã€‚ 
æœ¬è¨ˆç•«æ‰€æå‡ºçš„ç³»çµ±ä¸»è¦å¯¦éš›æ¸¬è©´æ–¼é«˜
é€Ÿå…¬è·¯ä¸Šï¼Œå‰æ–¹èˆ‡æ—å´è»Šé“ä¹‹è»Šè¼›çš†èƒ½æˆåŠŸ
çš„åµæ¸¬ã€æ¨™å®šè»Šè¼›åœ¨å½±åƒä¸­çš„ä½ç½®ä»¥åŠæ¸¬å¾—
è»Šè¼›ä¹‹é–“çš„ç›¸å°è·é›¢ã€‚æ¸¬è·çš„ç¯„åœç‚ºäº”è‡³ä¸‰
åå…¬å°ºã€‚ç”±å¯¦æ¸¬çµæœï¼Œæœ¬ç³»çµ±åœ¨æ—¥é–“èˆ‡å¤œé–“
ä¸­ï¼ŒåŒè»Šé“è»Šè¼›è¾¨è­˜ç‡é” 96%ä»¥ä¸Šï¼Œæ—å´è»Š
é“è»Šè¼›å‰‡é” 92%ä»¥ä¸Šã€‚æ—¥é–“æƒ…æ³ä¸‹èƒ½æ’é™¤åœ°
é¢æ¨™ç¤ºæ–‡å­—ã€æ©‹æ¨‘æ¥ç¸«ã€é«˜æ¶æ©‹é™°å½±èˆ‡è¡Œé“
æ¨¹é™°å½±ç­‰å¹²æ“¾ã€‚å¤œé–“æƒ…æ³ä¸­ï¼Œèƒ½æ’é™¤è·¯ç‡ˆã€
åå…‰è™ŸèªŒã€äº¤é€šç‡ˆçš„å¹²æ“¾åŠæ˜æš—åº¦ä¸å‡ç­‰æƒ…
æ³ï¼Œä¸¦åœ¨å„ç¨®ç…§åº¦ä¸‹æ­£å¸¸çš„åµæ¸¬ã€è¿½è¹¤è»Šè¼›ã€‚ 
 
é—œéµè©ï¼šå…ˆé€²é§•é§›è€…è¼”åŠ©ç³»çµ±ã€é›»è…¦è¦–è¦ºã€
è»Šè¼›åµæ¸¬ã€è»Šé“åµæ¸¬ã€åµŒå…¥å¼ç³»çµ±ã€‚ 
è‹±æ–‡æ‘˜è¦ 
The proposed All-Weather vehicle 
detection system is used in Forward Collision 
Warning (FCW) of Advanced Driver Assistance 
Systems (ADAS), it is achieved by image 
processing algorithm based on computer vision 
technologies. The space of car, portability, and 
commercialization are decisive considerations 
when implementing the system. So, we use the 
embedded hardware platform instead of the 
personal computer (PC) though it has good 
abilities of computing and immediacy. 
In hardware, we use Intel XScale PXA270 
SOC-based platform. The peripheral devices 
include: (1) USB Web Camera: the image 
capture device, (2) tough screen TFT-LCD 
display: graphic user interfaces and image 
display, (3) speaker: the speech warning output 
device. The software of the system contain 
Embedded Linux 2.6.15.3 operating system, 
Video for Linux Two open source code for 
driving Web Camera, the MiniGUI open source 
code that is utilized to design GUI in touch 
screen, and madplay open source code for 
processing voice signal.  
The functions of the vehicle detection 
algorithm include lane detection, vehicle 
detection, vehicle tracking, distance estimation, 
audio warning, and image information record. 
Audio alter and image record will be acted 
when the distance between preceding vehicle 
and the test car is inside the safe range. 
Moreover, the record of image also includes 
text information of time, date and vehicle 
distance, and stored in non-volatile storage 
device for the investigation of accident.  
In this work, the proposed system mainly 
tested on the highway, the preceding and 
passing vehicle are able to be detected 
correctly and the effective distance estimation 
 3 
çš„æ–¹æ³•æ˜¯ä»¥ PC å¯¦ç¾ï¼Œå› æ­¤è¼ƒç„¡è€ƒé‡åˆ°ç¡¬é«”è³‡
æºé™åˆ¶çš„å•é¡Œã€‚å…¶ä¸­ï¼Œå°ç¨±æ€§é‹ç®—æ–¹æ³•ä½¿ç”¨
Rã€Gã€B ä¸‰ç°éšåº¦å…±åŒè¨ˆç®—ï¼Œåœ¨åµŒå…¥å¼ç³»çµ±
ä¸­å°‡è€—è²»è¨±å¤šé‹ç®—çš„æ™‚é–“ã€‚åœ¨æœ¬ç ”ç©¶ä¸­ï¼Œåš
è©´ä»¥ç°éšå€¼é‹ç®—å–ä»£ RGB é‹ç®—ï¼Œä¹Ÿèƒ½å¾—åˆ°ä¸
éŒ¯æ•ˆæœã€‚ 
æ–‡ç»[5]ä¸­æå‡ºäº†ä»¥å…‰æµç‚ºåŸºç¤çš„æ–¹æ³•åµ
æ¸¬å‰æ–¹è»Šè¼›ã€‚åœ¨æ–‡ç»ä¸­æå‡ºäº†å¤šç¨®å…‰æµçš„è¨ˆ
ç®—æ–¹æ³•ï¼Œå…¶ä¸­ä»¥èª¤å·®å¹³æ–¹åŠ ç¸½æ³• (Sum of 
Squared Differences, SSD)æœ€ç‚ºå¸¸è¦‹ï¼Œä¸»è¦è¨ˆç®—
å­å½±åƒå€åŸŸä¸­çš„å€¼ï¼Œä¸¦æ‰¾å‡ºè©²å€åŸŸä¸­ SSD çš„
æœ€å°å€¼ï¼Œå°‡å…©å¼µå½±åƒä¹‹é–“çš„ä½ç§»ä½¿ç”¨å‘é‡è¡¨
ç¤ºï¼Œè©²å‘é‡å³ç‚ºå…©å¼µå½±åƒä¹‹å…‰æµã€‚åœ¨å‹•æ…‹å½±
åƒä¸­å…‰æµä½ç§»çš„å¤§å°ï¼ŒèƒŒæ™¯çš„è®ŠåŒ–å°æ–¼è»Šè¼›
çªç„¶å‡ºç¾çš„è®ŠåŒ–ç¨‹åº¦ï¼Œåˆ©ç”¨æ­¤ç‰¹æ€§åˆ†æå…‰æµ
ä¹‹ä½ç§»æ‰¾å‡ºè»Šè¼›çš„æ¦‚ç•¥ä½ç½®ã€‚é‹ç”¨å…‰æµæ³•æ–¹
å¼æ‰¾å‡ºå‰æ–¹è»Šè¼›èƒ½å¤ ä¸€åŒè¨ˆç®—å‡ºè»Šè¼›ä¹‹é–“çš„
ç›¸å°é€Ÿåº¦ï¼Œå°é§•é§›è€…è€Œè¨€ç²å¾—æ­¤è³‡è¨Šï¼Œåœ¨é¿
å…äº‹æ•…çš„ç™¼ç”Ÿä¸­ç„¡éæ˜¯å¤šå¢åŠ äº†ä¸€é …åƒè€ƒçš„
æŒ‡æ¨™ã€‚ä½†è¦è¨ˆç®—æ•´å¼µå½±åƒçš„å…‰æµå ´ï¼Œåœ¨åµŒå…¥
å¼ç³»çµ±ä¸­åŒæ¨£çš„æœƒé™·å…¥æœ‰é™ç¡¬é«”è³‡æºçš„è€ƒé©—
ä¸”æŠ—é›œè¨Šèƒ½åŠ›è¼ƒå·®ï¼Œåœ¨å®‰å…¨é˜²è­·çš„ç³»çµ±ä¸­ï¼Œ
æ‡‰ç”¨å…‰æµæ³•åµæ¸¬è»Šè¼›ä¹‹æº–ç¢ºåº¦ä»æ˜¯æœ‰å¾…æ”¹é€²
ä¹‹è™•ã€‚ 
åŸºæ–¼ä¸Šè¿°å¯è¡Œæ–¹æ³•åˆ†æï¼Œæœ¬è¨ˆç•«æå‡ºæ—¥
é–“è»Šè¼›åµæ¸¬æ¼”ç®—æ³•(å¦‚åœ–ä¸€)ï¼Œä¸»è¦åˆ†æˆåµæ¸¬ã€
è¿½è¹¤è»Šè¼›å…©å€‹éƒ¨ä»½ã€‚åœ¨æœå°‹æ¨¡å¼ä¸­ï¼Œæœ¬è¨ˆç•«
åˆ©ç”¨è»Šè¼›åº•éƒ¨é‚Šç·£çš„ç‰¹å¾µ(è»Šè¼›è…³å°)æ‰¾å°‹è»Š
è¼›ï¼Œå°‡åµæ¸¬çš„ç¨‹åºåˆ†ç‚º(1)ç¸®å°æœå°‹å€åŸŸèˆ‡å‰
è™•ç†ï¼Œä¸»è¦æ˜¯ç‚ºäº†è®“æ¼”ç®—æ³•èƒ½åœ¨ç¡¬é«”è³‡æºæœ‰
é™çš„åµŒå…¥å¼ç³»çµ±ä¸­æ›´æœ‰æ•ˆç‡çš„åŸ·è¡Œã€‚(2)å‰æ™¯
æ“·å–ï¼Œåˆ†é›¢å‰æ™¯èˆ‡èƒŒæ™¯å–å‡ºè»Šè¼›è¼ªå»“ã€è»Šé“
æ¨™ç¤ºç·šç­‰å½±åƒã€‚(3)è·¯é¢é›œè¨Šæ¿¾é™¤ï¼ŒæŠŠå‰æ™¯ä¸­
çš„ä¸éœ€è¦çš„é›œè¨Šç§»é™¤(ä¾‹ï¼šè»Šé“æ¨™ç¤ºç·š)ï¼Œç•™ä¸‹
è»Šè¼›åº•éƒ¨é‚Šç·£çš„å½±åƒã€‚(4)æ¨™ç¤ºè»Šè¼›è…³å°ï¼Œåˆ©
ç”¨è»Šé“ç·šåµæ¸¬å€åˆ†å‡ºå‰æ–¹è»Šè¼›è…³å°æ‰€åœ¨çš„è»Š
é“ï¼Œä¸¦ä½¿ç”¨æŠ•å½±åˆ†ææ¨™ç¤ºè…³å°ä½ç½®ã€‚(5)è»Šè¼›
è…³å°é©—è­‰ï¼Œåˆ©ç”¨è»Šè¼›å·¦å³å°ç¨±çš„ç‰¹æ€§å°è»Šè¼›
å€åŸŸçš„å½±åƒé€²è¡Œé©—è­‰ã€‚å¦‚é©—è­‰æˆåŠŸï¼Œå†ä½¿ç”¨
ä¸€é‚Šç•Œç›’å°‡è»Šè¼›å½±åƒæ¡†èµ·ã€‚ä¸é›£ç™¼ç¾åµæ¸¬æ¨¡
å¼çš„å¤šç¨‹åºå½±åƒè™•ç†æœƒè€—è²»è¨±å¤šç³»çµ±é‹ç®—é‡ï¼Œ
å› æ­¤åœ¨è»Šè¼›åµæ¸¬ç¢ºèªå¾Œï¼Œç³»çµ±å°‡æ”¹ä»¥è¿½è¹¤æ¨¡
å¼ç¹¼çºŒæ¨™ç¤ºè»Šè¼›ä½ç½®ï¼Œè—‰ä»¥é™ä½æ•´é«”é‹ç®—é‡ã€‚
å…¶è™•ç†ç¨‹åºè©³ç´°èªªæ˜å¦‚ä¸‹: 
A.1 ç¸®å°æœå°‹å€åŸŸèˆ‡å‰è™•ç† 
ç‚ºäº†æ¸›å°‘ç³»çµ±é‹ç®—é‡ä¸¦æå‡è»Šè¼›æœå°‹çš„
æ•ˆç‡ï¼Œåœ¨æœå°‹è»Šè¼›ä¹‹å‰æœ¬ç ”ç©¶å…ˆè¡Œå®šç¾©å½±åƒ
ä¸­çš„æ„Ÿèˆˆè¶£å€åŸŸ(Region of Interest, ROI)ï¼Œç¸®
å°æœå°‹è»Šè¼›çš„å€åŸŸã€‚æœ¬è«–æ–‡ç”¨è¼¸å…¥å½±åƒä¸­çš„
åœ°å¹³ç·šä½œç‚º ROI ä¹‹ä¸Šé‚Šç•Œï¼Œåœ°å¹³ç·šä»¥ä¸Šå€åŸŸ
ç‚ºå¤©ç©ºä¹Ÿæ˜¯éé“è·¯ä¹‹å€åŸŸï¼Œè»Šè¼›ä¸¦ä¸æœƒå‡ºç¾
æ–¼æ­¤è™•ã€‚ä¸‹é‚Šç•Œå‰‡å®šç¾©åœ¨å‰æ–¹ç´„äº”å…¬å°ºä¹‹è™•ï¼Œ
é™¤äº†å¡è»Šç­‰æƒ…æ³ï¼Œå‰æ–¹è»Šè¼›åœ¨æ­£å¸¸è¡Œé§›ç‹€æ³
ä¸‹ä¸¦ä¸æœƒå‡ºç¾åœ¨æ­¤å€åŸŸã€‚ 
 
 
   åœ–ä¸€ã€æ—¥é–“è»Šè¼›åµæ¸¬æ¼”ç®—æ³•åŸ·è¡Œä¹‹ç¨‹åº 
 
ç”±æ–¼è¼¸å…¥å½±åƒç‚º RGB è‰²å½©ç©ºé–“æ˜“å—å…‰æºå½±éŸ¿ï¼Œ
å› æ­¤æœ¬ç ”ç©¶å°‡ ROI è£¡ RGB å½±åƒè½‰æ›è‡³YCrCb
è‰²å½©ç©ºé–“[6]é™ä½å°å…‰æºçš„æ•æ„Ÿåº¦ï¼Œä¸¦ä½¿ç”¨
Y(äº®åº¦)è‰²ç³»ç©ºé–“é€²è¡Œä¹‹å¾Œçš„å½±åƒè™•ç†ç¨‹åºï¼Œ
æ¸›å°‘å½±åƒç¶­åº¦çš„è¨ˆç®—ï¼Œç¯€çœç³»çµ±ä¹‹é‹ç®—é‡ã€‚ 
A.2 å‰æ™¯æ“·å– 
åœ¨é€™ä¸€æ­¥é©Ÿè£¡ä½¿ç”¨ Sobel [6]é‚Šç·£åµæ¸¬å¼·
åŒ–ç°éšå½±åƒä¸­ç‰©ä»¶çš„è¼ªå»“ï¼Œä¸¦è—‰ç”± Otsuâ€™s 
Threshold Selection Method[7]å°‡ç‰©ä»¶è¼ªå»“èˆ‡
èƒŒæ™¯åˆ†é›¢ï¼Œå–å‡ºå‰æ™¯ç‰©ä»¶ã€‚ä¸€é–‹å§‹ä½¿ç”¨ Sobel
é‚Šç·£åµæ¸¬å¼·åŒ–æ°´å¹³èˆ‡å‚ç›´ç´‹ç†ã€‚å¼(1)ä¸­ f ç‚º
ä¸€å€‹å¤§å°ç‚º M Ã— N çš„å½±åƒï¼Œg(x,y)ç‚ºé‚Šç·£é‹
ç®—çš„è¼¸å‡ºå½±åƒï¼Œw(s,t)æ˜¯ä¸€å¤§å° m Ã— n ä¹‹æ¿¾æ³¢
å™¨é®ç½©ï¼Œå…¶å…§å®¹ç‚ºåƒç´ æ¬Šé‡å€¼ã€‚é®ç½©(Mask)
ä¸­å¿ƒä½ç½®éš¨è‘— x èˆ‡ y ç§»å‹•ï¼Œé®ç½©å…§åƒç´ ä¹‹ç´¢
å¼•ä½ç½®å‰‡ç”± s èˆ‡ t æ”¹è®Šï¼Œå…¶ä¸­ a=(m-1)/2ã€
b=(n-1)/2ã€‚x=0,1,2,â€¦,M-1ã€y=0,1,2,â€¦N-1ï¼Œé®
ç½©ä¸­ m èˆ‡ n ä¹‹å¤§å°éœ€ç›¸åŒä¸”ç‚ºå¥‡æ•¸ï¼Œèƒ½æ¥å—
çš„æœ€å°æ•¸å€¼ç‚º 3ã€‚åœ–äºŒç‚º Sobel çš„æ°´å¹³èˆ‡å‚ç›´
æ¿¾æ³¢é®ç½©æ¬Šé‡åˆ†é…ã€‚ 
 5 
è¼›å½±åƒä¹‹å°ç¨±è»¸æ˜¯å¦åœ¨å·²æ¨™ç¤ºå€åŸŸä¸­å¿ƒï¼Œå¦‚
æœå°ç¨±è»¸çš„åç§»é‡åœ¨é è¨­å€åŸŸç¯„åœ(Sth)å…§ï¼Œå‰‡
æ­¤å€åŸŸå½±åƒå‰‡å±¬è»Šè¼›å½±åƒã€‚æœ¬ç ”ç©¶å°‡æ–‡ç»[8]
çš„ RGBå°ç¨±æ€§é‹ç®—å¼ä¿®æ”¹æˆå¼(3)ä¹‹å°ç¨±è»¸é‹
ç®—ï¼Œåªè¨ˆç®—YCrCbä¸­çš„ Yï¼Œä»¥é™ä½ç³»çµ±ä¹‹é‹ç®—
é‡ã€‚ 
 
ğ‘† ğ‘— =     ğ‘ ğ‘— + âˆ†ğ‘¥, ğ‘– âˆ’ ğ‘ ğ‘— âˆ’ âˆ†ğ‘¥, ğ‘–  
ğ‘‰ğ‘…+âˆ†ğ‘˜
ğ‘—=ğ‘‰ğ¿âˆ’âˆ†ğ‘˜
ğ‘Š
2
âˆ†ğ‘¥=1
ğ‘‰ğ‘‡
ğ‘–=ğ‘‰ğµ
 
                                                                                                (3) 
ğ½ğ‘ ğ‘¦ğ‘š = ğ‘šğ‘–ğ‘› ğ‘† ğ‘— ğ‘ğ‘›ğ‘‘ ğ‘† ğ‘—  <  ğ‘†ğ‘¡ğ‘•  
 
å…¶ä¸­ï¼ŒVTç‚ºè»Šè¼›ä¸Šé‚Šç•Œï¼Œæ˜¯ç”±è»Šåº•å¾€ä¸Š
æ¨ç®—é›¶é»å…«å€æ‰€æ±‚å¾—ï¼Œ VBç‚ºè»Šè¼›åº•é‚Šç•Œï¼ŒVLç‚º
è»Šè¼›å·¦é‚Šç•Œï¼ŒVRç‚ºè»Šè¼›å³é‚Šç•Œï¼Œé€™ä¸‰å€‹é‚Šç•Œ
åœ¨ 3.43 ç¯€ä¸­å°±å·²å¾—çŸ¥ã€‚W ç‚ºè»Šè¼›å¯¬åº¦ï¼Œç”±å·¦
å³é‚Šç•Œç›¸æ¸›æ±‚å¾—ã€‚âˆ†xç‚ºè¨ˆç®—ç”¨åç§»é‡ï¼Œå…¶è¨ˆ
ç®—åç§»ç¯„åœåœ¨ 1 è‡³ W/2ã€‚j èˆ‡ i åˆ†åˆ¥ç‚º X è»¸èˆ‡
Y è»¸ä¹‹ç´¢å¼•å€¼ï¼Œâˆ†kç‚º j å¾€å·¦å³æ–¹å‘çš„æ“´å±•å€¼ã€‚ 
åœ–å››ç‚ºç¶“éå°ç¨±é‹ç®—å¾Œé¡¯ç¤ºå°ç¨±ä¸­å¿ƒçš„
çµæœï¼Œåœ¨ç¢ºèªå°ç¨±è»¸ä½æ–¼è»Šè¼›å½±åƒä¹‹ä¸­å¿ƒå€
åŸŸå¾Œï¼Œç”¨æ·±è—è‰²çš„é‚Šç•Œç›’(Bounding Box)å°‡è»Š
è¼›é‚Šç•Œæ¨™ç¤ºã€‚ 
 
 
åœ–å››ã€è»Šè¼›å½±åƒå°ç¨±è»¸èˆ‡é‚Šç•Œç›’ 
 
A.5 è»Šè¼›è¿½è¹¤ç¨‹åº 
åœ¨è»Šè¼›æ­£ç¢ºåµæ¸¬å¾Œï¼Œç‚ºé™ä½é‹ç®—é‡ï¼Œä½¿
ç”¨å…‰æµæ³•(Optical Flow)[5]èˆ‡çµ•å°å€¼å¹³å‡èª¤å·®
æ³•(Mean Absolute Error, MAE)å¯¦ç¾è»Šè¼›è¿½è¹¤
ä¹‹æ–¹æ³•ã€‚é€éåµæ¸¬å°ç¯„åœå½±åƒå€åŸŸä¹‹è®ŠåŒ–é‡ï¼Œ
èª¿æ•´è»Šè¼›é‚Šç•Œç›’çš„å¯¬èˆ‡é«˜ï¼Œè—‰ç”±æ­¤æ–¹æ³•é™ä½
ç³»çµ±æ•´é«”é‹ç®—é‡ã€‚ 
 
B. å¤œé–“è»Šè¼›åµæ¸¬æ¼”ç®—æ³• 
æˆ‘å€‘è§€å¯Ÿåœ¨å¤œé–“æƒ…æ³ä¸‹çš„å½±åƒä¸­ï¼Œç™¼ç¾
è¨±å¤šåœ¨æ—¥é–“æƒ…æ³ä¸‹å¯è¦‹çš„è»Šè¼›ç‰¹å¾µéƒ½å› å‘¨åœ
çš„ç…§åº¦ä¸è¶³è€Œæ¶ˆå¤±ï¼Œåƒæ˜¯è»Šè¼›é™°å½±èˆ‡ç›´è§’ç‰¹
å¾µç­‰ï¼Œå› æ­¤ç„¡æ³•ä½¿ç”¨æ—¥é–“è»Šè¼›åµæ¸¬æ–¹æ³•æœå°‹
å‰æ–¹è»Šè¼›ã€‚åœ¨å¤œé–“è»Šè¼›åµæ¸¬ä¸­ï¼Œä¸»è¦çš„å·¥ä½œ
æ˜¯åœ¨æ˜æš—çš„ç’°å¢ƒèˆ‡å‹•æ…‹å½±åƒä¸­åµæ¸¬å‡ºå‰æ–¹è»Š
è¼›ã€‚ä»¥ä¸‹å°‡è©³ç´°çš„ä»‹ç´¹å¤œé–“ç’°å¢ƒä¸­è»Šè¼›åµæ¸¬
ä¹‹ç¨‹åº(å¦‚åœ–äº”)ã€‚ 
 
  åœ–äº”ã€å¤œé–“è»Šè¼›åµæ¸¬æ¼”ç®—æ³•åŸ·è¡Œä¹‹ç¨‹åº 
 
    å¤œé–“è»Šè¼›åµæ¸¬ç”±å…­å¤§æ­¥é©Ÿæ‰€çµ„æˆï¼Œåˆ†åˆ¥
æ˜¯ï¼š(1)æ„Ÿèˆˆè¶£å€åŸŸçš„å®šç¾©èˆ‡è‰²å½©ç©ºé–“ä¹‹è½‰æ›ï¼Œ
ä¸»è¦æ˜¯ç‚ºäº†é™ä½ç³»çµ±é‹ç®—é‡èˆ‡æ¸›å°‘ä¸å¿…è¦çš„
æœå°‹å‹•ä½œã€‚(2)äº®é»ç‰©ä»¶çš„æ“·å–ï¼ŒæŠŠå¯èƒ½ç‚ºè»Š
å°¾ç‡ˆç‰¹å¾µçš„å½±åƒç‰©ä»¶æ“·å–ï¼Œåˆ†é›¢å‰æ™¯èˆ‡èƒŒæ™¯ã€‚
(3)ç§»é™¤é›œè¨Šèˆ‡å¼·åŒ–ç‰¹å¾µï¼ŒæŠŠå¼·åº¦ä¸è¶³ä¹‹äº®é»
ç‰©ä»¶ç§»é™¤ï¼Œä¸¦å¼·åŒ–å…¶é¤˜çš„äº®é»ç‰©ä»¶ï¼Œä½¿å…¶ç‰¹
å¾µæ›´æ˜“æ–¼åµæ¸¬ã€‚(4)äº®é»ç‰©ä»¶è³‡è¨Šè™•ç†ï¼Œå°‡å„
å€‹äº®é»ç‰©ä»¶å½±åƒè½‰æ›æˆç¨ï§·å½±åƒç‰©ä»¶ï¼Œä¸¦è¨ˆ
ç®—æ¯ä¸€å€‹è¢«åˆ†å‰²äº®é»ç‰©ä»¶çš„ç›¸é—œè³‡è¨Š(å¦‚å¯¬ã€
é«˜ç­‰)ã€‚(5)æ¡†é¸è»Šè¼›è»Šå°¾ç‡ˆï¼Œå…ˆåˆ†å‡ºä¸åŒè»Šé“
çš„è»Šè¼›è»Šå°¾ç‡ˆï¼Œä¸¦å°‡å„å€‹è»Šé“çš„è»Šè¼›è»Šå°¾ç‡ˆ
é€²è¡Œé…å°ï¼Œæ‰¾å‡ºè»Šè¼›æˆå°çš„è»Šå°¾ç‡ˆã€‚(6)é©—è­‰
è»Šè¼›å½±åƒï¼Œåˆ©ç”¨å‰ä¸€å¼µå½±åƒèˆ‡ä¸‹ä¸€å¼µå½±åƒé…
å°çš„çµæœé€²è¡Œæ¯”å°ï¼Œå¦‚æ¯”å°æˆåŠŸå‰‡å°‡æ­¤ä¸€é…
å°çµæœä¿ç•™ï¼Œå®Œæˆé©—è­‰ã€‚ 
B.1 æ„Ÿèˆˆè¶£å€åŸŸçš„å®šç¾©èˆ‡è‰²å½©ç©ºé–“ä¹‹è½‰æ› 
    å¦‚åŒæ—¥é–“åµæ¸¬æ¼”ç®—æ³•ï¼Œå®šç¾©ä¸€å€‹æ„Ÿèˆˆè¶£
å€åŸŸ(Region of interest, ROI)å…¶ç¯„åœèˆ‡æ—¥é–“åµ
æ¸¬æ–¹å¼ç›¸åŒã€‚å¦‚æ­¤å¯ä»¥éš”é›¢è¨±å¤šå¹²æ“¾å› ç´ (å¦‚
è·¯ç‡ˆã€äº¤é€šè™ŸèªŒç­‰)ï¼Œæ¸›å°‘æœå°‹çš„ç¯„åœï¼Œå¢åŠ 
æ¼”ç®—æ³•åŸ·è¡Œçš„æ•ˆç‡ã€‚åœ¨å¤œé–“æ™‚ï¼Œæˆ‘å€‘å¯ä»¥ç™¼
 7 
è¿´å¼æ–¹æ³•å¯¦ç¾æ­¤æ¼”ç®—æ³•ï¼Œåœ–ä¸ƒç‚ºå½±åƒç¶“ç”±ç›¸
é„°å…ƒç´ ç·¨è™Ÿæ³•åˆ†å‰²æˆå„å€‹ç¨ï§·ä¹‹äº®é»ç‰©ä»¶ï¼Œ
ä¸¦ä¸”ç”¨ä¸åŒé¡è‰²ä»£è¡¨å„å€‹äº®é»ç‰©ä»¶ä¹‹ç·¨è™Ÿã€‚ 
 
åœ–ä¸ƒã€äº®é»ç‰©ä»¶åˆ†å‰²ä¹‹çµæœ 
 
C. å¯æ‹“æ—¥å¤œé–“è¾¨è­˜æ–¹æ³•é¸æ“‡ 
æœ¬ç ”ç©¶ä½¿ç”¨å¯æ‹“ç†è«–[8][9]é€²è¡Œæ—¥é–“èˆ‡
å¤œé–“å¤©è‰²çš„è¾¨è­˜ï¼Œåˆ©ç”¨å½±åƒä¸­å¤©ç©ºèˆ‡é“è·¯çš„
äº®åº¦ç°éšå€¼ä½œç‚ºç‰¹å¾µä¾†å€åˆ†æ—¥é–“èˆ‡å¤œé–“ä¹‹æƒ…
æ³ï¼Œå…¶ä¸­åŠ å…¥é“è·¯çš„äº®åº¦ç°éšå€¼ç‰¹å¾µï¼Œå¢åŠ 
å–æ¨£çš„æ•¸ç›®ï¼Œèƒ½å¢åŠ è¾¨è­˜çš„æº–ç¢ºåº¦ã€‚æœ¬æ–‡å°
å¤©ç©ºèˆ‡é“è·¯å€åŸŸå–å¹³å‡ç°éšå€¼é€²è¡Œå–æ¨£ä¾†å»º
ï§·ç‰©å…ƒï¼Œåœ–å…«ç‚ºå¤©ç©ºèˆ‡é“è·¯å€åŸŸçš„å¹³å‡ç°éš
å€¼å–æ¨£çš„ç¯„åœï¼Œè—‰ç”±ç¸®å°å–æ¨£ç¯„åœå¯ä»¥é™ä½
é‹ç®—é‡ï¼Œå–å¹³å‡å€¼èƒ½é™ä½é«˜é »çš„é›œè¨Šå¹²æ“¾(å¦‚ï¼š
å¤œæ™šçš„è·¯ç‡ˆè™ŸèªŒã€æ—¥é–“çš„çƒé›²æˆ–é å±±ç­‰)ã€‚ 
 
   
(a)                (b) 
åœ–å…«ã€å¤©ç©ºèˆ‡é“è·¯äº®åº¦ç°éšå€¼çš„å–æ¨£å€åŸŸ (a)
å¤œé–“ (b)æ—¥é–“       
 
æ¥è‘—ä»‹ç´¹å¯æ‹“æ—¥å¤œé–“è­˜åˆ¥çš„æ­¥é©Ÿèˆ‡ç¨‹
åºï¼š 
Step 1: å»ºï§·æ—¥é–“èˆ‡å¤œé–“æƒ…æ³ä¸‹äº®åº¦ç°éšå€¼
çš„ç¶“å…¸åŸŸèˆ‡ç¯€åŸŸç¯„åœï¼Œå¦‚å¼(5)è‡³å¼ 8)ï¼Œå…¶ä¸­R0
å…§çš„V0ç‚ºç¶“å…¸åŸŸä¹‹ç¯„åœï¼ŒRpå…§çš„Vpç‚ºç¯€åŸŸä¹‹
ç¯„åœã€‚æœ¬æ–‡å„è‡ªçµ±è¨ˆä¸€è¬ç­†å½±åƒä¸­å¤©ç©ºèˆ‡é“
è·¯å€åŸŸçš„å¹³å‡ç°éšå€¼ä¸¦è¨ˆç®—å…¶è®Šç•°é‡ï¼Œå¦‚åœ–
ä¹èˆ‡åï¼Œè—‰ç”±é€™äº›çµ±è¨ˆæ•¸æ“šè³‡æ–™å®šç¾©å‡ºç¶“å…¸
åŸŸä¹‹ç¯„åœï¼Œç¯€åŸŸçš„é¸å®šæ˜¯æ ¹æ“šå„å€‹ç¶“å…¸åŸŸä¹‹
ä¸Šä¸‹é™è€Œå®šï¼Œå…¶é¸å®šç¯„åœåƒ…æœƒå½±éŸ¿é—œè¯å‡½æ•¸
å¯æ‹“åŸŸä¹‹ç¯„åœã€‚é™¤æ­¤ä¹‹å¤–ï¼Œæˆ‘å€‘åŠ å…¥äº†é“è·¯
èˆ‡å¤©ç©ºç°éšå€¼ç›¸åŠ çš„ç‰¹å¾µï¼Œè®“æ±ºç­–æ™‚æœ‰å¦ä¸€
å€‹å¯åƒè€ƒä¹‹å› ç´ ã€‚ 
 
åœ–ä¹ã€æ—¥é–“èˆ‡å¤œé–“å¤©ç©ºç°éšå€¼çµ±è¨ˆçµæœ 
 
åœ–åã€æ—¥é–“èˆ‡å¤œé–“é“è·¯ç°éšå€¼çµ±è¨ˆçµæœ 
 
ğ‘…0 =  ğ‘ƒï¼Œğ¶ï¼Œğ‘‰0 
=  
ğ‘ğ‘–ğ‘”ğ‘•ğ‘¡ğ‘¡ğ‘–ğ‘šğ‘’ ğ‘†ğ‘˜ğ‘¦ < 60, 100 >
ğ‘…ğ‘œğ‘ğ‘‘ < 40, 80 >
ğ‘†ğ‘˜ğ‘¦_&_ğ‘…ğ‘œğ‘ğ‘‘ < 35, 175 >
       (5) 
ğ‘…ğ‘ƒ =  ğ‘ƒï¼Œğ¶ï¼Œğ‘‰ğ‘ƒ 
=  
ğ‘ğ‘–ğ‘”ğ‘•ğ‘¡ğ‘¡ğ‘–ğ‘šğ‘’ ğ‘†ğ‘˜ğ‘¦ < 0, 120 >
ğ‘…ğ‘œğ‘ğ‘‘ < 0, 120 >
ğ‘†ğ‘˜ğ‘¦_&_ğ‘…ğ‘œğ‘ğ‘‘ < 0, 190 >
         (6) 
ğ‘…0 =  ğ‘ƒï¼Œğ¶ï¼Œğ‘‰0 
=  
ğ·ğ‘ğ‘¦ğ‘¡ğ‘–ğ‘šğ‘’ ğ‘†ğ‘˜ğ‘¦ < 110, 235 >
ğ‘…ğ‘œğ‘ğ‘‘ < 85, 200 >
ğ‘†ğ‘˜ğ‘¦_&_ğ‘…ğ‘œğ‘ğ‘‘ < 180, 300 >
       (7) 
ğ‘…ğ‘ =  ğ‘ƒï¼Œğ¶ï¼Œğ‘‰ğ‘ƒ 
=  
ğ·ğ‘ğ‘¦ğ‘¡ğ‘–ğ‘šğ‘’ ğ‘†ğ‘˜ğ‘¦ < 100, 255 >
ğ‘…ğ‘œğ‘ğ‘‘ < 70, 255 >
ğ‘†ğ‘˜ğ‘¦_&_ğ‘…ğ‘œğ‘ğ‘‘ < 170, 350 >
       (8) 
 9 
 
åœ–åäºŒã€æ—¥é–“è»Šè¼›åµæ¸¬ 
 
 
åœ–åä¸‰ã€å¤œé–“è»Šè¼›åµæ¸¬ 
 
å››ã€æˆæœè‡ªè©• 
æœ¬è¨ˆç•«å·²å®Œæˆæ—¥å¤œé–“è»Šè¼›åµæ¸¬å½±åƒè¾¨è­˜æ¼”ç®—
æ³•ï¼Œä¸¦å¯¦ä½œæ–¼åµŒå…¥å¼ç³»çµ±ï¼Œå…¶æˆæœåƒåŠ æ•™è‚²
éƒ¨ä¸»è¾¦ã€Œ98å¹´åº¦å¾®é›»è…¦è…¦æ‡‰ç”¨ç³»çµ±è¨­è¨ˆè£½ä½œ
ç«¶è³½ã€ï¼Œç²å¾—è¨Šè™Ÿè™•ç†èˆ‡é€šè¨Šç ”ç©¶æ‰€çµ„ã€ä½³ä½œã€ï¼Œ
åƒåŠ æ•™è‚²éƒ¨ SOCè¯ç›Ÿä¸»è¾¦ã€Œ2010å…¨åœ‹å¤§å­¸æ ¡
é™¢åµŒå…¥å¼ç³»çµ±å‰µæ„æ‡‰ç”¨çµ„ã€ï¼Œç²å¾—ã€è¨­è¨ˆå®Œæ•´
çã€ã€‚ä¸¦ä»¥â€œVision-based Vehicle Detection in 
the Nighttimeâ€ æŠ• ç¨¿ æ–¼ 2010 å¹´ ä¹‹ IEEE 
International Symposium on Computer, 
Communication, Control and Automation åœ‹éš›
ç ”è¨æœƒ (å·²åˆŠç™» )åŠä»¥â€ Vision-based vehicle 
detection for a driver assistance system â€œæŠ•ç¨¿
æ–¼ Elsevier æœŸåˆŠ Journal of Computers and 
Mathematics with Applications(å·²æ¥å—)ã€‚ 
 
åƒè€ƒæ–‡ç» 
[1] TRI æ‹“å¢£ç”¢æ¥­ç ”ç©¶æ‰€, â€œæ™ºæ…§å‹è»Šè¼›å¼•çˆ†è»Šç”¨é›»
å­æ–°ç™¼å±•,â€ TRI ç”¢æ¥­å°ˆé¡Œå ±å‘Š-132, Dec. 2008. 
[2] å°ç£äº¤é€šéƒ¨çµ±è¨ˆè™•, â€œè‡ºç£åœ°å€é«˜é€Ÿå…¬è·¯äº¤é€šäº‹
æ•… æ¦‚ æ³ çµ± è¨ˆ ,â€ from 
www.motc.gov.tw/mocwebGIP/wSite/public/Attac
hment/f1199704440845.doc ,2006. 
[3] M. Y. Chern and B. Y. Shyr, â€œLocating nearby 
vehicles on highway at daytime based on the front 
vision of a moving car,â€ in Proc. IEEE Conf. on 
Robotics and Automation, pp.2085-2090, Sep. 
2003. 
[4] H. Y. Chang, C. M. Fu, and C. L. Huang, 
â€œReal-time vision-based preceding vehicle tracking 
and recognition,â€ in Proc. IEEE Intâ€™l Conf. on 
Intelligent Vehicles Symposium, pp. 514-519, 2005. 
[5] A. Giachetti, M. Campani, and V. Torre, â€œThe Use 
of Optical Flow for Road Navigation,â€ IEEE Trans. 
on Robotics and Automation, vol. 14, no. 1, pp. 
34-48, 1998. 
[6] R. C. Gonzalez and R. E. Woods, Digital Image 
Processing, Prentice-Hall, Inc., 2002. 
[7] N. Otsu, â€œA Threshold Selection Method from 
Gray-Level Histograms,â€ IEEE Trans. on Systems, 
Man, and Cybernetics, vol. SMC-9, no.1, pp. 
62-66, Jan. 1979. 
[8] D. Ye, Y. Q. Yu, and B. Zenq, â€œResearch 
of Classification Based on Extenics,â€ in 
Proc. IEEE Intâ€™l Conf. on Computational 
Intelligence and Multimedia Applications, 
pp. 129-132, 2007. 
[9] ç‹å­Ÿè¼ã€æ—åºšè³¢ï¼Œ2006ï¼Œâ€œåˆ©ç”¨å¯æ‹“é¡ç¥ç¶“ç¶²è·¯
ç¬¬ä¸€å‹ä¾†ä½œæ±½è»Šæ’æ°£æ±¡æŸ“é™æ¸¬æ””æª¢ä¹‹å·¥å…·ï¼Œç¬¬ä¸€
å±†æ™ºæ…§ç”Ÿæ´»ç§‘æŠ€ç ”è¨æœƒï¼ŒNo.ICS-R14ï¼Œå°ä¸­ï¼Œæ°‘
åœ‹ä¹åäº”å¹´å…­æœˆã€‚ 
 
 
åƒåŠ æ¼”è¬›è€… M.S. EL NASCHIE(IEEE fellow)ä¹‹ keynote speechã€‚
éš¨å¾ŒåƒåŠ  session: computer & Mathematics with Applications
é€²è¡Œè«–æ–‡ç™¼è¡¨(è«–æ–‡å¦‚é™„ä»¶)ã€‚27æ—¥å‰‡åƒåŠ å…¶ä»–è­°ç¨‹åŠåƒè§€æ±è¯å¤§
å­¸ã€‚28æ—¥çµæŸç ”è¨æœƒè¡Œç¨‹ã€‚ 
äºŒã€èˆ‡æœƒå¿ƒå¾— 
   èˆ‡æœƒå­¸è€…åŠæ¥­ç•ŒåƒåŠ äººæ•¸çœ¾å¤šï¼Œä¸¦ä¸”æœ‰åŠæ•¸ä¾†è‡ªä¸–ç•Œå„åœ°ï¼Œ
å¯è¦‹æ­¤ç ”è¨æœƒé›–åƒ…èˆ‰è¾¦è‡³ç¬¬ä¸‰å¹´ï¼Œä½†å·²å—åˆ°ä¸–ç•Œå„åœ°ç ”ç©¶äººå“¡é‡
è¦–ã€‚Keynote speakerç‚º M.S. EL NASCHIEï¼Œè¬›é¡Œ â€œApplication of 
chaos and fractals in fundamental physics and set 
theoretical resolution of the two-slit experiment and the 
wave collapseâ€å—ç›Šè‰¯å¤šã€‚åƒåŠ å…©å¤©ç ”è¨æœƒç™¼è¡¨ä¹‹è«–æ–‡å¤šé” 150
ç¯‡ï¼Œé™¤ç­è§£ç›®å‰ä¸–ç•Œç”¢å­¸ç•Œæˆæœå¤–ï¼Œäº¦åƒè¨ªä¸»è¾¦å­¸æ ¡æ±è¯å¤§å­¸ï¼Œ
è¿‘å¹´ä¾†å¤§é™¸ä¸»è¾¦åœ‹éš›ç ”è¨æœƒï¼Œè®“åœ¨åœ°æ•™å¸«åŠå­¸ç”Ÿèƒ½æœ‰æ©Ÿæœƒåƒèˆ‡åœ‹
éš›ç ”è¨æœƒï¼Œä¸å¤±ç‚ºåŸ¹é¤Šæ•™å¸«åŠå­¸ç”Ÿåœ‹éš›è§€çš„å¥½æ–¹æ³•ï¼Œä¹Ÿæå‡å­¸æ ¡
çŸ¥ååº¦ã€‚ 
ä¸‰ã€è€ƒå¯Ÿåƒè§€æ´»å‹•(ç„¡æ˜¯é …æ´»å‹•è€…ç•¥) 
å››ã€å»ºè­° 
äº”ã€æ”œå›è³‡æ–™åç¨±åŠå…§å®¹ 
  æ”œå›ç ”è¨æœƒ precedingåŠä¸Šæµ·å¸‚æ±è¯å¤§å­¸ä»‹ç´¹ã€‚ 
recording will be activated if the distance is nearer than the safe range. A statistic of 
100 video road images are tested in our experiments, the nature of vehicles includes 
sedan, minivan, truck, and bus. The experimental results show that the proportion of 
correct identifications of proceeding vehicles is above 95.8% testing on highways in 
the daytime. Experimental results also indicate that the system correctly identifies 
vehicles in real time.  
Keywords: Advance driver assistance systems (ADAS), Vehicle detection, Optical 
flow. 
 
1. Introduction 
Advanced driver assistance systems (ADAS) have received considerable 
attentions in recent decade, because many car accidents caused mainly of driversâ€™ 
unawareness or fatigue. To warn the driver of any dangers that may lie ahead on the 
road is important to improve traffic safety and accident prevention. So a major 
function of ADAS is the detection of vehicles in front of our own one by using 
computer vision technologies since the cost of an optical sensor (such as CMOS and 
CCD) is much lower than an active sensor (such as laser or radar). Furthermore, 
optical sensors can be used in a wider range of applications, such as the lane departure 
warning systems and event video recorders.  
Various vehicle detection approaches have been reported in the computer vision 
While implementing the vehicle detection system, the space of car and the cost of 
hardware platform are the decisive considerations. Our work is to propose a refined 
vehicle detection algorithm to make it can be implemented in a cost-effective 
embedded platform. The vehicle detection algorithm includes road area finding, 
features of vehicle extraction, and vehicle verification. A tracking process dedicated in 
the detected vehicle region of image based on optical flow is also applied for reducing 
the complexity of computing. Furthermore, for the estimation of distance, a preceding 
vehicle range finding method based on a geometric perspective has also been 
presented. Voice alert and image recording will be activated if the distance is nearer 
than the safe range. 
2. Vehicle detection algorithm 
In our work, a CMOS camera is mounted interiorly on the windshield of a test 
car and the optical axis is parallel to the road surface. The camera captures the RGB 
color road environment image forward. For the considerations of the realization in an 
embedded system with limited hardware resources, the procedures of our proposed 
refined vehicle detection algorithm are shown in Fig. 1 and mentioned as follows. 
Firstly, the region of interest (ROI) area, the region vehicles possibly appear in the 
image, is defined. The left and right boundaries of ROI are the left and right 
boundaries of the captured image. The top of ROI is the horizon line in the image. The 
applied subsequently to intensify the binary road image. Finally, the land marks and 
interferences can be removed using the binary edge-detected image and the binary 
road image in a subtraction operation, yielding image with no lane marks (NLM), as 
presented in Fig. 2 (b). 
2.2. Range of the lane 
An area in image bound by lane marks is called road area image (RAI) where 
vehicles possibly appear. To verify the RAI area, the lane marks need to be detected in 
advance. In most images, lane marks are at 45 degrees to appear. Therefore, Sobel 
edge filters with Â±45 degree gradients in vertical are applied. Once the lane marks are 
enhanced by edge filters, the procedures of lane marks detection are described as 
follows. 
1)  The start point of this detection is at the center in horizontal direction and Yb 
(the bottom of ROI) in vertical direction. 
2) From the start point toward both sides in horizontal direction, find the first 
bright pixels in both sides. 
3) Once the first bright pixels are found both in left and right sides, recording 
the positions of the found pixels.  
4) If the bright pixel cannot be found while the horizontal position has already 
surmounted last position that found in the last finding, using one pixel inward 
VB. Then, the vehicle image block is found with the boundaries. The width of the 
vehicle image block is W=|VR-VL|. The height of the vehicle image block is set as 
H=0.8W. 
2.4. Footprint verification 
In Sec. 2.3, the footprint image may include wet spots, seam of a bridge, and 
shadows of passing vehicles. Therefore, a rule that determines whether these 
footprints are associated with vehicles is required. In this step, the symmetry operation 
is applied to verify the footprints. The symmetry equation is modified [9] using Eq. 
(1). Our approach is to find the most symmetric axis by minimizing the symmetry 
measure S(j) with the symmetry axis at x=j within the vehicle image block. 
th
j
H
SjSandjS ï€¼ï€½
ï€«ï€½
ï€«
ï€½ ï€½
ï€«
ï€½
)(min)(minargj
(1)                                                                  | i)  x,Î” - p(j  -  i)  x,Î”  p(j |           S(j)
sym
V
V  i
2W / 
1 x Î”
k Î”  V
kÎ” -V  j
âˆ‘ âˆ‘ âˆ‘
B
B
R
L
 
p(j, i) denotes the component in vehicle image block. VB, VL and VR are the 
bottom, left and right position of boundaries of the vehicle image block, respectively. 
W and H represent the width and height of the vehicle image block. Finally, the 
vehicle image block can be identified as a vehicle if the minimum symmetry measure 
is less than a certain threshold Sth. The value of Sth depends on the location of vehicle 
at different longitudinal distance in the image.  
the parameters of the camera are utilized to estimate the longitudinal distance to the 
preceding vehicle. We apply the estimation model presented in [13][14] to estimate 
the distance between the preceding vehicle and the test car from the captured image. A 
3D scene point (Xi, Yi, Zi) in the camera coordinate system captured by the camera is 
projected onto the pixel (ui, vi) on the 2D image coordinate as shown in Fig.3. Eq. (3) 
shows the projective phenomenon relation. f is the focal length of the camera. Sv is the 
scaling factor of height (the ratio of the physical height and the image pixel). Su is the 
scaling factor of width (the ratio of the physical width and the image pixel). We set the 
cameraâ€™s optical axis parallel to the road surface at a height H above the ground and 
assume a planar road surface. The underneath of the vehicle on the road at a distance 
Zi in front of the camera will project to the image at a height vi.  Then the distance Zi 
can be estimated by Eq. (4). 
)3(,
c
cv
i
c
cu
i
Z
YSf
v
Z
XSf
u ï€½ï€½  
)4(
i
v
i
v
HSf
Z ï€½  
4. Experimental results 
The proposed system was implemented on the INTEL XScale PXA270 
SoC-based (520MHz system clock, 32MB Flash ROM, and 64MB SDRAM) 
embedded hardware platform with a few peripheral devices (e.g., TFT-LCD touch 
screen, Ethernet, AC-97, USB etc.). A CMOS camera connected to the hardware 
resources. The proposed system is successfully implemented on a test car and tested 
on highway No. 1 in Taiwan, and its effectiveness is verified. The system also 
provides distance information for the further function of Adaptive Cruise Control. 
Moreover, voice alerts and image recording will be activated if the distance is nearer 
than the safe range. We hope the proposed system is useful for building the ADAS. 
For further studies, more environmental factors (e.g. presence of strong shadow, under 
harsh weather, the lighting conditions depend on the time of the day, and artificial 
illumination etc.) must be considered to optimize system performance and make the 
system more robust. 
Acknowledgement 
The present work is supported by National Science Council of Taiwan under Grant 
NSC-98-2221-E-167-018. 
References 
[1]  S.S. Huang, C.J. Chen, P.Y. Hsiao., L.C. Fu, On-board vision system for lane 
recognition and front-vehicle detection to enhance driver's awareness, IEEE Intâ€™l 
conf. on Robotics and Automation 3 (2004) 2456 - 2461. 
[2]  Z. Sun, G. Bebis, R. Miller, On-road vehicle detection using Gabor filters and 
support vector machines, IEEE Intâ€™l Conf. on Digital Signal Processing 2 (2002) 
1019-1022. 
[10]  R.C. Gonzalez, R.E. Woods, Digital image processing, Prentice-Hall , 2002. 
[11]  N. Otsu, A threshold selection method from gray-level histograms, IEEE Trans. 
on Systems, Man, and Cybernetics,  SMC-9, (1) (1979) 62 - 66. 
[12]  A. Singh, Optical flow computation: a unified perspective, IEEE Computer 
Society Press, (1992). 
[13]  G. P. Stein, O. Mano and A. Shashua: Vision-based ACC with a Single Camera: 
bounds on range and range rate accuracy, Proc. IEEE Intâ€™l Conf. on Intelligent 
Vehicles Symposium, (2003) 120-125. 
[14]  B.F. Wu, C.J. Chen, C.C. Kao, C.W. Chang, S.T. Chiu, Embedded weather 
adaptive lane and vehicle detection system, IEEE Intâ€™l Symposium on Industrial 
Electronics (2008) 1255-1260. 
 
Fig. 1. Processing flow of vehicle detection. 
ç„¡è¡ç”Ÿç ”ç™¼æˆæœæ¨å»£è³‡æ–™
å…¶ä»–æˆæœ 
(ç„¡æ³•ä»¥ï¥¾åŒ–è¡¨é”ä¹‹æˆ
æœå¦‚è¾¦ï§¤å­¸è¡“æ´»å‹•ã€ç²
å¾—çé …ã€é‡è¦åœ‹éš›åˆ
ä½œã€ç ”ç©¶æˆæœåœ‹éš›å½±éŸ¿
ï¦ŠåŠå…¶ä»–å”åŠ©ç”¢æ¥­æŠ€
è¡“ç™¼å±•ä¹‹å…·é«”æ•ˆï¨—äº‹
é …ç­‰ï¼Œè«‹ä»¥æ–‡å­—æ•˜è¿°å¡«
ï¦œã€‚) 
ç ”ç©¶æˆæœç²å¾—ä»¥ä¸‹å…¨åœ‹æ€§ç«¶è³½çé …: 
(1)ä»¥ã€Œå…¨æ—¥ï¤‚è¼›å½±åƒåµæ¸¬ç³»çµ±ã€ï¥«åŠ æ•™è‚²éƒ¨ä¸»è¾¦ 98 ï¦ï¨ã€Œå…¨åœ‹å¾®é›»è…¦æ‡‰ç”¨ç³»
çµ±è¨­è¨ˆè£½ä½œç«¶è³½ã€è¨Šè™Ÿè™•ï§¤èˆ‡é€šè¨Šç ”ç©¶æ‰€çµ„ã€ä½³ä½œã€ã€‚ 
(2)ä»¥ã€Œå…¨æ—¥ï¤‚è¼›å½±åƒåµæ¸¬ç³»çµ±ã€ï¥«åŠ æ•™è‚²éƒ¨ä¸»è¾¦ 98 ï¦ï¨ã€Œå…¨åœ‹å¾®é›»è…¦æ‡‰ç”¨ç³»
çµ±è¨­è¨ˆè£½ä½œç«¶è³½ã€è¨Šè™Ÿè™•ï§¤èˆ‡é€šè¨Šå¤§å­¸çµ„ã€ç¬¬ä¸‰åã€ã€‚ 
(3)ä»¥ã€Œå¤šåŠŸèƒ½é§•é§›è€…è¼”åŠ©ç³»çµ±ã€ï¥«åŠ æ•™è‚²éƒ¨ SoC ï¦—ç›Ÿä¸»è¾¦ã€Œ2010 å…¨åœ‹å¤§å­¸æ ¡
é™¢åµŒå…¥å¼ç³»çµ±è¨­è¨ˆç«¶è³½ã€å‰µæ„æ‡‰ç”¨çµ„ã€è¨­è¨ˆå®Œæ•´çã€ã€‚ 
 
 æˆæœé …ç›® ï¥¾åŒ– åç¨±æˆ–å…§å®¹æ€§è³ªç°¡è¿° 
æ¸¬é©—å·¥å…·(å«è³ªæ€§èˆ‡ï¥¾æ€§) 0  
èª²ç¨‹/æ¨¡çµ„ 0  
é›»è…¦åŠç¶²ï¤·ç³»çµ±æˆ–å·¥å…· 0  
æ•™æ 0  
èˆ‰è¾¦ä¹‹æ´»å‹•/ç«¶è³½ 0  
ç ”è¨æœƒ/å·¥ä½œåŠ 0  
é›»å­å ±ã€ç¶²ç«™ 0  
ç§‘ 
æ•™ 
è™• 
è¨ˆ 
ç•« 
åŠ  
å¡« 
é … 
ç›® è¨ˆç•«æˆæœæ¨å»£ä¹‹ï¥«èˆ‡ï¼ˆé–±è½ï¼‰äººï¥© 0  
