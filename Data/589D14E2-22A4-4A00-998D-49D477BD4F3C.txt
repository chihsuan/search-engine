appearance model. Experimental results demonstrate 
the robustness and accurate tracking results with 
challenging sequences. Besides, the proposed method 
outperforms other methods during intersection of 
similar color and objectï¼‡s partial occlusion. 
 
è‹±æ–‡é—œéµè©ï¼š Particle filter, SURF feature, Object tracking 
 
 2 
è¡Œæ”¿é™¢åœ‹å®¶ç§‘å­¸å§”å“¡æœƒå°ˆé¡Œç ”ç©¶è¨ˆç•«æˆæœå ±å‘Š 
äººå‹è¿½è¹¤èˆ‡èº«ä»½è­˜åˆ¥ç³»çµ±ä¹‹ç ”è£½ 
Development of the Human Tracking and Identity Recognition System 
 
è¨ˆç•«ç·¨è™Ÿï¼šNSC 99-2221-E-259 -020 -MY3 
åŸ·è¡ŒæœŸé™ï¼š99 å¹´ 08 æœˆ 01 æ—¥è‡³ 102 å¹´ 10 æœˆ 31 æ—¥ 
ä¸»æŒäººï¼šæ—ä¿¡é‹’åœ‹ç«‹æ±è¯å¤§å­¸è³‡è¨Šå·¥ç¨‹ç³» 
è¨ˆç•«åƒèˆ‡äººå“¡ï¼šé™³æ·³æ¾ æ—å¿—è»’ å³æ˜“å„’ ç‹é¼æ© 
æ—å˜‰è² è”£ç‘œå©· èŠæ™ºå ¯ 
 
æ‘˜è¦ 
è¿‘å¹¾å¹´ä¾†ï¼Œéš¨è‘—æ™ºæ…§å‹å®‰å…¨ç›£æ§ã€ç”Ÿç‰©èªè­‰ã€
é–€ç¦ç®¡ç†ç­‰å½±åƒè¡Œç‚ºåˆ†æå•é¡Œå—åˆ°é‡è¦–ï¼Œç‰©ä»¶è¿½
è¹¤é€™é …ç ”ç©¶è­°é¡Œä¹Ÿæ„ˆä¾†æ„ˆç†±é–€ã€‚ä½†åœ¨ç‰©ä»¶è¿½è¹¤çš„
å•é¡Œä¸Šï¼Œä»å—åˆ°å¹¾å€‹è®ŠåŒ–å› ç´ é™åˆ¶ï¼šå…‰ç·šè®ŠåŒ–ã€
å§¿å‹¢è®ŠåŒ–ã€èƒŒæ™¯è¤‡é›œã€é®è”½ä»¥åŠç›¸ä¼¼çš„é¡è‰²ç­‰å…·
æŒ‘æˆ°æ€§çš„å•é¡Œã€‚å› æ­¤è¿‘å¹´ä¾†æå‡ºçš„ç‰©ä»¶è¿½è¹¤æ–¹æ³•
ç›®æ¨™éƒ½åœ¨æ–¼å¦‚ä½•å…‹æœé€™äº›å› ç´ æ‰€å¸¶ä¾†çš„å¹²æ“¾ã€‚ 
æœ¬è¨ˆç•«çš„ä¸»è¦ç›®çš„æ˜¯å¸Œæœ›çµåˆç²’å­æ¿¾æ³¢å™¨
å’Œ Speeded Up Robust Features çš„æ–¹æ³•è§£æ±ºéƒ¨åˆ†
ç’°å¢ƒè®ŠåŒ–å› ç´ å°ç‰©ä»¶è¿½è¹¤é€ æˆçš„å¹²æ“¾ã€‚é€™å€‹æ–¹æ³•
ä¸åªç”¨äº†å‚³çµ±çš„é¡è‰²è³‡è¨Šä¹Ÿåˆ©ç”¨äº† SURF ç‰¹å¾µï¼Œ
ç”±æ–¼ SURF ç‰¹å¾µå°æ–¼å…‰ç·šè®ŠåŒ–ã€ç¸®æ”¾ä»¥åŠæ—‹è½‰ä¸
è®Šæ€§ï¼Œä½¿å¾—æˆ‘å€‘æ–¹æ³•çš„è¿½è¹¤æ•ˆæœæ›´åŠ å¼·å¥ã€‚æˆ‘å€‘
é‡å°æ¯ä¸€å€‹ç²’å­éƒ½è€ƒæ…®äº†ç©ºé–“ã€è‰²å½©ä»¥åŠ SURF 
ç‰¹å¾µï¼Œä¼°æ¸¬äº†æ¯ä¸€å€‹ç²’å­å’Œè¿½è¹¤ç‰©ä»¶ä¹‹ç‰¹å¾µçš„ç›¸
ä¼¼ç¨‹åº¦ï¼Œå› æ­¤æˆ‘å€‘çš„æ–¹æ³•è¼ƒå‚³çµ±åªè€ƒæ…®é¡è‰²è³‡è¨Š
çš„æ–¹æ³•æ›´åŠ å¼·å¥ã€‚å¯¦é©—çµæœä¹Ÿè­‰æ˜äº†æˆ‘å€‘çš„æ–¹æ³•
åœ¨å…·æœ‰æŒ‘æˆ°æ€§çš„å½±ç‰‡ä¸­è¡¨ç¾çš„ä¸éŒ¯ï¼Œé™¤æ­¤ä¹‹å¤–ï¼Œ
å’Œå…¶ä»–ç¯‡æ–¹æ³•ç›¸æ¯”ï¼Œæˆ‘å€‘çš„æ–¹æ³•åœ¨ç™¼ç”Ÿäº†éƒ¨åˆ†é®
è”½ã€å’Œè¿½è¹¤ç‰©ä»¶ä½æ–¼é¡è‰²ç›¸ä¼¼åº¦å¾ˆé«˜çš„æƒ…æ³ä¸‹ä¹Ÿ
å…·æœ‰ç«¶çˆ­åŠ›ã€‚ 
 
é—œéµè©ï¼šç²’å­æ¿¾æ³¢å™¨ã€SURFã€ç‰©ä»¶è¿½è¹¤ 
 
Abstractï¼  In recent years, object tracking is 
important in many applications in computer vision, 
e.g. intelligent surveillance system, identity 
recognition, security access control and so on. This 
topic has received much attention in the recent 
decade. Although the topic of object tracking has 
been well studied in computer vision, it still 
remains challenge in varying illumination condition, 
noise influence, scene change, clutter background, 
occlusion, and similar color. Therefore, how to 
develop a robust method for object tracking is 
seriously essential. 
The main purpose of this search is to propose 
a novel object tracking method based on particle 
filter and SURF feature. The proposed method uses 
both color feature and SURF feature. The SURF 
feature makes the tracking result more robust. On 
the other hand, particle selection can lead to time 
saving. In addition, we also consider the matched 
particle applicable to calculating SURF weight. 
Owing to the color, spatial, and SURF features 
being adopted, this method is more robust than 
traditional color-based appearance model. 
 4 
å¦ä¸€ç¨®æ–¹å¼ç‚ºå›ºå®šå¼é¡é ­çš„æ‹æ”ï¼Œæ­¤ç¨®æ–¹æ³•
åœ¨æŸç¨®ç¨‹åº¦ä¸Šå¯è¦–ç‚ºæ˜¯å›ºå®šå€åŸŸã€‚æ”å½±æ©Ÿæ“·å–å‡º
ä¾†çš„å³æ™‚å½±åƒåºåˆ—ï¼Œæœ€æ™®éçš„æ–¹æ³•æ˜¯å’Œå·²çŸ¥çš„åƒ
è€ƒèƒŒæ™¯åšå‰æ™¯åˆ†å‰²(Foreground Subtraction)é‹ç®—ï¼Œ
ç¶“éè™•ç†å¾Œï¼Œä¾¿å¯æ‰¾å‡ºå½±åƒä¸­å¯èƒ½çš„ç›®æ¨™ç‰©ï¼›åœ¨
[4]æ–¹æ³•ä¸­ï¼Œé€éçµåˆé¡è‰²ã€ç§»å‹•åŠç‰¹å¾µè³‡è¨Šä¾†æ¸¬
é‡ç‰©ä»¶çš„ç›¸ä¼¼åº¦ï¼Œç›®çš„æ˜¯ä½¿å¾—ç‰©ä»¶è¿½è¹¤æ›´ç©©å®šï¼Œ
ä¸¦èƒ½é™ä½é®è”½æ™‚çš„è¿½è¹¤å¤±èª¤ã€‚é›–ç„¶èƒŒæ™¯ç›¸æ¸›çš„è¿½
è¹¤æ¼”ç®—æ³•å…·æœ‰ç°¡å–®èˆ‡åŸ·è¡Œå¿«é€Ÿçš„å„ªé»ï¼Œå»ä¹Ÿé€ æˆ
å¯¦ç”¨ä¸Šçš„é™åˆ¶ã€‚å‰æ™¯åˆ†å‰²é›–å·²ç ”ç©¶å¤šå¹´ï¼Œä½†ä»æœ‰
è¨±å¤šå›°é›£è¦å…‹æœï¼Œå¦‚å³æ™‚æ€§éœ€æ±‚ã€èƒŒæ™¯çš„å¹²æ“¾(é¡
é ­æ™ƒå‹•ã€å…‰ç·šè®ŠåŒ–ç­‰)ã€èƒŒæ™¯ç‰©é«”æ“¾å‹•ã€è¿½è¹¤ç‰©
ä»¶çš„é¡è‰²èˆ‡èƒŒæ™¯ç›¸ä¼¼ã€é®è”½ç­‰ï¼Œéƒ½æœƒå½±éŸ¿è¿½è¹¤çµ
æœä¹‹æ­£ç¢ºæ€§ã€‚æœ‰é‘‘æ–¼å‰æ™¯åˆ†å‰²æŠ€è¡“çš„ç¼ºé™·ï¼Œç¾æœ‰
è¿½è¹¤ç³»çµ±æ”¹ç‚ºå°ˆæ³¨åœ¨æ¢è¨ç‰©ä»¶è¼ªå»“è¡¨ç¤ºæ¨¡å‹
(Appearance Model)ï¼Œåˆ©ç”¨ç›®æ¨™ç‰©çš„ç¨ç‰¹å½¢ç‹€ã€
é¡è‰²åˆ†ä½ˆã€ç›®æ¨™ç‰©ç‰¹æ®Šçš„ç´‹ç†æˆ–æ˜¯åˆ©ç”¨ç›®æ¨™ç‰©æ‰€
æ“·å–å‡ºä¾†çš„ç‰¹å¾µé»ç­‰ï¼›ä¸¦æ­é…ä¸åŒçš„æ¼”ç®—æ³•ï¼Œå¦‚ï¼š
Kalman Filterã€Particle Filterã€Mean-Shiftã€KLT 
(Kanade-Lucas-Tomasi)ã€Cam-Shiftã€Trust-region
åŠ Optical Flow åšç²¾ç¢ºçš„è™•ç†ã€‚åƒæ˜¯ Zhu ç­‰äºº[5]
æå‡ºçš„æ–¹æ³•ï¼Œé€éå ´æ™¯çµæ§‹çš„åˆ†æçµåˆä¾‹å­æ¿¾æ³¢
å™¨ï¼Œä»¥é™ä½è¤‡é›œèƒŒæ™¯è¿½è¹¤å¤±èª¤ï¼Œå¦‚æœè¿½è¹¤èƒŒæ™¯ç°¡
å–®ï¼Œé€éæ­¤æ–¹æ³•èƒ½æå‡è¿½è¹¤ç‡ï¼›åä¹‹ï¼Œå¦‚æœå ´æ™¯
éæ–¼è¤‡é›œï¼Œåè€Œæœƒé€ æˆè¿½è¹¤ç‡ä¸‹é™ã€‚åœ¨æ–¹æ³•[6]
ä¸­ï¼Œé€éç²’å­æ¿¾æ³¢å™¨é”æˆå¤šç‰©ä»¶çš„è¿½è¹¤ï¼Œé¦–å…ˆï¼Œ
åˆ©ç”¨ k-means åˆ†é¡å™¨å°‡å‰æ™¯èˆ‡èƒŒæ™¯åˆ†é¡ï¼Œæ¥è‘—å–
å‡ºè‰²å½©èˆ‡ç©ºé–“ç‰¹å¾µä½œç‚ºå€™é¸ç²’å­æ¬Šé‡çš„æ¸¬é‡åŠ
é¸å–ï¼Œæ­¤æ–¹æ³•èƒ½ä½¿ç”¨å°‘é‡çš„ particle é”åˆ°å¥½çš„è¿½
è¹¤ç‡ï¼Œä½†æ˜¯å¦‚æœç‰©ä»¶è‰²å½©èˆ‡èƒŒæ™¯éæ–¼ç›¸è¿‘ï¼Œå‰‡å‰
æ™¯èƒŒæ™¯åˆ†é¡æ™‚å®¹æ˜“ç™¼ç”Ÿå¤±èª¤ï¼Œæ­¤å¤–ï¼Œç‰©ä»¶ç™¼ç”Ÿé®
è”½æ™‚äº¦æœƒå°è¿½è¹¤çµæœé€ æˆå¾ˆå¤§çš„å½±éŸ¿ã€‚å°ä¸Šè¿°æ
å‡ºçš„æ–¹æ³•èˆ‡ç“¶é ¸ï¼Œè¦æ”¹è‰¯èˆ‡å¢é€²ç³»çµ±æ•ˆèƒ½ï¼Œä¸»è¦
è€ƒé‡çš„é—œéµåœ¨æ–¼ç’°å¢ƒçš„è®ŠåŒ–ã€ç›®æ¨™ç‰©çš„è®Šå‹•åŠæ”
å½±æ©Ÿæœ¬èº«çš„æ•ˆèƒ½ã€‚è€Œå‰å…©é …å› ç´ ï¼Œæ˜¯æˆ‘å€‘ç ”ç©¶æ”¹
è‰¯çš„ä¸»è¦æ–¹å‘ã€‚ 
 
ä¸‰ã€ç ”ç©¶æ–¹æ³• 
æˆ‘å€‘æå‡ºçš„æ¼”ç®—æ³•æµç¨‹å¦‚åœ–ä¸€ï¼šé¦–å…ˆé‹ç”¨åˆ†
é¡å™¨å°‡äººå‹åˆ‡å‰²å‡ºä¾†ï¼Œæ­é… Particle Filter é‡å°æ­¤
äººå‹åšè¿½è¹¤ï¼Œè¨­å®šä¸€é–€æª»å€¼ï¼Œé€²ä¸€æ­¥åˆ¤æ–·æ˜¯å¦ç™¼
ç”ŸéŒ¯èª¤è¿½è¹¤æˆ–æ˜¯éƒ¨åˆ†é®è”½çš„å•é¡Œã€‚åœ¨è¿½è¹¤éç¨‹ä¸­
å¦‚æœç‰©é«”ç™¼ç”Ÿäº†é®è”½æƒ…æ³æˆ–æ˜¯èµ°é€²é¡è‰²è¤‡é›œçš„
å ´æ™¯ï¼Œæˆ‘å€‘å¯ä»¥æŠŠ SURF çš„ç‰¹å¾µå€¼[7,8]å–å‡ºä¾†é‡
å°æ¯ä¸€å€å¡Šåšæ¯”å°ã€‚çµåˆ particle filter èˆ‡ SURF
ç‰¹å¾µçš„ç‰©ä»¶è¿½è¹¤ï¼Œè¼ƒå…ˆå‰çš„æ–¹æ³•æ›´å¼·å¥ã€ç©©å®šï¼Œ
ç•¶ç‰©ä»¶ç™¼ç”Ÿäº†éƒ¨åˆ†é®è”½ä»ç„¶å¯ä»¥åšæœ‰æ•ˆçš„è¿½è¹¤ã€‚
ä»¥ä¸‹å°å¹¾å€‹å€‹ä¸»è¦æ­¥é©Ÿåšé€²ä¸€æ­¥çš„èªªæ˜ã€‚ 
åœ–ä¸€ã€ç‰©ä»¶è¿½è¹¤æ¼”ç®—æ³•æµç¨‹åœ– 
 6 
å¾µé¸å–çš„å¯¦ä¾‹ï¼ŒåŠ å…¥ SURF ç‰¹å¾µå¯ä»¥æå‡ç‰©ä»¶è¿½
è¹¤çš„è¡¨ç¾ã€‚ 
, ,1, ( , )
2
0,
x y
i l j l
d d
d O x
else
ï§
ï€«ïƒ¬
ï€¼ïƒ¯
ï€½ ïƒ­
ïƒ¯
ïƒ®
       (3) 
 
 
 
3.4 ç²’å­æ¬Šé‡çš„è¨ˆç®— 
æ¯å€‹ç²’å­çš„æ¬Šé‡æ˜¯ç”±ç©ºé–“ã€è‰²å½©åŠ SURF ç‰¹
å¾µèˆ‡è¿½è¹¤ç‰©ä»¶çš„ç›¸ä¼¼åº¦æ‰€æ±ºå®šçš„ã€‚ç©ºé–“ç›¸ä¼¼åº¦æ˜¯
é€éè¨ˆç®—ç²’å­ä¸­å¿ƒèˆ‡å‰ä¸€è¿½è¹¤ç‰©ä»¶ä¸­å¿ƒçš„æ­å¹¾
é‡Œå¾·è·é›¢æ‰€ç²å¾—ã€‚è€Œç²’å­èˆ‡ç‰©ä»¶è‰²å½©ç›´æ–¹åœ–æ±ºå®š
äº†è‰²å½©ç›¸ä¼¼åº¦ã€‚å¦‚å…¬å¼(4)ï¼ŒP ğ‘†ğ‘–
ğ‘¡  ğ‘¥ğ‘—
ğ‘¡ åŠ P ğ¶ğ‘–
ğ‘¡  ğ‘¥ğ‘—
ğ‘¡ 
ä»£è¡¨åœ¨æ™‚é–“ tæ™‚ï¼Œè¿½è¹¤ç‰©ä»¶ ièˆ‡ç²’å­ jä¹‹é–“çš„ç©º
é–“å¯†åº¦å‡½æ•¸åŠè‰²å½©å¯†åº¦å‡½æ•¸ï¼š 
 
1
1
1
( ( ( )), ( ( )))
( | )
( ( ( )), ( ( )))
1
( | )
(( , ), ( ))
t t
YUV i YUV j
t t bin
i j t t
YUV i YUV j
t t
i j t t t
x y i
Min H O bin H x bin
P C x
Min H O bin H x bin
P S x
d C C center O ï¥
ï€­
ï€­
ï€­
ï€½
ï€½
ï€«
ïƒ¥ïƒ¥ (4) 
 
 
å¦‚å¼å­(5)ä¸­ï¼ŒSURF ç‰¹å¾µç›¸ä¼¼åº¦å‰‡æ˜¯æŒ‡ç²’å­èˆ‡è¿½
è¹¤ç‰©ä»¶çš„ SURF ç‰¹å¾µå°æ‡‰é»è·é›¢ã€‚ 
 
1
, ,
1
( , )
1
,
s
t t
i l j l
t t l
j it
i
d O x
L
s n
ï¢ï§
ï­
ï­
ï€­
ï€½ï€½ ï€½
ï€­
ïƒ¥
(5) 
 
s ç‚ºå°æ‡‰é»çš„æ•¸é‡ï¼Œn ç‚ºä¸è¢«ä½¿ç”¨çš„å°æ‡‰é»æ•¸é‡ï¼Œ
Î²åŠÎ³æ±ºå®šSURFç‰¹å¾µçš„keypointæ¯”å° (å¦‚:å¼(2)ã€
(3))ã€‚æœ€å¾Œï¼Œå°‡å…¬å¼(3)~(5)åˆä½µï¼Œæˆ‘å€‘ç²å¾—å¼å­(6)ï¼Œ
å³æ±ºå®šæ¯å€‹ç²’å­çš„æ¬Šé‡ï¼Œæœ€å¾Œç²å¾—ç›®æ¨™ç‰©ä»¶çš„æ–°
ä½ç½®åŠä¸­å¿ƒï¼š 
 
1
1
1 1
( (1 ) ) ,
( | ) ( | )
( ( | ) ( | ))
K
t t t t t
i j j j j
j
t t t t t
i j i j jt t
j jK K
t t t t t
i j i j j
j j
O w x W x
P S x P C x L
where w and W
P S x P C x L
ï¡ ï¡ï€­
ï€½
ï€½ ï€½
ï€½ ï€« ï€­
ï€½ ï€½
ïƒ¥
ïƒ¥ ïƒ¥
(6) 
 
 
å››ã€çµæœèˆ‡è¨è«– 
æœ¬è¨ˆç•«çš„å¯¦é©—çµæœæ‰€ä½¿ç”¨çš„æ¸¬è©¦å¹³å°ç‚º
Core i7- 3.4GHzï¼Œæ‰€ä½¿ç”¨çš„ä½œæ¥­å¹³å°ç‚º Windows 
7ï¼Œä»¥ C åŠ C++ç‚ºç¨‹å¼æ’°å¯«èªè¨€ï¼Œä¸¦ä»¥ OpenCV
å‡½å¼åº«è¼”åŠ©ã€‚ç‚ºäº†è©•ä¼°æ­¤æ–¹æ³•çš„æ•ˆèƒ½ï¼Œæˆ‘å€‘ä½¿ç”¨
å¹¾çµ„å½±ç‰‡é€²è¡Œæ¸¬è©¦(å¦‚è¡¨ä¸€)ã€‚å¯¦é©—ä¸­ï¼Œç”±æ­å¹¾é‡Œ
å¾·è·é›¢åŠå¹³å‡èª¤å·®æ–¹æ³•ä½œç‚ºæ¸¬é‡æ¨™æº–ã€‚ 
 
 
 
 
å½±ç‰‡(è³‡æ–™åº«) ä¸»è¦æŒ‘æˆ° 
Pets 2001 dataset1 camera1 è¤‡é›œçš„èƒŒæ™¯ 
karlwilhelmstraÃŸe winter èƒŒæ™¯çš„ç›¸ä¼¼ 
Girl é®è”½ 
åœ–äº”ã€SURFç‰¹å¾µé¸å– 
è¡¨ä¸€ã€ä¸åŒå…·æŒ‘æˆ°æ€§çš„æ¨£æœ¬å½±åƒï¼š 
 8 
æ¸¬è©¦å½±ç‰‡ä¸­ï¼Œéƒ½èƒ½ç²å¾—è‰¯å¥½çš„è¡¨ç¾ã€‚æˆ‘å€‘çš„æ–¹æ³•
ä¸åªä½¿ç”¨äº†å‚³çµ±çš„é¡è‰²è³‡è¨Šï¼Œä¹Ÿåˆ©ç”¨äº† SURF ç‚º
åŸºç¤çš„ç‰¹å¾µæŠ½å–æ–¹å¼ï¼Œç”±æ–¼ SURF æŠ½å–çš„ç‰¹å¾µå…·
æœ‰å°ºåº¦ä¸è®Šæ€§åŠæ—‹è½‰ä¸è®Šæ€§ï¼Œå› æ­¤é™ä½ç”±æ–¼æ”å½±
æ©Ÿé¡é ­èˆ‡ç›®æ¨™ä¹‹é–“è·é›¢ä¸åŒå¸¶ä¾†çš„å½±éŸ¿ï¼Œä¸¦æŠµæŠ—
å…‰ç·šçš„è®ŠåŒ–ã€‚æ­¤å¤–ï¼Œæˆ‘å€‘é‡å°æ¯ä¸€å€‹ç²’å­éƒ½è€ƒæ…®
äº†ç©ºé–“ã€è‰²å½©åŠ SURF ç‰¹å¾µï¼Œä¼°æ¸¬æ¯å€‹ç²’å­èˆ‡ç‰©
ä»¶ç‰¹å¾µçš„ç›¸ä¼¼ç¨‹åº¦ï¼Œæ‰€ä»¥æˆ‘å€‘çš„æ–¹æ³•ä¹Ÿè¼ƒå‚³çµ±åª
è€ƒæ…®é¡è‰²ä¹‹æ–¹æ³•è¼ƒå¼·å¥ï¼Œèˆ‡å…¶ä»–æ–¹æ³•ç›¸è¼ƒï¼Œæˆ‘å€‘
çš„æ–¹æ³•åœ¨ç™¼ç”Ÿäº†éƒ¨åˆ†é®è”½å’Œç‰©ä»¶ä½æ–¼é¡è‰²ç›¸ä¼¼
åº¦å¾ˆé«˜çš„æƒ…æ³ä¸‹ä¹Ÿå…·æœ‰ç«¶çˆ­åŠ›ã€‚ 
 
4.3 å»ºè­° 
ç”±æ–¼æœ¬è¨ˆç•«çš„æ¼”ç®—æ³•å°æ–¼å³æ™‚æ€§çš„éœ€æ±‚ä»
ä¸å¤ ï¼Œå› æ­¤æˆ‘å€‘æœªä¾†ä»æ˜¯ä»¥ä¸Šè¿°çš„ç ”ç©¶æˆæœç‚ºåŸº
ç¤ï¼Œè©¦é©—æ˜¯å¦æœ‰å…¶ä»–æ–¹æ³•èƒ½é™ä½è¨ˆç®—è¤‡é›œåº¦ï¼Œæˆ–
ä»¥å…¶ä»–æ›´å¼·å¥çš„ç‰¹å¾µè¡¨ç¤ºæ–¹å¼ä¾†åŠ å¼·ç²’å­çš„é¸
æ“‡ï¼Œå¸Œæœ›èƒ½ç”¨æ›´å°‘çš„ç²’å­æ•¸ç›®é”åˆ°ç›¸åŒã€ç”šè‡³æ›´
å¥½çš„å¯¦é©—çµæœï¼Œä»¥åŠ å¿«é€Ÿåº¦ã€‚ 
 
äº”ã€è¨ˆç•«æˆæœè‡ªè©• 
5.1 ç ”ç©¶å…§å®¹èˆ‡åŸè¨ˆç•«ç›¸ç¬¦ç¨‹åº¦ 
ä¸‰å¹´æœŸè¨ˆç•«ç‚ºäººå‹è¿½è¹¤èˆ‡èº«ä»½è­˜åˆ¥ç³»çµ±ä¹‹
ç ”è£½ã€‚ç¬¬ä¸€å¹´ç ”ç©¶äººè‡‰åµæ¸¬èˆ‡äººè‡‰è­˜åˆ¥ï¼Œç¬¬äºŒå¹´
æ¢è¨äººå‹è¿½è¹¤æ¼”ç®—æ³•ï¼Œç¬¬ä¸‰å¹´æœŸæœ›èƒ½åœ¨äººç¾¤ä¸­è¿½
è¹¤å¤šå€‹ç›®æ¨™ã€‚ 
æœ¬ç ”ç©¶å…§å®¹èˆ‡åŸè¨ˆç•«ä¹‹äººå‹è¿½è¹¤éƒ¨ä»½ç›¸ç•¶
åœ°ç¬¦åˆã€‚å°æ–¼èº«ä»½è­˜åˆ¥ç³»çµ±ä¹‹ç ”è£½ä¹‹äººå‹æ–¹é¢é”
åˆ°ä¸éŒ¯çš„æˆæœï¼Œä¸åƒ…è¾¨è­˜ç‡èˆ‡å…ˆå‰çš„ç ”ç©¶å­¸è€…ç›¸
è¼ƒä¹‹ä¸‹æœ‰æ‰€æå‡ï¼Œä¸¦ä¸”èƒ½ä»¥è¼ƒå…¶ä»–å­¸è€…å°‘çš„ç²’å­
æ•¸é”åˆ°æ›´å¥½çš„å¯¦é©—çµæœã€‚æ­¤å¤–ï¼Œåœ¨éƒ¨åˆ†é®è”½åŠé¡
è‰²ç›¸ä¼¼ä¹‹æ¢ä»¶ä¸‹ï¼Œä¹Ÿèƒ½é”åˆ°ä¸éŒ¯çš„æ•ˆæœã€‚ 
 
5.2 é”åˆ°é æœŸç›®æ¨™æƒ…æ³ 
åœ¨æœ¬ç ”ç©¶è¨ˆç•«ä¸­ï¼Œæˆ‘å€‘æå‡äº†è¾¨è­˜ç‡ï¼Œé”åˆ°
äº†ä¸éŒ¯çš„æ•ˆæœã€‚å› æ­¤å°‡æœ¬è¨ˆç•«æˆæœæŠ•ç¨¿è‡³å…¨åœ‹è¨ˆ
ç®—æ©Ÿæœƒè­° National Computer Symposium (NCS 
2013)ï¼Œå·²ç¶“è¢«æ¥å—åˆŠç™»ï¼Œæœªä¾†æœƒæŠ•ç¨¿è‡³å­¸è¡“æœŸ
åˆŠã€‚æ­¤å¤–ï¼Œå‰å…©å¹´ä¹‹ç ”ç©¶è¨ˆç•«äº¦è‡³å°‘æœ‰å…©ç¯‡æœŸåˆŠ
è«–æ–‡èˆ‡ä¸€ç¯‡æœƒè­°è«–æ–‡ã€‚ 
 
5.3 ç ”ç©¶æˆæœä¹‹å­¸è¡“æˆ–æ‡‰ç”¨åƒ¹å€¼ 
äººå‹è¿½è¹¤ç³»çµ±ä¸ç®¡æ˜¯é–€ç¦ç®¡ç†ã€ç›£æ§ç³»çµ±æˆ–
è€…æ˜¯å®‰å…¨ç›£æ§ç­‰ï¼Œçš†å·²è¢«å»£æ³›çš„æ‡‰ç”¨ã€‚æœ¬è¨ˆç•«å°
æ–¼å­¸è¡“ä¸Šçš„æ‡‰ç”¨æœ‰æ›´é€²ä¸€æ­¥çš„è²¢ç»ã€‚ 
 
å…­ã€åƒè€ƒæ–‡ç» 
[1] S. Haner and Yu. Gu, â€œCombing 
Foreground/Background Feature Points and 
Anisotropic Mean Shift For Enhanced Visual 
Object Tracking,â€ International Conf. Pattern 
Recognition (ICPR), Aug. 2010. 
[2] Y. Liu, W. Zhou, H. Yin, and N. Yu, 
â€œTracking Based on SURF and Superpixel,â€ 
International Conf. Image and Graphics, Aug. 
2011. 
[3] B. Babenko, M.H. Yang, and S. Belongie, 
â€œRobust Object Tracking with Online 
Multiple Instance Learning,â€ IEEE Trans. 
Pattern Analysis and Machine Intelligence, 
vol. 33, Aug. 2011. 
[4] V. Takala and M. Pietikainen, â€œMulti-object 
tracking using color, texture and motion,â€ 
IEEE Conf. Computer. Vision Pattern 
Recognition, pp. 1â€“7, Jun. 2007.  
[5] J. Zhu, Y. Lao, and F. Zheng, â€œObject 
Tracking in Structured Environments for 
Video Surveillance Applications,â€ IEEE 
Trans. Circuits and Systems for Video 
Technology, vol. 20, no. 2, Feb. 2010. 
[6] Y. Jhu, C. Chuang, and S. D. Lin, â€œMultiple 
Object Tracking via Particle Filter Based on 
Foreground Extraction,â€ 25th IPPR Conf. 
Computer Vision, Graphics, and Image 
Processing, Aug. 2012. 
[7] H. Bay, A. Ess, T. Tuytelaars, and L. Van 
Gool, â€œSURF: Speeded-Up Robust Features,â€ 
International Journal Computer Vision and 
Image Understanding, vol.110, no. 3, pp. 
346-359, 2008. 
 10 
 
[7] (Active Appearance Models) is the famous method based on extracting the shape 
and texture of face information. Recently, the AAM based method has been developed 
in age synthesis [8]. Some age synthesis algorithms focus on child or adult. For the 
child modeling analysis, the shape change of face image is the most important factor. 
Ramanathan and Chellappa [9] proposed a method that defines the landmark points and 
builds the growth model. For the adult modeling analysis, both shape and texture are 
usually analyzed. In addition, some approaches [10-11] proved that the age simulation 
can improve face recognition rate. 
With other applications of face aging, there are many applications relating to age 
estimation. It is useful that people may know personâ€™s age. Age estimation also can be 
viewed as classification problem or regression problem. For the classification problem, 
Ueki et al. [12] proposed a Gaussian model in a low-dimensional feature space using 
the EM algorithm. The method classified the model to the age group and compared the 
likelihood. For the regression problem, the support vector regression was applied by 
Guo et al. [13] to the age manifold for the age estimation. Suo et al. [14] explored 
different features, and adopted various regression methods. Also, Geng et al. [15] 
proposed a subspace approach named AGES (Aging pattern subspace) for automatic 
age estimation. 
In recent years, many tensor-based face representation literatures have been 
proposed. Rena et al. [16] proposed the tensor face model to analyze the factors of 
variation. The model assumed that the face images are multi-linear of different factors 
such as person, lighting viewpoint, and pixels. Inspired by the works mentioned above, 
we propose an aging simulation scheme which is based on bimode model algorithm for 
training. The training stage trains the age database to decompose the training sample. 
Then PCA (Principal Components Analysis) is applied to face recognition system. The 
simulation results presented in the paper are compared with the ground truth image of 
the same person. These results also show that the proposed aging simulation scheme is 
able to improve the performance of face recognition system. 
The rest of this paper is organized as follows. Section 2 presents the proposed 
scheme in aging simulation. Simulation results are demonstrated in Section 3. Finally, 
the conclusions are drawn in Section 4. 
 
2. The Proposed Scheme in Aging Simulation 
The proposed scheme contains one training stage, bimode model for database 
training. Figure 1 illustrates the complete flowchart. The deformation ofâ€¨facial muscle 
and the normalization procedure were addressed in [17]. The details of bimode model 
are described in the following section 2.1. Section 2.2 describes the step of estimating 
the person and age subspaces. Then section 2.3 illustrates face recognition by PCA. 
 
2.1 Bimode Model for Database Training 
In the experiments of face synthesis, we focus on age variations. Therefore, we 
estimate person and age subspaces and synthesize a new face image which has the 
person-identity parameter of test image and the age parameter of target image. The 
bimode, described in the previous subsection, allows a face to be translated to a 
synthesized image, which has the same age subspace as the given target image. Assume 
that id is the test image, Td is the target image. After bimode factorization, we obtain  
i
pu (person-identity parameters of image id ), 
i
au  (age parameters of image id ), 
T
pu  
(person-identity parameters of image Td ) and 
T
au  (age parameters of image Td ). 
Then, we synthesize the new image of the person in the image id  under the age style 
of the image Td  by 
T
a
i
p
i
synthesis uuWd 21ï€½  (i=1,â€¦,Np) (3) 
where i is the sample of person, W is the interaction vector. The results of aging 
simulation on age variation are shown in section 3. 
 
 
Figure 3. The example of rearranging database. 
 
2.3 Face Recognition by PCA 
Eigenface approach was described by Turk and Pentland [19]. The system functions 
by projecting face images onto a feature space that spans the significant variations 
among known face images. The significant features are known as eigenfaces. This 
consists of creating a training set of images, calculating their average, and then 
subtracting each image by this average image. Finally, the similarity is computed by 
Euclidean distances and used for face recognition. Figure 4 shows the flowchart of face 
recognition system. 
 
3. Simulation Results 
In this paper, the study reveals the proposed scheme in aging simulation is suitable 
for face recognition system. It introduces the FG-Net aging database. Simulation results 
variation of a target age is estimated from subspace of age groups. Finally, the bimode 
model is combined to synthesize face images. 
From the simulation results, it is noted that the proposed framework can simulate 
face image at different age group very well with some blurring effect, and the 
recognition rate is satisfied with aging simulation. Another advantage of bimode model 
is the lower computational complexity [18], because of simpler mode representation. 
The future work will focus on considering more appropriate patterns for aging 
simulation to increase the recognition rate.  
 
REFERENCES 
[1] H. Ling, S. Soatto, N. Ramanathan, and D. Jacobs, â€œA Study of Face Recognition as People Ageâ€ 
Proc. IEEE Conf. Computer Vision, 2007.. 
[2] N. Ramanathana, R. Chellappa, and S. Biswas, â€œComputational Methods for Modeling Facial Aging: 
A Surveyâ€ J. Visual Languages and Computing, vol. 20, no. 3, pp. 131-144, 2009. 
[3] Yun Fu, Guodong Guo, and T.S. Huang,â€œAge Synthesis and Estimation via Faces: A Surveyâ€ IEEE 
Transactions on Pattern Analysis and Machine Intelligence, vol.32, no.11, pp.1955-1976, Nov. 
2010. 
[4] S. Mukaida, H. Ando, K. Kinoshita, M. Kamachi, and K. Chihara, â€œFacial Image Synthesis Using 
Age Manipulation Based on Statistical Feature Extraction,â€ Proc. Conf. Visualization, Imaging, and 
Image Processing, 2002. 
[5] N. Ramanathan, and R. Chellappa, â€œFace Verification across Age Progression,â€ IEEE Trans. Image 
Processing, vol. 15, no. 11,pp. 3349-3361, Nov. 2006. 
[6] T. Kuratate, and T. Nishita, â€œA Simple Method for Modeling Wrinkles on Human Skin,â€ Proc. 
Pacific Conf. Computer Graphics and Applications, pp. 166-175, 2002. 
[7] T. Cootes, G. Edwards, and C. Taylor, â€œActive Appearance Models,â€ IEEE Transactions on. Pattern 
Analysis and Machine Intelligence, vol. 23, no. 6, pp. 681-685, June 2001. 
[8] E. Patterson, A. Sethuram, M. Albert, and K. Ricanek, â€œComparison of Synthetic Face Aging to Age 
Progression by Forensic Sketch Artist,â€ Proc. Seventh IASTED Intâ€™l Conf. Visualization, Imaging, 
and Image Processing, pp. 247-252, 2007. 
[9] N. Ramanathan, and R. Chellappa, â€œModeling Age Progression in Young Faces,â€ Proc. Intâ€™l Conf. 
Computer Vision and Pattern Recognition, vol. 1, pp. 387-394, 2006. 
[10] J. Wang, Y. Shang, G. Su, and X. Lin, â€œAge Simulation for Face Recognition,â€ Proc. Intâ€™l Conf. 
Pattern Recognition, pp. 913-916, 2006. 
[11] Unsang Park, Yiying Tong, and A.K. Jain, â€œAge-Invariant Face Recognition, â€ IEEE Transactions 
on Pattern Analysis and Machine Intelligence, vol.32, no.5, pp.947-954, May 2010. 
[12] K. Ueki, T. Hayashida, and T. Kobayashi, â€œSubspace-Based Age-Group Classification Using Facial 
Images under Various Lighting Conditions,â€ Proc. IEEE Conf. Automatic Face and Gesture 
Recognition, pp. 43-48, 2006 
[13] G. Guo, Y. Fu, T. S. Huang, and C. Dyer, â€œLocally Adjusted Robust Regression for Human Age 
Estimation,â€ Proc. IEEE Workshop Applications of Computer Vision, 2008. 
[14] J. Suo, T. Wu, S. C. Zhu, S. Shan, X. Chen, and W. Gao, â€œDesign Sparse Features for Age 
Estimation Using Hierarchical Face Model,â€ Proc. Eighth Intâ€™l Conf. Automatic Face and Gesture 
Recognition, 2008. 
[15] X. Geng, Z.-H. Zhou, and K. Smith-Miles, â€œAutomatic Age Estimation Based on Facial Aging 
Patternsâ€ IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 29, no. 12, 
December 2007. 
[16] S. Rana, W. Liu, M. Lazarescu, and S. Venkatesh, â€œA unified tensor framework for face 
recognition,â€ Pattern Recognition 42 (2009) 2850â€“2862. 
[17] S. D. Lin, C. H. Tu, C. Y. Chuang, and H.-T. Lin, â€œ Aging Simulation Using Facial Muscle Model â€ 
International Conference on Machine Learning and Cybernetics, July 2012. 
[18] Hui Yan, Jian Yang, and Jingyu Yang, â€œ Bimode model for face recognition and face 
representation â€ Neurocomputing,Vol. 74, Issue 5, pp. 741-748, Feb. 2011. 
[19] M. Turk, and A. Pentland, â€œEigenfaces for Recognition,â€ Journal of Cognitive Neuroscience, vol.3, 
no.1, pp.71-86, 1991. 
[20] FG-Net Aging Database, [Online]. Available: http://www.fgnet.rsunit.com/ 
çµ±èˆ‡æ‡‰ç”¨ã€ç®¡ç†ç§‘å­¸ã€æ¨¡å‹èˆ‡ä¼°è¨ˆã€å‰ç»å¤šåª’é«”è³‡è¨Šèˆ‡äººé¡äº’å‹•æŠ€è¡“ã€æ™ºæ…§å‹æ§åˆ¶èˆ‡æ‡‰ç”¨ã€æ¨¡ç³Šæ§åˆ¶ã€
è¾¨è­˜/åˆ†é¡ã€æŸ”æ€§è¨ˆç®—ã€æ¨¡å¼èˆ‡æ¼”ç®—æ³•ã€æ™ºæ…§å‹ç³»çµ±ã€ä¿¡è™Ÿè™•ç†ã€æ™ºæ…§å‹ç³»çµ±ä¹‹é›»è…¦æŠ€è¡“ã€è³‡æ–™è™•ç†ã€
è³‡è¨Šè™•ç†ã€è‡ªç„¶èªè¨€è™•ç†ã€çŸ¥è­˜æ¢ç´¢ç­‰ä¸»é¡Œã€‚å€‹äººè¦ºå¾—é€™æ˜¯ä¸€å€‹å¾ˆå¥½çš„æ„è¦‹äº¤æµã€‚ 
 
ä¸‰ã€ è€ƒå¯Ÿåƒè§€æ´»å‹•(ç„¡æ˜¯é …æ´»å‹•è€…çœç•¥) 
å€‹äººåˆ©ç”¨é–‹æœƒä¹‹é¤˜ï¼Œèµ°è¨ªå¤§å† ï¼ˆä¸Šæµ·ï¼‰å…¬å¸ï¼Œå¢å»£è¦‹èã€‚ 
 
å››ã€ å»ºè­° 
æœ¬æ¬¡æœƒè­°æ˜¯åœ‹éš›å‰µæ–°è¨ˆç®—ã€ä¿¡æ¯èˆ‡æ§åˆ¶ç ”è¨æœƒï¼Œå­¸ç•Œåƒèˆ‡æ­¤æ¬¡æœƒè­°çš„å­¸è€…ä¸å°‘ï¼Œä¹Ÿç™¼è¡¨äº†å¾ˆå¤šä¸åŒ
é ˜åŸŸçš„ç ”ç©¶æˆæœã€‚å€‹äººéå¸¸æœŸå¾…èƒ½å¤šåƒèˆ‡åœ‹éš›å­¸è¡“æ´»å‹•ï¼Œå»ºç«‹é•·æœŸçš„å­¸è¡“ç ”ç©¶äº¤æµã€‚ 
 
äº”ã€ æ”œå›è³‡æ–™åç¨±åŠå…§å®¹ 
åç¨±ï¼šICIC Express Letters(EI)æœŸåˆŠè«–æ–‡é›† CDã€‚ 
 
å…­ã€ å…¶ä»– 
æ„Ÿè¬åœ‹ç§‘æœƒæä¾›çš„ç ”ç©¶ç¶“è²»è£œåŠ©ï¼Œè®“æœ¬äººé †åˆ©å®Œæˆç ”ç©¶ä¸¦è‡³ä¸Šæµ·å¸‚ç™¼è¡¨è«–æ–‡ã€‚ 
 
 
99ï¦ï¨å°ˆé¡Œç ”ç©¶è¨ˆç•«ç ”ç©¶æˆæœå½™æ•´è¡¨ 
è¨ˆç•«ä¸»æŒäººï¼šï§´ä¿¡é‹’ è¨ˆç•«ç·¨è™Ÿï¼š99-2221-E-259-020-MY3 
è¨ˆç•«åç¨±ï¼šäººå‹è¿½è¹¤èˆ‡èº«ä»½ï§¼åˆ¥ç³»çµ±ä¹‹ç ”è£½ 
ï¥¾åŒ– 
æˆæœé …ç›® å¯¦éš›å·²é”æˆ
ï¥©ï¼ˆè¢«æ¥å—
æˆ–å·²ç™¼è¡¨ï¼‰
é æœŸç¸½é”æˆ
ï¥©(å«å¯¦éš›å·²
é”æˆï¥©) 
æœ¬è¨ˆç•«å¯¦
éš›è²¢ç»ç™¾
åˆ†æ¯” 
å–®ä½ 
å‚™ è¨» ï¼ˆ è³ª åŒ– ï¥¯
æ˜ï¼šå¦‚ï¥©å€‹è¨ˆç•«
å…±åŒæˆæœã€æˆæœ
ï¦œ ç‚º è©² æœŸ åˆŠ ä¹‹
å° é¢ æ•… äº‹ ...
ç­‰ï¼‰ 
æœŸåˆŠï¥æ–‡ 0 0 100%  
ç ”ç©¶å ±å‘Š/æŠ€è¡“å ±å‘Š 0 0 100%  
ç ”è¨æœƒï¥æ–‡ 1 1 100% 
ç¯‡ 
 
ï¥æ–‡è‘—ä½œ 
å°ˆæ›¸ 0 0 100%   
ç”³è«‹ä¸­ä»¶ï¥© 0 0 100%  å°ˆï§ å·²ç²å¾—ä»¶ï¥© 0 0 100% ä»¶  
ä»¶ï¥© 0 0 100% ä»¶  
æŠ€è¡“ç§»è½‰ 
æ¬Šï§ï¤Š 0 0 100% åƒå…ƒ  
ç¢©å£«ç”Ÿ 6 6 100%  
åšå£«ç”Ÿ 1 1 100%  
åšå£«å¾Œç ”ç©¶å“¡ 0 0 100%  
åœ‹å…§ 
ï¥«èˆ‡è¨ˆç•«äººï¦Š 
ï¼ˆæœ¬åœ‹ç±ï¼‰ 
å°ˆä»»åŠ©ï§¤ 0 0 100% 
äººæ¬¡ 
 
æœŸåˆŠï¥æ–‡ 0 0 100%  
ç ”ç©¶å ±å‘Š/æŠ€è¡“å ±å‘Š 0 0 100%  
ç ”è¨æœƒï¥æ–‡ 0 0 100% 
ç¯‡ 
 
ï¥æ–‡è‘—ä½œ 
å°ˆæ›¸ 0 0 100% ç« /æœ¬  
ç”³è«‹ä¸­ä»¶ï¥© 0 0 100%  å°ˆï§ å·²ç²å¾—ä»¶ï¥© 0 0 100% ä»¶  
ä»¶ï¥© 0 0 100% ä»¶  
æŠ€è¡“ç§»è½‰ 
æ¬Šï§ï¤Š 0 0 100% åƒå…ƒ  
ç¢©å£«ç”Ÿ 0 0 100%  
åšå£«ç”Ÿ 0 0 100%  
åšå£«å¾Œç ”ç©¶å“¡ 0 0 100%  
åœ‹å¤– 
ï¥«èˆ‡è¨ˆç•«äººï¦Š 
ï¼ˆå¤–åœ‹ç±ï¼‰ 
å°ˆä»»åŠ©ï§¤ 0 0 100% 
äººæ¬¡ 
 
