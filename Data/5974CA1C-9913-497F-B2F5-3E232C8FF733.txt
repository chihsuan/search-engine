1 
 
 
è¡Œæ”¿é™¢åœ‹å®¶ç§‘å­¸å§”å“¡æœƒè£œåŠ©å°ˆé¡Œç ”ç©¶è¨ˆç•«â–  æˆ æœ å ± å‘Š   â–¡æœŸä¸­é€²åº¦å ±å‘Š 
 
ä½¿ç”¨å¤šä½å…ƒéš±è—è³‡æ–™å›å¾©å¹¾ä½•è®Šå½¢å½±åƒ 
 
 
è¨ˆç•«é¡åˆ¥ï¼šâ–  å€‹åˆ¥å‹è¨ˆç•«  â–¡ æ•´åˆå‹è¨ˆç•« 
è¨ˆç•«ç·¨è™Ÿï¼šNSC 99ï¼2221ï¼Eï¼002ï¼137ï¼ 
åŸ·è¡ŒæœŸé–“ï¼š 99  å¹´ 8  æœˆ 1  æ—¥  è‡³ 100 å¹´ 7 æœˆ 31 æ—¥ 
 
è¨ˆç•«ä¸»æŒäººï¼šææ˜ç©— 
è¨ˆç•«åƒèˆ‡äººå“¡ï¼šè¬æ˜Œéœ–ã€æ›¾æ˜ å‚‘ã€è”¡ä½³å¨œ 
 
 
æˆæœå ±å‘Šé¡å‹(ä¾ç¶“è²»æ ¸å®šæ¸…å–®è¦å®šç¹³äº¤)ï¼šâ–¡ç²¾ç°¡å ±å‘Š  â– å®Œæ•´å ±å‘Š 
 
æœ¬æˆæœå ±å‘ŠåŒ…æ‹¬ä»¥ä¸‹æ‡‰ç¹³äº¤ä¹‹é™„ä»¶ï¼š 
â–¡èµ´åœ‹å¤–å‡ºå·®æˆ–ç ”ç¿’å¿ƒå¾—å ±å‘Šä¸€ä»½ 
â–¡èµ´å¤§é™¸åœ°å€å‡ºå·®æˆ–ç ”ç¿’å¿ƒå¾—å ±å‘Šä¸€ä»½ 
â–¡å‡ºå¸­åœ‹éš›å­¸è¡“æœƒè­°å¿ƒå¾—å ±å‘ŠåŠç™¼è¡¨ä¹‹è«–æ–‡å„ä¸€ä»½ 
â–¡åœ‹éš›åˆä½œç ”ç©¶è¨ˆç•«åœ‹å¤–ç ”ç©¶å ±å‘Šæ›¸ä¸€ä»½ 
 
 
è™•ç†æ–¹å¼ï¼šé™¤ç”¢å­¸åˆä½œç ”ç©¶è¨ˆç•«ã€æå‡ç”¢æ¥­æŠ€è¡“åŠäººæ‰åŸ¹è‚²ç ”ç©¶è¨ˆç•«ã€
åˆ—ç®¡è¨ˆç•«åŠä¸‹åˆ—æƒ…å½¢è€…å¤–ï¼Œå¾—ç«‹å³å…¬é–‹æŸ¥è©¢ 
          â–¡æ¶‰åŠå°ˆåˆ©æˆ–å…¶ä»–æ™ºæ…§è²¡ç”¢æ¬Šï¼Œâ–¡ä¸€å¹´â–¡äºŒå¹´å¾Œå¯å…¬é–‹æŸ¥è©¢ 
          
åŸ·è¡Œå–®ä½ï¼šåœ‹ç«‹å°ç£å¤§å­¸è³‡è¨Šå·¥ç¨‹å­¸ç³»æš¨ç¶²è·¯èˆ‡å¤šåª’é«”ç ”ç©¶æ‰€ 
3 
 
(A) Data Embedding 
As mentioned before, a template-based approach is proposed for data embedding. It is assumed 
that the templates are easy to be discriminated. As shown in Fig. 1, we consider two types of 
templates which are binary pattern and a blob. A set of English characters, say T  t, t, â€¦ , t	
, 
is adopted to be the examples of the binary templates in our experiments. The reason why we 
generate a template set is that we can use those templates to encode and decode messages. A blob 
[5] is inserted at image boundaries in order to describe the behavior of boundary pixels in a better 
way so that the distortion can be recovered appropriately.  
 
 
(a) Binary templates (b) Blob 
Fig. 1: Binary templates used in the experiments 
Since the digital wavelet transform (DWT) captures both frequency and location information, it is 
suitable for us to embed the predefined templates in DWT domain. The templates are inserted to 
the image by adjusting the strength of frequency components in the DWT domain. Since the 
modification of the coefficients in one of the subbands of DWT will affect other subbands in the 
corresponding area after geometric transformation, the templates are embedded into the 
predetermined locations of three subbands: HL, LH and HH simultaneously. 
To add a template t to the selected region R:  
Iâ€²x, y  Ix, y    1 if tx, y  1 and Ix, y  0Ix, y    1 if tx, y  1 and Ix, y  0Ix, y if tx, y  0  
where Ix, y denotes the intensity value at position x, y  and  
 
represents the variance 
within the region R. In case of zero variance, a value one is added as the penalty term. Parameter  controls the strength of the embedded data. For more complex regions, the data embedding 
strength should be much stronger to maintain the robustness. However, if the data embedding 
strength becomes stronger, the embedded data will be more perceptible.  
Another point should be addressed is that the binary template is not applicable to boundary 
regions. Therefore, a simple blob is inserted as the reference for better capturing the boundaries 
in the recovering process as shown in Fig. 2.  
The embedding procedure which is shown in Fig. 3(a) is summarized as the following steps: 
1) Apply DWT to original image. Ix, y. FDWTI  I##, I#$, I$#, I$$.  
2) Generate several templates T  t, t, â€¦ , t	
 for embedding. Each template carries log K 
bits information. 
3) The message M  b+, b, â€¦ , b,-
 is prepared to be embedded into the image.  
4) Encode the message using the template set. Define the locations C  C+,+, â€¦ . C0,1
  of 
5 
 
pL, K, Z  pZ 9 9 p:K3,4;L3,4, Z<p:L3,4;L3-,4, L3,4-<14=+
0
3=+  
The problem is formulated by the joint probability of the locations and the types of the templates 
given that the frequency strength map Z is calculated from the data-embedded image. 
 
Fig. 4 The Bayesian Network Model 
 
The joint probability can then be represented as 
pL, K|Z  z  9 9 p:K3,4;L3,4, Z<p:L3,4;L3-,4, L3,4-<14=+
0
3=+  
Notice that it is too complicated to find the maxima of the joint probability, pL, K|Z  z, the 
following joint probability is conducted to update the condition of nodes in the Bayesian network 
iteratively. 
L3,4?, K3,4?  argmaxB,C pL3,4  l, K3,4  k|L\L3,4  L?-\L3,4?-, K\K3,4  K?-\K3,4?-, Z  z 
Based on the local Markov property, given the parents, the state of a node is conditionally 
independent of its non-descendant nodes. The joint probability of location and type for one 
template is described as follows: 
 p:L3,4, K3,4;L\L3,4, K\K3,4, Z<  pL3,4, K3,4|L3-,4, L3F,4, L3,4-, L3,4F, Z 
It can be further factorized into two terms. 
pL3,4, K3,4|L3-,4, L3F,4, L3,4-, L3,4F, Z  p:K3,4|L3,4, Z<pL3,4|L3-,4, L3F,4, L3,4-, L3,4F 
where p:K3,4|L3,4, Z<  is named as the similarity measurement model and p:L3,4;L3-,4, L3F,4, L3,4-, L3,4F<  is the neighbor relationship model. These two models are 
detailed in the following sections. 
7 
 
FDWTW  W##, W#$, W$#, W$$ 
(2) Combine three subbands LH, HL and HH to compute the frequency strength map. Z  |W#$|  |W$#|  |W$$| 
(3) The location and the type of each template can be determined so this completes the 
extraction part. 
The extracted locations of the templates then serve as the reference points for image 
recovery.  
 
(C) Image Recovery 
As shown in Figs. 5(a) and (b), since we have two sets of reference points: one is the predefined 
positions of the templates and the other is obtained in the extraction step, the task becomes to 
solve a registration problem which recovers the geometrically distorted image back to the original 
one. The displacement parameters between each pair of templates can then be determined 
according to the reference points. 
Original Image Distorted Image Recovered Image 
 
(a) template insertion (b) template detection (c) image recovery 
Fig. 5: Image recovery by embedded templates 
 
For any given point p, the corresponding displacement d(p) is computed by  
dp   U Ï†?pd?
,
?=  
where Ï†?p is the interpolation basis function associated with template n, d? denotes the 
displacement of the nVW templates, and N is the total number of templates. Once the parameters 
are determined, the distorted image, IX, can be recovered to IY according to the following 
equation: IYp  IXp  dp. 
In other words, the pixels are interpolated adaptively based on the relative positions to the 
templates. 
 
Experimental Results 
In our experiments, several English letters of size 32Z32 as shown in Fig. 1 are randomly chosen 
to be the binary patterns in the proposed scheme. The experimental results are demonstrated in 
 3) Robustness: Experimentally, we notice that the image recovery process fails when the 
watermarked image undergoes severe affine transformations. For example, a rotation with 
angle greater than 6P or a scaling factor greater than 10%. When the Gaussian noise is 
concerned, the proposed scheme survives with variance up to 64 since the contrast context 
histogram resists it. StirMark[14] is a benchmarking tool for digital watermarking 
technologies. One of the challenging attacks in StirMark is random bending attack (RBA). 
Fig. 7 demonstrates an example of successfully recovering an image with RBA
 
(a) Original Image
(c) Positions of detected templates
Fig. 7: Recovery of an image with Random Bending Attack
Fig. 8 shows the performance in terms of bit error rate. For each test image, one hundred distorted 
images are randomly generated with respect to the same RBA strength automatically. The bit 
error rate (BER) is calculated once the proposed recovery technique is performed.
each data point in Fig. 8 represents the average BER of one hundred images with a specific RBA 
strength. As it is shown in the figure, the BER increases as the 
But overall speaking, BER remains satisfactory.
The CheckMark[15] benchmarking was initiated in order to evaluate watermarking technologies 
under warping attacks. The image grids are warped in the three
projected back onto a two-dimensional plane. Different levels of attacks are evaluated in Fig. 9. 
Similarly, one hundred distorted images are randomly generated with respect to the same warping 
factor automatically for each test image. The BER is comp
technique is applied. Each data point in Fig. 9 represents the average BER of one hundred images 
with a specific warping factor. As we can see from those curves, the performance is consistent 
when the warping factor is not greater than six.
9 
 
 (b) Random Bending Attack
 
 (d) Recovered image 
 
RBA strength becomes stronger. 
 
-dimensional space and 
uted after the proposed recovery 
 
. 
 
 
 
 In other words, 
then 
11 
 
Applications, pp. 423-431, 1999.  
[5] S. Voloshynovskiy, F. Deguillaume, and T. Pun, â€œMultibit digital watermarking robust against local nonlinear 
geometrical distortions,â€ IEEE International Conference on Image Processing, pp. 999-1002, October 2001.  
[6] G. Doerr, C. Rey, and J.-L. Dugelay, â€œWatermark resynchronization based on elastic graph matching,â€ the 
International Conference on Sciences of Electronic Technologies of Information and Telecommunications, March 
2005.  
[7] J.L. Dugelay,S. Roche,C. Rey, and G. Dorr, â€œStill image watermarking robust to local geometric distortions,â€ 
IEEE transactions on image processing, pp. 2831-2842, 2006.  
[8] F. Deguillaume, S. Voloshynovskiy, and T. Pun, â€œA method for the estimation and recovering from general affine 
transforms in digital watermarking applications,â€ SPIE, pp. 313-322, January 2002.  
[9] M. Awrangjeb, M. Murshed, and G. Lu, â€œGlobal geometric distortion correction in images,â€ IEEE Workshop on 
Multimedia Signal Processing, pp. 435-440, September 2006.  
[10] C.R. Huang, C.S. Chen, P.C. Chung, â€œContrast context histogram-A discriminating local descriptor for image 
matching,â€ IEEE International Conference on Pattern Recognition, pp. 53-56, 2006.  
[11] Fabien A. P. Petitcolas, Ross J. Anderson, Markus G. Kuhn, â€œAttacks on copyright marking systems,â€ 
Information Hiding, Second International Workshop, pp. 219-239, April 1998.  
[12] S. Pereira, S. Voloshynovskiy, M. Madueno, S. Marchand-Maillet and T. Pun, â€œSecond generation benchmarking 
and application oriented evaluation,â€ Information Hiding Workshop III, pp. 340-353, April 2001. 
99 å¹´åº¦å°ˆé¡Œç ”ç©¶è¨ˆç•«ç ”ç©¶æˆæœå½™æ•´è¡¨ 
è¨ˆç•«ä¸»æŒäººï¼šææ˜ç©— è¨ˆç•«ç·¨è™Ÿï¼š99-2221-E-002-137- 
è¨ˆç•«åç¨±ï¼šä½¿ç”¨å¤šä½å…ƒéš±è—è³‡æ–™å›å¾©å¹¾ä½•è®Šå½¢å½±åƒ 
é‡åŒ– 
æˆæœé …ç›® å¯¦éš›å·²é”æˆ
æ•¸ï¼ˆè¢«æ¥å—
æˆ–å·²ç™¼è¡¨ï¼‰
é æœŸç¸½é”æˆ
æ•¸(å«å¯¦éš›å·²
é”æˆæ•¸) 
æœ¬è¨ˆç•«å¯¦
éš›è²¢ç»ç™¾
åˆ†æ¯” 
å–®ä½ 
å‚™ è¨» ï¼ˆ è³ª åŒ– èªª
æ˜ï¼šå¦‚æ•¸å€‹è¨ˆç•«
å…±åŒæˆæœã€æˆæœ
åˆ— ç‚º è©² æœŸ åˆŠ ä¹‹
å° é¢ æ•… äº‹ ...
ç­‰ï¼‰ 
æœŸåˆŠè«–æ–‡ 0 0 100%  
ç ”ç©¶å ±å‘Š/æŠ€è¡“å ±å‘Š 0 0 100%  
ç ”è¨æœƒè«–æ–‡ 0 0 100% 
ç¯‡ 
 
è«–æ–‡è‘—ä½œ 
å°ˆæ›¸ 0 0 100%   
ç”³è«‹ä¸­ä»¶æ•¸ 0 0 100%  å°ˆåˆ© å·²ç²å¾—ä»¶æ•¸ 0 0 100% ä»¶  
ä»¶æ•¸ 0 0 100% ä»¶  
æŠ€è¡“ç§»è½‰ 
æ¬Šåˆ©é‡‘ 0 0 100% åƒå…ƒ  
ç¢©å£«ç”Ÿ 3 3 100%  
åšå£«ç”Ÿ 0 0 100%  
åšå£«å¾Œç ”ç©¶å“¡ 0 0 100%  
åœ‹å…§ 
åƒèˆ‡è¨ˆç•«äººåŠ› 
ï¼ˆæœ¬åœ‹ç±ï¼‰ 
å°ˆä»»åŠ©ç† 0 0 100% 
äººæ¬¡ 
 
æœŸåˆŠè«–æ–‡ 0 1 75%  
ç ”ç©¶å ±å‘Š/æŠ€è¡“å ±å‘Š 0 0 100%  
ç ”è¨æœƒè«–æ–‡ 1 1 100% 
ç¯‡ 
 
è«–æ–‡è‘—ä½œ 
å°ˆæ›¸ 0 0 100% ç« /æœ¬  
ç”³è«‹ä¸­ä»¶æ•¸ 0 0 100%  å°ˆåˆ© å·²ç²å¾—ä»¶æ•¸ 0 0 100% ä»¶  
ä»¶æ•¸ 0 0 100% ä»¶  
æŠ€è¡“ç§»è½‰ 
æ¬Šåˆ©é‡‘ 0 0 100% åƒå…ƒ  
ç¢©å£«ç”Ÿ 0 0 100%  
åšå£«ç”Ÿ 0 0 100%  
åšå£«å¾Œç ”ç©¶å“¡ 0 0 100%  
åœ‹å¤– 
åƒèˆ‡è¨ˆç•«äººåŠ› 
ï¼ˆå¤–åœ‹ç±ï¼‰ 
å°ˆä»»åŠ©ç† 0 0 100% 
äººæ¬¡ 
 
