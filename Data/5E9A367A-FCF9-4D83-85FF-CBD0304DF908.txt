3However, it is very challenging to bridge the semantic gap between low-level image features and
high-level concepts.
In recent years, the neural network methods have been proposed to solve the classification problem
[5, 16, 17, 19, 20, 27]. Among the neural networks, the radial basis function (RBF) network is the most
popular architecture because it has good learning and approximate capacity. However, the RBF networks
were sensitive to centers initialization, the centers of an RBF network need to be appropriately set. In
addition, the training procedure of the traditional RBF network is time-consuming, especially when the
dimension of the inputs is high. Moreover, there might contain redundant information in the low-level
features. To overcome these drawbacks, the high-level semantic category would be learned to map into
low-level features by using the proposed MRBF neural network, and furthermore, we adopt the principal
component analysis (PCA) to reduce the feature dimension and to derive effective and discriminative
features [4,18,25]. In addition, the HSV color space, statistical texture analysis and shape features are used
to represent the segmented objects, of which these features are more closely related to human visual
perception. Therefore, in this project, we use the MRBF neural network to improve the classification
accuracy and speed up the training time, while a combination of the SOM and LVQ networks is used to
select more appropriate centers for RBF networks.
Our proposed system consists of training and testing stages. Figure 1 shows the flowchart of the
proposed semantic-based image analysis system. In the training stage, the training images are segmented
into several regions by using J-image segmentation (JSEG) [6]. Next, the segmented regions would be
classified into semantic categories by the user manually. Since the segmentation results by the JSEG
usually exist over segmentation phonomonent, a user interaction process is provided to merge regions into
semantic objects. Therefore, the low-level image features such as color, texture and shape features can be
extracted from each category and then incorporated into the proposed modular RBF (MRBF) network
after reducing the feature dimension by using PCA. In addition, in the MRBF network, a combination of
the SOM and LVQ is applied to overcome the problem of center initialization in a traditional RBF network.
In the testing stage, the testing image is segmented into regions by JSEG. Then extract the
low-level image features from each region. The PCA is applied to sift significant features and to
reduce the feature dimension. Finally, feed the sifted features from every segmented region into
the trained MRBF network for semantic analysis. In addition, in our proposed system, we used the
percentage to describe the semantic category contained in the testing image.
The proposed semantic-based photograph analysis system has the following advantages: (1) it is
possible to estimate the semantic category of an image not only by using the low-level features extracted
in the whole image used in the conventional methods but also the object features such as color, texture and
shape; (2) it can achieve a reasonable accuracy rate after a rough image segmentation by using JSEG
segmentation and without employing user interaction to assign a semantic label; (3) the problem of a
center initialization in a traditional RBF network can be overcome by using the combination of an SOM
and LVQ network; and (4) the proposed MRBF network has a faster learning speed and a higher accuracy
rate for real world images than the traditional RBF network.
71,2,3, ,Tk kx E Y k NÔÄΩ ÔÄΩ ÔÅå (9)
Fig. 4. The edge histogram of the object region quantized into 24 bins.
To obtain enough principal components, we have computed the energy preservation factor P, by
retaining only M eigenvalues
1
1
M
i
i
N
i
i
P where N M
ÔÅ¨
ÔÅ¨
ÔÄΩ
ÔÄΩ
ÔÄΩ ÔÄæ
ÔÉ•
ÔÉ•
(10)
By means of PCA, we can get a new feature set ÔÅª ÔÅΩ1 2, , , Mx x xÔÅå . In addition to the dimensional reduction,
this set of feature variables can also have the maximal variance. For this reason, each segmented region is
presented by a lower dimensional feature vector, which is an input of the MRBF network.
2.4. Combining SOM Network and LVQ Network to Generate Appropriate Centers for
RBF Network
Since the RBF networks are sensitive to center initialization, how to select significant features for
center initialization is important. The SOM network has been proven to have the capacity of autoclustering.
In order to avoid the difficulty of center initialization, the SOM network is applied to obtain appropriate
11
Fig. 7. The MRBF network architecture.
The parametric model and learning capability of the MRBF network is similar to the RBF network.
Therefore, the parametric model of the MRBF network can be given as follows
1
( ) (|| ||)
k
j ji ji ji
i
f w ÔÅ¶
ÔÄΩ
ÔÄΩ ÔÄ≠ÔÉ•x x c (22)
where nRÔÉéx is an input vector, jiÔÅ¶ is the basis function of the MRBF network, jiw is the weight in the
output layer, 1 2( , ,..., )
T
ji ji ji jinc c cÔÄΩc denotes the i-th center of the j-th modular and ÔÉó denotes the
Euclidean norm.
If the basis function of the MRBF network is a Gaussian function, then Eq.(12) can be written as
2 2
1 1
( ) (|| ||) exp([ || || / ])
k k
jij ji ji ji ji ji
i i
f w wÔÅ¶ ÔÅ≥
ÔÄΩ ÔÄΩ
ÔÄΩ ÔÄ≠ ÔÄΩ ÔÄ≠ ÔÄ≠ÔÉ• ÔÉ•x x c x c (23)
Where jiÔÅ≥ is the i-th bandwidth of the Gaussian function of the j-th module as follows
k
d
ji
maxÔÄΩÔÅ≥ (24)
where dmax is the maximum Euclidean distance between the selected center of the j-th module, and k is the
center number of the j module.
1MÔÅ¶
..
..
‚Ä¶
x1
x2
xN
..
...
21ÔÅ¶
2kÔÅ¶
1kÔÅ¶
11ÔÅ¶
MkÔÅ¶
ÔÅì
ÔÅì
1Mw
21w
Mkw
2kw
...
f1
f2
fM
1kw
11w
ÔÅì
15
(1)
(2)
(3)
(4)
(5)
(6)
(7)
(a) (b) (c) (d) (e) (f)
Fig. 9. The classification results of the semantic-based photographic analysis. (a) original image,(b)
segmented image,(c) classification result of NonPCA with MRBF, (d) classification result of PCA with
RBF, (e) classification result of PCA with CSOM, (f)classification result of PCA with MRBF.
19
Ë®àÁï´ÊàêÊûúËá™Ë©ï
Êú¨Ë®àÂäÉÈñãÁôºÊ®°ÁµÑÂåñÂçäÂæëÂü∫Â∫ïÂáΩÊï∏È°ûÁ•ûÁ∂ìÁ∂≤Ë∑Ø(modular RBF neural networks, MRBF)Ôºå‰∏¶
ÁµêÂêà‰∏ªÊàê‰ªΩÂàÜÊûê(PCA)Â∞ç‰ΩéÈöéÁöÑÂΩ±ÂÉèÁâπÂæµÈÄ≤Ë°åÁâπÂæµÈÅ∏ÂèñÔºåÈÅ∏ÂèñÊúâÊïàÂèäÊúâÈëëÂà•Â∫¶ÁöÑÂΩ±ÂÉèÁâπÂæµÔºå
‰ª•Èôç‰ΩéMRBF ÁöÑËº∏ÂÖ•ÁâπÂæµÁ∂≠Â∫¶ÔºåÈÄ≤ËÄåË®àÁÆóÂΩ±ÂÉè‰∏≠ÂêÑÁ®ÆÈ´òÈöéË™ûÊÑèÈ†ÖÁõÆÁöÑÊàêÂàÜÔºåÈÅîÂà∞ÂΩ±ÂÉèÁÆ°ÁêÜ
ÁöÑÁõÆÁöÑ„ÄÇÊ≠§Â§ñÔºåÁÇ∫Ëß£Ê±∫ÂÇ≥Áµ±ÂçäÂæëÂü∫Â∫ïÂáΩÊï∏(RBF)È°ûÁ•ûÁ∂ìÁ∂≤Ë∑ØÁöÑ‰∏≠ÂøÉÈªûÂàùÂßãÂåñÂïèÈ°åÔºåÂä†ÈÄüMRBF
ÁöÑË®ìÁ∑¥ÂèäÊèêÂçáMRBF ÁöÑÂàÜÈ°ûÊïàËÉΩÔºåÊàëÂÄëÁµêÂêàËá™ÊàëÁµÑÁπîÊò†Â∞Ñ(SOM)ÂíåÂêëÈáèÂ≠∏ÁøíÈáèÂåñ(LVQ)Á∂≤
Ë∑ØÈÄ≤Ë°åÂàùÂßãÂÄºÁöÑË®≠ÂÆö„ÄÇÂØ¶È©óÁµêÊûúÈ°ØÁ§∫Êú¨Ë®àÁï´ÊèêÂá∫ÁöÑÊñπÊ≥ïÂ∞çÊñºË™ûÊÑèÁÇ∫Âü∫Á§éÁöÑÁÖßÁâáÂàÜÊûêÂÖ∑ÊúâÈ´ò
ÁöÑÂàÜÈ°ûÁ≤æÁ¢∫Â∫¶‰ª•ÂèäÂø´ÈÄüÁöÑË®ìÁ∑¥ÈÄüÂ∫¶„ÄÇ
Êú¨Ë®àÁï´ÁöÑÂàùÊ≠•ÊàêÊûúÂ∑≤ÁôºË°®ÂÖ©ÁØáÊúÉË≠∞Ë´ñÊñáÊñºÁ¨¨ÂçÅ‰∏ÄÂ±Ü‰∫∫Â∑•Êô∫ÊÖßËàáÊáâÁî®Á†îË®éÊúÉÔºåÂèä2007Âπ¥
ÂÖ®ÂúãË®àÁÆóÊ©üÊúÉË≠∞Ôºö
1. Chuan-Yu Chang, Shih-Yu Fu, and Chi-Fang Lee, 2006, Modular RBF Neural Network for Photograph
Analysis, Á¨¨ÂçÅ‰∏ÄÂ±Ü‰∫∫Â∑•Êô∫ÊÖßËàáÊáâÁî®Á†îË®éÊúÉ, 2006/12/14-15, È´òÈõÑ, pp.206-212.
2. ÂºµÂÇ≥ËÇ≤, ÊùéÁ∂∫Ëä≥, ÁéãÂÆè‰ªÅ, 2007, Ê§çÂü∫Êñº‰∏ªÊàê‰ªΩÂàÜÊûêËàáÊîØÊè¥ÂêëÈáèÊ©üÁöÑÂΩ±ÂÉèË™ûÊÑèÂÖßÂÆπÂàÜÊûêÁ≥ª
Áµ±, ÂÖ®ÂúãË®àÁÆóÊ©üÊúÉË≠∞, 2007/12/20-21, Âè∞‰∏≠, pp.172-177.
ÂÖ∂‰∏≠Á¨¨‰∫åÁØá‰∏¶ÂÖ•ÈÅ∏ÊúÄ‰Ω≥Ë´ñÊñáÁ´∂Ë≥ΩÔºåËÄåÂÆåÊï¥ÁöÑË´ñÊñáÂ∑≤ÊäïÁ®øËá≥IEEE Transactions on System, Man,
and CyberneticsÊúüÂàäÔºåÂ∑≤ÂÆåÊàêÁ¨¨‰∏ÄÊ¨°revise„ÄÇ
Êú¨Ë®àÁï´Ë®àÂüπËÇ≤ÂÖ©ÂêçÁ¢©Â£´Áè≠Â≠∏ÁîüÔºåÁõÆÂâçÂàÜÂà•Âú®ÊòìÈÄ£ÁßëÊäÄÂèäËôπÂÖâÁ≤æÂØÜÂ∑•Ê•≠ËÇ°‰ªΩÊúâÈôêÂÖ¨Âè∏Âæû
‰∫ãÁ†îÁôºÁöÑÂ∑•‰ΩúÔºåË°®ÁèæÁõ∏Áï∂ËâØÂ•Ω„ÄÇ
 Á≥ªÁµ±ÔßºÂà•Ëôü 
ÂÖ¨ÂãôÂá∫ÂúãÂ†±ÂëäÊèêË¶Å 
 
Âá∫ÂúãÂ†±ÂëäÂêçÁ®±ÔºöWCCI2008Âá∫Â∏≠ÂæåÊÑüÊÉ≥ 
                                            È†ÅÔ•©     Âê´ÈôÑ‰ª∂Ôºö‚ñ°ÊòØ‚ñ°Âê¶ 
 
Âá∫ÂúãË®àÁï´‰∏ªËæ¶Ê©üÈóú/Ô¶óÁµ°‰∫∫/ÈõªË©± 
The Chinese University of Hong Kong 
Âá∫Âúã‰∫∫Âì°ÂßìÂêç/ÊúçÂãôÊ©üÈóú/ÂñÆ‰Ωç/ËÅ∑Á®±/ÈõªË©± 
ÂºµÂÇ≥ËÇ≤/ÂúãÔß∑Èõ≤Ôß¥ÁßëÊäÄÂ§ßÂ≠∏/ÈõªËÖ¶ËàáÈÄöË®äÂ∑•Á®ãÁ≥ª/ÂâØÊïôÊéà/05-5342601 ext. 4337 
Âá∫ÂúãÔßêÂà•Ôºö‚ñ°1ËÄÉÂØü‚ñ°2ÈÄ≤‰øÆ‚ñ°3Á†îÁ©∂‚ñ°4ÂØ¶Áøí55ÂÖ∂‰ªñÔºàÂ¶ÇÂá∫Â∏≠ÊúÉË≠∞„ÄÅÔ•´ËßÄË®™Âïè„ÄÅ
ÊØîË≥Ω„ÄÅÊ•≠ÂãôË¶ñÂØüÁ≠âÔºâ 
 
Âá∫ÂúãÊúüÈñìÔºö97/6/2/~97/6/4         Âá∫ÂúãÂú∞ÂçÄÔºöÈ¶ôÊ∏Ø 
 
 
Â†±ÂëäÊó•ÊúüÔºö97/6/30 
 
 
ÂàÜÔßêËôü/ÁõÆÔºö 
 
 
ÈóúÈçµË©ûÔºö 
WCCI 2008„ÄÅneural network„ÄÇ 
 
ÂÖßÂÆπÊëòË¶ÅÔºöÔºà200~300Â≠óÔºâ 
 
Êú¨Âá∫ÂúãÂ†±ÂëäÊïòËø∞Êú¨‰∫∫Âà∞È¶ôÊ∏ØÂá∫Â∏≠WCCI2008ÊúÉË≠∞Ôºå‰∏¶ÁôºË°®Ô•ÅÊñáÁöÑÁ∂ìÈÅéÂèäÊî∂
Á©´„ÄÇÊ≠§Ê¨°ÊúÉË≠∞Êúâ 2228 ÁØáÔ•ÅÊñáÁöÑÊäïÁ®øÔºåÊúÄÂæåÂè™Êé•Âèó 1622 ÁØáÔ•ÅÊñáÁöÑÁôºË°®ÔºåÊé•ÂèóÔ•°
Á¥ÑÁÇ∫‰∏ÉÊàê„ÄÇÁî±Êñº WCCI2008 ÊòØ‰∏ÄÂÄãÁî±‰∏âÂÄãÂ§ßÂûãÁ†îË®éÊúÉ(IJCNN2008„ÄÅFuzzy-IEEE 
2008„ÄÅCEC2008)ÊâÄÁµÑÊàêÁöÑË∂ÖÂ§ßÂûãÂúãÈöõÊúÉË≠∞ÔºåÔ•´ËàáËÄÖÔ§≠Ëá™‰∏ñÁïå 70Â§öÂÄãÂúãÂÆ∂ÔºåÔ•´Ëàá
ÊúÉË≠∞ÁöÑ‰∫∫Ô•©Áõ∏Áï∂Â§ö„ÄÇ‰πüÂõ†Ê≠§Êï¥ÂÄãÊúÉË≠∞ÁöÑËàáÊúÉ‰∫∫Âì°‰∫íÂãïÁõ∏Áï∂Ô•ºÂ•ΩÔºåÂΩºÊ≠§ÂæàÂ§öÁöÑÊ©ü
ÊúÉÂèØ‰ª•Ê∑±ÂÖ•ÁöÑÔ¶∫Ëß£ÊúÄÊñ∞ÁöÑÁ†îÁ©∂ÊàêÊûú„ÄÇÁ∂úÂêàËÄåË®ÄÔºåËóâÁî±Ê≠§ÊúÉË≠∞ÁöÑÁ†îË®éÔºåÁç≤Ëá¥Â∫ï‰∏ã
ÂπæÈªûÊî∂Á©´Ôºö(1)Ô¶∫Ëß£Áõ∏ÈóúÔ¶¥ÂüüÊúÄÊñ∞ÁöÑÁôºÂ±ïÔß∫Ê≥Å„ÄÇ(2)Ë™çÔßºÁõ∏ÈóúÔ¶¥ÂüüÁöÑÁ†îÁ©∂Â≠∏ËÄÖÔºåÂ¢û
‰∏ªÊåÅ‰∫∫ÔºåÂú®Ë©≤ section‰∏≠ÂÖ±ÊúâÔßëÁØáÔ•ÅÊñáÔºå‰∏ªË¶ÅÂùáÊòØÊé¢Ë®éÊô∫ÊÖßË®àÁÆóÊäÄË°ìÊáâÁî®Âú®ÈÜ´Â≠∏
ÂèäËºîÂä©Ë®∫Êñ∑Á≠âÁõ∏ÈóúÂïèÈ°åÔºåÊâÄÊúâ‰ΩúËÄÖÂùáÂá∫Â∏≠Ë©≤ session‰∏¶ÁôºË°®Ô•ÅÊñáÔºåÊúÉ‰∏≠Ë®éÔ•ÅÁõ∏Áï∂
ÁÜ±Ô¶üÔºåÊòØ‰∏ÄÂÄãÊàêÂäüÁöÑÔ•ÅÊñáÁôºË°®ÊúÉ„ÄÇ 
 
ÂøÉÂæóÔºö 
WCCI2008 ÊòØ‰∏ÄÂÄãÁî±‰∏âÂÄãÂ§ßÂûãÁ†îË®éÊúÉ(IJCNN2008„ÄÅFuzzy-IEEE 2008„ÄÅ
CEC2008)ÊâÄÁµÑÊàêÁöÑË∂ÖÂ§ßÂûãÂúãÈöõÊúÉË≠∞ÔºåÔ•´ËàáËÄÖÔ§≠Ëá™‰∏ñÁïå 70Â§öÂÄãÂúãÂÆ∂ÔºåÊúÉÂ†¥‰∏≠‰∫∫Âô®
Áõ∏Áï∂Êó∫ÁõõÔºåÁâπÂà•ÊòØÂú®Â§ßÊúÉÊâÄÂÆâÊéíÁöÑÂπæÂ†¥ KeynoteÂùáÂê∏ÂºïÁàÜÊªøÁöÑ‰∫∫ÊΩÆÔºåÊòØ‰∏ÄÂÄãÁõ∏Áï∂
ÊàêÂäüÁöÑÊúÉË≠∞„ÄÇ 
Âú®ÊúÉË≠∞ÈÄ≤Ô®àÈÅéÁ®ãÔºåÈô§Ô¶∫ÂèØ‰ª•Ô¶∞ËÅΩÔ§≠Ëá™‰∏ñÁïåÂêÑÂúãÊúÄÊñ∞ÁöÑÁ†îÁ©∂ÊàêÊûúÂ§ñÔºåÔ§ÅÂèØÔßù
Áî®‰ºëÊÅØÁöÑÊôÇÈñìËàáÁõ∏ÈóúÂ≠∏ËÄÖÂ∞àÂÆ∂ÈÄ≤Ô®àÔ¶óË™º‰∫§Ôßä„ÄÇÊ≠§Â§ñÁ∂ìÁî±ÈÄôÊ¨°ÊúÉË≠∞ÔºåË™çÔßºÔ¶∫Ë®±Â§ö
Â≠∏ËÄÖÂ∞àÂÆ∂ÔºåÂ∞çÊñºÂúãÂÆ∂ÂèäÂÄã‰∫∫Âú®ÂúãÈöõËÉΩÔ®äÔ®ÅÁöÑÊèêÂçáÁ¢∫ÂØ¶ÊúâÈ°ØËëóÁöÑÂπ´Âä©„ÄÇ 
 
Âª∫Ë≠∞Ôºö 
1. ÂúãÁßëÊúÉÊáâÂ§öÈºìÔ•øÔ¶éËºïÂ≠∏ËÄÖÂá∫Â∏≠ÂúãÈöõÊúÉË≠∞ÔºåÁµ¶‰∫àËºÉÂ§öÁöÑÂá∫ÂúãË£úÂä©„ÄÇ 
2. Ô•¥ÂúãÂÖßÊúâÂ§ö‰∫∫ÂêåÊôÇÔ•´Âä†‰∏ÄÂÄãÊúÉË≠∞„ÄÇÂèØÁµÑÂúòÂâçÂæÄÔºå‰∏ÄÊñπÈù¢ÁØÄÔ•≠Ô¶ÉË≤ªÔºå‰∏ÄÊñπÈù¢ÂèØ
Áõ∏‰∫íÁÖßÊáâ„ÄÇ 
 
Ê¥ªÂãïÁõ∏ÁâáÔºö 
Abstract —ß Most of the thyroid nodules are
heterogeneous with various internal components, which
confuse many radiologists and physicians with their
various echo patterns in thyroid nodules. A lot of texture
extraction methods were used to characterize the
thyroid nodules. Accordingly, the thyroid nodules could
be classified by the corresponding textural features. In
this paper, five support vector machines (SVM) were
adopted to select the significant textural features and to
classify the nodular lesions of thyroid. Experimental
results showed the proposed method classifies the
thyroid nodules correctly and efficiently. The
comparison results demonstrated that the capability of
feature selection of the proposed method was similar to
the sequential floating forward selection (SFFS) method.
However, the proposed method is faster than the SFFS
method.
I. INTRODUCTION
odular lesions of the thyroid are very common among
the general populations. The incidence of palpable
thyroid nodules of the adult population is about 4% to 8%.
The incidence of thyroid nodules is much higher (50%) by
autopsy [1]. Because of sensitivity and convenience,
sonography is the modality of choice for diagnosis and
management of thyroid nodules [1], [2]. Most of the thyroid
nodules tend to have various internal echogenicities in the
sonogram, which makes the definite diagnosis of them
difficult. If the characteristic echogenicities for the major
components of the thyroid nodule can be realized, the
interpretation of thyroid sonography would be more
realistic, the misdiagnosis rate of thyroid cancer would be
decreased and management facilitated.
Sonographic findings of nodular lesions, such as nodular
goiter and thyroid tumors are well documented in textbooks
and many articles [3]-[5]. In nodular goiter, the sonographic
changes are usually heterogeneous. In follicular adenoma,
changes are either isoechoic or hyperechoic. In carcinoma,
the echogenicities vary [6]. Several ultrasound features
have been found to be associated with an increased risk of
thyroid cancer, including hypoechogenicity, predominantly
solid composition¬°etc. No ultrasound feature has both a
high sensitivity and a high positive predictive value for
thyroid cancer [1].
Fine-needle aspiration (FNA) represents a critical
C.Y. Chang and M.F. Tsai are with the Institute of Computer Science
and Information Engineering, National Yunlin University of Science &
Technology, Douliou, Yunlin, Taiwan (e-mail: chuanyu@yunteh.edu.tw).
S.J. Chen is with the Department of Medical Imaging, Buddhist Tzu Chi
General Hospital, Dalin, Chia-Yi, Taiwan.
diagnostic test in determining proper management of
thyroid nodular disease following thyroid ultrasonography.
Except for almost entirely cystic change, nodules larger
than 1 cm should be evaluated, because they have the
potential to be clinically significant cancers [1], [2].
However, many physicians are confused about the nature of
various echo patterns of thyroid nodules, or about target
selection of multiple thyroid nodules during ultrasound
guided FNA. Approximately 10% to 20% of thyroid
biopsies by FNA are nondiagnostic [7]. Nondiagnostic
FNAs of the thyroid may be associated with a high
probability of thyroid malignancy and need reaspiration [7].
Target selection of thyroid nodules disease for improvement
of diagnostic FNA should be emphasized here.
The support vector machine (SVM) has the capability of
generating a hyperplane to separate two sets and providing
good generalization performance. Nowadays, SVM had
been widely used for classification and prediction in many
fields.
Recently, various feature extraction methods were
proposed, i.e., we can obtain a lot of features from medical
images. However, it is difficult to select significant features
from the extracted features. Thus, in this paper, five SVMs
are applied to select the significant features.
Figure 1 shows six types of thyroid nodules with ROI,
which were outlined by radiologist and recognized by
biopsy. To recognize these thyroid nodules, we extracted 78
textural features from each ROI. The SVMs are then
applied to select the significant features from the extracted
78 features. Each SVM is trained by specific features,
which having more discrimination between two types of
thyroid nodules. In the experiments, the SVMs were
implemented by the libsvm [9].
This paper is organized as follows. In Section II, the
approach for thyroid nodules classification is described and
the corresponding procedures including the feature
extraction stage, the feature selection stage, and the
classification of this approach are presented. Section III,
shows the experimental results obtained by the proposed
method. Finally, conclusions are given in Section IV.
II. THYROID NODULES CLASSIFICATION
APPROACH
Figure 2 shows the flowchart of the proposed method.
There are three major parts including feature extraction,
feature selection, and thyroid nodules classification. Details
of these processes are described as follows:
Classification of the Thyroid Nodules Using Support Vector
Machines
Chuan-Yu Chang, Ming-Feng Tsai, and Shao-Jer Chen
N
3092
978-1-4244-1821-3/08/$25.00 c¬©2008 IEEE
Finally, we convolute them with the image and use the
statistics of the results. The features calculated from Laws¬°
texture energy measures are given by the following:
F20) LE mean, F21) EL mean, F22) SL mean, F23) EE
mean, F24) LS mean, F25) LE variance, F26) EL variance,
F27) SL variance, F28) EE variance, and F29) LS variance.
5) Neighboring Gray Level Dependence Matrix: This is
a two-dimensional matrix constructed by the gray level
relationship between every pixel and its neighbors in an
image [15]. Each element within the matrix is computed by
a mask, which defined by the distance parameter. For
example, if the distance = 1, we can obtain a 3¬° 3 mask,
when the distance = 2, we can obtain a 5¬° 5 mask and so on.
By using the mask, we compute each difference of gray
level which is equal to or less than a factor between center
pixel and its neighbors in an image. If the highest gray level
is g and the distance parameter is d, we can construct a
g-by-(d2-1) neighboring gray level dependence matrix. The
following features are calculated from this matrix:
F30) small number emphasis, F31) large number
emphasis, F32) number nonuniformity, F33) second
moment, and F34) entropy.
There are many combinations of the two parameters to
make up this matrix. In this study, the distance is 1 and the
difference of gray level is 0.
6) Wavelet Features: By using the one-dimensional
lowpass and highpass filter, the image would be
decomposed as a low and a high frequency sub-band,
respectively. Once we perform the decomposition with them
again, we obtain four sub-bands named as LL, LH, HL, HH.
Because of the LL sub-band is the approximation of the
image, so, we calculate the textural features from it.
In this paper, the filter coefficients were set by Antonini
et al. [16]. The mean, standard deviation, and Laws¬°
features of the LL sub-band image are calculated as wavelet
features. They are given by the following:
F35) mean, F36) standard deviation, and F37~F46) are
Laws¬° features of the LL sub-band.
7) Fourier Feature based on Local Fourier Coefficients:
The Fourier transform is applied to obtain the local Fourier
coefficients maps of the image [17]. Each coefficient
consists of two parameters: magnitude and phase angle.
Accordingly, the histograms of these two parameters are
obtained. Finally, the mean and standard deviation of the
magnitude and phase angle of local Fourier coefficients
maps are computed as textural feature. They are F47~F54)
are means of 8 magnitudes, F55~F62) are means of 8 phase
angles, F63~F70) are standard deviations of 8 magnitudes,
and F71~F78) are standard deviations of 8 phase angles.
B. Feature Selection
According to the previous stages, we extract totally 78
features from each ROI. We can use them to classify the
thyroid nodules directly, but it will be time-consuming for
the subsequent work when the size of ROI is large.
Thus, a wrapper-type method is carried out for feature
selection. This method introduces a classifier to show us
which combination of features has the best performance, i.e.,
the highest accuracy of classification that using this
combination. In our approach, we use five binary-SVMs to
perform the feature selection. Figure 3 shows the flowchart
of each binary-SVM.
Firstly, all feature vectors have been normalized with each
feature. Then we can calculate F-score [8] of each feature
from different category. Given feature vectors xk , k=1,¬° ,m,
where m is total number of feature vectors, and number of
positive and negative instances such as thyroid nodules of
follicles and fibrosis base are n+ and n-, respectively. The
F-score of the ith feature is calculated as:
)(
1
1)(
1
1
)()()(
1
2)()(
,
1
2)()(
,
2)(2)(
¬¶¬¶ 
 

 




 
n
k
iik
n
k
iik
iiii
xx
n
xx
n
xxxxiF (1)
where ix ,
)(
ix ,
)(
ix represent the average of the ith
feature of the whole, positive, and negative data sets,
respectively. )(
,

ikx is the ith feature of the kth positive
instance, and )(
,

ikx is the ith feature of the kth negative
instance.
After obtaining F-score of each feature, all feature vectors
were used to train SVM. A 3-fold cross validation method is
applied to evaluate the performance of each combination of
features [8]. After each process of cross validation, the
validation rate is recorded and the feature with the lowest
F-score will be eliminated. The remaining features are used
to train SVM and perform cross validation again. These
No
Yes
Feature set
Training
feature set
Validating
feature set
f = f - 1 f = 0?
Results
Fig. 3. The feature selection flowchart of each binary-
SVM.
Calculate F-score
Generate new data set with the
number of feature f, where f is
the total number of features
SVM training and
k-fold cross validation
3094 2008 International Joint Conference on Neural Networks (IJCNN 2008)
F-scores of two major bases of thyroid nodules. To illustrate
the selected features have significant discriminability, Fig. 5
shows the distribution of Follicles and Fibrosis base in the
LL-mean (F35) and sum entropy (F5) feature space.
Observing Fig. 5, we can clearly find the two groups can be
separated by a hyperplane easily.
To validate the performance of each SVM, the data set is
randomly partitioned into a training set and a test set. A
3-fold cross validation method is adopted, ie., the ratio of
training and test data is 2:1. For the generalization, we
perform the validation 10 times.
The average accuracy with the most discriminative
feature combination of each SVM was shown in Table II.
From Table II, we find the thyroid nodules can be classified
effectively by one, two or six features in System 1 and one
to three features in System 2. The average accuracies are all
higher than 96%. Table II also indicates the proposed
approach is available for different operation setups.
To demonstrate the effectiveness and efficiency of the
proposed method, the proposed method was compared with
a widely used approach proposed by Pudil et al., called
sequential floating forward selection (SFFS) [21]. The
classification results were shown in Table III. Owing to the
termination condition of SFFS is the number of features,
and it was decided by users. However, in practice, users
usually have no notion of how many features will result in a
better performance. Thus, we set the number of features
equals to that of our method. Observing Table II and III, we
find that the SFFS and the proposed method have similar
performance in average accuracies. However, in the case of
one selected feature, SFFS required less time than ours, but
as the number of selected features is equal to or larger than
two, the proposed method is faster than SFFS.
IV. CONCLUSION
Nodular lesions of the thyroid are very common among
the populations in Taiwan. According to the pathology,
thyroid nodules were categorized as the enlarged follicles,
the follicular cells with follicles, the papillary cells with
follicles, the follicular cells with fibrosis, the papillary cells
with fibrosis, and the fibrosis. Since the low resolution of
sonography, many physicians are confused about the nature
of various echo patterns of thyroid nodules.
To provide a helpful way to decrease the erroneous
diagnosis, a SVM-based thyroid nodules classification
method was proposed. Firstly, we extract 78 textural
features from ROIs, which were outlined by radiologist and
recognized by biopsy. To select the significant features, we
applied the SVMs for feature selection and obtain the more
discriminative feature set of different categorizes of thyroid
nodules. Finally, each SVM was trained by the sifted
features of corresponding category. The experimental
results showed the proposed classification approach
successfully identifies six kinds of thyroid nodules with
good performance. These results are very helpful in
interpretation of thyroid ultrasound and in enhancement of
diagnostic performance of ultrasound guided needle
aspiration.
ACKNOWLEDGEMENTS
This work was supported by Research Grants (NSC
94-2213-E-303-002 and NSC 96-2221-E-303-001) from
National Science Council, R.O.C and grants (DTCRD
96(2)-13) from Buddhist Dalin Tzu Chi General Hospital,
Chia-Yi, Taiwan, R.O.C. The authors would like to thank
department of pathology, Buddhist Dalin Tzu Chi General
Hospital, Chia-Yi, Taiwan, R.O.C. for the support and
guidance.
REFERENCES
[1] Frates MC, Benson CB, Charboneau JW, Cibas ES,
Clark OH, Coleman BG, Cronan JJ, Doubilet PM,
Evans DB, Goellner JR, Hay ID, Hertzberg BS,
Intenzo CM, Jeffrey RB, Langer JE, Larsen PR,
Mandel SJ, Middleton WD, Reading CC, Sherman SI,
Tessler FN, ¬°Management of Thyroid Nodules
Detected at US: Society of Radiologists in Ultrasound
Consensus Conference Statement¬°, Radiology
Vol.237, pp.794-800, 2005.
TABLE III
The Average Accuracies and their Corresponding Features
Selected by the SFFS Method
SVM
No.
Avg. Acc. (%) Features Time (sec)
S1 99.80198 F1, F4 1538.423
S2 99.54544 F1, F17 1198.576
S3 100 F1, F2,
F3, F4,
F5, F6
3233.349
S4 100 F1, F18 1118.36
Sy
st
em
1
S5 97.36841 F17 525.515
SVM
No.
Avg. Acc. (%) Features Time (sec)
S1 99.8077 F1, F2, F9 2763.515
S2 100 F1, F3 1321.843
S3 99.04109 F4 731.907
S4 100 F4 589.796
Sy
st
em
2
S5 100 F11 620.032
TABLE II
The Average Accuracies and their Corresponding Features
Selected by the Proposed Method
SVM
No.
Avg. Acc. (%) Features Time (sec)
S1 100 F5, F35 1149.765
S2 99.84848 F1, F24 875.501
S3 100 F5, F21,
F35, F48,
F54, F63
684.61
S4 99.56522 F30, F58 747.608
Sy
st
em
1
S5 96.31578 F34 597.189
SVM
No.
Avg. Acc. (%) Features Time (sec)
S1 100 F10, F65,
F69
1684.42
S2 100 F17, F34 984.984
S3 99.45205 F9 914.171
S4 100 F33 808
Sy
ste
m
2
S5 100 F34 846.983
3096 2008 International Joint Conference on Neural Networks (IJCNN 2008)
Â∞ÅÈù¢Ê†ºÂºè
ÂÖ¨ÂãôÂá∫ÂúãÂ†±Âëä
ÔºàÂá∫ÂúãÈ°ûÂà•ÔºöÂÖ∂‰ªñÔºöÂá∫Â∏≠ÊúÉË≠∞Ôºâ
ICICIC2008 Âá∫Â∏≠ÂæåÊÑüÊÉ≥
ÊúçÂãôÊ©üÈóúÔºöÂúãÁ´ãÈõ≤ÊûóÁßëÊäÄ
Â§ßÂ≠∏
Âá∫ Âúã ‰∫∫ËÅ∑ Á®±ÔºöÂâØÊïôÊéà
Âßì ÂêçÔºöÂºµÂÇ≥ËÇ≤
Âá∫ÂúãÂú∞ÂçÄÔºö‰∏≠ Âúã
Âá∫ÂúãÊúüÈñìÔºö 9 7 / 6 / 1 6 ~ 9 7 / 6 / 2 2
Â†±ÂëäÊó•ÊúüÔºö 9 6 / 6 / 3 0
Ê†°
Èï∑
ÂâØ
Ê†°
Èï∑
‰∏ª
‰ªª
Áßò
Êõ∏
‰∫∫
‰∫ã
ÂÆ§
ÂñÆ
‰Ωç
‰∏ª
ÁÆ°
Âá∫
Âúã
‰∫∫
Ê≥Å„ÄÇ(2)Ë™çË≠òÁõ∏ÈóúÈ†òÂüüÁöÑÁ†îÁ©∂Â≠∏ËÄÖÔºåÂ¢ûÈÄ≤ÂúãÂÆ∂ÂèäÂÄã‰∫∫Âú®ÂúãÈöõÁöÑËÉΩË¶ãÂ∫¶„ÄÇ
Ê≠£ÊñáÔºà1.ÁâàÈù¢ÁÇ∫ A4 Áõ¥ÂºèÊ©´Âç∞Ôºå‰∏¶Âä†Ë®ªÈ†ÅÁ¢º„ÄÇ2.ÁâàÈù¢Ë®≠ÂÆöÈÇäÁïåÁÇ∫‰∏ä‰∏ãÂ∑¶Âè≥ÂêÑË®≠ 2cm„ÄÇ3.Â≠óÈ´îÁÇ∫
Ê®ôÊ•∑È´î„ÄÅÂ§ßÂ∞èÁÇ∫ 14ÔºåË°åË∑ùÁÇ∫ 1.5 ÂÄçÈ´ò„ÄÇ4.ÂÖßÂÆπÊáâÂåÖÂê´„ÄåÁõÆÁöÑ„Äç„ÄÅ„ÄåÈÅéÁ®ã„Äç„ÄÅ„ÄåÂøÉÂæó„Äç„ÄÅ„ÄåÂª∫Ë≠∞„ÄçÂèä
ÂÖ∂‰ªñÁõ∏Èóú‰∫ãÈ†Ö„ÄÇÔºâ
ÁõÆÁöÑÔºö
Ê≠§Ê¨°Âá∫ÂúãÁöÑÁõÆÁöÑÂú®ÊñºÂá∫Â∏≠ The Third International Conference on Innovative
Computing, Information and Control (ICICIC2008)ÊúÉË≠∞ÔºåÁôºË°®ÂÖ©ÁØáË´ñÊñá‚ÄùApply an
Adaptive Center Selection Algorithm to Radial Basis Function Neural Network for
Face Recognition‚ÄùÂèä‚ÄùA Figure Extraction and Synthesis System by Learning Vector
Quantization Neural Networks‚ÄùÔºåÂÖ∂‰∏≠Á¨¨‰∏ÄÁØáË´ñÊñáÁöÑÂª∂‰º∏ÁâàÊú¨Áç≤Êé®Ëñ¶ÊäïÁ®øËá≥ÂúãÈöõÁü•
ÂêçÊúüÂàä International Journal of Innovative Computing, Information and Control
(IJICIC)ÁöÑ special issue (New Trends in Information Processing and Applications)„ÄÇ
Ê≠§Â§ñÔºåËóâÁî±ÊúÉË≠∞ÁöÑÁ†îË®éÔºåÂèØ‰∫ÜËß£Áõ∏ÈóúÈ†òÂüüÊúÄÊñ∞ÁöÑÁôºÂ±ïÁãÄÊ≥ÅÂèäË™çË≠òÁõ∏ÈóúÁöÑÁ†îÁ©∂Â≠∏
ËÄÖÔºåÂ¢ûÈÄ≤ÂúãÂÆ∂ÂèäÂÄã‰∫∫Âú®ÂúãÈöõÁöÑËÉΩË¶ãÂ∫¶„ÄÇ
ÈÅéÁ®ãÔºö
97 Âπ¥ 6 Êúà 16 Êó•‰∏äÂçà 8:30 Êê≠‰πòÁ´ãÊ¶ÆËà™Á©∫Áè≠Ê©ü(B7052)ÂâçÂæÄÈüìÂúãÈ¶ñÈÉΩÈ¶ñÁàæÂ∏ÇÔºå
Áî±ÊñºÁï∂Â§©È´òÈõÑÂ§ßÈõ®ÔºåËÉΩË¶ãÂ∫¶Êú™ÈÅîÈ£õÊ©üËµ∑ÈôçÊ®ôÊ∫ñÔºåÁè≠Ê©üÂª∂Ë™§Ëøë 30 ÂàÜÈêòÂæåËµ∑È£õÔºåÁ∂ì
Ê≠∑Á¥Ñ 2.5 ÂÄãÂ∞èÊôÇÁöÑÈ£õË°åÔºåÊñºÁï∂Âú∞ÊôÇÈñì 6 Êúà 16 Êó•‰∏≠Âçà 13:25 Â∑¶Âè≥ÊäµÈÅîÈüìÂúãÈ¶ñÁàæ„ÄÇ
Âá∫ÈóúÈö®Âç≥Êê≠ Bus ÂâçÂæÄÈ¶ñÁàæÔºå„ÄéÁÑ°ÊâÄ‰∏çÂú®Â§¢ÊÉ≥Â±ã„Äè (Ubiquitous Dream hall) ÈÄ≤Ë°åÂèÉ
Ë®™Ôºå‰∫ÜËß£ÈüìÂúãÂú® Ubiquitous ÊáâÁî®ÁöÑÊäÄË°ìÁôºÂ±ïÊÉÖÊ≥Å„ÄÇ
6 Êúà 17 Êó•Âú®È¶ñÁàæÂ∏ÇÂçÄÈÄ≤Ë°åÁü≠Êö´ÁöÑÂÅúÁïôÂèÉËßÄÂæåÊê≠Ê©üÂâçÂæÄ ICICIC2008 ÁöÑÊúÉË≠∞
Âú∞Èªû„ÄåÂ§ßÈÄ£„Äç„ÄÇÂ∞±Âú®È£õÊ©üÈôçËêΩÂâçÔºåÊ©üÈï∑Âª£Êí≠Ë™™ÊòéÂõ†Â§ßÈÄ£Ê©üÂ†¥Â§ßÈõ®ÂèäÊøÉÈúßÁöÑÈóú‰øÇÔºå
È£õÊ©üÊúÄÂæåËΩâÈôçÂ§©Ê¥•„ÄÇÁ∂ìÈÅéÊº´Èï∑ÁöÑÁ≠âÂæÖÔºåÁµÇÊñºÊñº 6/18 ÂáåÊô® 1:30 ÂàÜÂ∑¶Âè≥ÊäµÈÅîÂ§ßÈÄ£Ê©ü
Â†¥„ÄÇ
ICICIC2008 ÊúÉÂ†¥
ÈüìÂúãÈ¶ñÁàæ Ubiquitous Dream hall ÂèÉË®™
¬ª¬ª¬º
¬∫
¬´¬´¬¨
¬™ ¬ò¬ò 
¬ò
22
2
2
2
2
22
)(
V
V
V eee
kxg xik
xk
&
&
&
(1)
where ),( yxx  & is the variable in spatial domain.
The vector x& is determined by
TT sincos yxx  & . The standard deviation is the
width of wavelet filter and is often set as 2. The term
22Ve is subtracted in order to eliminate the
influence of illumination variance [8]. The k is
determined by S ¬ò 22 2sk ; and it represents
different scale of a kernel wavelet. The scales are
described by high frequency components. The scale
range is five indexed by s, where s=0¬´. The variant
T represents the orientation of a Gabor wavelet. The
eight orientations are determined, and indexing as
T={0,SSS} respectively. Accordingly,
we obtain 40 Gabor filters with different scales and
orientations
The convolution of a face image and the Gabor
filter is defined as:
dxdyyxgyxf
yxgyxfyxG
s
ss
¬≥¬≥ ¬ò 
 
),(),(
),(),(),(
,
,,
T
TT (2)
where f(x,y) is a face image, the * denotes
convolution operator and gs,T“è(x,y) is Gabor filters.
The 40 Gabor filters are convolved with a face image.
An average feature image is then obtained by
¬¶¬¶
  
 
4
0
87
0
, ),(
1),(
s
s yxGN
yxO
S
T
T (3)
where N = 40.
2.2 The architecture of neural network
2.2.1 Determination of the structure of neural
network. The radial basis function neural network is
a feed-forward multilayer neural network [2]. As
shown in Fig.2 , the structure consists of three layers:
an input layer, a single hidden layer of nonlinear
processing neurons, and an output layer. The output
of the radial basis function neural network is
calculated according to
miwy
N
k
kkiki ,....,2,1,),(
1
  ¬¶
 
cxI (4)
where 1u¬É¬è nx is an input vector. )(¬òkI is the
activation function of hidden neuron. The
Gaussian-based activation function is defined as
¬∏¬∏
¬∏
¬π
¬∑
¬®¬®
¬®
¬©
¬ß  2
2
2exp),(
k
k
kk VI
cx
cx , (5)
where 2kcx  is the Euclidean distance between an
input vector x and an associated center ck. The spread
parameter Vk controls the width of the kth hidden
neuron of RBF. The training procedure of the radial
basis function neural network consists of two steps.
In the first step, the corresponding kernel functions
are estimated by centers (ck) and the widths (Vk).
While, in the second step, the fully connected weights
between hidden layer and output layer are updated.
The number of hidden node is equal to the number of
class, and one class is mapping to one hidden node.
Each hidden node includes a transform matrix, which
provides an optimal center.
“è
I n p u t la y e r
H id d e n la y e r
O u tp u t la y e r
X 1
X n
y 1
y m
W i ,k
Fig.2 The schematic diagram of the specific
competitive learning (solid neuron is winner).
2.2.2 The adaptive choice of the center in the
hidden neurons. Since traditional RBF networks
were sensitive to center initialization, to obtain
appropriate centers, it is worth to find significant
features for further RBF clustering. In general, the
centers are chosen based on clustering algorithms,
such as, k-mean clustering and fuzzy c-mean
clustering. However, such unsupervised clustering
algorithms have no category information included in
the training set. On the contrary, in the face
recognition, the category information is included in
the training patterns [6]. Therefore, to recognize one
person, there is a corresponding hidden neuron in the
network. That is, if there are k persons to be
recognize we need k hidden neurons in the network.
In order to avoid the difficulty of center selection, the
principal component analysis (PCA) is applied to
obtain appropriate centers for RBF initialization.
The principal component analysis (PCA) is a
statistical method which determines an optimal linear
transformation matrix (Mj) from input vectors [2],
and the transformation matrix Mj is obtained as
follows:
kjnimm ij
i
j
i
jj ,..,2,1,,..,2,1    / O (6)
where ijO is the i-th eigenvalue of the covariance
matrix (/j), ijm is the corresponding eigenvector of
i
jO ( 12  ijm ). The transformation matrix Mj
composed of ijm i.e.Mj = ],...,,[
21 n
jjj mmm , and the
covariance matrix (/j) of the original feature vector is
calculated by:
¬¶¬¶
  
¬ò  /
n
i
Ti
j
i
j
n
i
T
j
i
jj
i
jj ZZn
IIII
n 11
1))((1 (7)
where ijI represents the i-th face image of j-th class
The 3rd Intetnational Conference on Innovative Computing Information 
and Control (ICICIC'08) 
978-0-7695-3161-8/08 $25.00 ¬© 2008 IEEE
Authorized licensed use limited to: National Yunlin University of Technology. Downloaded on October 26, 2008 at 21:03 from IEEE Xplore.  Restrictions apply.
from the 300 images. The remains are used for testing.
The recognition rates under different learning rate
and spread parameter are shown in Table 1. When the
spread parameter and learning rate set as 0.15 and
0.015, respectively, we obtain the highest recognition
rate. Therefore, in this paper all experiments are
carried out with K  and V 
Table 1. The recognition rates under different spread
parameters and learning rates.
Spread ParameterLearning
rate 0.2 0.15 0.1
0.05 90.67% 91.33% 89.33%
0.015 90.00% 92.67% 91.33%
0.01 90.00% 92.00% 90.00%
Table 2. Comparison of training time and epochs.
The proposed
method
The traditional
RBFFace
databases Training
time(s) epochs
Training
time(s) epochs
ORL 2670 133 4072 221
PICS 1161 112 2600 245
Yale 338 130 514 185
Table 3. The recognition rate for three face databases.
Face databasesApproach
ORL PICS Yale
The Proposed 82.00% 92.67% 97.33%
Gabor+RBF 61.00% 73.33% 90.67%
3.2 The complexity of training
To demonstrate the benefits of including the
PCA-based center initialization, the proposed method
is compared with a traditional RBF. In the traditional
RBF, the initial centers are randomly assigned. The
three face databases are adopted to compare the
training time and the number of epochs. For each
person, we selected half of the face images as the
training set, and the other half as the testing set (i.e.
we select 5 face images for training, and the
remaining 5 images for testing). The compared
results are shown in Table 2. We can discover in
Table 2 the training time is shorter than traditional
methods and the number of the epochs of the
proposed method is also smaller than others.
Obviously, the convergent speed of the proposed
method is faster than the traditional RBF.
3.3 Comparing with other approach using
different databases
To evaluate the generalization of the proposed
method, the three databases are used for testing.
There are 10 images of each person in the three face
databases. Therefore, a half of the images of each
person are used for training, the others are used for
testing. The recognition rate is defined as:
¬¶¬¶    Ni iNi iT CTR 11 (14)
where N is the number of persons, Ci is the number of
sub-sample in the ith person. The Ti is number of
correct classification in the ith person. The
experimental result is shown in the Table 3. The
recognition rate of the proposed method is 82% in
ORL, 92.67% in PICS, and 97.33% in Yale,
respectively. All the results are much better than the
traditional RBF method.
4. Conclusion
This paper proposed methods of a novel weight
updating and an appropriate centers selection in
RBFNN for face recognition. The centers of RBFNN
are adaptively selected by the principal component
analysis (PCA). The proposed method substantially
decreases the time of the search space in the gradient
method. Experimental results shown the proposed
method obtains higher recognition rate than the
traditional method in RBFNN. In addition, the
proposed method attenuates the influences of
illumination variety, facial expression, and poses
variations.
Acknowledgement
This work was supported by the National Science
Council Taiwan, under the grants NSC 96-2218-E-
224-007.
References
[1] C. H. Thomas Yang, S.H. Lai, L.W. Chang, ¬≥Hybrid
Image Matching Combining Hausdorff Distance With
Normalized Gradient Matching¬¥ Pattern Recognition,
Vol. 40, pp. 1173-1181, 2007.
[2] F. M. Ham I. Kostanic ,¬¥Principles of Neurocomuting
for Science & Engineering¬¥, McGraw-Hill
international edition, ISBN 0-07118161-x.
[3] H. Bae, S. Kim, ¬¥Real-time Face Detection and
Recognition Using Hybrid-information Extracted from
Face Space and Facial Features ¬¥ Image and Vision
Computing, Vol. 23 pp. 1181-1191, 2005.
[4] J. K. Sing, D.K.Basu, M.Nasipuri, M.Kundu, ¬≥Face
Recognition Using Point Symmetry Distance-based
RBF Network¬¥ Applied Soft Computing, Vol. 7 Issue 1,
pp.58-70, 2007.
[5] M. J. Er, S. Wu, J. Lu, H. L. Toh, ¬≥Face Recognition
With Radial Basis Function (RBF) Neural Networks¬¥
IEEE Trans. Neural Networks, Vol.13, NO.3, pp.
697-710, May 2002.
[6] M. J. Er, W. chen, and S.Wu, ¬≥High-speed Face
Recognition Based on Discrete Cosine Transform and
RBF Neural Networks¬¥ IEEE Trans. Neural Networks,
Vol.16, No.3 pp.679-691, May 2005.
[7] S. Haykin, ¬≥Neural Networks A Comprehensive
Foundation second edition¬¥ Prentice-Hall, Inc. ISBN
0-13-908385-5
[8] X. Wang, X. Tang, ¬¥Bayesian Face Recognition Using
Gabor Features¬¥, Pattern Recognition, November 8,
2003, Berkeley, California, USA.
The 3rd Intetnational Conference on Innovative Computing Information 
and Control (ICICIC'08) 
978-0-7695-3161-8/08 $25.00 ¬© 2008 IEEE
Authorized licensed use limited to: National Yunlin University of Technology. Downloaded on October 26, 2008 at 21:03 from IEEE Xplore.  Restrictions apply.
averaging operation is performed on the figural regions
to construct the figure template. The schematic diagram
of figure template construction is shown in Fig. 1.
Pre-process
Figure
Template
Within-Group
Variance
Subtraction
Convex
Hull
Opening
Average
Figure image
Method
of [3]
Figure region
Figure 1. The schematic diagram of constructing a figure
template
2.1. Four-step operation
Step 1: Minimum within-group variance: The minimal
within-group variance [4] is used to roughly separate
the figure images obtained by [3] into two groups,
figural and non-figural groups. The minimal within-
group variance is determined as follows:
   > @ggT 2221gminarg VV  , (1)
where g ranges from 0 to 255, and ƒ±1 and ƒ±2 are
variances of two groups. Through the Eq. (1), we
obtain a threshold T which is used to acquire the
suspicious figural regions.
Step 2: Subtraction: The second step subtracts the
corresponding region of the suspicious figural regions
in the initial frame from the figure region obtained in
step 1. The subtraction is defined as
     ¬∞¬Ø
¬∞¬Æ¬≠ d 
otherwise1
,,,,if0
,,
d0 thtyxftyxftyxF , (2)
where f(x,y,t) and f(x,y,t0) are the intensity of the figure
region at position (x,y) in frame t and t0, and thd is the
threshold. Note that the t0 frame is a background image
without any moving object.
The morphologic operations are tools for extracting
image components. They are useful in the
representation and description of region shape [5]. Two
morphologic operations including convex hull and
opening are adopted to refine the figure region.
Step 3: Convex Hull: Convex hull is a morphological
process which finds a minimum set includes all convex
in the original region such that any two points in the set
lies entirely within the set. The processes for obtaining
the convex hull, C(A), of a set A is described as follows:
Let Bi, i = 1,2,3,4, represent the four structuring
elements as shown in Fig. 2. The procedure consists of
iteratively applying the hit-or-miss transform to A with
Bi; when no further changes occur, we perform the
union with A and call the result Di. The procedure is
defined as implementing the equation:
1(  kik XX œ§œ† ,...3,2,1and4,3,2,1)   ¬â kiABi ,(3)
where AX ik  , and the operator ‰†¢ denotes the
morphological hit-or-miss transformÀÅ Let iconvi XD  ,
then the convex hull of A is obtained by
  
4
1 
 
i
iDAC . (4)
B1 B2 B3 B4
Figure 2. Structuring elements. Graygrids stand for 1 while
the √ó entries indicate GRQ¬∂WFDUH
After the convex hull operation, not only the figure
region but also the messy fractions are tends to
compact. Thus, an opening operation is applied to
smooth the contour of an object, to breaks narrow
isthmuses, and to eliminate thin protrusions.
Step 4: Opening: The opening of set A by structuring
element B, denoted as A∆ïB, is defined as
ABA ( $ œ§–Å BB ¬Ü) . (5)
That is the opening A by B is the erosion of A by B,
followed by a dilation of the result by B. After the
opening operation, the smooth figure-region fig is
obtained.
Then a figure template Fig was crated by averaging
the figure regions as follows:
   ¬¶
 
u 
N
i
i yxfigN
yxFig
0
,1255, , (6)
where figi(x,y) denotes the i-th figure region. It should
be noted that the template Fig is a gray scale image.
3. Figure Extraction
Based on the figure images and the figure template
obtained in pre-processing procedure, we can roughly
locate the figures from frames. The schematic flow
diagram of the proposed method is shown in Fig. 3.
3.1. Image feature extraction
The gray scale figure template can be classified into
three parts, figure, non-figure, and unknown regions,
by two thresholds thf and thn. If the intensity of a pixel
The 3rd Intetnational Conference on Innovative Computing Information 
and Control (ICICIC'08) 
978-0-7695-3161-8/08 $25.00 ¬© 2008 IEEE
Authorized licensed use limited to: National Yunlin University of Technology. Downloaded on October 26, 2008 at 21:01 from IEEE Xplore.  Restrictions apply.
