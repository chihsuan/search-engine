of buffer adjustments of descriptions and the 
reduction of the average number of selectable 
descriptions for m-dropping and binary dropping by 
factors of the number of receiving descriptions (n) 
and the number of discarded descriptions (m) are 
established. Experimental results showed that the m-
dropping, m = ceiling(n/2) generally outperformed m-
dropping, m = 2 and binary dropping in terms of 
service availability. Even though the accumulated 
reduction of buffer adjustments for m dropping 
policies was less than that for binary dropping, the 
average number of selectable descriptions for m-
dropping was much greater than that for binary 
dropping. Furthermore, Compared with the sequence 
dropping, the m-dropping, m = ceiling(n/2) would have 
much less number of buffer adjustments with little 
difference of the number of selectable descriptions. 
Ëã±ÊñáÈóúÈçµË©ûÔºö Dynamic buffering ¬∑ Service availability ¬∑ Multiple 
description coding ¬∑ Peer-to-peer ¬∑ Streaming 
 
  
 
buffer size), peers will not be able to cache or relay the video 
stream efficiently. Thus, the majority of peers have to rely on 
the streaming server to provide the requested video, leaving the 
forwarding bandwidth of most peers unused. In such cases, the 
intention of a P2P streaming system to take advantage of the 
peer resources (especially forwarding bandwidth) cannot be 
realized. 
 In general, on-demand video services enable clients to 
watch videos from beginning to end. As long as clients are able 
to buffer the initial part of the video they are watching, on-
demand service can provide access to the video to the next 
clients who request to watch it. Therefore, the key challenge is 
how to keep the initial part of a video in a peer's buffer for as 
long as possible, and thus maximize the service availability of a 
video for stream relay. In addition, to address the issues of 
delivering data on lossy network and providing scalable quality 
of services for clients, the adoption of multiple description 
coding has been proven as a feasible resolution by much 
research work. In our previous research work, we proposed a 
novel caching scheme for peer-to-peer on-demand streaming, 
called Dynamic Buffering [10]. The dynamic buffering relies 
on the feature of multiple description coding to gradually 
reduce the number of cached descriptions held in a peer's 
buffers, once the buffer is full. Preserving as many initial parts 
of descriptions in the buffer as possible, instead of losing them 
all at one time, effectively extends peers‚Äô service time.  
In dynamic buffering, buffered descriptions in a peer are 
sequentially selected  to discard, and their buffer space is 
reallocated to prolong the availability of initial blocks of other  
descriptions. What will be the impact on service availability in 
terms of the number of selectable descriptions if applying 
multiple descriptions dropping? Should the number of 
discarded descriptions be constant each time buffer adjustment 
is occurred? Or can it be an adaptive value based on the 
number of selectable descriptions in a peer‚Äôs buffer? In this 
paper, we studied three description dropping policies for 
dynamic buffering, called sequence dropping, m-dropping, 
and binary dropping. With sequence dropping, each time a 
peer‚Äôs buffer gets  filled up, it would sequentially discard 
descriptions one by one and then reallocate the released buffer 
space to other description in order to prolong their initial 
blocks. Furthermore,  a peer needs to report its buffer status to 
the server for bookkeeping purposes at each buffer adjustment, 
which inevitably causes computation and communication 
overheads. Such overheads can be avoided by m-dropping and 
binary dropping description policies which generally discard 
multiple descriptions at each buffer adjustment. In addition, 
we discuss two cases of m-dropping which are m =2 and m= 
. Mathematical formulas of the reduced number of buffer 
adjustments of descriptions and the reduction of the average 
number of selectable descriptions for m-dropping and binary 
dropping by factors of n and m are established. Experimental 
results showed that the m-dropping, m=   generally 
outperformed m-dropping, m=2 and binary dropping in terms 
of service availability.  
The remainder of the paper is organized as follows. In 
section II we introduce the concepts of multiple description 
coding (MDC), CoopNet, and dynamic buffering. In section III 
we present three description dropping policies for dynamic 
buffering. The experimental results and analyses are presented 
in section IV, and finally conclusions are drawn in section V. 
II. LITERATURE REVIEW  
A. Multiple Description Coding 
To address the issue of delivering video over lossy 
networks, many Multiple Description Coding (MDC) schemes 
have been proposed in the last few years. Normally, 
descriptions are independently transmitted over separate 
channels by exploiting path diversity of the multicast tree on 
P2P networks. Whenever all descriptions arrive without error, 
the fidelity of a video is maintained. In cases of transmission 
error due to broken links or a substantial data loss, the lost 
information can partially be recovered from the received 
descriptions. In addition, MDC can be used to provide scalable 
Quality of Service (QoS) for clients with various levels of 
downloading/forwarding bandwidth. In extreme cases, clients 
with limited network bandwidth, such as mobile devices, could 
still enjoy low quality videos by receiving only one description. 
The perceived QoS of watching videos depends on the number 
of descriptions a client receives. 
Multiple Description Coding (MDC) [11]‚Äì[14] is a flexible 
encoding technique capable of encoding a video into multiple 
sub-streams, called descriptions. Any subset of descriptions can 
be received and decoded by a peer to reconstruct the original 
video content with fidelity commensurate to the number of 
descriptions they receive. The more descriptions received, the 
higher the quality the reconstructed video content is. The 
flexibility of MDC enables peers with heterogeneous 
downloading capacity to receive a limited number of 
descriptions, but still enjoy a limited level of viewing quality 
according to the individual downloading capacity [14]. There 
has been a lot of research into the realization of MDC with 
existing coding standards. In particular, a great deal of effort 
has gone into developing an H.264/AVC standard-compliant 
multiple description (MD) encoder. 
B. CoopNet 
CoopNet is a typical P2P media streaming approach based 
on conventional cache-and-relay schemes. The primary 
characteristic distinguishing CoopNet from previous systems 
lies in its attempt to enhance the robustness of streaming 
services by means of MDC. In CoopNet, the streaming server 
encodes the streaming content into multiple descriptions using 
MDC, and distributes these descriptions among peers. Each 
peer is expected to receive descriptions from as many different 
parents as possible. With such a multi-parent transmission 
paradigm, peers are able to continue receiving parts of the 
streaming content and watch them at a lower quality level, even 
if some of the parents stop forwarding the streaming data due 
to accidental failure or intentional departure. However, like 
most conventional cache-and-relay schemes, CoopNet suffers 
from asynchronous arrival of peers and inefficient peer 
resource utilization. For example, suppose that the provided 
video is encoded into multiple descriptions of the same bit rate 
742
 
 
When a peer receiving n descriptions first provides stream 
relay service to a subsequent peers, within the available service 
duration, b, in the best cases there are n descriptions which can 
be selected; On the other hand, in the worst case there is only 
one description that can be forwarded. It is important to 
estimate the average number of descriptions which can be 
selected for stream relay. And the average number of 
descriptions can be computed by the summation of the product 
of each possible number of available descriptions and its ratio 
of available service duration as, 
 
It is interesting to note that the average number of 
selectable descriptions for relay in a new join peer receiving n 
descriptions is n-th harmonic number, and its approximate 
value is well-known as ln n + Œ≥, where Œ≥ is Euler's constant ( ~ 
0.57721). For the examples in Fig. 3, the average number of 
selectable descriptions n = 2, 4, 8, and 16, are 1.27, 1.96, 2.66, 
and 3.35. When the number of buffered descriptions in a peer is 
increased by a factor of two, the average number of selectable 
descriptions is also increased by a constant of 0.7 »ê= ln 2 +
  ‚àí  ln  +   =  ln 		 = ln 2»ë. It indicates that coding a 
description in a larger number of n does not effectively increase 
the number of selectable descriptions. Intuitively, n equal to 4, 
8, or 16 is a rational choice in our case. 
...
0
n
des.
n-1
des.
n-2
des. 1 des.2 des.
b/n b/(n-1) b/(n-2) b/3 b/2 b
ƒ° ƒ° ƒ° ƒ° ƒ°
 
1
1n n 
1
n
   
1
1 2n n  
...
... 1
3 2
1
2 1
T
available number of desriptions
ratio of available service
duration
 
Figure 2.  Diagram of service availability for dynamic buffering. 
 
Figure 3.  Ratios of available duration for 2, 4, 8, and 16 descriptions. 
B. M-dropping
In dynamic buffering, a peer needs to evenly allocate the 
released buffer space to other descriptions once the buffer is 
filled up. In addition, a peer needs to report its buffer status to 
the server for bookkeeping purposes.  Such computation and 
communication overheads can be avoided by m-dropping 
which selects m descriptions to drop, when buffer allocation 
adjustment is necessary. Note that when the number of 
selectable descriptions, c, is less or equal to m, the sequence 
dropping is applied for the rest of descriptions.  By dropping 
buffer space of multiple descriptions at a time, we may 
alleviate overheads of buffer adjustment but inevitably reduce 
the service availability of a peer since a peer can no longer 
relay discarded descriptions to subsequent peers. Take example 
of m equal to 2. When n is equal to 8, as shown in Fig. 4(a), 
with sequence dropping policy, the average service availability 
is 2.718. In Fig. 4(b), with m-dropping policy, the average 
service availability becomes 2.583, which is 0.135 less than 
sequence dropping, and 15 times buffer adjustments of 
descriptions. 
b/4 b/3 b/2 b
1/8 1/20 1/12 1/21/56 ƒ°ƒ°ƒ°…Éƒ°…É
0 b/8 ƒ°ƒ°ƒ°…Éƒ°…É
1/6
T
8 4 13 27 6 5
 
(a) Sequence dropping 
b/4 b/2 b
1/8 1/21/24
0 b/8
1/4
b/6
T
8 4 126
1/12
 
(b) m-dropping, m=2 
Figure 4.  The time line of service availability for n equal to 8 with sequence 
dropping and  m-dropping, m=2. 
From above examples, we observe that the duration where a 
peer that can originally relay n-1 descriptions with sequence 
dropping now can provide only n-2 descriptions with m-
dropping by m equal to 2. That is, the average numbers of 
buffered descriptions in a peer with sequence dropping and m-
dropping are  (n-1)/(n√ó(n-1)) and (n-2)/(n√ó( n-1)), respectively. 
Comparing to sequence dropping, the reduction of service 
availability is 1/(n√ó(n-1)) but saving n-1 times of buffer 
adjustments of descriptions. 
Based on the analysis of the previous example, we may 
establish the mathematical relationships between the value of m 
in m-dropping policy and service availability. 
Lemma 1.  Compared to sequence dropping, the reduced 
number of buffer adjustments of descriptions for a peer with m-
dropping is, 
‚àë ‚àë ( ‚àí  ‚àí ) 
 
 . 
In Lemma 1, 	  represents the number of discarding m 
descriptions in a peer, and  ‚àë ( ‚àí  ‚àí )  represents the 
reduced number of buffer adjustments of descriptions each 
time m descriptions is discarded. Given a duration that a peer 
with sequence dropping can relay  n-1 descriptions, now with 
 
 
 
  
1
1 1 1 1 11 2 2 1
1 1 2 2 3 1 2
1 1 1 1 11
1 2 3 2
1 ln .
n
i
n n n
n n n n n
n n n
n
i


           
    
      
 
 	 


744
  
 
descriptions for the three description dropping policies 
increases along with the number of receiving descriptions. As 
expected, the sequence dropping and the binary dropping have 
the most and the least average number of selectable 
descriptions. The average number of selectable descriptions for 
m-dropping is between that for sequence dropping and binary 
dropping, but the average number of selectable descriptions m-
dropping, m=	 is closer to that of sequence dropping. With 
m-dropping, m=2, when the number of receiving descriptions is 
not the factor of 2, the average number of selectable 
descriptions is smaller. On the other hand, with binary 
dropping there is a significant increase on the average number 
of selectable descriptions when the number of receiving 
description is 2k. As shown in figure, the average number of 
selectable descriptions for those description dropping policies 
increases sharply when the number of receiving descriptions is 
eight or less. Beyond that, the increase becomes slower. The 
number of receiving descriptions is 8 or 16 would be a good 
choice in our experiments. 
 
Figure 6.  The average number of selectable descriptions for various number 
of receiving descriptions with description dropping polices. 
V. CONCLUSION AND FUTURE WORK 
In this paper, we proposed three description dropping  
policies for dynamic buffering, called sequence dropping, m-
dropping, and binary dropping. With sequence dropping, each 
time a peer‚Äôs buffer gets  filled up, it would sequentially 
discard descriptions one by one and reallocate the released 
buffer space to other description in order to prolong their 
initial blocks. Furthermore, a peer needs to report its buffer 
status to the server for bookkeeping purposes at each buffer 
adjustment, which inevitably causes computation and 
communication overheads. Such overheads can be avoided by 
m-dropping and binary description dropping policies which 
generally discard multiple descriptions at each buffer 
adjustment. Experimental results showed that the m-dropping, 
m=  generally outperformed m-dropping, m=2 and binary 
dropping in terms of service availability. Note that even 
though the accumulated reduction of buffer adjustments for m-
dropping polices was less than that for binary dropping, the 
average number of selectable descriptions for m-dropping was 
much greater than that for binary dropping.  
 
REFERENCES 
[1] S. Androutsellis-Theotokis and D. Spinellis, ‚ÄúA survey of peer-to-peer 
content distribution technologies,‚Äù ACM Computer Survey, vol. 36, no. 
4, pp.335‚Äì371, 2004. 
[2] I. Stoica, R. Morris, D. Liben-Nowell, D. R. Karger, M. F. Kaashoek, F. 
Dabek, and H. Balakrishnan, ‚ÄúChord: a scalable peer-to-peer lookup 
protocol for Internet applications,‚Äú  IEEE/ACM Trans. on Networking, 
vo.11, no.1, pp.17-32, 2003. 
[3] R. Schollmeier, ‚ÄúA definition of peer-to-peer networking for the 
classification of peer-to-peer architectures and applications,‚Äù in Proc. of 
First International Conference on Peer-to-Peer Computing, pp.101‚Äì102, 
2004. 
[4] T. T. Do, K. A. Hua, and M. A. Tantaoui, ‚ÄúP2vod: providing fault 
tolerant video-on-demand streaming in peer-to-peer environment,‚Äù in 
Proc. of IEEE Conference on Communications, pp.1467‚Äì1472, 2004. 
[5] Y. Guo, K. Suh, J. Kurose, and D. Towsley, ‚ÄúP2cast: peer-to-peer 
patching scheme for vod service,‚Äù in Proc. of ACM Conference on 
WWW, pp.301‚Äì309, 2003. 
[6] E. Kusmierek, Y. Dong, and D. H. Du, ‚ÄúLoopback: exploiting 
collaborative caches for large-scale streaming,‚Äù IEEE Transactions on 
Multimedia, vo.8, no.2, pp.233‚Äì242, 2006. 
[7] Y. Cui, B. Li, and K. Nahrstedt, ‚Äúostream: asynchronous streaming 
multicast in application-layer overlay networks,‚Äù IEEE Journal on 
Selected Areas in Communications, vo.22, no.1, pp.91‚Äì106, 2004. 
[8] K. A. Hua, Y. Cai, and S. Sheu, ‚ÄúPatching: a multicast technique for true 
video-on-demand services,‚Äù in Proc. of ACM Multimedia, pp.191-200, 
1998. 
[9] A. Hu, ‚Äú Video-on-demand broadcasting protocols: A comprehensive 
study, ‚Äù in Proc. of IEEE INFOCOM, pp.508-517, 2001. 
[10] Chow-Sing Lin ‚ÄúImproving the Availability of Streams by Dynamic 
Buffering on VoD P2P Network‚Äù, The KSII Transactions on Internet 
and Information Systems (TIIS), vol. 4, no. 4, pp. 491-508. August, 
2010. 
[11] V. K. Goyal, ‚ÄúMultiple description coding: compression meets the 
network,‚Äù IEEE Signal Processing Magazine, vo.18, no.5, pp.74‚Äì93, 
2001. 
[12] A. Albanese, J. Blomer, J. Edmonds, M. Luby, and M. Sudan, ‚ÄúPriority 
encoding transmission,‚Äù IEEE Trans. on Information Theory, vo.42, no.6, 
pp.1737‚Äì1744, 1996. 
[13] Y. Wang, A. Reibman, and S. Lin, ‚ÄúMultiple description coding for 
video delivery,‚Äù in Proc. of the IEEE, vo.93, no.1, pp.57‚Äì70, 2005. 
[14] X. Tan and S. Datta, ‚ÄúBuilding multicast trees for multimedia streaming 
in heterogeneous P2P networks,‚Äù in Proc. of Systems Communications, 
pp.141‚Äì146, 2005. 
[15] Chow-Sing Lin and Guan-Sheng Wang ‚ÄúBalanced Dynamic Buffering 
for Scalable P2P Video-on-Demand Streaming with Multiple 
Description Coding‚Äù, The Fifth International Conference on Complex, 
Intelligent, and Software Intensive Systems (CISIS-2011), Korea, June, 
2011. 
 
746
Peer-to-Peer Netw. Appl.
point where they first joined the broadcast, instead
of from the beginning, and therefore, any peer with
sufficient forwarding bandwidth can provide services to
later peers. In this study, we only focus on on-demand
video services.
In on-demand media streaming systems [1, 2], a
streaming server is equipped with a limited amount of
outbound bandwidth as well as a number of videos.
Users issue requests to watch any one of the provided
videos. Upon receiving a user‚Äôs request, on-demand
streaming systems must ensure the user to receive a
continuous and complete playback of the requested
video. On-demand media streaming services gener-
ally require streaming servers to dedicate a substantial
amount of forwarding bandwidth to each user, for a
long period of time. Such resource consumption of
media streaming has driven most service providers to
shift system design from traditional Client-Server ar-
chitecture to Peer-to-Peer (P2P) architecture [1‚Äì4]. In
P2P systems, a user, also called as a peer, consumes
resources from the system, and contributes resources
to the system [5]. With the aid of users, the scalability
of on-demand streaming systems can be increased and
more users can be served.
In the past, there was a great deal of work done
on providing on-demand streaming services in a P2P
manner [6‚Äì10]. Most of these systems employed the
cache-and-relay schemes [11, 12], that require each
peer to cache the most recent video stream it receives.
As long as the initial part of the video stream remains
in its buffer, the peer can then relay the cached stream
to late-arriving peers in a pipelining fashion. Figure 1
shows a snapshot of peers‚Äô buffers at time 7 for the
cache-and-relay scheme. To clarify the sequence of a
video stream, the video is equally divided into a series
of n blocks, denoted as b 1, b 2, . . ., and b n. Note that
the data cached in the buffer is video blocks that have
already been watched. In this example a peer‚Äôs buffer
is capable of caching 4 video blocks at one time; loaded
from the left to right in a pipeline fashion. There are
Fig. 1 A snapshot of peers‚Äô buffers at time 7
three peers p1, p2, and p3, requesting the same video,
and arriving at time 0, 2, and 5. Peer p1 is the first peer
to request and receive the video stream from the server.
At time 2, p2 arrives. Since p1 still holds the initial
video block b 1 in its cache, it forwards the cached video
blocks to p2 sequentially. Similarly, when p3 arrives
at time 5, p2 still holds b 1, and forwards the cached
video blocks to p3. Peers p2 and p3 arrive before the
preceding peers have filled up the buffers, and are still
holding the initial part of the video. Therefore, each
peer can receive the entire requested video from its pre-
ceding peer(s) in a pipelining fashion. With the cache-
and-relay scheme, much of the workload can effectively
be shifted from the server to other capable peers, and
the server can avoid wasting its limited outbound band-
width on delivering duplicate video streams to peers
with the same request.
In Video-on-Demand (VoD) systems [13‚Äì15] based
on the cache-and-relay scheme described above, the
ability of a peer to contribute to the system for serving
new peers depends both on the amount of available
forwarding bandwidth and the existence of the initial
part of a video stream in its buffers. For example,
consider peer p arriving at time t and equipped with a
buffer capable of caching s time units of the requested
video stream. The peer cannot serve (relay blocks to)
any peer arriving later than time (t + s) even though it
has adequate available forwarding bandwidth. Because
the initial segment of the video stream is not held in its
buffer beyond time t + s, it cannot provide subsequent
peers with the entire video. In other words, the service
capability of p is restricted to [t + 1, t + s]. Most exist-
ing systems based on the conventional cache-and-relay
scheme are vulnerable to asynchronous arrival of peers.
If the time between peers‚Äô arriving is long (in compar-
ison to the buffer size), peers will not be able to cache
or relay the video stream efficiently. Thus, the majority
of peers have to rely on the streaming server to provide
the requested video, leaving the forwarding bandwidth
of most peers unused. In such cases, the intention of
a P2P streaming system to take advantage of the peer
resources (especially forwarding bandwidth) cannot be
realized.
In general, on-demand video services enable clients
to watch videos from beginning to end. As long as
clients are able to buffer the initial part of the video
they are watching, on-demand service can provide ac-
cess to the video to the next clients who request to
watch it. Therefore, the key challenge is how to keep
the initial part of a video in a peer‚Äôs buffer for as long
as possible, and thus maximize the service availability
of a video for stream relay. In addition, to address the
issues of delivering data on lossy network and providing
Peer-to-Peer Netw. Appl.
description (MD) encoder. Such MDC schemes can
generally be divided into two categories:
1. Schemes that exploit the spatial correlation be-
tween each frame of the sequence, such as
Polyphase Spatial Subsampling Multiple Descrip-
tion Coding (PSSMDC) [23] and Multiple Descrip-
tion Motion Coding (MDMC) [24]
2. Schemes that take advantage of the temporal cor-
relation between each frame of the sequence,
such as Multiple State Video Coder (MSVC) [25]
and the Motion-Compensated Multiple Descrip-
tion (MCMD) [26] video coding.
2.2 CoopNet
CoopNet is a typical P2P media streaming approach
based on conventional cache-and-relay schemes. The
primary characteristic distinguishing CoopNet from
previous systems lies in its attempt to enhance the
robustness of streaming services by means of MDC. In
CoopNet, the streaming server encodes the streaming
content into multiple descriptions using MDC, and dis-
tributes these descriptions among peers. Each peer is
expected to receive descriptions from as many different
parents as possible. With such a multi-parent trans-
mission paradigm, peers are able to continue receiving
parts of the streaming content and watch them at a
lower quality level, even if some of the parents stop for-
warding the streaming data due to accidental failure or
intentional departure. However, like most conventional
cache-and-relay schemes, CoopNet suffers from asyn-
chronous arrival of peers and inefficient peer resource
utilization. For example, suppose that the provided
video is encoded into multiple descriptions of the same
bit rate r, and peer p receives descriptions n with a
buffer size b . In CoopNet, p will cache all received
descriptions and its buffer will be saturated with the
streaming content b/(n √ó r) time units after arriving.
The initial parts of all the received descriptions are then
squeezed out of the buffer by incoming data, and p is
no longer able to forward the complete video to any
newly arrived peer in a pipelining manner. Therefore,
when peers subsequent to p arrive too late, such as
during off-peak time or requesting unpopular videos,
the outbound bandwidth of p tends to be unused, and
the server is burdened with a greater workload.
To address the aforementioned problems inherent in
conventional cache-and-relay schemes, in our previous
work we seek to take advantage of the flexible encod-
ing potential of MDC like CoopNet and proposed a
novel caching scheme, called Dynamic Buf fering [21].
In conventional cache-and-relay schemes, the service
capability of peers will suddenly disappears after the
peers‚Äô buffer fills up with streaming data. In this pro-
posed dynamic buffering scheme, the service capability
of peer degrades more gradually. We expected the
dynamic buffering scheme to deal with asynchronous
requests more effectively, and thus to achieve a more
efficient utilization of peer resources, further alleviat-
ing the workload imposed on the server. To the best
of our knowledge, this was the first paper to propose
the application of dynamic buffering schemes to on-
demand MDC streaming for P2P networks. Simulation
results showed that the proposed dynamic buffering
scheme significantly outperformed conventional cache-
and-relay schemes such as CoopNet.
2.3 Dynamic buffering
When the buffer of a peer is saturated, in our previous
work we proposed Dynamic Buf fering [21] which drops
the descriptions that have not been forwarded to any
peer one by one. Then it evenly distributes the released
buffer to other descriptions to prolong the service time
of the initial part of the video. In other words, with the
concept of dynamic buffering the number of buffered
descriptions gradually decreased once the buffer of a
peer gets full. With dynamic buffering, the buffer is
released on description basis. That is, only a buffer for a
non-forwarded description is released at a time. If there
is more than one non-forwarded, the description with
the most aggregate forwarding bandwidth is selected
to drop. Note that such an adjustment does not cause
the degradation of viewing quality but does limit the
selection of forwarded descriptions. As an example
shown in Fig. 2, the 12-minute video is encoded into 4
even-rated descriptions d1, d2, d3, and d4. The first peer,
p0, arrives at the 0th min and receives 4 descriptions
from the server with each buffering length equals 3
min. At time 3rd minute, p0‚Äôs buffer is filled up with
4 descriptions. Instead of losing the initial parts of all 4
descriptions at one time as the conventional cache-and-
relay scheme does, p0 chooses one description, says
d1, to discard and then evenly distributes the released
buffer to other descriptions. In this way, now the buffer
length of the remaining descriptions is 4 min, providing
one-extra minute for servicing new peers. p0 will repeat
the above process every time its buffer is filled up until
there is only one description left in its buffer. As shown
in Fig. 2 during the time 3 and 4, time 4 to 6, and
time 6‚Äì12, p0 would only have 3, 2, and 1 description
to forward, respectively. If peer p1 arrives after time
12, since p0 has no the initial part of any description
to offer, p1 will requests the desired descriptions the
server.
Peer-to-Peer Netw. Appl.
Peer p still enjoys n-description viewing quality since
it merely chooses not to cache one of the n descrip-
tions it receives after playback. As shown in Fig. 3b,
after sacrificing one description, p is able to continue
keeping the initial parts of the other (n ‚àí 1) descrip-
tions until time t + b/(n √ó r) + (b/(n √ó r)) √ó r/((n ‚àí
1) √ó r) = t + b/((n ‚àí 1) √ó r), where (b/(n √ó r)) √ó r in-
dicates the room made by discarding one description
and (b/(n √ó r)) √ó r/((n ‚àí 1) √ó r) the additional time
period for which the other (n ‚àí 1) descriptions can be
preserved. If no peer arrives and requests descriptions
from p all the while, ultimately there will be only one
description left in p‚Äôs buffer, and p will not be able to
preserve the initial part of the description that it has
ever received and thus will lose its service capability
after time t + b/r, as shown in Fig. 3c.
From Fig. 3a‚Äìc, it can be observed that the dynamic
buffering scheme allows a peer to gracefully degrade
rather than completely losing its service capability after
its buffer is filled up with the descriptions it keeps.
More specifically, the conventional cache-and-relay
scheme prohibits p from supplying any description in
its entirety to subsequent peers after time t + b/(n √ó r),
whereas the dynamic buffering scheme enables p to
supply (n ‚àí k) descriptions in time period [t + b/((n ‚àí
k + 1) √ó r), t + b/((n ‚àí k) √ó r)], where 1 ‚â§ k ‚â§ n ‚àí 1.
Since the expiration time of p‚Äôs service capability is
largely extended from t + b/(n √ó r) to t + b/r, p has
a greater opportunity to fully utilize its forwarding
bandwidth, thereby effectively alleviating the workload
of the streaming server. The dynamic buffering scheme
is expected to outperform the conventional cache-and-
relay scheme especially when peers are equipped with
a small buffer or their inter-arrival times are large, such
as in the case of unpopular videos or off-peak times.
It is worthwhile to note that the concept of dy-
namic buffering is different from the buffer manage-
ment scheme proposed in [27], in which the authors
proposed a P2P VoD system that utilizes SVC for
the minimization of startup and recovery delay, and
to deal with heterogeneous user capability. Starting
from the SVC base layer only, the startup delay for
a peer can be reduced. Furthermore, by dynamically
adding or dropping SVC enhancement layers, the oc-
currences of frame freezing due to network congestion
and insufficient peer bandwidth can be minimized. The
assumptions made in [27] and its goals of system design
were intrinsically different from ours. First, in [27] they
assumed unlimited buffer space of a peer so that they
did not address the issue of losing service availability
of a peer due to missing initial block of the cached
video caused by limited buffer space as the assumption
made in this paper. Second, the SVC assumed in the
paper is so called layer coding which consists of a base
layer and multiple enhancement layers. Layers have
strong dependency for decoding and must be decoded
in order. On the contrary, the SVC we applied is so
called multiple description coding where descriptions
do not exist any coding dependency. Any number of de-
scriptions can be combined to provide fractional quality
of a video. Third, the buffer management in [27] aims at
balancing startup delay and playback quality, while our
dynamic buffering focusing on prolonging the service
availability of a peer in order to alleviate server loading.
3 Service availability for dynamic buffering
3.1 Sequence dropping
Assume that a peer with the buffer space of b receives n
descriptions of equal bit rate r at time T = 0. Therefore,
b/n buffer space is allocated to each description. For
simplicity of analysis, assume that r is equal to the bit
rate of one description, and r = 1. Figure 4 shows the
Fig. 4 Diagram of service availability for dynamic buffering
Peer-to-Peer Netw. Appl.
4, 8, and 16 are 1.27, 1.96, 2.66, and 3.35. When the
number of buffered descriptions in a peer is increased
by a factor of two, the average number of selectable
descriptions is also increased by a constant of 0.7 . It
indicates that coding a description in a larger number of
n does not effectively increase the number of selectable
descriptions. Intuitively, n equal to 4, 8, or 16 is a
rational choice in our case.
3.2 M-dropping
In dynamic buffering, a peer needs to evenly allocate
the released buffer space to other descriptions once the
buffer is filled up. In addition, a peer needs to regularly
report its buffer status to the server at each buffer ad-
justment for bookkeeping purposes. Such computation
and communication overheads can be avoided by m-
dropping which selects m descriptions to drop, when
buffer allocation adjustment is necessary. In the aspect
of system implementation, a server could establish two
socket connections with a peer for control messaging
and data delivery. After each buffer adjustment, a peer
would report its buffer status including, the available
descriptions to forward, the buffer lengths of cached
descriptions, the available buffer space of each descrip-
tion, and etc., to a server for the scheduling of peer
joining and failure recovery. Discussing detailed com-
munication protocols of dynamic buffering are beyond
the scope of this paper. It is noted that when the num-
ber of selectable descriptions, c, is less than or equal
to m, the sequence dropping is applied for the rest
of descriptions. By dropping buffer space of multiple
descriptions at a time, we may alleviate overheads of
buffer adjustment of descriptions but inevitably reduce
the service availability of a peer since a peer can
no longer relay discarded descriptions to subsequent
peers. Take example of m equal to 2. When n is equal
to 8, as shown in Fig. 6a, with sequence dropping policy,
the average service availability is 2.718. In Fig. 6b,
with m-dropping policy, the average service availabil-
ity becomes 2.583, which is 0.135 less than sequence
dropping, and 7 + 5 + 3 = 15 times buffer adjustments
of descriptions.
From above examples, we observe that the duration
where a peer that can originally relay n ‚àí 1 descriptions
with sequence dropping now can provide only n ‚àí 2
descriptions with m-dropping by m equal to 2. That
is, the average numbers of buffered descriptions in
a peer with sequence dropping and m-dropping are
(n ‚àí 1)/(n √ó (n ‚àí 1)) and (n ‚àí 2)/(n √ó (n ‚àí 1)), respec-
tively. Comparing to sequence dropping, the reduction
of service availability is 1/(n √ó (n ‚àí 1)) but saving n ‚àí 1
times of buffer adjustments of descriptions. Based on
the analysis of the previous example, we may establish
the mathematical relationships between the value of m
in m-dropping policy and service availability.
Lemma 1 Compared to sequence dropping, the reduced
number of buf fer adjustments of descriptions for a peer
with m-dropping is,
 n‚àí1m ‚àí1‚àë
i=0
m‚àí1‚àë
j=1
(n ‚àí j ‚àí mi), 0 < m < n.
(a)
(b)
Fig. 6 The time line of service availability for n equal to 8 with sequence dropping and m-dropping, m = 2. a Sequence dropping.
b M-dropping, m = 2
Peer-to-Peer Netw. Appl.
Table 2 The reduced number
of the average number
selectable descriptions
for various n, m
We start with the statement S(6) and find that
S(6) :
1‚àë
i=0
1
(6 ‚àí 2i) (5 ‚àí 2i) =
1
6 √ó 5 +
1
4 √ó 3
= 2
6 √ó 5 +
1
5 √ó 4
=
1‚àë
j=0
2 ‚àí j
(6 ‚àí j) (5 ‚àí j) .
So S(6) is true. Now we assume the truth of S(a),
for some (particular) a = 2k, where k ‚àà N+ and k > 3.
That is,
a
2 ‚àí2‚àë
i=0
1
(a ‚àí 2i) (a ‚àí 2i ‚àí 1) =
a
2 ‚àí2‚àë
j=0
a
2 ‚àí j ‚àí 1
(a ‚àí j) (a ‚àí j ‚àí 1)
is a true statement (when n is replaced by a). From this
assumption we want to deduce the truth of
S(a + 2) :
a
2 ‚àí1‚àë
i=0
1
(a ‚àí 2i + 2) (a ‚àí 2i + 1)
=
a
2 ‚àí1‚àë
j=0
a
2 ‚àí j
(a ‚àí j + 2) (a ‚àí j + 1) .
Using the induction hypothesis S(a), we find that
a
2 ‚àí1‚àë
i=0
1
(a ‚àí 2i + 2) (a ‚àí 2i + 1)
=
a
2 ‚àí2‚àë
i=‚àí1
1
(a ‚àí 2i) (a ‚àí 2i ‚àí 1)
=
a
2 ‚àí2‚àë
i=0
1
(a ‚àí 2i) (a ‚àí 2i ‚àí 1) +
1
(a + 2) (a + 1)
=
a
2 ‚àí2‚àë
j=0
a
2 ‚àí j ‚àí 1
(a ‚àí j) (a ‚àí j ‚àí 1)
+
( a
2
(a + 1) (a) +
a
2 + 1
(a + 2) (a + 1)
‚àí 1( a
2 + 2
) ( a
2 + 1
) ‚àí 1( a
2 + 2
) + 1
(a + 2)
)
=
a
2 ‚àí2‚àë
j=0
a
2 ‚àí j ‚àí 1
(a ‚àí j) (a ‚àí j ‚àí 1)
‚àí
(
1
( a
2 + 2
) ( a
2 + 1
) ‚àí
a
2
(a + 1) (a)
‚àí
a
2 + 1
(a + 2) (a + 1) +
1
(a + 2) ‚àí
1
( a
2 + 2
)
)
Peer-to-Peer Netw. Appl.
to
‚åä n
2(i+1)
‚åã
/(
‚åä n
2i
‚åã
(
‚åä n
2i
‚åã ‚àí 1)) with binary dropping, a
reduction of service availability of (
‚åä n
2i
‚åã ‚àí ‚åä n2(i+1)
‚åã ‚àí
1)/(
‚åä n
2i
‚åã
(
‚åä n
2i
‚åã ‚àí 1)). Because a peer discards ‚åà c2
‚åâ
de-
scriptions when c equals to 3,
‚åä
log2
n
3
‚åã + 1 represents
the number of
‚åà c
2
‚åâ
descriptions discarded, and for
each discarding the reduction of service availability is
‚åä
n
2i
‚åã
‚àí
‚åä
n
2(i+1)
‚åã
‚àí1‚àë
j=1
‚åä
n
2i
‚åã
‚àí
‚åä
n
2(i+1)
‚åã
‚àí j
(
‚åä
n
2i
‚åã
‚àí j+1)
(‚åä
n
2i
‚åã
‚àí j
) , as shown in Lemma 6.
4 Experimental results and analysis
In this section, we present the experimental results of
sequence dropping, m-dropping, and binary dropping
policies and provide insightful analysis on the accumu-
lated reduction of buffer adjustment of descriptions,
service availability, and the reduction of service avail-
ability. It is noted that these experimental results were
derived from MATLAB without real system imple-
mentation. Lemmas of 1 to 6 were input into MATLAB
to observe the performance of proposed dropping poli-
cies of dynamic buffering. Only the service availability
of a peer was studied and there was no simulation
topology involved.
Figure 7 shows the accumulated reduction of buffer
adjustment of descriptions for m-dropping and binary
dropping policies for various number of receiving de-
scriptions, compared to sequence dropping. The se-
Fig. 7 The accumulated reduction of buffer adjustments for var-
ious number of receiving descriptions with description dropping
policies
quence dropping serves as the baseline for comparison,
and therefore has a reduction of zero. As shown in
figure, the accumulated reduction of buffer adjustment
of descriptions for m-dropping and binary dropping
increases along with the increase of the number of
receiving descriptions. The binary dropping has the
most accumulated reduction of buffer adjustment of
descriptions, followed by the m-dropping, m = ‚åà n2
‚åâ
and
m-dropping, m = 2. With the number of receiving de-
scriptions n = 32, it is notable that the binary dropping
has 28% and 84% more on accumulated reduction of
buffer adjustment of descriptions, respectively. Binary
dropping and m-dropping, m = ‚åà n2
‚åâ
discard one half
of the number of receiving descriptions at first time
of buffer adjustment and intuitively have greater accu-
mulated reduction of buffer adjustment of descriptions
than m-dropping, m = 2.
Figure 8 shows the average number of selectable
descriptions for various number of receiving descrip-
tions with description dropping policies. The average
number of selectable descriptions for the three descrip-
tion dropping policies increases along with the number
of receiving descriptions. As expected, the sequence
dropping and the binary dropping have the most and
the least average number of selectable descriptions.
The average number of selectable descriptions for m-
dropping is between that for sequence dropping and
binary dropping, but the average number of selectable
descriptions m-dropping, m = ‚åà n2
‚åâ
is closer to that of
Fig. 8 The average number of selectable descriptions for vari-
ous number of receiving descriptions with description dropping
policies
Peer-to-Peer Netw. Appl.
detailed information of how to select a description to
drop in dynamic buffering scheme, please refer to [22].
It is noted that this process requires the involvement of
P2P system statistics kept in a streaming server. Such a
centralized scheme for global maximization of system
throughput has been proven in much research work as
a feasible solution on P2P streaming networks, such as
[22, 28, 29].
In the future, we plan to extend our model to cope
with the dynamic join of peers for other extended ver-
sions of dynamic buffering, such as balanced dynamic
buf fering [22]. Performance measures on a more practi-
cal experimental platform will be reported in our future
publication.
Acknowledgements This work was partially supported by Na-
tional Science Council under contracts NSC 100-2221-E-024-006
and NSC 100-2815-C-024-008-E.
References
1. Androutsellis-Theotokis S, Spinellis D (2004) A survey of
peer-to-peer content distribution technologies. ACM Com-
put Surv 36(4):335‚Äì371
2. Stoica I, Morris R, Liben-Nowell D, Karger DR, Kaashoek
MF, Dabek F, Balakrishnan H (2003) Chord: a scal-
able peer-to-peer lookup protocol for internet applications.
IEEE/ACM Netw 11(1):17‚Äì32
3. Rowstron A, Druschel P (2001) Pastry: scalable, distributed
object location and routing for large-scale peer-to-peer sys-
tems. In: ACM conference on distributed systems, pp 329‚Äì
350
4. Ripeanu M (2001) Peer-to-peer architecture case study:
Gnutella network. In: Proceedings of IEEE P2P
5. Schollmeier R (2001) A definition of peer-to-peer network-
ing for the classification of peer-to-peer architectures and
applications. In: First international conference on peer-to-
peer computing, 2001. Proceedings, pp 101‚Äì102
6. Castro M, Druschel P, Kermarrec AM, Nandi A, Rowstron
A, Singh A (2003) Splitstream: high-bandwidth multicast in
cooperative environments. In: Proc. of ACM symposium on
operating system principles, pp 298‚Äì313
7. Cui Y, Nahrstedt K (2003) Layered peer-to-peer streaming.
In: Proceedings of ACM NOSSDAV, pp 162‚Äì171
8. Do TT, Hua KA, Tantaoui MA (2004) P2vod: providing
fault tolerant video-on-demand streaming in peer-to-peer
environment. In: Proc. of IEEE communications, pp 1467‚Äì
1472
9. Guo Y, Suh K, Kurose J, Towsley D (2003) P2cast: peer-
to-peer patching scheme for vod service. In: Proc. of ACM
WWW, pp 301‚Äì309
10. Kusmierek E, Dong Y, Du DH (2006) Loopback: exploiting
collaborative caches for large-scale streaming. IEEE Trans
Multimedia 8(2):233‚Äì242
11. Jin S, Bestavros A (2002) Cache and relay streaming me-
dia delivery for asynchronous clients. In: Proc. international
workshop on networked group communication (NGC02),
Boston, MA, USA
12. Cui Y, Li B, Nahrstedt K (2004) Ostream: asynchronous
streaming multicast in application-layer overlay networks.
IEEE J Sel Areas Commun (JSAC) 22:91‚Äì106
13. Dan A, Sitaram D, Shahabuddin P (1994) Batching: schedul-
ing policies for an on-demand video server with batching.
In: ACM conference on multimedia, pp 15‚Äì23
14. Hua KA, Cai Y (1998) Patching: a multicast technique
for true video-on-demand services. In: Proc. of ACM MM,
pp 191‚Äì200
15. Hu A (2001) Video-on-demand broadcasting protocols: a
comprehensive study. In: IEEE INFOCOM, pp 508‚Äì517
16. Goyal VK (2001) Multiple description coding: compression
meets the network. IEEE Signal Process Mag 18(5):74‚Äì93
17. Lu Z, Pearlman WA (1998) An efficient, low-complexity au-
dio coder delivering multiple levels of quality for interactive
application. In: Proc. of IEEE multimedia signal, pp 529‚Äì534
18. Albanese A, Blomer J, Edmonds J, Luby M, Sudan M
(1996) Priority encoding transmission. IEEE Trans Inf The-
ory 42(6):1737‚Äì1744
19. Wand Y, Reibman AR, Lin S (2005) Multiple description
coding for video delivery. In: Proc. of the IEEE, pp 57‚Äì70
20. Tan X, Datta S (2005) Building multicast trees for multimedia
streaming in heterogeneous P2P networks. In: IEEE systems
communications, pp 141‚Äì146
21. Lin C-S (2010) Improving the availability of scalable on-
demand streams by dynamic buffering on P2P networks. KSII
Trans Int Inf Syst (TIIS) 4(4):491‚Äì508
22. Lin C-S, Wang G-S (2011) Balanced dynamic buffering for
scalable P2P video-on-demand streaming with multiple de-
scription coding. In: The fifth international conference on
complex, intelligent, and software intensive systems (CISIS-
2011), Korea
23. Bernardini R, Durigon M, Rinaldo R, Celetto L, Vitali A
(2004) Polyphase spatial subsampling multiple description
coding of video streams with h264. In: Proc. of IEEE in-
ternational conference on image processing, vol 5, pp 3213‚Äì
3216
24. Campana O, Milani S (2004) A multiple description coding
scheme for the h.264/avc coder. In: Proc. of the international
conf. on telecommunication and computer networks, pp 191‚Äì
195
25. Apostolopoulos J (2001) Reliable video communication over
lossy packet networks using multiple state encoding and path
diversity. In: Proc. of visual communications: image process-
ing, pp 392‚Äì409
26. Zandon‚Äòa N, Milani S, De Giusti A (, .) Motion-compensated
multiple description video coding for theh.264/avc standard.
In: Proc. of IADAT international conf. on multimedia, image
processing and computer vision, pp 290‚Äì294
27. Ding Y, Liu J, Wang D, Jiang H (2010) Peer-to-peer video-
on-demand with scalable video coding. Comput Commun
33(14):1589‚Äì1597
28. Padmanabhan VN, Wang HJ, Chou PA, Sripanidkulchai
K (2002) Distributing streaming media content using coop-
erative networking. In: ACM conference on NOSSDAV,
pp 177‚Äì186
29. Lin C-S ( 2011) Enhancing P2P live streaming performance
by balancing description distribution and available forward-
ing bandwidth in P2P streaming network. Int J Commun Syst
24(4):568‚Äì585
Âá∫Â∏≠ÂúãÈöõÂ≠∏Ë°ìÊúÉË≠∞ÂøÉÂæóÂ†±Âëä 
                                                             
Ë®àÁï´Á∑®Ëôü NSC 100-2221-E-024-006- 
Ë®àÁï´ÂêçÁ®± Âà©Áî®ÂãïÊÖãÁ∑©Ë°ùÊèêÂçáÂêåÂÑïÁ∂≤Ë∑ØÂèØË™øÂºèÂ™íÈ´î‰∏≤ÊµÅ‰πãÂèØÂæóÊÄßÂèäÂ†ÖÈüåÊÄß 
Âá∫Âúã‰∫∫Âì°ÂßìÂêç 
ÊúçÂãôÊ©üÈóúÂèäËÅ∑Á®± 
ÊûóÊúùËàà (Chow-Sing Lin), ÊïôÊéà 
ÂúãÁ´ãÂè∞ÂçóÂ§ßÂ≠∏ Ë≥áË®äÂ∑•Á®ãÁ≥ª 
ÊúÉË≠∞ÊôÇÈñìÂú∞Èªû ‰∏≠ÂúãÈõ≤ÂçóÊòÜÊòé, 8/5 ~ 8/12, 2012 
ÊúÉË≠∞ÂêçÁ®± 
ChinaCom 2012 & International Workshop on Intelligent Multimedia 
Computing and Communications 
ÁôºË°®Ë´ñÊñáÈ°åÁõÆ 
Design and Implementation of Streaming Scalable H.264/AVC Videos with 
Loopback-MDC on Peer-to-Peer Networks 
 
 
The International Workshop on Intelligent Multimedia Computing and Communications (IWIMCC) 
was held at, Kunming, Yunnan, China in conjunction with ChinaCom 2012 on 8/7 ~ 8/10, 2012.  It 
provides a premium forum for discussions among leading experts from the academia and industry 
about hot topics of research and development in the emerging field of intelligent multimedia 
computing and communications. We solicit high quality technical papers that describe original and 
unpublished research on intelligent multimedia computing and communication. I also served as the 
Program Chair for the IWIMCC. 
 
 The IWIMCC was a one-day workshop on Aug. 7, 2012 and had two sessions, one in the 
morning and the other in the afternoon. Our paper, ‚ÄúDesign and Implementation of Streaming 
Scalable H.264/AVC Videos with Loopback-MDC on Peer-to-Peer Networks,‚Äù was arranged to 
orally present in the first session of IWIMCC. Four papers were organized to present in this session. 
In addition to our paper, they are ‚ÄúLaplacian-Based H.264 Intra-Prediction Mode Decision,‚Äù by 
Chi-Chou Kao  et al., ‚ÄúA Joint Consideration of Channel Assignment and Multicast Routing in 
MCMR WMNs,‚Äù by Wen-Lin Yang et al, and ‚ÄúAdaptive Digital Video Transmission with STBC 
over Rayleigh Fading Channels,‚Äù by Jia-Chyi Wu et al. After my presentation, there are a couple of 
questions for our proposed scheme. It was pleasant to exchange some research ideas with other 
international scholars. I also attended the afternoon session of IWIMCC, and there were also four 
papers presented. There was one paper, ‚ÄúCloud-based H.264-SVC Transcoder Design for Video 
Conferencing System,‚Äù closely related to my research field. After the presentation, I asked a couple 
of questions about the details of real time transcoding in the cloud. The discussion inspired me to 
further extend my on-going research work by utilizing the state-of-art technology of cloud 
computing. There were a lot of papers related to LTE presented in ChinaCom 2012. The next 
generation (4G) of communication technology will LTE obvious will be prevailed in the next few 
years. We should be aware of how to efficiently apply mobile streaming on LTE communication 
technology. 
Design and Implementation of Streaming Scalable
H.264/AVC Videos with Loopback-MDC on
Peer-to-Peer Networks
Chow-Sing Lin‚àó and Rong-Hua Chang
‚àóDept. of Computer Science and Information Engineering,
National University of Tainan
33, Sec. 2, Shu-Lin St, Tainan 700, Taiwan (R.O.C.)
Email:mikelin@mail.nutn.edu.tw
Abstract‚ÄîWith the rapidly development of broadband net-
works, more and more users nowadays tend to acquire their
desired videos from media-on-demand servers. How to effi-
ciently provide multimedia contents for a large number of
heterogeneous users on the Internet has become a noticeable
issue. In our previous work, we proposed the Loopback-MDC
scheme on CDN-P2P network to address such a scalability issue.
In this paper, we present the design and implementation of
a novel peer-to-peer streaming system with Loopback-MDC,
named TuBeck, on actual networks. We functionally divide the
TuBeck into Preprocessor, Server, Peer, LM Protocol and Network
Infrastructure Library working modules. In TuBeck, multimedia
sources are preprocessed to multiple description as a sequence
of H.264/AVC chunks for real-time streaming. The network
infrastructure library provides nodes (server and peers) with the
fundamental functionality of network connections and commu-
nications. Message exchange and streaming control among nodes
follow the pre-defined LM protocol. The experimental results
successfully showed the superiorly of TuBeck with Loopback-
MDC in reducing server loading on practical applications.
Keywords‚ÄîStreaming, Peer-to-Peer, Multiple Description Cod-
ing, Loopback-MDC, H.264
I. INTRODUCTION
The main concern of a media server is to maintain high
scalability so that when a great number of requests suddenly
arrive at a media server, such as the time during the 911
attack in U.S., the system can still serve each request within a
reasonable delay without breakdown. It challenges the network
bandwidth in a media system to accommodate such bursty re-
quests. To effectively address this issue, multicast techniques,
such as batching [1] and patching [2], have been theoretically
considered as effective approaches to scale well with the
increase in the number of clients. However, due to lack of
multicast capability on current IP network, such schemes are
difficult to implement to accommodate large-scale operations.
Content Distribution Network (CDN), on the other hand, is
based on placing a number of proxy servers at the edges
of the Internet. Video contents are first distributed to these
proxy servers and then delivered by each server to clients in
its neighborhood.
In addition, a P2P approach, where peers collaborate with
one another to reduce server loading, provides a feasible
solution for the scalability issue. It has recently become a
popular alternative to CDN to cope with the growing demand
of the end users [3]. In a P2P scheme a peer not only acts as
a client to receive services but also as a server to forward
services to other peers. As more and more peers join the
network, the aggregate peer resources raises the capacity of
a P2P system, which effectively addresses the flash crowd
problem. In addition, many initiatives have demonstrated the
feasibility of combining the CDN and P2P approaches to gain
the scalability advantage of P2P as well as the reliability and
manageability advantages of CDNs [4]. Such a hybrid CDN-
P2P scheme is a cost-effective approach to provide large scale
media steaming on the Internet.
It is suggested that the deployment and maintenance of a
CDN server [4], [5] is quite expensive. Since a proxy server
often has limited resources and may be unable to cache an
entire video, a prefix of a video is usually cached [5], [6].
With only caching the partial video in the proxy server, it is
crucial to effectively utilize buffer space of clients watching
the same video to help caching the rest of video segments
for circulating the entire video stream in order to reduce the
server interventions. In Loopback [5], the client collaboration
to complement proxy caching is exploited. Clients arriving
closely form a forwarding loop, like chaining [2], with the first
client receiving video segments from a proxy and the last client
returning segments to the proxy. A video stream is forwarded
from one client to the next within a loop in the order of their
arrivals. Even if resources contributed by clients are limited,
the Loopback scheme has shown the significant reduction in
the storage space and bandwidth requirements of the proxy
and the loads of central server. Despite its superiority, in
the Loopback only a single version, non-scalable stream is
assumed. As a result, it would fail to handle the heterogeneity
of clients where clients have various downloading capability
and require different viewing quality.
Recent studies have shown that the multiple description
coding (MDC) technique [7], [8] can be adopted to solve the
issues of Asymmetric Access Link, Heterogeneity, Dynamics
and Resource Utilization in P2P systems defined in [9]. It is
a scalable coding technique and encodes a video into several
Fig. 1. System Architecture of TuBeck.
Fig. 2. Data flow of preprocessing video sources.
chroma subsampling 4:2:2, each U and V component whose
amount is only half of the amount of Y component needed
to be evenly distributed to descriptions by SMDC as well.
Figure 3 shows an example of SMDC for evenly coding a
4 √ó 4 frame in YUV format with 4:2:2 chroma subsampling
into 4 descriptions. As shown in the figure, each description
is encoded into 2 √ó 2 frame with luminance samples of four
(Y) , chrominance samples of two U and two V.
IV. SERVER AND PEER MODULES
In TuBeck, the server module provides functionalities of
stream management, network delivery, P2P topology, and
resource management. Figure 4 shows the function blocks
of server module which are Stream Control Management
(SCM), Resource Management, P2P Topology, and Stream
Transmitter. In SCM the service accepter is responsible for
accepting a new connection and spawning a peer handler (PH)
to provide consequent services, such as available source peers,
based on LM protocol. Those PHs are managed under the peer
handler collection (PHC). In case a peer is left expectedly or
unexpectedly, its corresponding PH is removed by PHC. The
recovery processor is responsible for processing intra-d and
inter-d recoveries with the aid of P2P topology for reconstruct-
ing peer connectivity. In P2P topology, loops in the system
are managed as a loop list by the loop provider. Each loop is
Fig. 3. An example of SMDC for coding a 4 √ó 4 frame in YUV format
with 4:2:2 chroma subsampling into 4 descriptions.
represented as a allotment list managed by allotment provider.
an allotment is the abstract entity of a peer which contains
the information of peer id, requested description id and video
id, and the first and the last received chunk ids in buffer. In
resource management video files are managed and indexed
Fig. 4. The function blocks of server module.
 0
 10
 20
 30
 40
 50
 60
 70
 80
 90
 100
 2  4  6  8  10  12  14
S e
r v
e r
/ p
r o
x y
 l o
a d
i n
g  
( %
)
Arrival rate (peers/minute)
Server/proxy loading with intra/inter-d recovery
Server/proxy loading without intra/inter-d recovery
(a)
 0
 10
 20
 30
 40
 50
 60
 70
 80
 90
 100
 0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9
S e
r v
e r
/ p
r o
x y
 l o
a d
i n
g  
( %
)
Failure rate (failure peers/arrival peer)
Server/proxy loading with intra/inter-d recovery
Server/proxy loading without intra/inter-d recovery
(b)
 0
 10
 20
 30
 40
 50
 60
 70
 80
 90
 100
 2  4  6  8  10  12  14
S e
r v
e r
/ p
r o
x y
 l o
a d
i n
g  
( %
)
Quality (descriptions/peer)
Server/proxy loading with intra/inter-d recovery
Server/proxy loading without intra/inter-d recovery
(c)
Fig. 7. The server/proxy loading with/without intra/inter-d recovery for Loopback-MDC
Fig. 6. The emulation environment for the performance study of TuBeck.
failure rate increases, the loading of both schemes increases as
shown in Fig. 7(b). Again, the loopback-MDC with intra/inter-
d recovery would have lower server loading then the other
scheme. The largest difference 18.8% happened at failure rate
equal to 0.6. The difference of loading for the two schemes get
smaller when failure rate is beyond 0.7. Figure 7(c) shows the
server loading of loopback-MDC with intra/inter-d recovery
decreases along with the increase of viewing quality. The
one without intra/inter-d recovery appears to consistently react
to the increase of viewing quality. In general, the one with
intra/inter-d recovery has average 15.9% more than the other
one, and the largest difference of loading for the two schemes
reaches 22.3% at arrival rate equal to 14 as Fig. 7(a) shown.
VII. CONCLUSION
In this paper, we introduce the design and implementa-
tion of a P2P streaming system with Loopback-MDC with
H.264/AVC videos, named TuBeck. System architecture, pre-
processing of media sources into MDC, server module, peer
module are presented in details. In addition, we deployed the
experiment to observe the characteristics of TuBeck in real
network infrastructure. The experimental results successfully
showed the superiority of TuBeck with Loopback-MDC in
reduction server loading on practical applications. Due to lim-
ited space, we postpone the detailed design, implementation,
and performance study of video player for TuBeck to a future
publication.
ACKNOWLEDGMENT
This work was partially supported by National Science
Council under contracts NSC 97-2221-E-024-014-MY3.
REFERENCES
[1] S. Sheu, K. A. Hua, , and W. Tavanapong, ‚ÄúChaining: A generalized
batching technique for video-on-demand,‚Äù in Proceedings of IEEE
International Conference on Multimedia Computing and Systems ‚Äô97,
August 1997, pp. 110‚Äì117.
[2] K. A. Hua, Y. Cai, and S. Sheu, ‚ÄúPatching: A multicast technique
for true video-on-demand services,‚Äù in Proceedings of the Sixth ACM
International Conference on Multimedia, September 1998, pp. 191‚Äì200.
[3] D. A. Tran, K. A. Hua, and T. Do, ‚ÄúZigzag: An efficient peer-to-
peer scheme for media streaming,‚Äù in Twenty-Second Annual Joint
Conference of the IEEE Computer and Communications, April 2003.
[4] D. Xu, S. S. Kulkarni, C. Rosenberg, and H. K. Chai, ‚ÄúA cdn-p2p hybrid
architecture for cost-effective streaming media distribution,‚Äù Computer
Networks, vol. 44, no. 3, pp. 353‚Äì382, 2004.
[5] E. Kusmierek, Y. Dong, and D. H. C. Du, ‚ÄúLoopback: Exploiting
collaborative caches for large-scale streaming,‚Äù IEEE Transactions on
Multimedia, vol. 8, no. 2, pp. 233‚Äì242, 2006.
[6] W. Ma and D. H. C. Du, ‚ÄúReducing bandwidth requirement for deliver-
ing video over wide area networks with proxy server,‚Äù IEEE Trans. on
Multimedia, vol. 4, no. 4, pp. 539‚Äì550, Dec. 2002.
[7] V. K. Goyal, ‚ÄúMultiple description coding: Compression meets the net-
work,‚Äù IEEE Signal Processing Magazine, vol. 18, pp. 74‚Äì93, September
2001.
[8] H.-H. Bai, A.-H. Wang, Y. Zhao, J.-S. Pan, and A. Abraham, Dis-
tributed Multiple Description Coding: Principles, Algorithms and Sys-
tems. Springer-Verlag New York Inc., 2011.
[9] C.-S. Lin, W.-T. Syu, and I.-T. Lee, ‚ÄúImproving the scalability of p2p
streaming based on fine-grained balancing scheme,‚Äù in Proc. of the IEEE
22nd International Conference on Advanced Information Networking
and Applications (AINA2008), March 2008, pp. 795‚Äì802.
[10] C.-S. Lin, ‚ÄúEnhancing p2p live streaming performance by balancing de-
scription distribution and available forwarding bandwidth,‚Äù International
Journal of Communication Systems, vol. 24, no. 5, pp. 568‚Äì585, 2011.
[11] C.-S. Lin and I.-T. Lee, ‚ÄúApplying multiple description coding to
enhance the streaming scalability on cdn-p2p network,‚Äù International
Journal of Communication Systems, vol. 23, no. 5, pp. 553‚Äì568, May
2010.
[12] Joint Video Team (JVT) of ISO/IEC MPEG & ITU-T VCEG, ‚ÄúJoint
model (jm) - h.264/avc reference software,‚Äù ver. 18.0. [Online].
Available: http://iphome.hhi.de/suehring/tml/
[13] O. Campana, A. Cattani, A. D. Giusti, S. Milani, N. Zandona, and
G. Calvagno, ‚ÄúMultiple description coding schemes for the h.264/avc
coder,‚Äù in Proceedings of the International Conference on Wireless
Recognizable Terminals and Protocols, May 2006, pp. 217‚Äì221.
Data Systems Lab @ NUTN 
/30 
Outline 
Chow-Sing Lin 
ÔÇó Introduction 
ÔÇó P2P Streaming 
ÔÇó MDC 
ÔÇó Loopback-MDC 
ÔÇó System Architecture of  TuBeck 
ÔÇó Preprocess of  Multimedia Sources 
ÔÇó Server Module 
ÔÇó Peer Module 
ÔÇó Player 
ÔÇó LM Protocol 
ÔÇó Performance Study 
ÔÇó Conclusion 
1 
Data Systems Lab @ NUTN 
/30 
C.-S. Lin 3 
Peer Heterogeneity 
ÔÇó There are peers with different connection types in P2P 
networks. 
Download bandwidth high low 
Data Systems Lab @ NUTN 
/30 
C.-S. Lin 5 
Versioned Streaming 
ÔÇó The server encodes media into streams with different 
bitrates, each for a specific connection type. 
Data Systems Lab @ NUTN 
/30 
C.-S. Lin 7 
Scalable Video Coding 
ÔÇó Layered Encoding 
ÔÇó Layers are decoded dependently  
 
ÔÇó Multiple Description Coding 
ÔÇó Descriptions are decoded independently  
 
Data Systems Lab @ NUTN 
/30 
C.-S. Lin 9 
Layered Encoding (cont‚Äô) 
ÔÇó Account for heterogeneous capability 
ÔÇó Enable progressive quality enhancement 
Layer li can be decoded only if  layers l0 through li-1 are available. 
decoded 
encoded 
Enhancement Layer (lm) 
Base Layer (l0) 
Enhancement Layer (l2) 
‚Ä¶
 
Enhancement Layer (l1) 
The more layers decoded, the better quality perceived. 
Data Systems Lab @ NUTN 
/30 
Multiple Description Coding (MDC) 
Chow-Sing Lin 
ÔÇó A flexible coding technique provides for progressive 
quality enhancement. 
ÔÇó MDC is originated from the Bell Lab for preserve voice 
quality from hardware failure. 
‚Ä¶
 
encoded 
Description 1 
Description 2 
Description n 
decoded 
The streaming content can be encoded into 
 a set of  independent sub-stream, called descriptions. 
Any subset of  descriptions ca  be decoded  
to reco struct the original presentation. 
11 
Data Systems Lab @ NUTN 
/30 
Loopback-MDC 
Chow-Sing Lin 
ÔÇó The Loopback-MDC applied the MDC technique and 
cache management for CDN-P2P streaming networks. 
Peer left Failur  recovery Local Network 
Proxy 
Peer 
Server 
13 
Which descriptions to be selected to 
receive ? 
‚Ä¢ Open-Loop-First (OLF) 
Loopback-MDC recovers missing gap due 
to parent peer failure by failure recovery 
including inter/intra description recovery 
Loopback caching  
Data Systems Lab @ NUTN 
/30 
Preprocess of  Multimedia Sources 
ÔÇó Video sources were acquired and pre-processed into four 
descriptions by SMDC in format of  H.264 chunks. 
YUV video source 
SMDC 
JM encoder 
JM encoder 
JM encoder 
JM encoder 
YUV 
YUV 
YUV 
YUV 
H.264 
H.264 
H.264 
H.264 
Description 1 
Disk Array 
Description 4 
Description 3 
Description 2 
15 
Data Systems Lab @ NUTN 
/30 
Internet
System Architecture of  TuBeck 
Chow-Sing Lin 
ÔÇó System Architecture of  TuBeck is functionally divided 
into following modules 
Server 
Player 
LM Protocol 
Network Infrastructure Library 
(NI Library) 
Peer 
Player 
Peer 
Disk Array 
‚Ä¢ Stream Transmitter 
‚Ä¢ Stream Control Management 
‚Ä¢ P2P Topology 
‚Ä¢ Resource Management 
‚Ä¢ Stream Control Management 
‚Ä¢ Resource Management 
‚Ä¢ Stream Receiver 
‚Ä¢ Stream Relay 
Communications between server and peer 
foll ws L  protocol 
Common functions for server and peer 
modules 
‚Ä¢ Data Management 
‚Ä¢ Network Connection 
‚Ä¢ Utilities 
‚Ä¢ JM H.264 decoder 
‚Ä¢ SMDC Merge  
‚Ä¢ Renderer 
17 
‚Ä¶ 
Data Systems Lab @ NUTN 
/30 
Architecture of  Peer Module 
Chow-Sing Lin 
Resource Management 
Chunk Provider 
‚Ä¶ 
Chunk Table 
Description 
Provider 
‚Ä¶ 
Description Table 
Video Provider 
‚Ä¶ 
Video Index 
Stream Handler 
Collection 
‚Ä¶ 
Stream Handlers 
H.264 
Chunks 
Stream 
Request 
Accepter 
‚Ä¶ 
Stream 
Handler 
N
ew
 C
o
n
n
ec
ti
o
n
 
Stream Relay 
Request Handler 
Collection 
‚Ä¶ 
Request Handlers 
H.264 
Chunks 
Service 
Connector 
Stream 
Receiver 
Stream Control Management 
Recovery Requester 
Intra-description 
Recovery 
Inter-description 
Recovery 
Failure 
Recovery 
Requesting 
Connectivity 
LM Protocol 
19 
Data Systems Lab @ NUTN 
/30 
MDC Player Snapshot 
O
n
e 
d
es
cr
ip
ti
o
n
s 
T
w
o
 d
es
cr
ip
ti
o
n
s 
T
h
re
e 
d
es
cr
ip
ti
o
n
s 
F
o
u
r 
d
es
cr
ip
ti
o
n
s 
26.66dB 
31.31dB 
27.58dB 
33.63dB 
21 
Data Systems Lab @ NUTN 
/30 
Performance Study 
Chow-Sing Lin 
ÔÇó Emulated experiment settings 
 
 
 
 
 
 
ÔÇó Each run last 10 minutes with loop-playing the video 
sequence. 
Parameter Values Distribution 
Arrival rate (peers /minute) 2, 4, 6, 8, 10, 12, 14 Poisson 
Failure rate (failure peers/arrival 
peer) 
0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9 Uniform 
Adaptability (descriptions/video) 16 - 
Quality (descriptions/ peer) 2, 4, 6, 8, 10, 12, 14 Normal 
Buffer space (minute) 0.5 Uniform 
23 
Data Systems Lab @ NUTN 
/30 
Performance Study (cont.) 
Chow-Sing Lin 
ÔÇó The performance of  Loopback-MDC with/without 
intra/inter-d recovery was measured for comparison. 
 
ÔÇó Server/proxy loading: 
ùë†
ùë† + ùëù
√ó 100% 
ÔÇó ùë†: the number of  descriptions server totally outputs 
ÔÇó ùëù: the number of  descriptions peers totally output 
25 
Data Systems Lab @ NUTN 
/30 
Performance Study (cont.) 
Chow-Sing Lin 
ÔÇó As failure rate increases, the loopback-MDC with 
intra/inter-d recovery would have lower server loading 
then the other scheme. 
27 
Data Systems Lab @ NUTN 
/30 
Conclusion 
Chow-Sing Lin 
ÔÇó Design and implementation of  a P2P streaming system 
with Loopback-MDC for H.264/AVC videos, named 
TuBeck 
ÔÇó Pre-processing of  media sources 
ÔÇó Server module,  peer module, and NI Library 
ÔÇó H.264/AVC-compatible  MDC player 
ÔÇó LM protocol 
 
ÔÇó Emulated experiment showed the superiority of  TuBeck 
on reduction server loading with respect to various 
arrival rates, failure rates, and view qualities. 
29 
ÂúãÁßëÊúÉË£úÂä©Ë®àÁï´Ë°çÁîüÁ†îÁôºÊàêÊûúÊé®Âª£Ë≥áÊñôË°®
Êó•Êúü:2012/12/14
ÂúãÁßëÊúÉË£úÂä©Ë®àÁï´
Ë®àÁï´ÂêçÁ®±: Âà©Áî®ÂãïÊÖãÁ∑©Ë°ùÊèêÂçáÂêåÂÑïÁ∂≤Ë∑ØÂèØË™øÂºèÂ™íÈ´î‰∏≤ÊµÅ‰πãÂèØÂæóÊÄßÂèäÂ†ÖÈüåÊÄß
Ë®àÁï´‰∏ªÊåÅ‰∫∫: ÊûóÊúùËàà
Ë®àÁï´Á∑®Ëôü: 100-2221-E-024-006- Â≠∏ÈñÄÈ†òÂüü: Ë®àÁÆóÊ©üÁ∂≤Ë∑ØËàáÁ∂≤ÈöõÁ∂≤Ë∑Ø
ÁÑ°Á†îÁôºÊàêÊûúÊé®Âª£Ë≥áÊñô
Â∞à‰ªªÂä©Ôß§ 0 0 100%  
ÂÖ∂‰ªñÊàêÊûú 
(ÁÑ°Ê≥ï‰ª•Ô•æÂåñË°®ÈÅî‰πã
ÊàêÊûúÂ¶ÇËæ¶Ôß§Â≠∏Ë°ìÊ¥ª
Âãï„ÄÅÁç≤ÂæóÁçéÈ†Ö„ÄÅÈáç
Ë¶ÅÂúãÈöõÂêà‰Ωú„ÄÅÁ†îÁ©∂
ÊàêÊûúÂúãÈöõÂΩ±ÈüøÔ¶äÂèä
ÂÖ∂‰ªñÂçîÂä©Áî¢Ê•≠ÊäÄË°ì
ÁôºÂ±ï‰πãÂÖ∑È´îÊïàÔ®ó‰∫ã
È†ÖÁ≠âÔºåË´ã‰ª•ÊñáÂ≠óÊïò
Ëø∞Â°´Ô¶ú„ÄÇ) 
ÁÑ° 
 ÊàêÊûúÈ†ÖÁõÆ Ô•æÂåñ ÂêçÁ®±ÊàñÂÖßÂÆπÊÄßË≥™Á∞°Ëø∞ 
Ê∏¨È©óÂ∑•ÂÖ∑(Âê´Ë≥™ÊÄßËàáÔ•æÊÄß) 0  
Ë™≤Á®ã/Ê®°ÁµÑ 0  
ÈõªËÖ¶ÂèäÁ∂≤Ô§∑Á≥ªÁµ±ÊàñÂ∑•ÂÖ∑ 0  
ÊïôÊùê 0  
ËàâËæ¶‰πãÊ¥ªÂãï/Á´∂Ë≥Ω 0  
Á†îË®éÊúÉ/Â∑•‰ΩúÂùä 0  
ÈõªÂ≠êÂ†±„ÄÅÁ∂≤Á´ô 0  
Áßë 
Êïô 
Ëôï 
Ë®à 
Áï´ 
Âä† 
Â°´ 
È†Ö 
ÁõÆ Ë®àÁï´ÊàêÊûúÊé®Âª£‰πãÔ•´ËàáÔºàÈñ±ËÅΩÔºâ‰∫∫Ô•© 0  
 
