å…±  é   ç¬¬ 2 é  
 
æ–‡ç»æ¢è¨ 
é—œè¯æ€§è³‡æ–™ä¸åƒ…æ˜¯ç¶²é æœå°‹ã€æ•´åˆçš„æ ¸å¿ƒæŠ€è¡“ï¼Œæ›´æ˜¯è¨±å¤šå…¶ä»–ç ”ç©¶é ˜åŸŸï¼Œä¾‹å¦‚ï¼šè‡ªç„¶èª
è¨€åˆ†æ (Embley et al. 1998, Bernstein et al. 2005, Pazienza et al. 2005, SÃ¡enz and Vaquero 
2005)ã€Question Answering (Harabagju et al. 2000, Mann 2002, Ravichandran and Hovy 2002)ã€
Machine Translation (Hovy 1998, Mahesh and Nirenburg 1996, Okumura and Hovy 1994)ä¸­çš„æ ¸
å¿ƒé—œéµï¼Œåœ¨é€™äº›é ˜åŸŸä¸­ï¼Œäº†è§£å­—è©ä¸­é–“çš„é—œè¯ä»¥åŠæ¦‚å¿µä¸­çš„é—œè¯æ˜¯éå¸¸é‡è¦çš„ï¼Œè€Œå¤§éƒ¨åˆ†çš„
ç ”ç©¶éƒ½æœƒåˆ©ç”¨ Ontology ä¾†ä½œç‚ºé—œè¯æ€§è³‡æ–™çš„æ ¼å¼ï¼ŒOntology (Klein et al. 2002, Klein and Fensel 
2001, Heflin and Hendler 2000, Smith and Christopher 2001, Benjamins et al. 1999, Gruber 2003) 
èƒ½å¤ è®“ä½¿ç”¨è€…åŠç³»çµ±å°æ–¼æŸå€‹æ¦‚å¿µã€å°ˆæ¥­é ˜åŸŸæœ‰è‘—é€šç›¤äº†è§£ï¼Œä½¿å¾—ä½¿ç”¨è€…èˆ‡ç³»çµ±ä¹‹é–“èƒ½å¤ æº
é€šé †åˆ©ã€‚ 
å› æ­¤æœ‰ç ”ç©¶å¸Œæœ›èƒ½é‡å° Ontology çš„ç¹è¤‡å»ºç½®æ­¥é©Ÿï¼Œåˆ©ç”¨ç³»çµ±è‡ªå‹•åŒ–çš„ç”¢ç”Ÿ Ontologyï¼Œä»¥
æ¸›å°‘äººåŠ›æŠ•æ³¨ã€åŠ é€Ÿ Ontology çš„å»ºç½®ã€‚å»ºç½® Ontology éœ€è¦å¹¾å€‹ä¸åŒçš„æ­¥é©Ÿï¼Œå¾åˆæœŸçš„æŒ‘é¸é ˜
åŸŸã€æŒ‘é¸è³‡æ–™ä¾†æºï¼›ä»¥åŠæ¥ä¸‹ä¾†è‡ªå‹•è¾¨è­˜å‡ºé ˜åŸŸé‡è¦è©å½™åŠè¾¨è­˜é—œä¿‚ (Alani et al. 2003a)ï¼›åˆ°
å¾ŒæœŸçš„è‡ªå‹•ç”¢ç”Ÿåˆ†é¡ã€ä»¥åŠæœ€å¾Œé€²è¡Œæ¼”åŒ–çš„æ­¥é©Ÿã€‚æ¯ä¸€é …æ­¥é©Ÿéƒ½æœ‰å…¶å›°é›£èˆ‡æŒ‘æˆ°ï¼Œå› æ­¤ç›®å‰
è‡ªå‹•åŒ–çš„ç ”ç©¶ï¼Œå¤šåŠéƒ½å°ˆæ³¨æ–¼æŸå€‹æ­¥é©Ÿçš„è‡ªå‹•åŒ–éç¨‹ï¼Œå°‘æœ‰èƒ½å¤ å…¨ç¨‹è‡ªå‹•åŒ–çš„ã€‚ 
ç›®å‰ç”šå°‘æœ‰ç ”ç©¶èƒ½å¤ é”åˆ°å®Œå…¨è‡ªå‹•åŒ–å»ºç½® Ontologyï¼Œå³ä½¿æœ‰ä¹Ÿæ˜¯åœ¨å°‘æ•¸çš„å›ºå®šé ˜åŸŸä¸Šï¼Œ
ä¾‹å¦‚ï¼šFuzzy Ontology (Widyantoro and Yen 2001)ï¼Œé€™å€‹ç ”ç©¶èƒ½è‡ªå‹•åŒ–çš„å°æ–¼è³‡æ–™å»ºç«‹æ¦‚å¿µå¢
é›† (Cluster)ï¼Œæ‰¾å‡ºé—œéµå­—ï¼Œå†ç‚ºé€™äº›é—œéµå­—å»ºç«‹é—œè¯ï¼Œä½†æ­¤ç ”ç©¶æ‰€åˆ©ç”¨çš„è³‡æ–™çš†æ˜¯ä¾†è‡ªæ–¼ IEEE 
transaction çš„è³‡æ–™ï¼Œæœ‰è‘—ç›¸ä¼¼çš„è³‡æ–™æ ¼å¼ï¼›å¦ä¸€æ–¹é¢ï¼Œå®ƒæ‰€ä½¿ç”¨çš„é—œä¿‚è¼ƒç‚ºç‰¹åˆ¥ï¼Œæ˜¯ç›´æ¥ä½¿
ç”¨æ•¸å­—ä¾†è¡¨é”ç›¸é—œç¨‹åº¦ï¼Œè€Œéè‡ªç„¶èªè¨€çš„æ–¹å¼ä¾†è¡¨é”ã€‚ä¹Ÿæœ‰ç ”ç©¶é‡å°æ™ºæ…§è²¡ç”¢æ–‡ä»¶ä¾†å»ºç«‹åœ–
ç¤ºæ¦‚å¿µçš„ Ontology (Yan and Soo 2008)ï¼Œä¹Ÿèƒ½åšåˆ°æ“·å–è³‡æ–™ã€é—œä¿‚çš„è‡ªå‹•åŒ–ã€‚ä½†æ‰€ä½¿ç”¨çš„è³‡æ–™
æ˜¯çµæ§‹æ˜é¡¯çš„è³‡æ–™ã€‚ 
ä»¥ä¸Šç ”ç©¶å¤§éƒ½æ˜¯è‘—é‡åœ¨ç‰¹å®šé ˜åŸŸï¼Œé¸å®šå›ºå®šé ˜åŸŸï¼Œå…¶å¯¦çš†æ˜¯åœ¨åŒå€‹é ˜åŸŸçŸ¥è­˜ä¸­è‡ªå‹•ç™¼å±•
Ontology çš„æ„æ€ã€‚å¯çœ‹å‡ºéå¾€å¾ˆå¤šè‡ªå‹•åŒ–å»ºç½® Ontology çš„ç ”ç©¶ï¼Œéƒ½æ˜¯ç”±å›ºå®šé ˜åŸŸçŸ¥è­˜é–‹å§‹ç™¼
å±•ã€‚è€Œåœ¨å›ºå®šé ˜åŸŸä¸­ï¼Œå…¶å¯¦æœ‰è‘—å›ºå®šå¸¸ç”¨è©å½™èˆ‡é—œä¿‚å½¢å¼ï¼Œç¨±ç‚ºé ˜åŸŸçŸ¥è­˜ã€‚é€™äº›é ˜åŸŸçŸ¥è­˜åˆ°
äº†åˆ¥çš„é ˜åŸŸç•¶ä¸­å¯èƒ½ç„¡æ³•é©ç”¨ã€‚å› æ­¤é›–ç„¶åœ¨é€™äº›ç ”ç©¶ä¸­ï¼Œæ‰€æå‡ºçš„æ–¹æ³•éƒ½èƒ½é”åˆ°ä¸éŒ¯çš„æ•ˆæœï¼Œ
å»ç„¡æ³•å½ˆæ€§åˆ°é‹ç”¨åˆ°å„é ˜åŸŸç•¶ä¸­ã€‚ 
è‡³æ–¼åœ¨åœ¨ä¸å›ºå®šé ˜åŸŸçŸ¥è­˜çš„å•é¡Œä¸Šï¼Œæˆ‘å€‘ä¸¦æ²’æœ‰æ‰¾åˆ°ä»»ä½•çš„ç ”ç©¶èƒ½åšå®Œæ•´çš„è‡ªå‹•å»ºç½®ï¼Œ
åªæœ‰çœ‹åˆ°ä¸€äº›ç ”ç©¶èƒ½å”åŠ©æ¯”è¼ƒä¸åŒçš„ Ontology (Wiesman et al. 2001, , Gal et al. 2004, Gal et al. 
2005)ï¼Œç”³è«‹äººéå»èˆ‡å­¸ç”Ÿæ‰€ç ”ç™¼çš„æŠ€è¡“ (Hsu et al. 2006)ï¼Œä¹Ÿæ˜¯å±¬æ–¼é€™ä¸€å€‹å¤§é …ã€‚ 
å¾ä¸Šè¿°çš„æ–‡ç»æ¢è¨å¯å¾—çŸ¥ï¼Œè¦å…¨ç„¶è‡ªå‹•åŒ–å»ºç«‹ Ontology æ˜¯ä¸€å¤§æŒ‘æˆ°ï¼Œåœ¨æœ¬è¨ˆç•«ä¸­ï¼Œæˆ‘å€‘
å°‡å˜—è©¦è‘—å¾ä¸å›ºå®š Formatã€ä¸æ˜ç¢ºé ˜åŸŸé–‹å§‹ï¼Œç„¶å¾Œåˆ©ç”¨è©å½™ç°¡çŸ­çš„ä½¿ç”¨è€…æª¢ç´¢è©å½™åšçš„èªæ–™
ä¾†æºï¼Œå˜—è©¦è‡ªå‹•å»ºç«‹èµ·æ¦‚å¿µä¹‹é–“çš„ä¸Šä¸‹ä½ã€åˆ†é¡é—œä¿‚ã€è‡ªå‹•å»ºç«‹èµ·ä¹‹é–“çš„é—œä¿‚ï¼Œé€™å°‡æ˜¯ä¸€å€‹
æ¥µå¤§çš„æŒ‘æˆ°ï¼Œä¸éæ ¹æ“šç”³è«‹äººèˆ‡å­¸ç”Ÿéå»çš„ç ”ç©¶æˆæœä¾†çœ‹ï¼Œé€™æ¨£çš„ç ”ç©¶è¨ˆç•«å»æ˜¯å¯¦éš›å¯è¡Œçš„ã€‚ 
98-2221-E-007-096- Final Report11/4
å…±  é   ç¬¬ 4 é  
 
åƒè€ƒæ–‡ç» 
â€¢ (Alani et al. 2003) Harith Alani, Sanghee Kim, David E. Millard, Mark J. Weal, Paul H. Lewis, Wendy 
Hall, and Nigel R. Shadbolt. Automatic Extraction of Knowledge from Web Documents. 2nd 
International Semantic Web Conference - Workshop on Human Language Technology for the Semantic 
Web abd Web Services, 2003. 
â€¢ (Alani et al. 2003a) Harith Alani, Sanghee Kim, David E. Millard, Mark J. Weal, Weal Hall, Paul H. 
Lewis and Newis Shadbolt. Web based Knowledge Extraction and Consolidation for Automatic 
Ontology Instantiation. 2nd
 
International Conference Knowledge Capture (K-Cap'03), Workshop on 
Knowledge Markup and Se-mantic Annotation, 2003. 
â€¢ (Agrawal et al. 2008) Rakesh Agrawal, Anastasia Ailamaki, Philip A. Bernstein, Eric A. Brewer, 
Michael J. Carey, Surajit Chaudhuri, AnHai Doan, Daniela Florescu, Michael J. Franklin, Hector 
Garciaâ€Molina, Johannes Gehrke, Le Gruenwald, Laura M. Haas, Alon Y. Halevy, Joseph M. 
Hellerstein, Yannis E. Ioannidis, Hank F. Korth, Donald Kossmann, Samuel Madden, Roger Magoulas, 
Beng Chin Ooi, Tim Oâ€™Reilly, Raghu Ramakrishnan, Sunita Sarawagi, Michael Stonebraker, Alexander 
S. Szalay, Gerhard Weikum, The Claremont Report on Database Research, 
http://db.cs.berkeley.edu/claremont/claremontreport08.pdf , 2008. 
â€¢ (Bernstein et al. 2005) Abraham Bernstein, Esther Kaufmann, Christoph Buerki, and Mark Klein. How 
Similar Is It? Towards Personalized Similarity Measures in Ontologies. Wirtschaftsinformatik, pp. 
1347-1366, 2005. 
â€¢ (Buscaldi et al. 2005)Davide Buscaldi, Paolo Rosso, Emilio Sanchis Arnal. A wordnet-based query 
expansion method for geographical information retrieval. Working Notes for the Cross-Language 
Evaluation Forum (CLEF) Workshop, 2005. 
â€¢ (Chandrasekaran et al. 1999) B. Chandrasekaran, John R. Josephson, and V. Richard Benjamin. What 
are ontologies, and why do we need them?. IEEE Intelligent Systems, 14(1), pp. 20-26, 1999.  
â€¢ (Dean et al. 2003) Mike Dean, Guus Schreiber, Sean Bechhofer, Frank van Harmelen, James Hendler, 
Ian Horrocks, Deborah L. McGuinness, Peter F. Patel-Schneider, and Lynn Andrea Stein. OWL Web 
Ontology Language Reference. W3CWorking Draft, 2003.  
â€¢ (Dou et al. 2003) Dejing Dou, Drew McDermott, and Peishen Qi. Ontology Translation on the Semantic 
Web. Conference on Ontologies, Databases and Applications of Semantics, 2003. 
â€¢ (Embley et al. 1998) David W. Embley, Douglas M. Campbell, Randy D. Smith, and Stephen W. Liddle. 
Ontology-Based Extraction and Structuring of Information from Data-Rich Unstructured Documents. 
Conference on Information and Knowledge Management CIKM'98 Proceedings, pp.52-59, 1998. 
â€¢ (Ehrig and Staab 2004) Marc Ehrig and Steffen Staab. Efficiency of ontology mapping approaches. 
International Workshop on Semantic Intelligent Middleware for the Web and the Grid at ECAI 04, 
2004. 
 
98-2221-E-007-096- Final Report11/4
å…±  é   ç¬¬ 6 é  
 
â€¢ (Jiang et al. 2009) Yunliang Jiang, Hui-Ting Yang, Kevin Chen-Chuan Chang, Yi-Shin Chen, AIDE: 
Ad-hoc Intents Detection Engine over Query Logs, Submitted to SIGMOD 2009 
â€¢ (Jiang et al. 2009a) Yunliang Jiang, Hui-Ting Yang, Kevin Chen-Chuan Chang, Yi-Shin Chen, Query 
Intent Detection: Searching Query Log Online, Submitted to WWW 2009 
â€¢ (Kalfoglou and Schorlemmer 2003) Yannis Kalfoglou and Marco Schorlemmer. Ontology mapping: 
The state of the art. The Knowledge Engineering Review, (1), pp. 1â€“31, 2003. 
â€¢ (Kietz et al. 2000) Joerg-Uwe Kietz, Alexander Maedche, and Raphael Volz. A method for 
semi-automatic Ontology acquisition from a corporate intranet. Proc. of Workshop Ontologies and Text, 
co-located with (EKAWâ€™2000), 2000. 
â€¢ (Kim 2002) Henry Kim. Predicting How Ontologies for the Semantic Web Will Evolve. Communications 
of the Association for Computing Machinery (ACM), 45(2), pp. 48â€“54, 2002. 
â€¢ (Klein and Fensel 2001) Michel Klein and Dieter Fensel. Ontology versioning on the semantic web. 
Proceeding of International Semantic Web Working Symposium (SWWS), 2001. 
â€¢ (Klein et al. 2002) Michel Klein, Dieter Fensel, Atanas Kiryakov, and Damyan Ognyanov. Ontology 
versioning and change detection on the web. Proceeding of 13th International Conference on 
Knowledge Engineering and Management, 2002. 
â€¢ (Lee et al. 2007) Chang-Shing Lee, Yuan-Fang Kao, Yau-Hwang Kuo, and Mei-Hui Wang. Automated 
Ontology construction for unstructured text documents. Data & Knowledge Engineering, 60(3), pp. 
547-566, 2007.Â 
â€¢ (Liu et al. 2009) Po-Ching Liu, Kevin Chen-Chuan Chang, Yi-Shin Chen. Are We Searching for the 
Same Thing? A Large-Scale Analysis of Search Engine Logs. Submitted to SIGIR 2009 
â€¢ (Maedche and Staab 2001) Alexander Maedche and Steffen Staab. Ontology learning for the semantic 
web. IEEE Intelligent Systems, 16 (2), pp. 72â€“79, 2001. 
â€¢ (Maedche and Staab 2002) Alexander Maedche and Steffen Staab. Measuring similarity between 
ontologies. Proceedings of the European Conference on Knowledge Acquisition and Management 
(EKAW), 2002. 
â€¢ (Maedche et al. 2003) Alexander Maedche, Boris Motik, Ljiljana Stojanovic, Rudi Studer, and Raphael 
Volz. Ontologies for Enterprise Knowledge Management. IEEE Intelligent Systems, 18(2), pp. 26-33, 
2003. 
â€¢ (Mahesh and Nirenburg 1996) Kavi Mahesh and Sergei Nirenburg. Meaning Representation for 
Knowledge Sharing in Practical Machine Translation. Proceedings of the FLAIRS-96 track on 
Information Interchange, Florida AI Research Symposium, 1996. 
â€¢ (Mann 2002) Gideon S. Mann. Fine-Grained Proper Noun Ontologies for Question Answering. 
SemaNet'02: Building and Using Semantic Networks, 2002. 
â€¢ (Mcllraith et al. 2001) Sheila A. McIlraith, Tran Cao Son, and Honglei Zeng. Semantic Web Services. 
IEEE Intelligent Systems 16(2), pp. 46-53, 2001. 
98-2221-E-007-096- Final Report11/4
å…±  é   ç¬¬ 8 é  
 
â€¢ (Smith and Christopher 2001) Barry Smith and Christopher Welty. Ontology: Toward a New Synthesis.  
Proceedings of the international conference on Formal Ontology in Information Systems, 2001. 
â€¢ (Staab et al. 2001) Steffen Staab, Hans-Peter Schnurr, Rudi Studer, and York Sure. Knowledge 
Processes and Ontologies. IEEE Intelligent Systems, 16 (1), pp. 26-34, 2001. 
â€¢ (Stojanovic et al. 2002) Nenad Stojanovic, Ljiljana Stojanovic, and Siegfried Handschuh. Evolution in 
the Ontology-based knowledge management systems. European Conference on Information Systems 
(ECIS), 2002. 
â€¢ (Sure et al. 2002) York Sure, Michael Erdmann, Juergen Angele, Steffen Staab, Rudi Studer, and Dirk 
Wenke. OntoEdit: collaborative Ontology development for the semantic web. Proceedings of the First 
International Semantic Web, 2002. 
â€¢ (Lee et al. 2001) Tim Berners-Lee, James Henlder and Ora Lassila. The Semantic Web. Scientific 
American, 2001.  
â€¢ (Voorhees 1994) Ellen M. Voorhees. Query Expansion using Lexical-Semantic Relations. Proceedings 
of the 17th Annual ACM-SIGIR Conference, pp. 61-69, 1994. 
â€¢ (Wang and Ali 2005) James Z. Wang and Farha Ali. An efficient ontology comparison tool for semantic 
web applications. The 2005 IEEE / WIC /ACM International Conference onWeb Intelligence (WIâ€™05), 
pp. 372â€“378, 2005. 
â€¢ (Wang et al. 2005) James Z.Wang, Farha Ali, and Rashmy Appaneravanda. A web service for efficient 
ontology comparison. Proceedings of the IEEE International Conference on Web Services (ICWS05), 
pp. 843â€“844, 2005. 
â€¢ (Widyantoro and Yen 2001)Dwi H. Widyantoro and John Yen. A fuzzy Ontology-based abstract search 
engine and its user studies. Proceedings of the 10th IEEE International Conference on Fuzzy Systems, 
2001. 
â€¢ (Wiesman et al. 2001) Floris Wiesman, Nico Roos, and Paul Vogt. Automatic Ontology mapping for 
agent communication. Proceedings of BNAIC '01, pp. 291- 298, 2001. 
â€¢ (Yan and Soo 2008) Shih-Yao Yan and Von-Wun Soo. Comparing the Conceptual Graphs Extracted 
from Patent Claims. Sensor Networks, Ubiquitous and Trustworthy Computing, 2008. SUTC '08. IEEE 
International Conference, pp. 394-399, 2008. 
â€¢ (Yoshinaga et al. 1999) Kazuyuki Yoshinaga, Takao Terano, and Ning Zhong. Multi-lingual intelligent 
information retriever with automated Ontology generator. Proceedings of the Third International 
Conference on Knowledge-Based Intelligent Information Engineering Systems, pp. 62â€“65, 1999. 
â€¢ (Zhou et al. 2002) Lina Zhou, Queen E. Booker, and Dongsong Zhang. ROD â€“ toward rapid Ontology 
development for underdeveloped domains. Proceedings of the 35th Annual Hawaii International 
Conference on System Sciences, 2002. 
98-2221-E-007-096- Final Report11/4
II. FRAMEWORK
 
 
	


	














ï¬€ï¬ï¬‚


ï¬ƒ

ï¬€
 
ï¬€
 
!
ï¬

ï¬€"
#
ï¬€

"$
%
!

 
ï¬€
ï¬ƒ

ï¬€
&
'
(
)
*
)+, -
./
0102
3.
21
* 4
)'2
/
5
(
6
7
89:;
<=
>? @>A:
B
C
=
9:DE
#FF

ï¬€
G
H
IJ
HK L
MM
N
O
P
Q

$
R




ï¬€ï¬€

ï¬€
R
ï¬‚
S
"
 
TU
	
V
O
W
Fig. 1. Framework
HOMME1 employs four different types of web data, search
logs, web directory data, WorNet, and social bookmarks, to
map the concepts. The architecture is illustrated in Figure 1.
In the demonstration system, the search logs are obtained from
MSN Search with 15 million queries and the associated list of
clicked URLs sampled over one month; the directory data are
manually labeled categories assigned to websites and extracted
from the Open Directory Project (ODP) [5]; a complete list
of nouns is crawled from WordNet [6] for support; and, the
social bookmarks are a list of top manually assigned tags to
each URL from Delicious.com [7].
During the offline process, these four data sources are
integrated and mapped together by the Resource Integrator.
The integrator first filters non-English characters, punctuations,
and white spaces. Subsequently, the categories and tags are
automatically obtained through a custom built crawler and
mapped onto the click logs. Finally, this module maps each
clicked URL to its ODP category, ODP title, and related
Delicious tags to assemble a huge consolidated dataset, which
is the input data for the follow-up processes.
Both Term Extractor and Term Mapper utilize the previ-
ously consolidated data matrix as input to collect the related
data. For each given keyword k, The Term Extractor looks
through the whole matrix for the other terms whose related
details contain k and generates the corresponding term list as
the output. The Term Mapper then employs the output list
to build a Query-Tag Matrix (or features matrix). First, terms
will be classified according to the categories in ODP. Second,
the matrix will be built by counting the frequency of the tags
(features) assigned to each query.
Once the term list and Query-Tag Matrix are ready, two im-
portant modules Relationship Finder and Concept Clustering,
which are described later, are activated.
1Homme means the human being in French, and we use this name for our
system which contains human intelligence.
A. Relationship Finder
The Relationship Finder seeks to find important semantic
relationships between terms, such as â€œ Southwest is-A air-
line companyâ€ or â€œae has-Meaning American eagle and has-
Website www.ae.comâ€. Because of the variety of relationships
between the terms, different Relationship Finders are designed.
Each finder is dedicated to a specific type of relationship. In
HOMME, seven kinds of relationship finders, i.e., Is-A, Has-
Subclass, Has-Data-About, Has-Meaning, Is-Equal-To, Has-
Website, and Specialization/Generalization, are introduced.
Figure 2 describes the detailed data used in these relationship
finders.
 


 


	
 	







	
 

ï¬€
ï¬


ï¬‚
ï¬ƒ 
ï¬‚ 
ï¬ƒ
!

ï¬

"



ï¬‚
ï¬‚ï¬

"



ï¬‚
#$%
&
'(
)
%*
) +,
-
,
.
/

01
	
2
3ï¬‚


4
3




56



578
3

9:;

<9

/


5=
ï¬‚

ï¬‚


5>

8


57


5?
3
8
!ï¬

Fig. 2. Relationship Finder
â€¢ Is-A Relationship Finder: This finder focuses on ana-
lyzing the patterns of the queries and assigned titles of
the clicked URL by ODP. This finder extracts all the
nouns and the corresponding noun modifiers from the
queries and assigned titles based on the noun lists of
WordNet. If the modifier and the noun appear together
frequently or the noun has the related domain name, the
finder constructs one â€œis-Aâ€ relationship between the pair
of nouns together and the noun modifier alone.
â€¢ Has-Subclass Relationship Finder: This finder empha-
sizes on examining the match between the query and the
ODP category assigned to the clicked URL. Once the
match frequently exists, one â€œhas-subclassâ€ relationship
is then established (e.g. â€œtravelâ€ is super class of â€œtravel
agentsâ€).
â€¢ Has-Data-About Relationship Finder: This finder
finds the match between the queries and the
resource path of the clicked URLs. Once there
is a match, the finder constructs one â€œhas-data-
aboutâ€ relationship between the domain name and
the submitted queries. For instance, from the URL
http://www.mtv.com/music/artist/bowlingforsoupartist.htm
clicked after querying â€œbowling for soupâ€, we can
determine that â€œmtvâ€ has data about â€œbowling for soupâ€.
Fig. 4. Categories for query â€œCinco de mayoâ€
Fig. 5. Mind Map for the query â€œToyotaâ€
user can find more queries related to recipes, holidays, food,
etc. For the same query, when clicking the Society category
he can find related queries such as â€œhow is cinco de mayo
celebrated in mexicoâ€. Going deeper under Society, queries
about history, social studies, or even the war around 1950 can
be found by the user.
In our second scenario, the user types â€œtoyotaâ€ as the search
keyword. The Ontology Builder immediately provides the
mind map for â€œtoyotaâ€ (as illustrated at Figure 5). From the
map, the user can learn that Toyota not only sells normal cars
but forklifts as well. The official company that sells forklifts is
called â€œToyota material Handling U.S.A. Inc.â€, whose official
website is www.toyotaforklift.com. Another official website of
Toyota is www.toyota.com which contains information about
â€œSolaraâ€, â€œYarisâ€, â€œPriusâ€etc. (which are the car brands from
Toyota). Furthermore, the user can also find that Toyota offers
financial services promising to close the gap between the userâ€™s
transportation needs and her cash flow. She can also find
several kinds of services provided online.
If the user wants to check data related to Toyota across
Fig. 6. Categories for query â€œToyotaâ€
different categories, she can employ the Concept Finder to
explore the concept spaces as shown in Figure 6. She can also
find out that Toyota is involved in sports. There is a â€œHouston
Toyota Centerâ€, which is an indoor arena located in Texas.
Apparently, this arena is sponsored by Toyota. Different sports
games can also be found in that particular cluster, such as â€œPac
10 Conferenceâ€ and â€œIndiana Rivalsâ€.
As shown in this demo, HOMME provides the user with
a graphical tool able to facilitate the search experience and
enrich him or her with previously unknown knowledge. Even
with a very small dataset, HOMME was able to provide in-
tuitive and relevant information. Moreover, HOMME demon-
strates the feasibility of future research on Web Information
Integration by taking advantage of the Ontological knowledge
provided by the Ontology Builder.
REFERENCES
[1] R. A. Baeza-Yates, C. A. Hurtado, and M. Mendoza, â€œQuery
recommendation using query logs in search engines.â€ in EDBT
Workshops, ser. Lecture Notes in Computer Science, W. Lindner,
M. Mesiti, C. Trker, Y. Tzitzikas, and A. Vakali, Eds., vol. 3268.
Springer, 2004, pp. 588â€“596. [Online]. Available: http://dblp.uni-
trier.de/db/conf/edbtw/edbtw2004.html
[2] R. Baeza-Yates and A. Tiberi, â€œExtracting semantic relations from
query logs,â€ in KDD â€™07: Proceedings of the 13th ACM SIGKDD
international conference on Knowledge discovery and data mining.
New York, NY, USA: ACM, 2007, pp. 76â€“85. [Online]. Available:
http://dx.doi.org/10.1145/1281192.1281204
[3] S. Sekine and H. Suzuki, â€œAcquiring ontological knowledge from query
logs.â€ in WWW, C. L. Williamson, M. E. Zurko, P. F. Patel-Schneider,
and P. J. Shenoy, Eds. ACM, 2007, pp. 1223â€“1224. [Online]. Available:
http://dblp.uni-trier.de/db/conf/www/www2007.html
[4] (2010) Google wonder wheel. [Online]. Available:
http://www.googlewonderwheel.com/
[5] (2010) Open directory project. [Online]. Available: http://www.dmoz.org
[6] G. A. Miller, â€œWordnet: A lexical database for english,â€ Communications
of the ACM, vol. 38, pp. 39â€“41, 1995.
[7] (2010) Del.icio.us. [Online]. Available: http://delicious.com/
to as crowd wisdom since it collects session data from all
users. In this work, we propose a Pattern Recognition Query
(PRQs) method, which aims to integrate both sets of wis-
dom to achieve a query suggestion method. First, we for-
mally define session and search log as follows:
Definition 2.1. : A user session s of user u is a set of
records {ã€ˆ ipu, q1, t1, ã€‰,ã€ˆ ipu, q2, t2, ã€‰,...,ã€ˆ ipu, qn, tn, ã€‰},
where ti+1 - ti Â¡ Î˜ âˆ€ i = 1 to n-1. ipiu, qi, ti, andÎ˜ are IP
address of the machine which submits the query, the submit-
ted query, the timestamp when the query is submitted, and
a defined threshold value, respectively.
To address the queries in the session, we further denote
the set of consecutive queries submitted in this session as
Qs, i.e., Qs = {q1, q2, ..., qn}.
Definition 2.2. : A search log L consists of the session data
s of all search engine users, i.e., L={s1,s2,...,sn}.
Given the search log L and the session of the current
user, our goal is to generate a set of refined queries as sug-
gestions to accelerate the userâ€™s search process to retrieve
desired information. The proposed system can be divided
into two categories: offline and online processing, as illus-
trated in Figure 1.
&RRFFXUUHQFH
4XHU\([WUDFWLRQ
6HDUFK/RJ
,QVHUWLRQ
([WUDFWLRQ
&RRFFXUUHQFH
4XHU\,QGH[
,QVHUWLRQ
,QGH[
2IIOLQH
2QOLQH
LQSXWVHVVLRQ
$JJUHJDWH
FDQGLGDWHV	UHSUHVHQWDWLYHV
)HWFKFDQGLGDWHV
IURPHDFKLQGH[
RXWSXWVXJJHVWLRQV
6HVVLRQ5HS
6HOHFWLRQ 6XJJHVWLRQ
*HQHUDWLRQ
,QWHQW
&ODVVLILFDWLRQ
Figure 1. System framework
In offline processing, search log data is given as input.
Offline processing aims to integrate clues to user intent and
the search pattern from the session by two parallel pro-
cesses: insertion extraction and co-occurrence query ex-
traction. The details of offline processing are described in
Section 3.
In online processing, the session of the current user
is given as input. Online processing first performs two
preprocesses- intent classification and session represen-
tative selection- to extract essential information. The
â€œconceptsâ€ , which can be phrases or terms contained in
the query, that best describe user intent will be exploited to
fetch candidate suggestions from the indexes built offline.
Finally, suggestion generation aggregates better candidates
and representatives as final suggestions. The details of on-
line processing is described in Section 4.
3 Offline Processing
Search logs contain past search patterns. By utilizing
these search patterns, other users with similar search intents
get needed information faster. We intend to apply crowd
wisdom in two ways: specialization and association.
Specialization. As we mentioned before, users may
consecutively reformulate their queries to find information
more closely related to their search intents. Although previ-
ous studies have investigated various reformulation patterns
in query sessions [8], we only focus on one reformulation
pattern: specialization, i.e., users specify the meaning of the
query by inserting more keywords [8]. The goal of inser-
tion extraction is to extract and reuse the insertion pattern
as candidate suggestions.
Association. Queries that frequently co-occur in the
same query session may be conceptually related. For ex-
ample, the queries â€œharry potterâ€ and â€œjoanne kathleen
rowlingâ€ can be viewed as candidate suggestions for each
other. These query pairs are extracted by the process co-
occurrence query extraction.
The insertion extraction process scans all sessions in the
search log and identifies all concepts having the added key-
words (i.e., the insertion concepts) in the follow-up queries.
For each concept C having the insertions, we build the in-
sertion index to pre-store each insertion of C as well as the
corresponding frequency of this insertion to C. The inser-
tions are then ranked according to the frequency.
The co-occurrence query extraction process is to ex-
tract useful query pairs that led to click-through behav-
iors and that also frequently appeared in the same ses-
sion. In other words, these useful query pairs (termed co-
occurrence queries afterward) can assist users to retrieve
target pages easily.
To analyze the importance of co-occurrence queries,
we first built a co-occurrence query index to collect co-
occurrence click queries for each query q i. The importance
of each co-occurrence query qj to qi is evaluated according
to Equation 1. The concept of this equation is similar to
TF-IDF that is, the importance is proportionally increased
to the frequency of the query in the session but decreased
by the frequency of the query in the search log.
26
keyword. Queries that better describe user intent can
lead to more click-through since the information re-
trieved is more related and arouses user interest.
We compute the score of each keyword k âˆˆ Qs based on
the following equation:
s(k) = Î± Â· fk
max fk
+ Î² Â· ok
max ok
+ Î³ Â· c.fk
max c.fk
(2)
Each feature value is normalized by dividing the maxi-
mum one in the session. Î±, Î², and Î³ are weighting parame-
ters of each feature, which can be adjusted according to the
application, where Î±+ Î² + Î³ = 1. For fear that incomplete
concepts could lead to incorrect suggestions, we further in-
spected whether selected keywords can be combined. Given
the consecutive queries Qs and selected keywordsKs of the
session s, the process outputs the set of representative con-
cepts Cs.
The process starts by combining keywords into phrases.
Each keyword is combined with other keywords, and we
examine whether any query in Qs contains the combina-
tion. The combination that appeared in Qs will be added to
the set Combinee. After all combinations are examined, we
remove the keyword that totally depends on combinations
in Combinee (i.e. the keyword is contained in the combi-
nations every time it appears). After dependent keywords
are removed, combinations in Combinee and the remaining
keywords form the candidate concepts.
Similarly, we check whether the combinations in Com-
binee can be further combined, and we remove dependent
combinations iteratively until no combination of concepts
exists in the session. Finally, dependent concepts are re-
moved, and the remaining concepts are representative con-
cepts. These concepts will be given scores based their fre-
quency, order, and click frequency using the same rules as
keyword selection.
After the session is classified and the representative con-
cepts are selected, we retrieve candidate suggestions from
indexes built offline. For each concept C âˆˆ Cs, we re-
trieve the insertions applied from the insertion index as
well as their co-occurrence queries drawn from the co-
occurrence query index. The concepts apply insertions and
co-occurrence queries form the set of candidate suggestions
CSs. The system processes Cs and CSs are used to gener-
ate final suggestions at the next stage.
4.3 Suggestion Generation
In this process, we associate the current user with past
users who had similar search intents by searching for: (1)
insertions connected with representative concepts from the
insertion index, and (2) queries that co-occurred with the
representative concepts from the co-occurrence query in-
dex. The concepts, adding insertions and co-occurrence
query data, are candidate suggestions.
To determine which representative concept and candi-
dates should be included in the final suggestions, we pro-
pose a scoring mechanism to determine their importance.
First, we assign a parameter K to determine the number of
suggestions that should be presented to the user. We then
determine the relative proportion of (1) representative con-
cepts and candidates, and (2) candidates generated by dif-
ferent measures in the final suggestions based on the classi-
fied type. With K and the predefined proportion, the num-
ber of representative concepts and candidates generated by
different aspects in the final suggestions is decided.
To generate the top-K suggestions, we score each repre-
sentative concept C âˆˆ Cs and candidate suggestion cs âˆˆ
CSs to decide which one is more important. Since rep-
resentative concepts were already scored in the previous
stage, we score the candidates at this stage based on two
aspects:
Trigger score(Ts). Each candidate is â€œtriggeredâ€ by cer-
tain information embedded in the session. The â€œtriggerâ€
may be the representative concepts. Ts indicates how im-
portant the candidate cs is to its trigger tcs. The trigger
score of each cs is computed by Equation 3. Note that the
weight of cs is normalized by dividing the maximum weight
among all candidates retrieved by tcs.
Ts(cs) = wcs/maxwtcs (3)
Context score(ConS). Since the approach is context-
aware, we consider the relevance between the candidates
and all representative concepts. The relevance is measured
by whether the candidate co-occurred with the representa-
tive concepts in past sessions. The relevance between cs
and Ci is measured by Equation 4, where cs âˆˆ CS and
Ci âˆˆ C.
Rel(cs, Ci) =
{
TIcs
maxTIlCi
if cs âˆˆ lCi
0 otherwise
(4)
The context score of each candidate cs is measured by
Equation 5, where Rel(cs, Ci) represents average relevance
score among all lists that contain cs, and olcs represents
number of lists that cs appears.
Rel(cs, Ci) =
1
olcs
Ã—
âˆ‘
Rel(cs, Ci), âˆ€cs âˆˆ lCi
Cons(cs) = 0.5Ã— olcs
max olcsi
+ 0.5Ã—Rel(cs, Ci) (5)
28
gated the precision and recall ratio under different settings
of the parameter K . K was set to 10, 20, 50, and all (i.e, all
candidate suggestions will be returned to the current user).
The precision and recall of PRQs dramatically exceeded
those of other approaches under all settings. We can observe
that the approach with higher coverage reached a better per-
formance. The above comparisons demonstrate that PRQs
outperforms existing query suggestion approaches in differ-
ent ways. We compared some differences between PRQs
and the comparison baselines to figure out potential reasons
for this increased performance.
TSM generates candidate suggestions according to the
current user query. Relevance with the search context is
considered when ranking these candidates. This mechanism
may work for sessions with focus intent since all queries in
the session are explicitly related. For sessions with general
or changing intents, however, the performance of TSM may
decrease due to the neglect of search context when selecting
candidates.
CACB addresses the order of consecutive queries. It
transforms session data into concept sequences from search
logs in order to generate suggestions for the current user
session. When transforming consecutive queries into a con-
cept sequence, the queries are mapped to the concept sepa-
rately. Therefore, users with similar search intents who sub-
mit queries in different orders may be considered to have
different search intents that cannot be associated. Cao et
al. implemented CACB with a much larger-scale query log.
If the source query log is very large, the mined concept
sequences may be sufficient to handle the above problem.
Otherwise, the requirement that users with similar search
intents must submit queries in a similar order may be too
strict and lead to a decrease in performance.
This points out that we could apply search context in a
more flexible manner. Instead of considering consecutive
queries separately, we could view usersâ€™ search contexts
from a more integrated perspective. This is also the motiva-
tion for summarizing user sessions with representative con-
cepts, one feature of PRQs. Another potential reason is that
PRQs utilizes search context more than other approaches
do. This helps when we need more clues in order to pro-
vide suggestions. The advantage of the above mechanisms
is reflected by the high coverage of PRQs.
6 CONCLUSION AND FUTURE WORK
In this paper, we presented a novel query suggestion
approach - PRQs(Pattern Recognition Query suggestion),
which exploit search context and query logs to help users
search for required information more efficiently. PRQs is
â€œcontext-awareâ€ in that it integrates the whole search con-
text in a two-fold manner: consecutive queries and refor-
mulation patterns. Moreover, we summarize user search
context by selecting the representative concepts that best
describe user intents, and we provide customized sugges-
tions according to usersâ€™ search patterns. The experimental
results show that PRQs outperforms previous context-aware
query suggestion methods.
References
[1] R. A. Baeza-Yates, C. A. Hurtado, and M. Mendoza.
Query recommendation using query logs in search en-
gines. In EDBT Workshops, pages 588â€“596, 2004.
[2] D. Beeferman and A. Berger. Agglomerative clustering
of a search engine query log. In KDD â€™00: Proceedings
of the 6th ACM SIGKDD international conference on
Knowledge discovery and data mining, pages 407â€“416,
New York, NY, USA, 2000. ACM.
[3] H. Cao, D. Jiang, J. Pei, Q. He, Z. Liao, E. Chen, and
H. Li. Context-aware query suggestion by mining click-
through and session data. In KDD â€™08: Proceeding
of the 14th ACM SIGKDD international conference on
Knowledge discovery and data mining, pages 875â€“883,
New York, NY, USA, 2008. ACM.
[4] J. Dean and S. Ghemawat. Mapreduce: Simplified data
processing on large clusters. In OSDI â€™04: Proceedings
of the 6th Symposium on Operating Systems Design and
Implementation, pages 137â€“150, 2004.
[5] B. M. Fonseca, P. Golgher, B. PoË†ssas, B. Ribeiro-Neto,
and N. Ziviani. Concept-based interactive query expan-
sion. In Proceedings of the 14th ACM international
conference on Information and knowledge manage-
ment, pages 696â€“703, New York, USA, 2005. ACM.
[6] C.-K. Huang, L.-F. Chien, and Y.-J. Oyang. Relevant
term suggestion in interactive web search based on con-
textual information in query session logs. Journal of the
American Society for Information Science and Technol-
ogy, 54(7):638â€“649, 2003.
[7] R. Jones, B. Rey, O. Madani, and W. Greiner. Generat-
ing query substitutions. In WWW â€™06: Proceedings of
the 15th international conference on World Wide Web,
pages 387â€“396, New York, NY, USA, 2006. ACM.
[8] S. Y. Rieh and H. I. Xie. Analysis of multiple query re-
formulations on the web: The interactive information
retrieval context. Inf. Process. Manage., 42(3):751â€“
768, 2006.
[9] Z. Zhang and O. Nasraoui. Mining search engine query
logs for query recommendation. In WWW â€™06: Pro-
ceedings of the 15th international conference on World
Wide Web, pages 1039â€“1040, New York, NY, USA,
2006. ACM.
30
æ­¤åœ–æ˜¯å¤§æœƒç¬¬ä¸€å¤©çš„Keynote speechä¸­å…¶ä¸­ä¸€åŠçš„äººæ•¸ï¼Œå› ç‚ºæœƒå ´å¤ªå¤§äº†ç„¡æ³•åŒæ™‚æ‹åˆ°
æ‰€æœ‰çš„äººï¼Œé€™å…©å¤©æˆ‘å€‘è½äº†å¾ˆå¤šå ´Sessionsï¼Œå…¶ä¸­ä¸€å€‹æœ€éœ‡æ’¼çš„æ˜¯ 
Title: Towards The Web of Concepts: Extracting Concepts from Large Datasets 
Presenters: 
Aditya Parameswaran, Stanford University, United States of America 
Hector Garcia-Molina, Stanford University, United States of America 
Anand Rajaraman, Kosmix Corporation, United States of America 
 
 
Hector Garcia-Molinaæ˜¯ç¾åœ‹ç›®å‰æœ€ç´…çš„Database Researcher,å› ç‚ºä»–æ——ä¸‹çš„å­¸ç”Ÿå°±æ˜¯åœ¨
å”¸æ›¸æœŸé–“å‰µç«‹Googleç„¶å¾Œåˆ°ç¾åœ¨ä¸€ç›´éƒ½é ˜å°è¶¨å‹¢ï¼Œæ‰€ä»¥Hectorå’Œå­¸ç”Ÿå€‘çš„paperç™¼è¡¨åœ¨
VLDBä¸€ç´šæœŸåˆŠä¸¦ä¸è¶³ç‚ºå¥‡ï¼Œè®“æˆ‘å€‘éœ‡æ’¼çš„æ˜¯å› ç‚ºè©²ç¯‡paperçš„å…§å®¹æˆ‘å€‘å¯¦é©—å®¤åœ¨å…©å¹´
å‰å°±å®Œæˆä¸¦å˜—è©¦æŠ•éåˆ°å¹¾å€‹ä¸€ç´šæœŸåˆŠï¼Œéƒ½è¢«å›çµ¶ï¼ŒåŸå› éƒ½èªªæ²’æœ‰å‰µæ–°ï¼ŒæŠ€å·§ä¸è¶³ç‚ºå¥‡ï¼Œ
æ‰€ä»¥é€™å…©å¹´æœ¬ç ”ç©¶å®¤åˆç ”ç™¼å¥½å¹¾å€‹ä¸åŒçš„æŠ€è¡“ï¼Œæ‰€ä»¥æˆ‘å€‘é€™æ¬¡å°±ç‰¹åˆ¥ä¾†å­¸ç¿’ç‚ºä»€éº¼åŒ
æ¨£çš„å…§å®¹è¢«HectoråŒ…è£å¾Œå¯ä»¥é€²å…¥VLDB 
 
9/15ä¸‹åˆæœ‰ä¸€å ´Panelæ˜¯åœ¨è¬›è§£Cloud Computing, 
Title: Cloud Databases: What's New?  
Participants:  
Daniel Abadi (Yale Univ.),  
Michael Carey (Univ. of California, Irvine),  
Surajit Chaudhuri (Microsoft Research),  
Hector Garcia-Molina (Stanford Univ.),  
ç„¡ç ”ç™¼æˆæœæ¨å»£è³‡æ–™ 
å…¶ä»–æˆæœ 
(ç„¡æ³•ä»¥ï¥¾åŒ–è¡¨é”ä¹‹æˆ
æœå¦‚è¾¦ï§¤å­¸è¡“æ´»å‹•ã€ç²
å¾—çé …ã€é‡è¦åœ‹éš›åˆ
ä½œã€ç ”ç©¶æˆæœåœ‹éš›å½±éŸ¿
ï¦ŠåŠå…¶ä»–å”åŠ©ç”¢æ¥­æŠ€
è¡“ç™¼å±•ä¹‹å…·é«”æ•ˆï¨—äº‹
é …ç­‰ï¼Œè«‹ä»¥æ–‡å­—æ•˜è¿°å¡«
ï¦œã€‚) 
ç„¡ 
 æˆæœé …ç›® ï¥¾åŒ– åç¨±æˆ–å…§å®¹æ€§è³ªç°¡è¿° 
æ¸¬é©—å·¥å…·(å«è³ªæ€§èˆ‡ï¥¾æ€§) 0  
èª²ç¨‹/æ¨¡çµ„ 0  
é›»è…¦åŠç¶²ï¤·ç³»çµ±æˆ–å·¥å…· 0  
æ•™æ 0  
èˆ‰è¾¦ä¹‹æ´»å‹•/ç«¶è³½ 0  
ç ”è¨æœƒ/å·¥ä½œåŠ 0  
é›»å­å ±ã€ç¶²ç«™ 0  
ç§‘ 
æ•™ 
è™• 
è¨ˆ 
ç•« 
åŠ  
å¡« 
é … 
ç›® è¨ˆç•«æˆæœæ¨å»£ä¹‹ï¥«èˆ‡ï¼ˆé–±è½ï¼‰äººï¥© 0  
