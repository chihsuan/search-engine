 1
can then be altered individually or as a whole 
depending on the request.   Various speakers can be 
emulated as long as the properties of the pitch 
contour, spectral parameters and energy variation are 
correctly grasped and transformed.      
 
Keywords: Voice Conversion, Harmonic + noise 
model, hidden Markov model â€“ weighted 
deviation linear transform, Text-to-Speech. 
 
1. ç°¡ä»‹ 
è²éŸ³è½‰æ›(Voice Conversion)çš„æŠ€è¡“è©žå½™ï¼Œé¡§å
æ€ç¾©å°±æ˜¯èªžè€…å½¼æ­¤è²éŸ³çš„è½‰æ›ï¼Œäº¦å³å°‡ï¤­æºè€…
(source speaker)çš„è²éŸ³è½‰æ›æˆå¦ä¸€ç›®æ¨™èªžè€…(target 
speaker)çš„è²éŸ³ï¼ŒèªžéŸ³è½‰æ›æŠ€è¡“çš„æ‡‰ç”¨é¢å»£æ³›ï¼Œèˆ‰
å‡¡è§’è‰²æ‰®æ¼”ã€éŸ³è³ªéŸ³è‰²ç•Œå®šã€å½±åŠ‡é…éŸ³ã€ç—…æ…‹èªž
éŸ³(pathologic voice)ä¹‹ä¿®æ­£ã€ç”šæˆ–è—ï§«èº«ä»½ç­‰ï¼Œï¨¦
æœ‰å…¶å¯¦ç”¨åƒ¹å€¼ã€‚ 
åœ¨æœ¬è¨ˆç•«ä¸­ï¼Œæ‰€è¦é¢å°çš„ä¸»è¦èª²é¡Œæœ‰ä¸‰ï¼šå…¶
ä¸€ã€å»ºæ§‹ä¸€å¥—é©åˆè²éŸ³è½‰æ›çš„ç™¼è²æ¨¡åž‹ï¼Œå…¶äºŒã€
æŽŒæ¡å„æ¨¡åž‹ï¥«ï¥©å°éŸ³è³ªå±¬æ€§çš„å½±éŸ¿ï¼Œé€éŽï¥«ï¥©çš„
æ“ç¸±èª¿æŽ§å‡ºæ‰€æƒ³è¦çš„èªžéŸ³ç‰¹æ€§ï¼›å…¶ä¸‰ã€å°‡å…¶èˆ‡æ–‡
å­—è½‰èªžéŸ³ä¹‹åŠŸèƒ½é€²ä¸€æ­¥çµåˆï¼Œè®“è²éŸ³çš„è®ŠåŒ–ï¤åŠ 
è±å¯Œï¼Œæ“´å¤§å…¶æ‡‰ç”¨å±¤é¢ã€‚ 
 
 
2. HNM åœ¨èªžéŸ³åˆæˆä¹‹è€ƒï¥¾ 
è¿‘ï¦Žï¤­æ¯”è¼ƒå—åˆ°é’çžçš„èªžéŸ³æ¨¡åž‹ä¸»è¦å¤§æŠµæœ‰
äºŒï¼Œåˆ†åˆ¥ç‚º Stylianou é–‹ç™¼ä¹‹HNM [1]ï¼Œå¦ä¸€å‰‡æ˜¯
Kuwahara æ‰€ç™¼å±•å‡ºçš„Speech Transformation and 
Representation using Adaptive Interpolation of 
weiGHTed spectrum (STRAIGHT) [2]ï¼Œé€™ï¥¸å¥—ç³»çµ±
ï¨¦æ˜¯ä¹ï¼ï¦Žä¸­æœŸæ‰€ç™¼å±•çš„æŠ€è¡“ï¼Œåœ¨æ¨¡åž‹ï¥«ï¥©çš„è¦
åŠƒèˆ‡è¨­å®šä¸Šï¼Œæˆ‘å€‘ï¥«è€ƒï¦ºStylianouçš„HNMåŽŸå§‹è¨­
è¨ˆï¼Œå°‡å…·æœ‰é€±æœŸç‰¹æ€§çš„æœ‰è²èªžéŸ³æ‹†è§£æˆä½Žé »å€çš„
è«§æ³¢(harmonics, è¨˜ç‚º ( )h t )èˆ‡é«˜é »å€çš„é›œè¨Š(noise, 
è¨˜ç‚º ( )n t )è¡¨ç¤ºï¼Œå„è‡ªè¡¨ç‚º 
 
( )0( ) ( ) ( )
1
( ) ( ) k
L t
j k t t t
k
k
h t a t e Ï‰ Ï†+
=
= âˆ‘ ,    (1) 
[ ]( ) ( , ) ( )n t v t b tÏ„= âˆ—     (2) 
 
å…¶ä¸­ ( )ka t , 0 ( )k tÏ‰ , ( )k tÏ†  åˆ†åˆ¥ç‚ºç¬¬ k å€‹è«§æ³¢ä¹‹
æŒ¯å¹…ã€é »ï¥¡åŠç›¸ä½ã€‚ ( , )v tÏ„ ç‚ºæ™‚è®Šï¦„æ³¢éŸ¿æ‡‰ï¼Œ ( )b t
æ³›æŒ‡ç™½é›œè¨Šã€‚å°‡ ( )h t èˆ‡ ( )n t åˆä½µå¾Œå³ç‚ºé«˜å“è³ªçš„èªž
éŸ³ä¿¡è™Ÿ ( )s t ï¼Œäº¦å³ ( ) ( ) ( )s t h t n t= + ã€‚æ­¤ä¸€åŽŸï§¤æºè‡ª
æ–¼æœ‰è²èªžéŸ³çš„é »è­œçµæ§‹ï¼Œçµåˆæ¿€æºï¦„æ³¢çš„æ¦‚ï¦£è€Œ
æˆï¼Œè©³ç´°å…§å®¹å¯ï¥«è€ƒ [1]ã€‚ 
ä¸€èˆ¬çš„HNMåˆ†æžåŠåˆæˆå¤šèˆ‡éŸ³é«˜é€±æœŸåŒæ­¥ï¼Œ
ä½†æœ¬è¨ˆç•«åŸºæ–¼æ–¹ï¥¥æ€§è€ƒï¥¾ï¼ŒåŒæ™‚ä¹Ÿç‚ºï¦ºä½¿éŸ»ï§˜çš„
èª¿æ•´å¯ä»¥ï¤åŠ å®¹ï§ ï¼Œå› æ­¤æŽ¡ç”¨ï¦ºå›ºå®šéŸ³æ¡†åˆ†å‰²çš„
æ–¹å¼ï¼Œï¥§ç®¡æ˜¯æœ‰è²èªžéŸ³é‚„æ˜¯ç„¡è²èªžéŸ³ï¼Œæ¯ä¸€éŸ³æ¡†
ä¸­åƒ…é¸å–ä¸€çµ„ä»£è¡¨æ€§æ¨¡åž‹ï¥«ï¥©ï¼Œè€Œæ‰€é¸ç”¨éŸ³æ¡†é•·
ï¨å®šç‚º15msï¼Œé€™å·²æ˜¯ç¶­æŒé«˜è©±è³ªçš„æœ€ä½Žé™ï¨ï¼Œå€˜
ï¥´éŸ³æ¡†ï¤¥å¾—ï¤é•·ï¼Œå³æœ‰å¯èƒ½å°Žè‡´åˆæˆéŸ³è³ªä¸‹ï¨‰ã€‚ 
è¨ˆç•«æ‰€æŽ¡ç”¨ä¹‹æ¨¡åž‹ï¥«ï¥©è©³ï¦œæ–¼è¡¨ 1ã€‚ï¥«ï¥©åœ¨
èª¿æ•´éŽå¾Œï¼Œï¥¥å¯é–‹å§‹åŸ·ï¨ˆèªžéŸ³åˆæˆï¼Œé›–ç„¶åˆ†æžæ™‚
æ˜¯æŽ¡éŸ³æ¡†ç‚ºå–®ä½ï¼Œä½†æœ‰è²èªžéŸ³ä¿¡è™Ÿé‚„æ˜¯å¿…é ˆé€å€‹
é€±æœŸç”¢ç”Ÿï¼Œç‚ºæ±‚è¨ˆç®—ä¸Šçš„ç°¡ï¥¥ï¼Œåœ¨æ­¤æŽ¡ç”¨ï¦ºéŸ³é«˜
åŒæ­¥ç–ŠåŠ çš„æŠ€å·§ [3]ï¼Œæ„å³æ‰€ç”¨çš„æ¨¡åž‹ï¥«ï¥©æ˜¯å¾žæ‰€
åœ¨ä½ç½®çš„é„°è¿‘éŸ³æ¡†æŽ¨ç®—è€Œå¾—ï¼Œæ¯æ¬¡å…ˆï¨ˆåˆæˆå‡º2å€
éŸ³é«˜é€±æœŸçš„ä¿¡è™Ÿï¼Œå…¶å¾Œç¶“éŽæ¬Šå€¼çª—æ¡†è™•ï§¤äºˆä»¥ç–Š
åŠ ï¼Œé€™ç•¶ä¸­é‚„ç‰¹åˆ¥è—‰åŠ© [4] ä¹‹ç›¸ä½æ ¡æ­£æŠ€è¡“ï¼Œè®“
å‰å¾Œé€±æœŸçš„ä¿¡è™Ÿèƒ½æº–ç¢ºåŒæ­¥ã€‚  
 
è¡¨ 1ï¼š HNM parameters for voice conversion  
 
 
 
 
 
 
 
 
 
 
 
 
 
åœ¨ï¥«ï¥©è®Šè¿­é »æ¬¡ç”±éŸ³æ¡†è½‰ç‚ºéŸ³é«˜é€±æœŸæ™‚ï¼Œï¥«ï¥©
å…§æ’æŠ€è¡“å³ï¥§å¯æˆ–ç¼ºï¼Œåœ¨æ­¤æ˜¯æŽ¡ç”¨å¦‚ä¸‹æ–¹å¼é€²ï¨ˆï¼š 
 
1
Ë†Ë† Ë† Ë†( ) Ë† Ë†
i i
t x
L x xt
L L
Î» Î» Î» +=
âŽ› âŽžâˆ’ âŽ› âŽž= +    âŽœ âŽŸ âŽœ âŽŸâŽœ âŽŸ âŽ âŽ âŽ âŽ 
 (3)
 
ä¸Šå¼çš„ x ç‚ºç›®å‰åˆæˆä¿¡è™Ÿæ‰€åœ¨ä¸­å¿ƒé»žä½ç½®åˆ°å‰ä¸€
å€‹éŸ³æ¡†ä¸­å¿ƒé»žçš„è·ï§ªï¼Œ LË† ç‚ºé æœŸçš„éŸ³æ¡†é•·ï¨ã€‚é ˆ
è¦å…§å·®çš„ï¥«ï¥©ï¼Œæ„æŒ‡å¼(3)ä¸­çš„ Ë† ( )tÎ» ï¼Œé™¤ï¦ºå¯ä»¥æ˜¯
è«§æ³¢æŒ¯å¹…èˆ‡ç›¸ä½å¤–ï¼Œæœ€å¤§æœ‰è²é »ï¥¡å’Œé›œè¨ŠæŽ¡ç”¨çš„
ï¦„æ³¢ç›¸é—œä¿‚ï¥©ï¼ˆå¦‚LSPï¥«ï¥©ï¼‰å‡å¯é©ç”¨ã€‚ 
å…§æ’é›–å¯ä½¿ä¿¡è™Ÿè¼ƒå¹³ï¤„åŠç”¢ç”Ÿæ¼¸è¿‘å¼çš„æ”¹
è®Šï¼Œä½†é€™å¿…é ˆæ˜¯åœ¨é„°è¿‘éŸ³æ¡†çš„ï¥«ï¥©è®ŠåŒ–å¹…ï¨ï¥§å¤§
èˆ‡éŸ³é«˜é€±æœŸä¼°æ¸¬ç„¡èª¤çš„æƒ…å½¢ä¸‹ï¼Œå‡ï¥´éŸ³éšŽä¼°æ¸¬ï¥§
æº–è€Œå‡ºç¾å€å¿½æ”¹è®Šçš„æƒ…å½¢ï¼ˆï¦µå¦‚pitch halvingæˆ–
pitch doublingï¼‰ï¼Œå‰‡å¿…é ˆåŠ å…¥ä¸€å¥—èª¿æ•´æ©Ÿåˆ¶ä½œç‚ºæ”¹
å–„ï¼Œå…¶ä½œæ³•å¦‚ä¸‹ã€‚ 
 
ï§ºæ³ä¸€ï¼š 
é¦–å…ˆè€ƒæ…®éŸ³æ¡†i+1æ¯”éŸ³æ¡†içš„åŸºé »å¤§çš„æƒ…å½¢ï¼ˆå¦‚
åœ–1ï¼‰ï¼Œå¦‚æžœæ­¤æ™‚ç›´æŽ¥å°‡éŸ³æ¡†ièˆ‡éŸ³æ¡†i+1çš„è«§æ³¢ï¼ŒæŒ‰
ç…§è«§æ³¢çš„å€‹ï¥©ï¤­ä¸€å°ä¸€é€²ï¨ˆå…§æ’ï¼Œï¥¥æœƒç”¢ç”Ÿå°ç…§
å•é¡Œã€‚ 
ç‚ºï¦ºè§£æ±ºé€™å€‹å•é¡Œï¼Œå¯ä»¥æ ¹æ“šéŸ³æ¡†é–“åŸºé »çš„
æ¯”ï¦µ 1Î· ï¼ˆè¨ˆç®—å¦‚å…¬å¼(4)ï¼‰ ï¤­é€²ï¨ˆåˆ¤æ–·ï¼Œé€™å€‹æ¯”ï¦µ
Model parameters Number Unvoiced Voiced 
Frame length: fL  1 3 3 
LSF parameter: kl  18 3 3 
Power level: 2Ïƒ  5 3 - 
Fundamental frequency: 0f  1 - 3 
Maximum voiced frequency : mF  1 - 3 
Magnitude harmonics: ka  0/mF fâŽ¢ âŽ¥âŽ£ âŽ¦  - 3 
Phase harmonics: kÏ†  0/mF fâŽ¢ âŽ¥âŽ£ âŽ¦  - 3 
Harmonic variation: kÎ³  13 - 3 
 3
Male to Female Female to Male Size 
CM GMM PDLT HMM+ 
WDLT 
CM GMM PDLT HMM+
WDLT 
42  4.271 3.863 3.798 3.746 5.170 4.612 4.569 4.475 
52  4.152 3.812 3.746 3.669 4.991 4.542 4.505 4.338 
62  4.048 3.764 3.682 3.574 4.873 4.473 4.425 4.222 
72  3.975 3.692 3.599 3.454 4.768 4.376 4.315 4.073 
Male to Female Female to Male size 
CM GMM PDLT HMM+ 
WDLT 
CM GMM PDLT HMM+
WDLT 
42  4.449 4.122 4.012 3.968  5.501  5.114  5.029 4.885 
52  4.328 4.101 4.004 3.929  5.336  5.047  5.016 4.813 
62  4.238 4.108 4.005 3.878  5.240  5.038  5.009 4.764 
72  4.166 4.096 4.063 3.865  5.182  5.088  5.052 4.731 
è²è…”è½‰ç§»å‡½ï¥©(vocal tract transfer function)ã€‚å› æ­¤åœ¨
éŸ³è³ªæˆ–è²éŸ³è½‰æ›çš„ç ”ç©¶ä¸­å¸¸å°±æ¿€æºèˆ‡é »è­œçš„å€‹åˆ¥
è®ŠåŒ–åŠäºŒè€…çš„é—œï¦šè©³åŠ è¨Žï¥ã€‚æœ¬è¨ˆç•«äº¦ï¥§ï¦µå¤–ï¼Œ
æ˜¯ä»¥é »è­œåŠæ¿€æºï¼ˆå°¤å…¶æ˜¯èˆ‡æœ‰è²æ¿€æºå¯†ï¨€ç›¸é—œçš„
éŸ³é«˜é€±æœŸï¼‰ç‚ºæŽ¢è¨Žä¸»é«”ã€‚ 
 
3.1. ç·šé »è­œå°ï¥«ï¥©ä¹‹è½‰æ› 
è¡¨ä¸­èˆ‡é »è­œç›´æŽ¥ç›¸é—œçš„æœ‰ç·šé »è­œå° (line 
spectrum pair, LSP)ä¿‚ï¥©( kl ) [5] ä»¥åŠè«§æ³¢æŒ¯å¹…
( ka )ï¼Œï¥´å°‡è«§æ³¢æŒ¯å¹…çš„å¤§å°ä¾å…¶æ‰€åœ¨å€é »ä½ç½®ï¦š
çµç‚ºåŒ…çµ¡ç·šï¼Œå…¶ï§—ï¨‹èˆ‡ç·šé »è­œå°ï¥«ï¥©æŽ¨æ¼”çš„å…±æŒ¯
å³°çµæ§‹éžå¸¸è¿‘ä¼¼ï¼Œå› å…¶ä¿‚ï¥©å€‹ï¥©è¼ƒç‚ºç°¡æ½”ï¼Œæœ‰ï¥§
å°‘å­¸è€…æ˜¯ä»¥ç·šé »è­œå°ï¥«ï¥©ä½œç‚ºè½‰æ›æ¨™çš„[6][7]ã€‚æœ¬
è¨ˆç•«äº¦ï¥¦å¦‚æ­¤ï¼Œç¶“éŽè©³ç´°æ¯”è¼ƒç ”ç©¶ï¼Œæœ€çµ‚ç™¼å±•å‡º
çš„è½‰æ›å‡½ï¥©å¦‚ä¸‹: 
 
( ) ( )Ë† ( ) ( ) | ( ) ( )( ) ( )( )1Qm P S m m mi i iii âŽ¡ âŽ¤= + âˆ’âˆ‘ âŽ¢ âŽ¥âŽ£ âŽ¦= y xy X Î¼ V x Î¼   
(13) 
ä¸Šå¼ä¸­çš„ ( )mx èˆ‡ ( )my å³ç‚ºè½‰æ›å‡½ï¥©çš„è¼¸å…¥å’Œè¼¸
å‡ºå‘ï¥¾ï¼Œä¸»è¦çš„çµ„æˆæ˜¯é »è­œç‰¹å¾µï¥«ï¥©ï¼Œ m æ˜¯èˆ‡æ™‚
åºæœ‰é—œçš„éŸ³æ¡†ï¥ªå¼•ï¼Œé€™ï§¨å¯ç°¡å–®æƒ³åƒæˆç¬¬ m å€‹éŸ³
æ¡†çš„ç·šé »è­œå°ä¿‚ï¥©ï¼Œè€Œ ( )mX  å‰‡æ˜¯ä»£è¡¨è§€å¯Ÿè‡³ç¬¬
m éŸ³æ¡†çš„ç‰¹å¾µå‘ï¥¾åºï¦œï¼Œæ›è¨€ä¹‹ X  åŒ…å«å¾žèµ·å§‹
åˆ° ä»Š çš„ é » è­œ å‘ ï¥¾ åº ï¦œ çš„ é›† åˆ ï¼Œ äº¦ å³  X  
{ }(1), , ( )m= x xâ€¦ ã€‚ è€Œ ( )iS m  æ˜¯è©²éŸ³æ¡†ä¸­çš„ç¬¬ i  
å€‹é¦¬å¯å¤«ï§ºæ…‹ï¼Œè‡³æ–¼ sN æŒ‡çš„æ˜¯ï§ºæ…‹çš„ï¥©ç›®ã€‚é€
éŽè²æ°å®šï§¤ï¼Œæ¢ä»¶æ©Ÿï¥¡ ( )( ) | ( )iP S m mX  çš„è¨ˆç®—  
 
( ) ( )
( )
1
( ), ( )
( ) | ( )
( ), ( )
i
i Q
j
j
P S m m
P S m m
P S m m
=
=
âˆ‘
X
X
X
. (14) 
 
ä¸Šå¼ä¸­çš„ï¦—åˆæ©Ÿï¥¡ ( )( ), ( )iP S m mX  å¯ç¶“ç”±è¿­å¸¶
æ–¹å¼å–å¾—ï¼Œè©³ç´°éŽç¨‹å¯ï¥«è€ƒ [8]èˆ‡[9]. 
æˆ‘å€‘æ›¾é‡å°ç¢¼æœ¬å°æ˜ (codebook mapping, CM) 
[10]ã€é«˜æ–¯æ··åˆæ¨¡åž‹(GMM, Gaussian mixture model) 
[11]ã€åˆ†æ®µå¼åå·®ç·šæ€§è½‰æ› (piecewise deviation 
linear transform, PDLT) [12]ã€éš±è—å¼é¦¬å¯å¤«æ¨¡åž‹
(Hidden Markov Model, HMM) ä½µåŒæ¬Šé‡åå·®ç·šæ€§
è½‰æ› (weighted deviation linear transform, WDLT) 
ã€åˆç¨±HMM+WDLTã€‘ [9] ä¹‹æ–¼ç·šé »å°ï¥«ï¥©ä¹‹è½‰
æ›åšéŽåˆæ­¥æ•ˆèƒ½åˆ†æžã€‚å¯¦é©—å°è±¡æ˜¯ä»¥ç”·ï¦é–“çš„è²
éŸ³è½‰æ›ç‚ºä¸»ï¼Œèªžï¦¾åº«æŽ¡é›†è‡ªä¸€ç”·ä¸€ï¦æ‰€ï¤¿è£½ä¹‹æ‰¿
è¼‰ï¤†ï¼Œæ‰€æœ‰å¯èƒ½çš„åœ‹èªžéŸ³ç¯€å‡æœƒå‡ºç¾åœ¨ï¤†é¦–ã€ï¤†
ä¸­ã€ï¤†å°¾ç­‰ä¸‰å€‹ä½ç½®ï¼Œç¸½å…±å„æœ‰1409ï¤†ã€‚æ‰€å°æ‡‰
çš„éŸ³ç¯€æ®µï¤˜ç¶“äººå·¥ç¯©é¸å‡ºï¤­å¾Œé€²ï¨ˆåˆ†æžï¼Œå†åˆ†åˆ¥
åŠƒåˆ†éŸ³æ¡†ä»¥åŠè¨ˆç®—æ¨¡åž‹ï¥«ï¥©å€¼ï¼Œæœ€å¾Œé€™äº›éŸ³æ¡†é‚„
å¿…é ˆç¶“ç”±å‹•æ…‹æ™‚è»¸æ ¡æ­£(Dynamic Time Warping, 
DTW) [13]ï¼Œè®“é »è­œï¥«ï¥©å‘ˆç¾æœ€ä½³çš„å°æ‡‰ã€‚ 
ä¸€èˆ¬è€Œè¨€ï¼Œåœ¨æª¢é©—ä¸Šè¿°æ–¹æ³•çš„å„ªç¼ºé»žæ™‚ï¼Œé™¤ï¦º
è§€å¯Ÿè¨“ï¦–æ¨£æœ¬çš„åæ‡‰å¤–ï¼Œé€šå¸¸é‚„æœƒå¦å¤–æº–å‚™ä¸€äº›
å¤šé¤˜çš„æ¸¬è©¦çµ„ä½œç‚ºå°ç…§ç”¨ã€‚æ­¤è™•æŽ¡ï¨ˆçš„ä½œæ³•ä¹Ÿï¥§
ï¦µå¤–ï¼Œåœ¨å…¨éƒ¨çš„èªžï¦¾ä¸­ï¼Œç´„ç•¶2/3æ˜¯ç”¨ï¤­è¨“ï¦–ï¼Œå…¶
é¤˜1/3å‰‡æ˜¯ç•¶ä½œæ¸¬è©¦ç”¨ã€‚å°±éŸ³ç¯€çš„ï¥©ï¥¾è€Œè¨€ï¼Œè¨“ï¦–
çµ„å…±è¨ˆ1409 x 2 å€‹å–æ¨£ï¼Œæ¸¬è©¦çµ„å‰‡æœ‰ 1409å€‹ï¼Œè‡³
æ–¼éŸ³æ¡†ï¥©å‰‡å„æœ‰41428 åŠ 21849å€‹ã€‚ 
ä»¥æˆ‘å€‘è’é›†èªžï¦¾ç‚ºï¦µï¼Œå…¶é »è­œäº’è½‰åœ¨ 42 ã€
52 ã€ 62 ã€ 72  å››ç¨®ï¥§åŒç¢¼æœ¬ï¥©ï¥¾ä¸‹ï¼Œç¶“éŽå„ç¨®ï¥§
åŒè½‰æ›æ–¹æ³•å°é »è­œå°ï¥«ï¥©æ‰€é€ æˆçš„é »è­œå¤±çœŸå¦‚è¡¨
2ã€3æ‰€ç¤ºï¼Œè‡³æ–¼æ‰€å¼•ç”¨çš„å¤±çœŸè¨ˆç®—å¦‚ä¸‹ï¼š 
 
( )
( ) ( )( ) 1/21 20.5 100
0
Ë†,
1 1 Ë†20log /
0.5
f
s
SP
N
j j
t t
f st
D
A e A e d
N
Ï‰ Ï‰ Ï‰ Ï‰Ï‰
âˆ’
=
=
âŽ¡ âŽ¤âŽ¢ âŽ¥âŽ¢ âŽ¥âŽ£ âŽ¦âˆ‘ âˆ«
y y
        (15) 
ä¸Šå¼ä¹‹ ( )jtA e Ï‰  èˆ‡ ( )Ë† jtA e Ï‰  ä»£è¡¨æŽ¨ç®—å¾ž ty  å’Œ 
Ë† ty æ‰€æŽ¨ç®—ä¹‹åŽŸå§‹æ¨™çš„åŠç¶“éŽè½‰æ›çš„é »è­œï¼Œ fN  å‰‡
ç‚ºéŸ³æ¡†ç¸½ï¥©ã€‚ 
 
 
è¡¨  2ï¼š  Average spectral distortions between the 
target and converted LSP parameters in the 
training set 
 
 
 
è¡¨  3ï¼š  Average spectral distortions between the 
target and converted LSP parameters in the test 
set 
 
 
å°±å¯¦é©—çµæžœï¤­çœ‹ï¼Œç¢¼æœ¬çš„å¢žåŠ ç¢ºå¯¦å¯å°‡ï¨‰ä½Žé »
è­œå¤±çœŸï¼Œä½†æ”¹å–„å¹…ï¨ä¼¼ä¹Žï¥§å¤§ï¼Œè€Œç¢¼æœ¬è®Šå¤§å¾Œä¹Ÿ
ï¦šå¸¶è€—ç”¨ï¤å¤šçš„è¨ˆç®—è³‡æºèˆ‡è¨˜æ†¶å®¹ï¥¾ï¼Œä¸­é–“çš„å¹³
 5
0 1000 2000 3000 4000 5000 6000 7000 8000
0
1
2
3
4
5
6
11th Critical Band
Frequency [Hz]
Ma
gn
itu
de
åœ–  3ï¼š  Illustration of extracting iÎ³  in the 11th 
critical band (blue dashed line: FFT spectrum; 
red solid line: LPC spectrum) 
 
ï¦¸å±¬ï¤­æºè€…çš„13å€‹ï§¶ç•Œé »å¸¶æ¯”å€¼å¯ï¦œç‚ºè½‰æ›
å‡½ï¥©çš„è¼¸å…¥ï¥«ï¥©ï¼Œç¶“è½‰æ›å‡½ï¥©çš„ä½œç”¨è½‰æˆç›®æ¨™è€…
çš„æ¯”å€¼ã€‚ç•¶è¦åˆæˆèªžéŸ³æ™‚ï¼Œä»¥æ±‚å¾—çš„é »è­œåŒ…çµ¡ç·š
åœ¨ç‰¹å®šé »ï¥¡ 0kf çš„é »è­œå¤§å°(è¡¨ç‚º 0( )g A kf )ä¹˜ä¸Š
æŽ¨ä¼°çš„æ¯”å€¼ ( )Ë† yiÎ³ å³æ˜¯è«§æ³¢ Ë†( )a k è©²æœ‰çš„æŒ¯å¹… 
 
0 1
( )
0
Ë†Ë†( )
( )i i
y
ikf
ga k
A kfÎ» Î»
Î³
+â‰¤ â‰¤ =    (20) 
 
 
4. è²éŸ³è½‰æ›ç³»çµ±èˆ‡è½æ¸¬çµæžœ 
ç¶œåˆä¸Šè¿°HNMæ¨¡åž‹ï¥«ï¥©è½‰æ›æ©Ÿåˆ¶å¦‚åœ–2æ‰€
ç¤ºã€‚è©²ç³»çµ±çš„æ‰€æœ‰åˆ†æžå·¥ä½œï¨¦æ˜¯åœ¨å›ºå®šé•·ï¨çš„éŸ³
æ¡†æž¶æ§‹ä¸‹é€²ï¨ˆï¼Œä»¥æ–¹ï¥¥èªžéŸ³ï¥«ï¥©ä»¥ä¸€å°ä¸€æ–¹å¼é€²
ï¨ˆè½‰æ›ï¼Œä½†é€™ï¥§æ„è¬‚éŸ³æ¡†é•·ï¨ä¹Ÿå¿…ç„¶ä¸€æˆï¥§è®Šï¼Œ
åªè¦æŽ§åˆ¶æ¯ä¸€éŸ³æ¡†é•·ï¨ï¼Œå…¶å¯¦ä¹Ÿæ•‘é–“æŽ¥æ±ºå®šï¦ºéŸ³
é•·ã€‚åœ¨é€™ï§¨ï¼Œæˆ‘å€‘æ˜¯æŠŠéŸ³æ¡†é•·ï¨ç•¶æˆè½‰æ›å‡½ï¥©çš„
è¼¸å‡ºå€¼ï¼Œé€™å€‹å€¼å¯ç”¨DTWæ ¡æº–æ™‚ï¤­æºç«¯èˆ‡ç›®æ¨™ç«¯
çš„ï¥ªå¼•è®ŠåŒ–æ¯”å€¼ä½œç‚ºä»£è¡¨ï¼Œå‡½ï¥©è¼¸å…¥ä»èˆŠæ˜¯åªæœ‰
ç·šé »è­œå°ï¥«ï¥©ï¼Œåªè¦å°‡æŽ¨ä¼°çš„è¼¸å‡ºå€¼ä¹˜ä»¥åŽŸå§‹éŸ³
æ¡†é•·ï¨å³ç‚ºæ–°éŸ³æ¡†çš„é•·ï¨ã€‚ 
 
åœ–4ï¼šParametric conversion for HNM 
 
ç‚ºæª¢é©—åœ– 4 è®Šè²ç³»çµ±çš„æ•ˆæžœå¥½å£žï¼Œæœ¬è¨ˆç•«ç‰¹
é‡å°ï¥´å¹²åˆæˆçš„èªžéŸ³æ¨£æœ¬é€²ï¨ˆå¹³å‡æ„ï¨Šåˆ†ï¥©
(mean opinion score, MOS)ä¹‹è½ï¦Šæ¸¬é©—ï¼Œå°è±¡åŒ…æ‹¬
(1)åƒ…æœ‰éŸ³é«˜æ”¹è®Šï¼›(2)éŸ³é«˜ï¼‹CM æ³•ä¹‹é »è­œæ”¹è®Šï¼›
(3)éŸ³é«˜ï¼‹HMM-WDLT æ³•ä¹‹é »è­œæ”¹è®Šï¼›(4) éŸ³é«˜ï¼‹
HMM-WDLT èˆ‡è«§æ³¢/é »è­œæ¯”ï¼›(5)éŸ³æ¡†ï¥«ï¥©ï¥§åšä»»
ä½•æ”¹è®Šä¹‹é‡æ–°åˆæˆã€‚ 
ä¸Šè¿°é™¤ç¬¬äº”ç¨®æƒ…æ³æä¾› HNM æ‰€èƒ½åˆæˆçš„éŸ³
è³ªæ°´å¹³ï¼Œå…¶é¤˜å››ç¨®å‰‡æ˜¯åæ˜  HNM ï¥«ï¥©ä¿®æ”¹éŽå¾Œçš„
å½±éŸ¿ï¼Œæˆ‘å€‘ç¸½å…±é‚€è«‹ 12 ä½è©¦è½è€…ï¼Œå¾žè¡¨ 4 çµæžœå¯
çŸ¥ï¼Œä»»ä½•ï¤å‹•åŽŸå§‹ï¥«ï¥©çš„èˆ‰å‹•ï¨¦æœƒå°Žè‡´éŸ³è³ªä¸‹
ï¨‰ï¼Œä¸€æ—¦éŸ³é«˜èˆ‡é »è­œåŒæ™‚æ”¹è®Šæ™‚ï¼ŒéŸ³è³ªæ¸›æå°¤å…¶
æ˜Žé¡¯ï¼ŒæƒŸ HMM-WDLT çš„è½‰æ›æˆæ•ˆçµ‚ç©¶é‚„æ˜¯å„ªæ–¼
CM æ–¹æ³•ï¼Œç•¶è«§æ³¢/é »è­œæ¯”çš„èª¿æ•´åŠŸç”¨åŒ¯é›†åœ¨ä¸€èµ·
æ™‚ï¼Œåˆæˆè²éŸ³ç²å¾—è¼ƒä½³æ”¹å–„ï¼Œè½èµ·ï¤­ä¹Ÿæœ€èƒ½è²¼è¿‘
è½‰æ›å°è±¡æ‰€æ‡‰æœ‰ç‰¹æ€§ã€‚ 
 
è¡¨ 4ï¼šListening test results. 
 
 
 
 
 
 
 
5. æ–‡å­—è½‰èªžéŸ³ä¹‹æ‡‰ç”¨ 
éŸ³é•·(duration)èˆ‡éŸ³é«˜(pitch)æ˜¯éŸ³éŸ»(prosody)
çš„ï¥¸å¤§æ±ºå®šæ€§å› ç´ ï¼Œï¥¥éš¨è‘—èªžéŸ³å…§å®¹èˆ‡è²å­¸å±¬æ€§
çš„æ”¹è®Šï¼Œï¥¥å¯ç™¼å‡ºä»»ä½•æ‰€æƒ³è¦çš„èªžèª¿ã€‚æ‰€è¬‚çš„éŸ³
é•·ä¿®æ”¹ï¼Œå³æ˜¯å°‡ä¿¡è™Ÿçš„é•·ï¨ä½œç¸®çŸ­æˆ–æ˜¯ï¤¥é•·ï¼Œé€²
è€Œæ”¹è®ŠèªžéŸ³çš„ï¥¯è©±é€Ÿï¥¡ã€‚è€Œæœ¬æ¬¡æ‰€ç™¼å±•çš„ HNM ç™¼
è²æ¨¡åž‹å¼·èª¿æ˜¯ä»¥éŸ³æ¡†ï¤­çµ„æˆæ•´æ®µèªžéŸ³ï¼Œèª¿æ•´å€‹åˆ¥
éŸ³æ¡†çš„é•·ï¨å³å¯é”åˆ°éŸ³é•·ä¿®æ”¹çš„æ•ˆæžœï¼Œï¥©å­¸å¼å¦‚
å…¬å¼ (21)ã€(22)ï¼š 
 
( ) ( )
0
Ë† ; /
t iD t d i t LÎ² Ï„ Ï„=    = âŽ¡ âŽ¤âŽ¢ âŽ¥âˆ«  (21)
( )( )
( )( )
1
1
1Ë†[ ]
iL i
i L
iL i
i L
L i d L
L
d
Î² Ï„ Ï„
Î² Ï„ Ï„
âˆ’
âˆ’
âŽ› âŽž=  â‹…âŽœ âŽŸâŽ âŽ 
        =  
âˆ«
âˆ«
 (22)
 
å‰ï¥¸å¼ä¸­çš„ ( )iÎ² Ï„ ç‚ºï¤˜åœ¨ç¬¬ iå€‹éŸ³æ¡†ç¯„åœå…§çš„éŸ³é•·
ä¿®æ”¹æ¯”ï¦µï¼Œ ( )DË† t å’Œ Ë†[ ]L i .åˆ†åˆ¥ä»£è¡¨åˆæˆä¿¡è™Ÿåœ¨æ™‚é–“
t ä¹‹å‰çš„ç¸½é•·ä»¥åŠç¬¬ i å€‹éŸ³æ¡†çš„ä¿®æ­£é•·ï¨ï¼Œè€Œ L ç‚º
åŽŸå§‹éŸ³æ¡†é•·ï¨ï¼Œå…¶ä¸­éŸ³æ¡†ï¥ªå¼• i ç‰¹åˆ¥åŠ è¨»åœ¨éƒ¨åˆ†ï¥«
ï¥©çš„ä¸Šæ¨™ä½ç½®ï¼Œè—‰æ­¤å¼·èª¿éŸ³æ¡†æ‰®æ¼”çš„è§’è‰²ã€‚æ­¤è™•
çš„ Ë†[ ]L i æ­£å¯ä»¥è·Ÿè®Šè²ç³»çµ±çš„ yË†fL ç›¸äº’ï¦šçµï¼Œæ­é…å…¶
å®ƒè®Šï¤éŽå¾Œçš„ HNM æ–°ï¥«ï¥©ï¼Œï¥¥å¯ç™¼å‡ºäººå·¥èªžéŸ³ã€‚ 
ä¸Šè¿°æ¦‚ï¦£æ‰€æŽ¨æƒ³çš„æœ€ç›´æŽ¥æ‡‰ç”¨ï¥¥æ˜¯æ–‡å­—è½‰èªž
éŸ³ï¼Œä¸€å¥—å®Œæ•´çš„å­—è½‰éŸ³ç³»çµ±æ˜¯ç”±ï¤†åž‹å‰–æžã€æ–·è©žã€
èªžï¦¾ç¯©é¸ã€éŸ³éŸ»èª¿æ•´ã€èªžéŸ³åˆæˆç­‰æ¨¡çµ„å»ºæ§‹è€Œæˆï¼Œ
æœ¬è¨ˆç•«çš„ä¸»è¦ä»»å‹™è‘—é‡åœ¨å¾Œæ®µï¼Œä¹Ÿå°±æ˜¯éŸ³éŸ»èª¿æ•´
ä»¥å¾Œçš„éƒ¨åˆ†ã€‚ä¹‹å‰çš„æ–·è©žèˆ‡éŸ³éŸ»ç·¨è¼¯é ˆçµåˆåˆ¥è™•
æ‰€èƒ½å–å¾—è³‡æºæˆ–ï¥«è€ƒä»–äººæ–¹æ³•ï¼Œå…¶ä¸­æ–·è©žæ˜¯é¦–å…ˆ
æ‰€å¿…é ˆè¦è™•ï§¤çš„æ­¥é©Ÿï¼Œé›–ç„¶é€™é …è™•ï§¤ç¨‹åºå¯é€éŽ
è¾­å…¸ä¸­çš„è³‡ï¦¾åº«é€²ï¨ˆæ¯”å°ï¼Œæ‰¾å‡ºæ‰€è¦åˆ†æžçš„æ–‡ç« 
 
Speech analysis 
ÃŽExtract HNM parameters 
Conversion (I)
Conversion (II)
Linear  
transformation
Model 
parameter 
generator 
Speech 
synthesis 
0
xf Target 
speech
Source 
speech 
0
yË†f
1 18 1 13, , , , , ,
x x x x x
ml l FÎ³ Î³âŽ¡ âŽ¤âŽ£ âŽ¦" " Ë† Ë† Ë†1 13, , ,y y ymFÎ³ Î³âŽ¡ âŽ¤âŽ£ âŽ¦"
1 18, ,
x xl lâŽ¡ âŽ¤âŽ£ âŽ¦" Ë† Ë† Ë†1 18, , ,y y yfl l LâŽ¡ âŽ¤âŽ£ âŽ¦"
 (i) Pitch (ii) Pitch + CM 
(iii) Pitch + 
HMM-WDLT 
(iv) Pitch + 
HMM-WDLT 
+ HV 
(v) Original 
HNM 
MOS 
(in a range of 1~5) 3.11  2.59  2.83  2.98  4.15  
XAB 
(correct rate in 
percentage) 
92.7% 92.7% 97.9% 100.0% 100.0% 
 7
mismatches in concatenative speech synthesisâ€, 
IEEE Trans. Speech and Audio Processing, Vol. 
9, No. 3, pp. 232-239, 2001. 
[5] F. K. Soong and B. H. Juang, â€œOptimal 
quantization of LSP parameters. IEEE Trans. 
Speech Audio Process. Vol. 1, No. 1, 15-24, 
1993. 
[6] A. Kain and M. W. Macon, â€œSpectral voice 
conversion for Text-to-Speech synthesisâ€, in 
Proc. of ICASSP, pp. 285-299, 1998 
[7] D. Erro and A. Moreno, â€œWeighted frequency 
warping for voice conversionâ€, in Proc. of 
Interspeech, pp. 1965-1968, 2007. 
[8] P. Jax and P. Vary â€œOn artificial bandwidth 
extension of telephone speech,â€ Signal 
Processing, 83, 1707-1719, 2003.   
[9] H. T. Hu and C. Yu, â€œCombining HMM and 
Weighted Deviation Linear Transformation for 
Highband Speech Parameter Estimationâ€, 
IEICE Transactions on Information and 
Systems, E92.D , No. 7, pp.1488-1490, 2009. 
[10] M. Abe, S. Nakamura, K. Shikano, and H. 
Kuwabara, â€œVoice conversion through vector 
quantization,â€ in Proc. of ICASSP, pp. 655-658, 
1988.  
[11] Y. Stylianou, O. Cappe, and E. Moulines, 
â€œContinuous Probabilistic Transform for Voice 
Conversion,â€ IEEE Trans. on Speech and 
Audio Processing, Vol. 6, No. 2, pp. 131-142, 
1998. 
[12] H. T. Hu and Y. Chu â€œNarrowband-to-wideband 
expansion of telephony speech using piecewise 
deviation linear transformationâ€, International 
Journal of Electrical Engineering (IJEE), 2010. 
[13] L. Rabiner and B. H. Juang, Fundamentals of 
speech recognition, Prentice-Hall, 1993. 
[14] Y. Chen, M. Chu, E. Chang, J Liu, and R. Liu, 
â€œVoice Conversion with Smoothed GMM and 
MAP Adaptationâ€, in Proc. EUROSPEECH, pp. 
2413-2416, 2003. 
[15] L. M. Arslan, â€œSpeaker transformation 
algorithm using segmentalâ€, codebooks 
(STASC), Speech Communication, 28, pp. 
211-226, 1999. 
[16] M. M. Hasan, A. M. Nasr, and S. Sultana, â€œAn 
approach to voice conversion using feature 
statistical mappingâ€, Applied Acoustics, pp. 
513â€“532, 2005. 
[17] C. Y. Tseng, S. H. Pin, Y. Lee, H. M. Wang, Y. 
C. Chen, â€œFluent speech prosody: Framework 
and modelingâ€, Speech Communication, 46, 
284â€“309, 2005. 
 2
 
äºŒã€èˆ‡æœƒå¿ƒå¾— 
æœ¬æ¬¡ç ”è¨Žæœƒå¸å¼•è¨±å¤šåœ‹å®¶çš„å­¸è€…å°ˆå®¶å…±åŒï¥«èˆ‡ï¼Œæœƒè­°ï¥æ–‡ç¯©é¸åš´æ ¼ï¼Œé€šéŽï¥¡åƒ…ç´„ä¸‰æˆ
(131/440)ï¼Œæ‰€æœ‰é€šéŽå¯©æŸ¥çš„ï¥æ–‡å‡ç²åˆŠç™»åœ¨ IEEE Xplore ä¸¦ï¦œç‚º  EI (Compendex) èˆ‡  ISI 
Thomson (ISTP)çš„ï¥ªå¼•ï¼ŒæŒ‰ï§¤æ˜¯å ´é —å…·æ°´æº–çš„å­¸è¡“ç››æœƒã€‚ç„¶å› æœƒè­°å ´æ‰€å€‰ä¿ƒè®Šï¤ï¼Œå…¼ä¹‹ä¸¦ç„¡å¼·åˆ¶
è¦æ±‚ä½œè€…å¿…é ˆç¾å ´å ±å‘Šæ–¹ç²å‡†åˆŠç™»ï¼Œä»¥è‡´å‡ºå¸­ï¥¡åƒ…ç´„ï§‘æˆå·¦å³ã€‚å€‹äººä¸»æŒçš„ session åœ¨ç¬¬äºŒæ—¥ä¸Š
åˆï¼Œèµ·åˆæŽ’å®š 15 å ´æ¬¡çš„å ±å‘Šï¼ŒåŽŸæœ¬é‚„æ“”å¿ƒä¸‰å°æ™‚çš„æ™‚é–“ï¥§è¶³æ‡‰ä»˜ï¼Œæœªï¦¾ç¼ºå¸­è€…æ¯”é æœŸå¤šï¼Œè¨±å¤š
è©²åœ¨ä¸‹åˆå ±å‘Šçš„äººç«Ÿä¹Ÿï§¶æ™‚è¦æ±‚æŒªè‡³ä¸Šåˆå ±å‘Šï¼Œå¤šå°‘äºˆäººéŒ¯æ„•çš„æ„Ÿè¦ºã€‚ 
æœ¬äººéžå¸¸æ¦®å¹¸èƒ½æœ‰æ­¤æ¬¡æ©Ÿæœƒï¥«èˆ‡æ­¤æ¬¡æœƒè­°ï¼Œé™¤ç™¼è¡¨è‡ªå·±çš„ç ”ç©¶æˆæžœå¤–ï¼Œä¹Ÿæœ‰æ©Ÿæœƒï¦°è½å„åœ‹
è¨Šè™Ÿè™•ï§¤å°ˆæ¥­äººå£«åœ¨ç›¸é—œï¦´åŸŸçš„æŽ¢ï¥ªä»¥åŠæ‡‰ç”¨ç§‘æŠ€çš„æœ€æ–°é€²å±•ï¼Œå¯¦ç²ï¨—ï¥¼å¤šã€‚ 
 
ä¸‰ã€è€ƒå¯Ÿï¥«è§€æ´»å‹•(ç„¡æ˜¯é …æ´»å‹•è€…ï¥­ï¥¶) 
ç„¡ 
 
å››ã€å»ºè­° 
ï¥«åŠ åœ‹éš›ç ”è¨Žæœƒé™¤å¯çµï§¼åœ‹å…§å¤–å°ˆå®¶å­¸è€…ï¼Œèˆ‡å…¶äº¤ï§Šï¨€ç£‹ä¹‹å¤–ï¼Œä¹Ÿæœ‰åŠ©æ–¼çž­è§£å­¸è¡“å‹•å‘èˆ‡
ç§‘æŠ€æ–°çŸ¥ï¼Œè®“è‡ªå·±çš„ç ”ç©¶è¶•ä¸Šä»–äººçš„è…³æ­¥ã€‚è€Œé€™ï§çš„ç ”è¨Žæœƒå°ç ”ç©¶ç”Ÿçš„å­¸ç¿’æˆé•·æ ¼å¤–æœ‰ï¨—è™•ï¼Œ
æœªï¤­å¦‚æžœç¶“è²»è¨±å¯ï¼Œæ‡‰å¤šé¼“ï¥¿ç ”ç©¶ç”Ÿå‡ºåœ‹ï¥«åŠ å­¸è¡“æœƒè­°ï¼ŒåŠ©å…¶å¢žå»£ï¨Šèžå’Œæé«˜åœ‹éš›è¦–é‡Žã€‚ 
 
äº”ã€æ”œå›žè³‡ï¦¾åç¨±åŠå…§å®¹ 
æœƒè­°ï¥æ–‡é›†ä¸€å†Šï¼šProceedings of the 2009 International Conference on Signal Processing Systems 
(ICSPS 2009) 
 
ï§‘ã€å…¶ä»– 
ç„¡ 
 
 
 
 
1
2
0
1
2
0
1
2
0
1
2
0
2[ ] 2 2 cos
( )
2[ ] 2 2 cos
[ ] [ ]
[ ] [ ] /
lp
lp
N
k
N
k
N
k
N
k
kX k
N
F
kX k
N
x k x k
x k x k N
S W
W S W H
W
W H

 

 

 

 
Âª ÂºÂ§ Â·Â« Â»Â¨ Â¸Â© Â¹Â¬ Â¼ Âª ÂºÂ§ Â· Â« Â»Â¨ Â¸Â© Â¹Â¬ Â¼
Â­ Â½ Â° Â°Â° Â° Â® Â¾Â° Â°  Â° Â°Â¯ Â¿
Â¦
Â¦
Â¦
Â¦


 
 
            (3) 
where the second row of Eq. (3) is the time-domain 
representation using Parsevalâ€™s theorem with [ ]x k  denoting 
the IFFT derived from [ ]X k .  The pitch period is found by 
searching the location of the maximum ( )F W  within a 
reasonable index range, i.e. 
^ `
min max
Ë† arg max ( )
p p
p FW Wd d ,                  (4) 
where minp  and maxp  are chosen as 20 and 180, respectively. 
Fig. 1 illustrates the modified spectral flattening procedure 
along with the resulting ( )F W .  Peaks are found in ( )F W  at 
the multiples of the pitch period.  The time lag of the largest 
peak is commonly regarded as the pitch period.  One of the 
important features of ( )F W  is that the peak value also reflects 
the periodical strength.  For periodical signals, Eq. (3) 
generally comes up with a value much greater than unity at the 
pitch period.  For random noise, the values derived from the 
numerator and denominator in Eq. (3) are very close, 
rendering a ratio around unity.     
The operation in the denominator of ( )F W  is equivalent to 
get the squared sum of the difference between the zero-padded 
signal [ ]x i  and its circularly rotated version [ ]x i W .  Let us 
decompose [ ]x i  into a periodical component termed [ ]s i  and 
a non-periodical component termed [ ]d i .  Suppose now, for a 
specific W c , [ ]s i  and [ ]s i W c  are identical due to signal 
periodicity, whereas [ ]d i  and [ ]d i W c  are presumably 
uncorrelated.  Then, the expectation of the numerator of 
( )F W c  can be approximated by 4 2 2ss ss ddMR R MRW c  ,
where ssR  and ddR  represent the zero-lag autocorrelation 
function of [ ]s i  and [ ]d i , respectively.  M denotes the actual 
frame length with no zero padding involved.  Likewise, the 
denominator can be substituted by 2 2ss ddR MRW c  .  Hence 
the expectation of ( )F W c  becomes 
> @
    
    
1 2
0
1 2
0
( )
[ ] [ ] [ ] [ ]
[ ] [ ] [ ] [ ] /
N
i
N
i
E F
s i d i s i d i
E
s i d i s i d i N
E W
W W
W W H

 

 
c 
Âª Âºc c    Â« Â»Â« Â» Â« Â»c c     Â« Â»Â¬ Â¼
Â¦
Â¦
4 2 2
.
2 2
ss ss dd
ss dd
MR R MR
R MR
W
W
c | c 
          (5) 
If we further define ss
dd
R
R
J  , then J  is readily computed 
from Eq. (5) such that  
 
 
2 1
4 2 2
M
M
EJ W W E
 c c  .              (6) 
Here we introduce a new term xK  called â€œperiodical indexâ€ 
(PI), which is defined as the ratio of ssR  to xxR  as
1
ss ss
x
xx ss dd
R R
R R R
JK J     .            (7) 
We will demonstrate the usefulness of PI in the following 
sections. 
III. ACOUSTIC FEATURES FOR V/UV DETECTION
Five feature parameters are under test.  The first one is the 
signal power in logarithmic scale, which is defined by   
1
2
1
0
1log ( )
fL
if
v x i
L

 
Â§ Â· Â¨ Â¸Â¨ Â¸Â© Â¹Â¦ ,              (8) 
where fL  is the frame length.  This is an important feature 
reflecting the vocal intensity.  The second parameter 2v  is the 
zero crossing rate (ZCR), which is an acoustic feature heavily 
used in speech analysis and can be calculated by 
   12
0
0.5 ( 1) ( )
fL
if
v sign x i sign x i
L

 
  Â¦ .       (9) 
For the third parameter, we adopt the spectral entropy (SE) 
[10] that has been attempted in voice activity detection.  The 
SE can be derived from [ ]X k  by first assigning a probability 
mass function using 
0 500 1000 1500 2000 2500 3000 3500 4000
1
2
3
4
5
6
x 104
Frequency [Hz]
Mag
nitu
de
(a)
0 20 40 60 80 100 120 140 160 180
0
2
4
6
8
10
12
14
peak value
Time lag
Amp
litud
e
(b)
0 20 40 60 80 100 120 140 160 180
0
0.2
0.4
0.6
0.8
1
Time lag
Amp
litud
e
(c)
Figure 1.  Pitch estimation by examining the periodicity index derived 
from the estimation function.  
(a) original spectrum (dash line), modified spectrum (solid line). 
(b) estimation function ( )F W  derived from the modified spectrum. 
(c) periodicity index derived from ( )F W
136
Authorized licensed use limited to: NATIONAL ILAN UNIVERSITY. Downloaded on January 31, 2010 at 03:17 from IEEE Xplore.  Restrictions apply. 
Table 2 lists the results.  The error rates appear quite steady 
for the 8 experimental arrangements; the averages are around 
3.31% for the Viterbi algorithm and 3.45% for the soft 
decision method while 1v , 2v , 3v  and 4v  are taken into 
account.  In case 4v  (PI) is substituted by 5v  (NUAC), the 
error rates are increased to 3.90% and 3.78%, however.   
It is observed in our experiments that the misclassifications 
often occur in the transition areas.  For these areas, sometimes 
it is hard to make a definite decision even by manual judgment.  
The other factor impeding the classification accuracy consists 
in the range for deriving 4v  and 5v , which is 2.25 times 
longer than that used to derive 1v , 2v  and 3v .  This results in 
considerable overlap and consequently leads to ambiguous 
outcomes.  Hence in Table 2 we present another statistics 
wherein the errors at the conjunctions (i.e., 0H ÃŽ 1H , or 
1H ÃŽ 0H ) are exempted.  Under the less rigorous condition, 
the error rates for the Viterbi algorithm are 0.52% and 0.76% 
in average for feature sets 1 2 3 4( , , , )v v v v  and 1 2 3 5( , , , )v v v v ,
respectively.  Such low error rates are generally good enough 
to conduct speech analysis and synthesis with satisfactory 
quality. 
V. PITCH TRACKING
As shown in Fig. 1, the function ( )F W  given in Eq. (3) 
generally results in distinct peaks at multiples of the pitch 
period.  Most often the highest peak occurs at the pitch period.  
However, influences like formants and/or background noise 
might perturb the peak amplitude or produce spurious peaks.  
Hence a better strategy for picking the right peak is to refer to 
all candidates across neighboring frames.  This turns out to be 
another optimization problem resolvable using the Viterbi 
search, which aims at finding the optimal path with the highest 
likelihood.  As the full Viterbi search is computationally 
burdensome, we limit the number of candidates to 3 in each 
frame.  The search process can be best apprehended using a 
trellis diagram shown in Fig. 3.  In this trellis, each node 
denotes a distinct state at a time frame and each arrow 
represents a transition to a new state at the next frame.   
The chance of getting to a trellis entry from the previous 
nodes is computed as the product of these nodes' observation 
probabilities and the transition probabilities between them.  In 
this study, the probability of observing io  at node iS  is given 
as  
     | ( ) ( ) |i i i i i iP S P P S P S o o o          (13) 
where io  is the observation vector of feature parameters 
extracted at frame i , i.e. > 1v , 2v , 3v ,  1 2 3, , iK K K ÂºÂ¼ , in which 
 1 2 3, ,K K K  stands for a 3-component tuple with kK  being the 
PI of the k th peak of the estimation function.  Only one 
component is selected from  1 2 3, ,K K K  to form the 
observation vector when used in voicing detection.  In Eq.  
(13), the ( )iP S  is assigned as a constant for all iS â€™s.  Hence 
( ) ( )i iP P So  can be treated as a scale factor c , which is 
negligible in the searching process.  Also, the choice of the 
pitch state iS  is equivalent to picking the pitch candidate iSp
at the particular state under the voicing condition 1H .  As a 
result, 
   1Ë†| , |ii i S iP S cP p p H|  o o .         (14) 
From Bayes' rule, we have  
     1 1 1Ë† Ë†, | | | ,i iS i i S iP p p H P H P p p H   o o o .   (15) 
Since
   
 
   
 
 
1 1
1
1 1
1 1 0 0
0 0
1 1
| ( )
|
( )
| ( )
| ( ) | ( )
1
| ( )1
| ( )
i
i
i
i
i i
i
i
P H P H
P H
P
P H P H
P H P H P H P H
P H P H
P H P H
 
 
 

o
o
o
o
o o
o
o
   (16) 
This term is readily obtained as the prior probabilities, i.e. 
0( )P H  and 1( )P H , and the likelihood estimates, i.e. 
 0|P x H  and  1|P x H , are assessable from HMM.  On the 
other hand, as the PI itself is a convenient voicing indicator, 
 1Ë† | ,k iP p p H o  can be given in a heuristic manner. 
Figure 3.  Illustration of Viterbi search. 
â€¦â€¦ 
â€¦â€¦ 
â€¦â€¦ 
Frame index 
1
2
3
1 2 3 t-1 t
Node
number 
Node 
probability 
Transition 
probability 
Table 2:  Error rates (in percentage) based on the HMM detectors. 
Log-signal power, ZCR, SE, 
Periodical index 
Log-signal power, ZCR, SE, 
Unbiased autocorrelation 
Viterbi  Soft Decision Viterbi  Soft Decision 
Features 
Test set Rigid Less 
Rigid 
Rigid Less
Rigid 
Rigid Less
Rigid 
Rigid Less 
Rigid 
1 3.34 0.49 3.01 0.57 4.09 0.85 3.54 0.81 
2 3.64 0.55 3.57 0.91 4.19 0.66 3.82 0.96 
3 3.28 0.70 3.61 0.97 3.96 0.81 3.83 1.08 
4 3.18 0.50 3.40 0.87 3.28 0.54 3.30 0.74 
5 3.24 0.48 3.78 0.66 3.80 0.55 3.91 0.74 
6 2.79 0.37 2.91 0.57 3.70 0.57 3.29 0.73 
7 3.39 0.51 3.60 0.72 3.72 0.57 4.10 0.93 
8 3.60 0.59 3.75 0.78 4.49 0.91 4.43 1.14 
Average 3.31 0.52 3.45 0.76 3.90 0.68 3.78 0.89 
138
Authorized licensed use limited to: NATIONAL ILAN UNIVERSITY. Downloaded on January 31, 2010 at 03:17 from IEEE Xplore.  Restrictions apply. 
