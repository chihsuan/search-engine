exemplar-based inpainting technique or matting, are 
used to develop the new types of forged image.  
This project focuses on the detecting images forged 
by the techniques of exemplar-based inpainting. We 
propose a fast and effective forgery detection 
algorithm for exemplar-based inpainting forged image. 
Our algorithm consists of two major parts: suspicious 
region detection and forged region identification. In 
the first part, we compute the similarity among 
regions in the image to find the region pairs with 
high similarity, and then the proposed corresponding 
vector field is applied to find the suspicious 
regions. This vector field is especially forged image 
with uniform background by using corresponding 
vector. In the second part, we present a multi-region 
correlation (MRC) technique to analyze the relation 
between all the suspicious regions, and then identify 
the forged regions. Moreover, a fast searching 
algorithm based on weight transformation is proposed 
to speed up the similarity detection. 
 
è‹±æ–‡é—œéµè©ï¼š Digital image forensics, digital forgery detection, 
exemplar-based inpainting technique 
 
  1 
 
ä¸€ã€å‰è¨€ 
ç”±æ–¼ç¶²è·¯æ™®åŠåŒ–ã€é›»è…¦æ•ˆèƒ½æå‡åŠç›¸é—œè»Ÿç¡¬é«”å¿«é€Ÿæ›´æ–°ï¼Œä½¿å¾—æ•¸ä½å¤šåª’é«”ç§‘æŠ€è¿…é€Ÿç™¼å±•ï¼Œç”±æ–¼æ•¸
ä½å½±åƒå·²ç¶“é€æ¼¸æˆç‚ºæˆ‘å€‘ç”Ÿæ´»ä¸­ç²å–é‡è¦è³‡è¨Šæˆ–æ˜¯æ–°èåª’é«”å‚³æ’­çš„ç®¡é“ï¼Œé€²æ­¥è¿…é€Ÿçš„å½±åƒè™•ç†æŠ€è¡“å‰µ
é€ å‡ºæ›´å¤šç¨®é¡çš„æ•¸ä½å½é€ å½±åƒã€‚å› æ­¤æ•¸ä½å½±åƒå½é€ åµæ¸¬(Digital Image Forgery Detection)å—åˆ°äººå€‘çš„é—œ
æ³¨ï¼Œæ­¤é ˜åŸŸæ­£è™•æ–¼è¿…é€Ÿç™¼å±•éšæ®µï¼Œé€™äº›æŠ€è¡“å¯æ‡‰ç”¨åœ¨è¨±å¤šåœ°æ–¹ï¼Œå¦‚ï¼šä¿éšªè™•ç†ã€æ–°èé›œèªŒç…§ç‰‡çš„çœŸå½
è­˜åˆ¥ã€çŠ¯ç½ªç¾å ´ç…§ç‰‡çš„çœŸå½è¾¨è­˜â€¦ç­‰ã€‚ç›®å‰å­˜åœ¨çš„æ•¸ä½å½±åƒå½é€ åµæ¸¬çš„æ–¹æ³•åˆ†æˆActive-based approach 
[1][2][3] å’ŒPassive-based approach [8]-[25]ã€‚Active-based approachå…¶ä¸»è¦ç‰¹å¾µç‚ºåœ¨æ•¸ä½å½±åƒä¸­å¿…é ˆé å…ˆ
ç½®å…¥æŸäº›è³‡è¨Šï¼Œå¦‚æµ®æ°´å°ï¼Œè€Œåµæ¸¬æ™‚å†å¾å½±åƒä¸­å–å‡ºäº‹å…ˆç½®å…¥çš„è³‡è¨Šé€²è¡Œè­˜åˆ¥ä¹‹å·¥ä½œï¼›Passive-based 
approachå‰‡ç‚ºä¸ä¾è³´ä»»ä½•é å…ˆç½®å…¥æŸäº›è³‡è¨Šä¸‹ï¼Œé‡å°å½±åƒçš„çœŸå½åŠä¾†æºé€²è¡Œè­˜åˆ¥å·¥ä½œã€‚Active-based 
approachçš„ç¼ºé»æ˜¯ä¸€èˆ¬æ•¸ä½è£ç½®ä¸¦æ²’æœ‰æ”¯æ´é å…ˆç½®å…¥è³‡è¨Šä¹‹åŠŸèƒ½ï¼Œå› æ­¤è¦ä½¿ç”¨é€™é¡çš„æ–¹æ³•å¿…é ˆæœ‰ç‰¹æ®Šè£
ç½®æˆ–å¾Œè™•ç†ç½®å…¥è³‡è¨Šåˆ°æ•¸ä½å½±åƒä¸­ï¼Œæ‰€ä»¥ç„¡æ³•å»£æ³›ä½¿ç”¨ã€‚ 
 
äºŒã€ç ”ç©¶ç›®çš„ 
æœ‰åˆ¥æ–¼ç›®å‰å¤§éƒ¨åˆ†çš„ç ”ç©¶ï¼Œæˆ‘å€‘å°‡ä»¥è‡ªå‹•ç”¢ç”Ÿçš„å½é€ å½±åƒä½œç‚ºç ”ç©¶ä¸»è»¸ï¼Œæ­¤é¡å‹çš„å½é€ æ–¹å¼æˆ‘å€‘
å°ˆæ³¨åœ¨åµæ¸¬exemplar-based inpainting techniqueï¼Œå› ç‚ºexemplar-based inpainting techniqueå…·æœ‰è‰¯å¥½ä¿®è£œå½±
åƒç¼ºæå€åŸŸçš„èƒ½åŠ›ï¼Œæ­¤é¡å‹å½±åƒçœŸå¯¦æ€§çš„å•é¡Œå€¼å¾—è¢«æ³¨æ„ã€‚æœ¬ç ”ç©¶æå‡ºä¸€å€‹æœ‰æ•ˆä¸”å¿«é€Ÿçš„å½±åƒå½é€ åµ
æ¸¬æ¼”ç®—æ³•ï¼Œé‡å°Digital Image Inpainting techniqueæ‰€ç”¢ç”Ÿçš„æ•¸ä½å½é€ å½±åƒé€²è¡Œåµæ¸¬ï¼Œæ ¹æ“šç›¸é—œç‰¹å¾µåµæ¸¬
èƒ½å¤ å”åŠ©ä½¿ç”¨è€…é€²è¡Œæ•¸ä½å½±åƒçœŸå½åˆ¤æ–·ï¼Œå¯¦é©—çµæœè­‰æ˜æˆ‘å€‘æå‡ºçš„å½±åƒå½é€ åµæ¸¬æ¼”ç®—æ³•ç¢ºå¯¦å…·æœ‰é«˜æº–
ç¢ºç‡è­˜åˆ¥çœŸå¯¦å½±åƒèˆ‡å½é€ å½±åƒã€‚ 
 
ä¸‰ã€æ–‡ç»æ¢è¨ 
æ•¸ä½å½±åƒå½é€ åµæ¸¬è¶Šä¾†è¶Šå—åˆ°æ³¨æ„ï¼Œè¨±å¤šç›¸é—œç ”ç©¶å·²ç¶“æœ‰ä¸€å®šçš„æˆæœï¼Œå› æ­¤å·²ç¶“æœ‰Survey paper 
[4][5][6][7] æ•´ç†ç›¸é—œç ”ç©¶ä¹‹çµæœï¼Œæ ¹æ“šMahdian et al.[5] æå‡ºä¸€èˆ¬å½é€ å½±åƒçš„ç¨®é¡å¯ä»¥åˆ†ç‚ºä¸‰é¡ï¼Œ (1) 
Removing-based forgery: removing or concealing region of interest in the digital image ï¼› (2) 
Compositing-based forgery: compositing region of interest into the digital imageï¼›(3) Misrepresenting-based 
forgery: misrepresenting the image informationã€‚å¤§éƒ¨åˆ†çš„æ•¸ä½å½é€ åµæ¸¬ç›¸é—œç ”ç©¶éƒ½æ˜¯é‡å°ä¸Šè¿°åˆ†é¡æ‰€ç”¢
ç”Ÿçš„å½é€ å½±åƒé€²è¡Œåµæ¸¬ï¼Œæˆ‘å€‘ä¾æ“šæ“·å–ä¸åŒé‡è¦ç‰¹å¾µä¾†å›é¡§ç›¸é—œç ”ç©¶ï¼š  
ï¼ˆä¸€ï¼‰Identification of image source([20][21][22][23])ï¼šæ•¸ä½å½±åƒéƒ½æ˜¯ä¾†è‡ªä¸åŒçš„æ•¸ä½å½±åƒè£ç½®ï¼Œç”±æ–¼ä¸
åŒçš„æ•¸ä½å½±åƒè£ç½®ï¼Œåœ¨å½±åƒè£ç½®å…§éƒ¨çš†æœ‰ä¸åŒçš„åƒæ•¸è¨­å®šæˆ–å½±åƒè™•ç†æ ¸å¿ƒï¼Œå› æ­¤é€šå¸¸ç¶“ç”±é€™äº›åŒä¸€è£
ç½®æ‰€ç”¢ç”Ÿçš„å½±åƒæœƒæœ‰ç‰¹æ®Šçš„ç‰¹å¾µï¼Œç•¶å½±åƒä¸­æœ‰ä¸ä¸€è‡´çš„ç‰¹å¾µå‡ºç¾æ™‚ï¼Œæ¥µå¯èƒ½æ­¤å½±åƒç‚ºå½é€ å½±åƒã€‚ 
ï¼ˆäºŒï¼‰Re-sampling[18][19]ï¼šåœ¨å‰µé€ å½±åƒåˆæˆæ™‚ï¼Œé€šå¸¸éœ€è¦ä½œre-samplingçš„æ“ä½œ(å¦‚ : resizeã€rotateã€
translate)ï¼Œè€Œre-samplingä¹Ÿæœƒä¼´éš¨interpolationï¼Œå› æ­¤åƒç´ ä¹‹é–“çš„é—œé€£æ€§æœƒç™¼ç”Ÿè®ŠåŒ–ï¼Œå…¶ç”¢ç”Ÿç‰¹æ®Šçš„é€±æœŸ
é—œä¿‚å¯ä½œç‚ºåˆ¤æ–·å½é€ çš„ä¾æ“šã€‚ 
ï¼ˆä¸‰ï¼‰ Lighting direction[15][16][17]ï¼šä¸€èˆ¬å¸¸è¦‹åˆæˆå½±åƒé€šå¸¸æ˜¯ç”±å…©å¼µä»¥ä¸Šçš„ä¾†æºå½±åƒæ‰€åˆæˆè€Œæˆï¼Œ
ä½†é€šå¸¸å¾ˆé›£ä¿æŒä¸€è‡´çš„å…‰æºæ¢ä»¶ï¼Œå› æ­¤ä¸åŒä¾†æºå½±åƒå…¶æ‹æ”ç’°å¢ƒä¸ä¸€æ¨£ä¹Ÿæœƒå°è‡´å…‰æºçš„æ–¹å‘ä¸ä¸€æ¨£ï¼Œ
æ‰€ä»¥å…‰æºä¸ä¸€è‡´æ€§èƒ½å¤ ç”¨ä¾†æª¢è¦–æ˜¯å¦ç‚ºå½é€ å½±åƒã€‚ 
ï¼ˆå››ï¼‰Region duplication (copy-move or copy-paste)[8][9]10][11]ï¼šRegion duplicationæ˜¯ä¸€èˆ¬å¸¸è¦‹çš„å½±åƒå½
é€ æ–¹æ³•ï¼Œå…¶å½é€ çš„æ–¹å¼æ˜¯åœ¨å½±åƒä¸­è¤‡è£½ä¸€å€‹å€åŸŸç„¶å¾Œè²¼åˆ°åŒä¸€å½±åƒä¸­å¦ä¸€å€‹å€åŸŸï¼Œå®ƒå¯èƒ½æ˜¯è¦éš±è—ä¸€
å€‹ç‰©ä»¶æˆ–ä¸€å€‹å ´æ™¯ï¼Œä¸€äº›ç ”ç©¶è€…æå‡ºä¸åŒæ–¹æ³•å»åµæ¸¬Region duplication çš„å•é¡Œã€‚ 
  3 
 
Figure 1. Illustration of relation group. 
æˆ‘å€‘ä½¿ç”¨ key valueçš„æ–¹å¼ç¾¤èšç›¸ä¼¼ color intensity feature çš„ blocksï¼Œåˆ©ç”¨ binary searchå°‹æ‰¾æœ€ç›¸ä¼¼
çš„ key valueï¼Œé€é matchingç›¸ä¼¼ color intensity feature çš„ blocksèƒ½å¤ æº–ç¢ºå°‹æ‰¾åˆ° best match blockï¼Œå¦‚æ­¤
å¯ä»¥ä¸å¿…æµªè²»æ™‚é–“åœ¨ matching color intensity featureç›¸ä¼¼åº¦ä½çš„ blocksä¸Šï¼Œæœ‰æ•ˆæå‡ srarching æ•ˆèƒ½ã€‚ 
åœ¨æˆ‘å€‘æå‡ºçš„æ–¹æ³•ä¸­ï¼Œç›®çš„å¸Œæœ›å°‡ target block çš„ color intensity feature ä¿ç•™ï¼Œå› æ­¤ weight valueæ‰®
æ¼”éå¸¸é‡è¦çš„è§’è‰²ã€‚å¦å¤–ï¼Œkey valueçš„æ±ºå®šèˆ‡ search rangeçš„å¤§å°æ˜¯æ¯æ¯ç›¸é—œçš„ï¼Œsearch rangeçš„å¤§å°
å½±éŸ¿æ•´å€‹ matching algorithmçš„åŸ·è¡Œæ•ˆèƒ½ï¼Œå› æ­¤æˆ‘å€‘ä¹Ÿå°‡åˆ†æä¸åŒ search rangeçš„å¤§å°å°æ–¼æ•ˆèƒ½çš„å½±éŸ¿ã€‚ 
ç‚ºæ±ºå®šèƒ½å¤ ä»£è¡¨ target blockçš„ color intensity featureï¼Œå› æ­¤æˆ‘å€‘å®šç¾©ä¸€å€‹ measure functionï¼Œæˆ‘å€‘ä¾
æ“š exhaustive searchçš„ similarity detectionçµæœç‚ºæ¨™æº–ï¼Œå®šç¾©ä¸€å€‹å®Œæ•´æ€§(Completeness)measure functionï¼Œ
å®Œæ•´æ€§è¶Šé«˜è¡¨ç¤ºæ‰€é¸æ“‡çš„ intensity featureè¶Šå…·ä»£è¡¨ target blockçš„ color intensity featureï¼Œå…¬å¼å®šç¾©å¦‚ä¸‹ï¼š 
%e d
e
R R
Completeness
R
ïƒ‡
ï€½                          (1) 
where eR ç‚º exhaustive search çš„ similarity detection çµæœï¼Œ dR ç‚ºä¸åŒ weight transformation çš„ similarity 
detectionçµæœã€‚ 
 åœ¨æ­¤æˆ‘å€‘æ¸¬è©¦å››ç¨®ä¸åŒ weight transformationæ‰€ç”¢ç”Ÿçš„æ•ˆæœï¼Œå€‹åˆ¥ç‚ºç›¸åŒ weightã€å¶æ•¸ weight å’Œå¥‡
æ•¸weightï¼ŒåŠè³ªæ•¸(prime number) weight transformationï¼Œæˆ‘å€‘é‡å°key valueç›¡é‡èƒ½å¤ å”¯ä¸€ä»£è¡¨ target block
çš„ color intensity feature ä¹‹ç‰¹æ€§é€²è¡Œåˆ†æï¼Œæˆ‘å€‘å®šç¾©ä¸€å€‹ measure function ä¾†é‡æ¸¬ key value çš„å”¯ä¸€æ€§
(Uniqueness)ï¼Œå…¬å¼å®šç¾©å¦‚ä¸‹:  
1 1 %
B
N
Uniqueness
N
ï€­ï€½                             (2) 
where 1 1N ï€­ ç‚ºç¸½å…±å”¯ä¸€ key valueå°æ‡‰åˆ°ä¸€å€‹ target blockçš„å€‹æ•¸ï¼Œ BN ç‚ºæ‰€æœ‰ target blockçš„å€‹æ•¸ã€‚ 
Figure 2 å‘ˆç¾ prime numbers weight transformationå…·æœ‰æœ€é«˜çš„ one-to-oneæ•ˆæœï¼Œå¦å¤–ï¼Œå¥‡æ•¸ weight 
transformationä¹Ÿå…·æœ‰ä¸€å®šç¨‹åº¦çš„ one-to-oneæ•ˆæœã€‚  
  5 
å¥½çš„ key value èƒ½å¤ ä»¥æœ€å° search range é”åˆ°æœ€ä½³æ•ˆèƒ½ï¼Œå› æ­¤ search range å°‡å½±éŸ¿åŸ·è¡Œçš„æ•ˆèƒ½èˆ‡
matching æ•ˆæœï¼Œsearch rangeå¤§æœ‰è¼ƒä½³çš„ matching æ•ˆæœï¼Œæ™‚é–“è¤‡é›œåº¦æ¥è¿‘ exhaustive searchï¼Œsearch range
å°æœ‰è¼ƒä½³çš„æ™‚é–“è¤‡é›œåº¦ï¼Œä½† matching æ•ˆæœè¼ƒå·®ï¼Œæˆ‘å€‘å¿…é ˆåœ¨å…©å€‹ç›®æ¨™ä¸­å–å¾—å¹³è¡¡ï¼Œå› æ­¤æˆ‘å€‘åˆ†ææ¯ä¸€
ç¨® weight transformationçš„æœ€ä½³ search rangeè¨­å®šã€‚æˆ‘å€‘çš„ç›®æ¨™æ˜¯å¸Œæœ›åœ¨é€Ÿåº¦èˆ‡å®Œæ•´åº¦å–å¾—å¹³è¡¡ï¼Œå› æ­¤
æˆ‘å€‘è¦æ±‚å®Œæ•´åº¦é” 90%ä»¥ä¸Šçš„ç›¸å°æ‡‰çš„ search rangeæ‰€åŸ·è¡Œçš„æ™‚é–“ï¼Œç‚ºæ­¤æ¼”ç®—æ³•çš„æœ€ä½³æ•ˆèƒ½ã€‚ 
 
äº”ã€çµæœèˆ‡è¨è«– 
 æœ¬ç« ç¯€å°‡é©—è­‰æˆ‘å€‘æå‡ºå½é€ åµæ¸¬æ¼”ç®—æ³•çš„æœ‰æ•ˆæ€§ï¼Œç¨‹å¼é–‹ç™¼ç’°å¢ƒç‚º Visual Studio 2005 æ­é…ä½¿ç”¨
OpenCV libraryï¼Œå¯¦é©—è¨­å‚™ç‚ºæ¡Œä¸Šå‹é›»è…¦(Intel Core 2 Duo CPU E8400 3.0GHz, 2GB RAM)ï¼Œå¯¦é©—åƒæ•¸ç‚º
Block Size = 5 5ï‚´ ã€ï¨  = 0.5ã€ï¡ ,ï¢  = 0.7ã€ cT = 3ï¼Œæ¸¬è©¦å½±åƒç‚ºä½¿ç”¨ Criminisiâ€™ algorithmæ‰€ç”¢ç”Ÿçš„å½é€ 
å½±åƒï¼Œå¦å¤– copy-move forgeryæ˜¯ä½¿ç”¨ PhotoImpact æ‰€ç”¢ç”Ÿçš„å½é€ å½±åƒã€‚ 
 æœ¬å¯¦é©—çš„ç›®çš„æ˜¯é©—è­‰æå‡ºæ¼”ç®—æ³•çš„æœ‰æ•ˆæ€§ï¼Œæˆ‘å€‘ä½¿ç”¨äº”ç¨®ä¸åŒçš„å¯¦é©—ä¾†é©—è­‰ï¼Œå¯¦é©— 1ç‚º single forged 
regionå’Œæ²’æœ‰ uniform backgroundçš„å½é€ åµæ¸¬çµæœï¼Œå¯¦é©— 2ç‚º single forged regionå’Œæœ‰ uniform background
çš„å½é€ åµæ¸¬çµæœã€‚Figure 4.çš„çµæœç‚ºé‡å° single forged regionå’Œæ²’æœ‰ uniform background çš„æ¸¬è©¦å½±åƒé€²
è¡Œåµæ¸¬ï¼Œå¦‚ Figure 4.(a)æ‰€ç¤ºï¼Œå½±åƒä¸­ woman ç‚º target regionï¼ŒFigure 4.(b)å°‡ womanç§»é™¤ï¼› Figure 4.(c)
ç‚º example-based inpainting techniquen æ‰€ç”¢ç”Ÿçš„å½é€ å½±åƒï¼›Figure 4.(d) é¡¯ç¤ºåˆæ­¥é‹ç®—å‡ºçš„å¯ç–‘å€åŸŸçš„éƒ¨
åˆ†ï¼Œæˆ‘å€‘å¯ä»¥çœ‹åˆ°åœ¨éƒ¨åˆ†çš„èƒŒæ™¯å€åŸŸæœ‰è¨±å¤šè¢«åˆ¤å®šç‚ºå¯ç–‘å€åŸŸã€‚Figure 4.(e)é¡¯ç¤ºæˆ‘å€‘æå‡ºçš„æ¼”ç®—æ³•èƒ½å¤ 
æº–ç¢ºåµæ¸¬å‡º forged region ä¸¦ä¸”æœ‰æ•ˆæ’é™¤å…¶ä»– non-forged region ç”¢ç”Ÿçš„ false alarmï¼›è€Œå¦ä¸€æ–¹æ³• Wuâ€™s 
algorithmçš„çµæœåªèƒ½é¡¯ç¤ºç²—ç•¥çš„ forged regionä¸¦ä¸”ç„¡æ³•æ’é™¤å…¶ä»– non-forged(Figure 4.(f))ã€‚Figure 5å‰‡é¡¯
ç¤ºå¦å¤–ä¸€å€‹å…·æœ‰å‡å‹»èƒŒæ™¯çš„å½±åƒã€‚Figure 5.(a)ç‚ºåŸå§‹å½±åƒï¼Œè€Œ Figure 5.(b)ç‚ºç¶“é inpainting è™•ç†å¾Œçš„å½
é€ å½±åƒã€‚Figure 5.(c) ç‚ºç›¸ä¼¼å€å¡Šæœå°‹çš„çµæœï¼Œå¯ä»¥è§€å¯Ÿåˆ°åœ¨èƒŒæ™¯çš„åœ°æ–¹æœ‰å¾ˆå¤§çš„ä¸€éƒ¨ä»½æˆç‚ºå¯ç–‘å€åŸŸï¼Œ
é€™æ˜¯ä¸€èˆ¬ç”¨ç›¸ä¼¼åº¦ä¾†è™•ç†çš„æ–¹æ³•æœƒé‡åˆ°çš„å•é¡Œï¼Œå› ç‚ºå‡å‹»èƒŒæ™¯å¾ˆå®¹æ˜“é€ æˆé€™ç¨®ç¾è±¡ï¼›è€Œæˆ‘å€‘çš„æ–¹æ³•ä¹‹
çµæœ(Figure 5.(d))å¯å¤§å¹…åº¦æ”¹å–„é€™ç¨®ç¾è±¡ï¼Œæ‰¾å‡ºç›¸ç•¶æ­£ç¢ºçš„å½é€ å€åŸŸã€‚ 
 
   
(a)                          (b)                       (c) 
   
(d)                          (e)                        (f) 
  7 
[5] B. Mahdian and S. Saic, â€œBlind methods for detecting image fakeryâ€, in IEEE International Carnahan Conference on Security 
Technology, page(s): 280 - 286, 2008. 
[6] Z. Zhang, Y. Ren, X. J. Ping, Z. Y. He and S. Z. Zhang,â€œA Survey on passive-blind image forgery by doctor method detectionâ€, 
in International Conference on Machine Learning and Cybernetics, page(s): 3463 - 3467, 2008. 
[7] W. Luo, Z. Qu , F. Pan and J. Huang, â€œA survey of passive technology for digital image forensicsâ€, in Frontiers of Computer 
Science, page(s): 166 - 179, 2007. 
[8] J. Fridrich, D. Soukal and J. Lukas, â€œDetection of copy-move forgery in digital imagesâ€, in Proceedings of Digital Forensic 
Research Workshop, page(s): 55 - 61, 2003. 
[9] A. Langille and M. Gong, â€œAn Efficient Match-based Duplication Detection Algorithmâ€, in Proceedings of the 3rd Canadian 
Conference on Computer and Robot Vision, page(s): 63 - 71, 2006. 
[10] B. Mahdian and S. Saic, â€œ Detection of copyâ€“move forgery using a method based on blur moment invariantsâ€, in Forensic 
science international, page(s): 180 - 189, 2007. 
[11] H. L. Huang, W. Q. Guo and Y. Zhang, â€œC. Rey and J. L. Dugelay, â€œA survey of watermarking algorithms for image 
authenticationâ€, in EURASIP Journal on applied Signal Processing, special issue on image analysis for multimedia 
interactive services, page(s): 613 - 621, 2002. 
[12]  F. Hartung and M. Kutter,â€ Multimedia watermarking techniquesâ€, in Proc. IEEE, page(s):1079 - 1107, 1999.  
[13] C. S. Lu and H. M. Liao, â€œStructural digital signature for image authentication: an incidental distortion resistant schemeâ€, in 
IEEE Transactions on Multimedia, page(s): 161 - 173, 2003. 
[14] H. Farid, â€œImage forgery detectionâ€, in IEEE Signal Processing Magazine, page(s): 16 - 25, 2009. 
[15] B. Mahdian and S. Saic, â€œBlind methods for detecting image fakeryâ€, in IEEE International Carnahan Conference on Security 
Technology, page(s): 280 - 286, 2008. 
[16] Z. Zhang, Y. Ren, X. J. Ping, Z. Y. He and S. Z. Zhang,â€œA Survey on passive-blind image forgery by doctor method detectionâ€, 
in International Conference on Machine Learning and Cybernetics, page(s): 3463 - 3467, 2008. 
[17] W. Luo, Z. Qu , F. Pan and J. Huang, â€œA survey of passive technology for digital image forensicsâ€, in Frontiers of Computer 
Science, page(s): 166 - 179, 2007. 
[18] J. Fridrich, D. Soukal and J. Lukas, â€œDetection of copy-move forgery in digital imagesâ€, in Proceedings of Digital Forensic 
Research Workshop, page(s): 55 - 61, 2003. 
[19] A. Langille and M. Gong, â€œAn Efficient Match-based Duplication Detection Algorithmâ€, in Proceedings of the 3rd Canadian 
Conference on Computer and Robot Vision, page(s): 63 - 71, 2006. 
[20] B. Mahdian and S. Saic, â€œ Detection of copyâ€“move forgery using a method based on blur moment invariantsâ€, in Forensic 
science international, page(s): 180 - 189, 2007. 
[21] H. L. Huang, W. Q. Guo and Y. Zhang, â€œDetection of copy-move forgery in digital images using SIFT algorithmâ€, in IEEE 
Pacific-Asia Workshop on Computational Intelligence and Industrial Application, page(s): 272 - 276, 2008. 
[22] W. Li, N. Yu and Y. Yuan, â€œDoctored JPEG image detectionâ€, in IEEE International Conference on Multimedia and Expo, 
page(s): 253 - 256, 2008. 
[23] J. Lukas and J. Fridrich, â€œEstimation of primary quantization matrix in double compressed jpeg imagesâ€, in Proc. Digital 
Forensic Research Workshop, page(s): 67 - 84, 2003. 
[24] Z. Qu, W. Luo and J. Huang, â€œA convolutive mixing model for shifted double JPEG compression with application to passive 
image authenticationâ€, in IEEE International Conference on Acoustics, Speech and Signal Processing, page(s):1661 - 1664, 
2008. 
 1 
 
åœ‹ç§‘æœƒè£œåŠ©å°ˆé¡Œç ”ç©¶è¨ˆç•«é …ä¸‹å‡ºå¸­åœ‹éš›å­¸è¡“æœƒè­°å¿ƒå¾—å ±å‘Š 
                                     æ—¥æœŸï¼š101å¹´ 8æœˆ 20æ—¥ 
                                 
ä¸€ã€åƒåŠ æœƒè­°ç¶“é 
 
è¨ˆç•«ç·¨è™Ÿ NSC  100-2221-E-259-033 
è¨ˆç•«åç¨± 
ä»¥å½±åƒä¿®è£œå½é€ åœ–ç‰‡ç‚ºç›®æ¨™ä¹‹åŸºæ–¼å¤šå€åŸŸé—œé€£æŠ€è¡“çš„å½é€ åµæ¸¬ç ”ç©¶ 
å‡ºåœ‹äººå“¡
å§“å 
å¼µæ„æ”¿ 
æœå‹™æ©Ÿæ§‹
åŠè·ç¨± 
åœ‹ç«‹æ±è¯å¤§å­¸è³‡å·¥ç³»å‰¯æ•™æˆ 
æœƒè­°æ™‚é–“ 
101å¹´ 7æœˆ 18æ—¥
è‡³ 
101å¹´ 7æœˆ 20æ—¥ 
æœƒè­°åœ°é» Piraeus-Athens, Greece 
æœƒè­°åç¨± 
The Eighth International Conference on 
Intelligent Information Hiding and Multimedia Signal Processing 
(IIH-MSP 2012) 
ç™¼è¡¨è«–æ–‡
é¡Œç›® 
 Multi-Camera Based Social Network Analysis 
 3 
 
åœ– 3 æœƒè­°æœƒå ´å ±åˆ°ç¾æ³ 
 
 
åœ– 4 æœƒè­°æœƒå ´ä¸€éš… 
 
æˆ‘æ‰€ç™¼è¡¨çš„è«–æ–‡æŠ¬é ­ç‚ºMulti-Camera Based Social Network and Personality Analysisï¼Œå…§å®¹æ—¨åœ¨å°‡å¤šæ”å½±
æ©Ÿæ‰€æ‹æ”çš„äººå“¡è¡Œç‚ºçš„å½±ç‰‡ï¼Œé€éåˆ†æäººå€‘ä¹‹é–“çš„äº’å‹•è¡Œç‚ºä¾†å»ºç«‹ç¤¾äº¤ç¶²è·¯åŠäººæ ¼åˆ†æã€‚å»ºç«‹ç¤¾äº¤ç¶²
è·¯çš„è³‡è¨ŠåŒ…å«äº’å‹•çš„å°è±¡ã€æ‰€è¡¨é”çš„è‚¢é«”èªè¨€èˆ‡æƒ…ç·’è³‡è¨Šï¼Œé€²è€Œæ ¹æ“šåˆ†æåœ˜é«”å…§æ‰€æœ‰æˆå“¡ä¹‹é–“çš„è¡Œç‚º
åŠå°å½¼æ­¤çš„æ…‹åº¦ï¼Œä¾†å»ºç«‹é€™åœ˜é«”çš„ç¤¾äº¤ç¶²è·¯ã€‚æˆ‘å€‘æå‡ºçš„åˆ†ææ–¹å¼ï¼Œé™¤äº†å‹å¥½çš„äº’å‹•é—œä¿‚ä¹‹å¤–ï¼Œæˆ‘å€‘
é‚„è€ƒé‡äº†å­æƒ¡çš„äº’å‹•é—œä¿‚ï¼Œä¸¦çµåˆæ…‹åº¦æ–¹å‘æ€§ä¾†è¡¨é”äººå“¡ä¹‹é–“çš„äº’å‹•ï¼Œè®“åˆ†æçµæœèƒ½æ›´è²¼åˆ‡ç¾å¯¦çš„äº’
å‹•æƒ…æ³ã€‚æ­¤å¤–ï¼Œé€éåˆ†æä¸€å€‹äººæ‰€æœ‰çš„ç¤¾äº¤äº’å‹•è¡Œç‚ºï¼Œå¯ä»¥æ­¸ç´å…¶è¡Œç‚ºæ¨¡å¼ï¼Œè€Œé€™è¡Œç‚ºæ¨¡å¼å³å¯è½‰æ›
æˆç›¸é—œçš„äººæ ¼ç‰¹è³ªï¼Œåœ– 5ç‚ºç³»çµ±çš„ç¤ºæ„åœ–ã€‚ 
æœ¬è«–æ–‡ç™¼è¡¨çš„è‹±æ–‡æ‘˜è¦ç‚ºï¼š 
Social network and personality analysis are popular topics in social science. However, it needs a lot of human 
labor to get the information in psychological analysis. In this paper, we propose a multi-camera based 
evaluation system which can automatically track and recognize the human activities in an environment, and 
then build the corresponding social network and personality graph. The proposed system contains three major 
 5 
 
åœ– 6 è«–æ–‡ç™¼è¡¨æœƒå ´ 
 
 
åœ– 7 è«–æ–‡ç™¼è¡¨æœƒå ´ 
 
 7 
 
åœ– 9 Keynote Speaker æŠ•å½±ç‰‡ä¹‹ä¸€ã€‚ 
 
 
åœ– 10 Keynote Speaker æŠ•å½±ç‰‡ä¹‹äºŒã€‚ 
 
åœ– 11 Keynote Speaker æŠ•å½±ç‰‡ä¹‹ä¸‰ã€‚ 
 9 
åœ– 14 Keynote Speaker æŠ•å½±ç‰‡ä¹‹å…­ã€‚ 
æ­¤æ¬¡åƒèˆ‡æœƒè­°ç­è§£ç›¸é—œé ˜åŸŸåœ¨é€™ä¸€å¹´å…§æŠ€è¡“çš„ç™¼å±•ï¼Œä¹Ÿå’Œç›¸é‡çš„å­¸è€…äº’ç›¸è¨è«–ï¼Œå¢é€²å½¼æ­¤çš„äº¤æµï¼Œ
æ„Ÿè¦ºæ”¶ç©«è‰¯å¤šã€‚ 
ä¸‰ã€æ”œå›è³‡æ–™åç¨±åŠå…§å®¹ 
IIH-MSP 2012æœƒè­°è«–æ–‡å…‰ç¢Ÿç‰‡ 
 
 
 
Multi-Camera Based Social Network Analysis 
I-Cheng Chang*, Jia-Hong Yang and Yi-Hsiang Liao 
Department of Computer Science and InformationÊ³Engineering 
National Dong Hwa University, Hualien, Taiwan, R.O.C. 
E-mail: icchang@mail.ndhu.edu.tw* 
 
 
Abstractâ€”Social network analysis is a popular topic in social 
science. However, it needs a lot of human labor to get the 
information in psychological analysis. In this paper, we propose a 
multi-camera based evaluation system which can automatically 
track and recognize the human activities in an environment, and 
then build the corresponding social network and personality 
graphs. The proposed system contains three major parts: human 
detection, social behavior detection, and social interaction 
analysis. Experimental results show that the proposed system can 
discover the social network through analyzing peopleâ€™s social 
interactions and provide a good result approximated to ground 
truth.  
Keywords- Social network analysis; Personality analysis; 
Posture recognition; Emotion recognition 
I. INTRODUCTION  
Social network analysis is a popular topic in social science. 
A social network can be regarded as a collection of social 
interactions constructed by relations between members of 
group. We can understand social interactions between members 
through the social network analysis, and it can be applied to all 
people related fields. For example, teachers can take care of the 
isolated students by understanding their social behaviors in 
sub-groups. Personality analysis is also an important issue in 
the related fields. However, traditional psychological social 
network analysis and personality analysis needs a lot of labor 
to get the information. 
Research about social network analysis can be found in 
different fields. Thomas [1] studied studentsâ€™ social space in 
schooling by analyzing studentsâ€™ social network. Using data 
from high school and beyond, Thomas derived eight curricular 
positions from an analysis of studentsâ€™ profiles of course work 
in high school. Kumar et al. [2] studied structure and evolution 
of online social networks. They presented a series of 
measurements of two large real networks, Flickr-photo sharing 
and Yahoo! 360. Moncur [3] discovered recovery situations of 
psychotic patients by analyzing social networks of patients. Yu 
et al. [4] constructed the social network with technologies of 
computer vision. They used the appearing frequency of people 
as the features for their relationship and presented relations 
with non-directional connections.  
Most works about personality analysis are only found in 
psychological field. Murray [5] found the relationship between 
teacherâ€™s personality and studentâ€™s instructional ratings. 
Caldwell and Burger [6] studied human personality 
characteristics of job applicants. Caspi [7] worked on 
discovering relations between personality and crime. The 
concept of Sociogram [8], which defines special nodes and 
relationship between nodes, is used in psychological social 
network analysis. Laiâ€™s personality analysis [9] was a usual 
tool used in psychological personality analysis, and it classified 
people into five personality types. 
This work proposes a system which constructs a social 
network of a group of people by analyzing peopleâ€™s behaviors 
from monitoring videos and generates each individualâ€™s 
personality. Figure 1 shows the system flowchart. The 
proposed system consists of three parts: human detection, 
social behavior detection and social interactions analysis. The 
system obtains human posture images from static cameras and 
the face images from active cameras in human detection, and 
then identifies human social behaviors through recognizing 
their behaviors. Finally, we model the social network by 
analyzing the relationship among the people and generate the 
personality graphs from their social behaviors. 
 
 
Figure 1. The flow chart of system overview. 
The remainder of this paper is organized as follows. 
Sec.II describes scene selection with max separation. Sec.III 
introduces social behavior detection which includes target 
determination, posture recognition and emotion recognition. 
2012 Eighth International Conference on Intelligent Information Hiding and Multimedia Signal Processing
978-0-7695-4712-1/12 $26.00 Â© 2012 IEEE
DOI 10.1109/IIH-MSP.2012.48
174
with i neurons, the hidden layer with h neurons, and the output 
layer with j neurons. We use six neurons (i=6) in the input 
layer, which contains six angles. These six angles stand for the 
degree of opening the upper right eye, the lower right eye, the 
upper left eye, the lower left eye, the upper lip, and the lower 
lip, respectively. The angles of opening are calculated from the 
four horizontal and vertical corners of eyes and lips. The output 
layer has three neurons (j=3), such that all facial images are 
classified into three emotions, which are no emotion, happy, 
and sad. 
E. Facial Feature Extraction 
1) Eye detection 
We exploit Haar Cascade [10] eye classifier to detect eyes 
on face image. There are three kinds of Haar-like features, 
which are edge Haar-like feature, line Haar-like feature and 
Center-surround Haar-like feature. Haar-like feature is a mask, 
and the difference between pixels on its black and white areas 
is used as the features. Eye pictures and non-eye pictures are 
used to train an eye classifier. 
2) Lip detection 
Active shape model (ASM) [17] is used to track the lip 
contour and get the four end points of lip contour as the lip 
feature. To differentiate the lips and skin, we adopt the 
pseudo-hue model to describe the color distribution. Besides 
the pseudo-hue model, the luminance information is also used 
to enhance the edge detection, which is defined as 
( ) ( ) ( )
( ) ( ) ( )
upper y
lower y
Edge x H x L x
Edge x H x L x
	 = âˆ‡ âˆ’
 

 

= âˆ‡ +
 

 
                              
(5)
 
where Edgeupper(x) represents edge strength between upper lips 
and skin, Edgelower(x) represents edge strength between lower 
lips and skin and L(x) represents the luminance value of x. 
IV. SOCIAL NETWORK AND PERSONALITY ANALYSIS 
After collecting all social behaviors, we get the information 
about the social interactions happening in the group. The 
section describes how we model the social network and get the 
personality. 
A. Social Network Construction 
Three emotion types (no emotion, happy and sad) and 
seven posture types (hands hold the chest, hands on the hips, 
hands tied behind, hands hang down, hand points at people, 
shake hands with people and wave hand to people) are defined 
in this work. We assign a score to each interaction attitude. 
For example, the shaking hand with people is the friendly 
body sign and it gets score 3.0; however, pointing at people is 
the hostile posture, so this interaction gets score -3.0. The 
interaction attitude score (IA) is evaluated as follow:  
( )
1
M
i i
i
IA E PÎ± Î²
=
= +

                         (6) 
where  and Â£ are weights of emotion and posture, Ei denotes 
the emotion of the ith social behavior, Pi denotes the posture 
of the ith social behavior. We divide interaction attitude into 
five scales from hostile to friendly, and then the score is 
normalized from -2.0 to 2.0. Figure 3 shows the example of a 
social network which is represented as a sociogram. A node 
denotes a person and the edges between two nodes represent 
the interactions. The green number [2]1.1 in node A denotes 
that person A receives two friendly interactions and the score 
of friendly interactions is 1.1. The red number [1]2.7 denotes 
that node A receives one hostile interaction and the score of 
hostile interactions is 2.7. There are two types of social 
networks:  global social network and personal social network. 
A global social network includes all the social interactions, 
and a personal social network is a part of a global social 
network, which only related to one single person. 
 
 
Figure 3.  Example of  a social network. The green line depicts the friendly 
interaction and red line depicts the hostile interaction. The width of line 
denotes the strength of interaction. 
B. Personality Construction  
A personâ€™s social behaviors are stored in his personal social 
network, and this network can further derive the 
corresponding personality. We weight all his behaviors on the 
filtered scales of Laiâ€™s personality analysis, so that we could 
classify his personality type with Laiâ€™s criterions. The 
personality score (PS) is described as follows:  
1
( )
N
i ij j
j
PS Scale W IA
=
=

                            (7) 
where PS(Scalei) denotes the score of the ith scale. Ten scales 
are uses here, i.e., ascendancy, social extraversion, thinking 
extraversion, rhathymia, cyclic tendency, inferiority feeling, 
anxiety, cooperativeness, aggressiveness and general activity. 
N denotes the amount of features of social behaviors, Wij 
denotes the weights of the ith scale and the jth feature of social 
behaviors, IAj denotes the unsigned interaction attitude value 
of the jth feature of social behaviors.  
V. EXPERIMENTAL RESULTS AND DISCUSSION 
In the experiments, we setup three static cameras and three 
active cameras in a classroom, and there are six persons 
appearing in the recorded videos. We prepare a story includes 
the common situations that might happen in a developing 
group. Tuckman [18] proposed five stages from the group 
development, which are forming stage, storming stage, 
norman stage, performing stage and adjourning stage. Since 
adjourning stage means that the group finishes its job and is 
going to disband and it doesnâ€™t have obvious changes, so we 
perform the first four stages in our experiments. Ten persons 
are invited to watch the recorded videos and score each actorâ€™s 
176
åœ‹ç§‘æœƒè£œåŠ©è¨ˆç•«è¡ç”Ÿç ”ç™¼æˆæœæ¨å»£è³‡æ–™è¡¨
æ—¥æœŸ:2012/10/29
åœ‹ç§‘æœƒè£œåŠ©è¨ˆç•«
è¨ˆç•«åç¨±: ä»¥å½±åƒä¿®è£œå½é€ åœ–ç‰‡ç‚ºç›®æ¨™ä¹‹åŸºæ–¼å¤šå€åŸŸé—œé€£æŠ€è¡“çš„å½é€ åµæ¸¬ç ”ç©¶
è¨ˆç•«ä¸»æŒäºº: å¼µæ„æ”¿
è¨ˆç•«ç·¨è™Ÿ: 100-2221-E-259-033- å­¸é–€é ˜åŸŸ: å½±åƒè™•ç†
ç„¡ç ”ç™¼æˆæœæ¨å»£è³‡æ–™
å…¶ä»–æˆæœ 
(ç„¡æ³•ä»¥ï¥¾åŒ–è¡¨é”ä¹‹æˆ
æœå¦‚è¾¦ï§¤å­¸è¡“æ´»å‹•ã€ç²
å¾—çé …ã€é‡è¦åœ‹éš›åˆ
ä½œã€ç ”ç©¶æˆæœåœ‹éš›å½±éŸ¿
ï¦ŠåŠå…¶ä»–å”åŠ©ç”¢æ¥­æŠ€
è¡“ç™¼å±•ä¹‹å…·é«”æ•ˆï¨—äº‹
é …ç­‰ï¼Œè«‹ä»¥æ–‡å­—æ•˜è¿°å¡«
ï¦œã€‚) 
å”åŠ©è¾¦ï§¤ ICS2012 åœ‹éš›ç ”è¨æœƒ 
 æˆæœé …ç›® ï¥¾åŒ– åç¨±æˆ–å…§å®¹æ€§è³ªç°¡è¿° 
æ¸¬é©—å·¥å…·(å«è³ªæ€§èˆ‡ï¥¾æ€§) 0  
èª²ç¨‹/æ¨¡çµ„ 0  
é›»è…¦åŠç¶²ï¤·ç³»çµ±æˆ–å·¥å…· 0  
æ•™æ 0  
èˆ‰è¾¦ä¹‹æ´»å‹•/ç«¶è³½ 0  
ç ”è¨æœƒ/å·¥ä½œåŠ 0  
é›»å­å ±ã€ç¶²ç«™ 0  
ç§‘ 
æ•™ 
è™• 
è¨ˆ 
ç•« 
åŠ  
å¡« 
é … 
ç›® è¨ˆç•«æˆæœæ¨å»£ä¹‹ï¥«èˆ‡ï¼ˆé–±è½ï¼‰äººï¥© 0  
 
