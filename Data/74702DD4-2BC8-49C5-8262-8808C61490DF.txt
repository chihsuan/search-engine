 2 
2
1/ 2/ 2
1 1( | ) exp{ ( )}
2(2 ) 'ik D ik
p d xÏ‰ = âˆ’
pi
x
S
 
2 1( ) ( ) ( ') ( )Tik ik ikd x âˆ’= âˆ’ âˆ’x m S x m  
0  'ik ik r= + â‹…S S I5Ã¢ : u Ã´ i Â€ # Ãµ Â¼ Ã¶ Ã·   0  Â€ Ã # Ãµ Â¼ Ã¸ Ã¹ !  
1
( | ) ( | )Ki ik
k
p p
=
Ï‰ = Ï‰âˆ‘x x 5 
 Ãº   { }( , ') max log ( | ) ( ' | )i iid p p= âˆ’ Ï‰ Ï‰x x x x Â¥ Ã» Ã¼ p Ã½ Ã¾ Â  M Ã© TU #Ã Â¿ TU 
q r LLE { |   ! " Â½ | Â¼ #TU 5 
  Statistical LLE Â† Â‡ } e + TU Ã· RÃ€Ãš  " Â¾ Â½ | Â¼ Â­ @ q r 	 
 5
   7 8 	 
 25 Â¶    TSLeTU V  l 1960 	 e + 0  
 Â¥ 1120
	 Y 6    +   d 840 	 Ã± 6    + 5  Kâ€“nearest neighbors A Â€ } Ã± ! " A Â€
Â Â  Fig. 25 
 
 
Fig. 2 
3.       	 
  
	 
   Ã· R          Ãƒ Â® Ã· RÃ€ÂŸ  Â  Â£Y   Â‚ 
t Ã–  u ) *  ) *   S 7 8 Â‘    !R) * #TU 6 " #  
 : $ 5Ã¢ 7 8 Â‘  Â¶ b % Â…  9: eh p q r f g  	 
 5eh p 
! Ã© & 6 '  ( Â¶ Â…h i " ) Â¶ Â… * Ã— + J Â’ , Ãƒ  - & 35eh p 
	 
    . Â¶ Ã… A / Ã° 0 12 3 4 5  6  GÂ…f g GÂ…j k Â’ Â¡ GÃ¸ eh p  7
	 
 51
8 9 j k f g    : Â‚ Âƒ j k Â„ Â…;o } 5Ã• <  u Â… = > u ? @ A  8 9 
 4 
No. Sign Hand 
shape1
Hand 
shape2
Acc (%) 
GVF 
Acc (%) 
Enh. ACM
1 And One Two 56 74
2 Die One Ten 96 96
3 Nice Six Male 100 100
4 Masculine Male Brown 93 93
5 Thanks Male Vice 100 100
6 Feminine Female Brown 89 89
7 Increase Lu Very 100 100
8 Decrease Very Lu 100 100
9 Cut Two Brown 100 100
10 Kick Borrow Five 100 100
11 Have? Hand â€˜10000â€™ 100 100
12 Free Money Five 85 100
13 100 Fist One 81 81
14     Fist Two 63 85
15     Fist Three 67 78
16     Fist Four 63 93
17 Tell Zero Five 52 100
18 Catch Five Fist 96 96
19 Pain Five Together 100 100
20 Message Gentle â€˜10000â€™ 100 100
    Average 87.05 94.25 
 
) * Â…Ã€Ã© & d  l 49DÃ™  Â‰ x Â¶ Â… e    57 8 
 f Â²
20 /   eh p 3q r   0 1 2 l 21D g Â› ) * Â…5  h Â¡ :S
Ã¥ p Â‚ Âƒ j k Â„ Â…;Ã° i f g /eh p  + J Â…j Â‘    Ã· RK Ã§ . 	 
 ) *
eh p 35 
4.    
: u Z [ \ E F ; < 1 _ H b c e	 
  h i #ef g 7 8 !
"  k \ ÂŒ Â Â Â  l d Â  d v 
 P Q H b c #e + TU V 
   y z  x y z { | o p q r H b c #e
 Ã  
   Statistical LLE { | } ! " Z m 	 
 m Ã—  
 P Q eh i # n TU V 
   Â‚ Âƒ j k Â„ Â…q r h i #ef g Â‰ 	 
 TSLeh p 3 
 
Multi-view Hand Shape Recognition Using Statistical LLE 
 
 
Yi-Jay Gu, Pi-Fuei Hsieh, Ming-Hua Yang, and Chung-Hsien Wu 
Department of Computer Science and Information Engineering 
National Cheng Kung University 
Tainan 701, Taiwan, R.O.C. 
{p7693133, pfhsieh, p7694128}@mail.ncku.edu.tw, and chwu@csie.ncku.edu.tw 
 
ABSTRACT 
The image-based object recognition problem 
becomes complicated when the objects of interest are 
not posed at a fixed view. This study attempts to 
recognize the multi-view hand shapes in Taiwanese sign 
language (TSL) based on a novel statistical locally 
linear embedding (LLE). The original LLE is an 
unsupervised nonlinear dimensionality reduction 
approach that utilizes the local linearity to discover the 
low dimensional manifold embedded in the high 
dimensional space. This suggests that LLE may 
preserve neighborhood configuration in the nonlinear 
structure of the multi-view hand shape data distribution. 
For better classification performance, this study 
proposes a statistical LLE that incorporates the class 
label information statistically to improve the multiclass 
classification capability posterior to dimensionality 
reduction. Experimental results show that the statistical 
LLE gave a classification performance superior to the 
original LLE and the linear dimensionality reduction 
methods such as LDA and PCA in multi-view TSL hand 
shape recognition problem. 
 
 
1: INTRODUCTION 
 
While speaking is the most efficient way to 
communicate with others for people with normal hearing, 
for the hearing-impaired people, the sign language takes 
the place of speaking. Sign language is so complicated 
for normal hearing people that normal hearing people 
cannot master a sign language without training for a 
period of time. This embarrassment causes the 
inconvenience of communication with the hearing 
impaired people. Thus a sign language recognition 
system is developed to ease the inconvenience. 
Generally, a sign gesture in a sign language can be 
decomposed to phonemes, which are the smallest 
contrastive units in the language. Typical phonemes 
include hand shapes, palm orientations, motion 
trajectories and facial expressions. In parallel to this 
analysis, sign language recognition can be realized by 
identifying phonemes individually and then integrating 
the results into a conclusion for a sign gesture [1]. 
Therefore the recognition performance of an individual 
phoneme affects the overall performance of such sign 
language recognition. In this paper, we focus on 
multi-view hand shape recognition, which is associated 
with hand shape and palm orientation phonemes, when 
developing a vision-based sign language recognition 
system. 
In this study, an image of size M Ã— N is regarded as a 
point located in an MN-dimensional space. In this case, 
the dimensionality of the data to be processed is 
relatively large compared with the number of training 
samples. In order to avoid the curse of the dimensionality 
[2], the dimensionality reduction process is necessary in 
high dimensional data classification. The principal 
component analysis (PCA) and the linear discriminant 
analysis (LDA) [ 3 ][ 4 ] are two well-known linear 
dimensionality reduction methods. PCA and LDA are of 
limited used when the data distribution is complicated 
and the scatter matrices cannot sufficiently describe the 
class separability or when the linear projection inferred 
by PCA or LDA is not appropriate. 
Recently, the locally linear embedding (LLE) [5] 
algorithm has been proposed to tackle the nonlinear 
dimensionality reduction problem. LLE is an 
unsupervised learning algorithm that attempts to 
discover the embedded manifold by preserving the 
neighborhood of a data point. The underlying idea of 
LLE is based on the assumption that data lying on a 
nonlinear manifold can be viewed as distributing linearly 
in a local patch if the data are well sampled and lying on a 
smooth manifold. Although LLE has capability to 
recover the global nonlinear structure from locally linear 
fits, the class label information is not taken into account 
when mapping samples from the high dimensional space 
to a low dimensional feature space. A supervised LLE 
(SLLE) algorithm [6][7] has been proposed to utilize the 
class label information by scaling the Euclidean distance 
between samples according to their class labels. 
Although SLLE improves the performance of LLE 
related to classification, the information provided by the 
Euclidean distance between samples is not sufficient 
enough to select proper neighbors for classification. In 
this paper, we propose a statistical LLE algorithm to 
incorporate the class label information by estimating the 
similarity between samples statistically. In experiments, 
both linear and nonlinear dimensionality reduction 
approaches were employed to map the segmented hand 
shape images into a low dimensional space, and the 
K-NN classifier was used to evaluate the performance. 
This paper is organized as follows. Section 2 
discusses the hand shape segmentation procedure. 
Section 3 introduces the original LLE algorithm. Section 
4 presents the proposed statistical LLE algorithm. 
Section 5 shows the classification results in the 
the same neighbors in the high dimensional space with 
the optimal reconstruction weights. 
 
4: STATISTICAL LLE 
 
The data of each class in the high dimensional space 
are not necessarily normally distributed. In order to 
delineate the distribution more accurately, each class is 
modeled by a set of Gaussian clusters. In other words, 
several Gaussian subclasses are defined to describe a 
hand shape class. Various clustering algorithms have 
been developed for a long time, such as k-means 
clustering, hierarchical clustering, and fuzzy clustering. 
In this paper, the k-means algorithm was employed for its 
efficiency and easy implementation. 
Assume that there are K clusters in each of L classes. 
After clustering, all the training samples are labeled into 
one of the KL clusters. Given a D dimensional sample x, 
the probability density of the cluster ikÏ‰  is determined 
as 
 
2
1/ 2/ 2
1 1( | ) exp{ ( )},
2(2 ) 'ik D ik
p d xÏ‰ = âˆ’
pi
x
S
 (5) 
 
2 1( ) ( ) ( ') ( ),Tik ik ikd x âˆ’= âˆ’ âˆ’x m S x m  (6) 
where 'ik ik r= + â‹…S S I  is the sample covariance matrix 
of the k-th cluster in class iÏ‰  plus a generalization term 
to prevent singularity and make the estimation more 
robust. In practice, the value of r is determined 
empirically. 
Since the subclasses are mutually exclusive and 
statistically exhaustive, the likelihood of each class for 
the sample x can be determined by the sum of the 
subclass likelihood as 
 
1
( | ) ( | )Ki ik
k
p p
=
Ï‰ = Ï‰âˆ‘x x . (7) 
The objective of statistical LLE is to derive a 
relationship between samples and each class based on the 
statistics. Without losing the generality, assume that 
samples are independent. Under this assumption, the 
likelihood of any pairs of sample x and sample 'x  
belonging to the same class iÏ‰  is equal to the product of 
their class memberships associated with iÏ‰ . Therefore, 
the relationship between any pairs of samples for a class 
iÏ‰  can be evaluated by the minus logarithm of the 
maximum likelihood that the two samples belong to the 
same class. A relationship d is defined by 
 { }( , ') max log ( | ) ( ' | )i iid p p= âˆ’ Ï‰ Ï‰x x x x . (8) 
The measurement d incorporates the class infor- 
mation provided by the statistical cluster model for each 
class. In statistical LLE, d takes the place of original 
Euclidean distance. Later, the K nearest neighbors of 
each samples are determined according to d. The 
subsequent steps follow the same procedure of LLE. 
 
5: EXPERIMENTS 
 
5.1: Dataset 
 
A total of 25 frequently used TSL hand shapes, as 
shown in Fig. 2, were selected for the experiments. The 
hand shape images of size 240Ã—352 pixels were captured 
in the lab under a controlled light source and a stationary 
background. For each hand shape, 2 rotations, yaw and 
pitch, according to different orientations were performed 
to generate hand shape images with 20 different views in 
each orientation.  
 
 
Fig. 2: TSL hand shapes used in experiments. 
 
5.2: Multi-view TSL Hand Shape Recognition: 
Subject-dependent Experiments 
 
In this experiment, each TSL hand shape was 
regarded as a class. The TSL hand shape segmented 
images were divided into training and testing dataset. For 
each hand shape, 1120 hand shape images with 
multi-view were randomly selected as training dataset 
and the other 840 images were used for testing.  
The traditional linear approaches, such as PCA and 
LDA, were employed to reduce the dimensionality of the 
multi-view TSL hand shape data. In order to estimate the 
hand shape data distribution more precisely, K-means 
clustering were performed to define six subclasses from 
each original class before applying LDA. In nonlinear 
approaches, LLE, SLLE and the proposed statistical LLE 
were applied respectively with 25 neighbors for 
reconstruction weights in the neighborhood selection 
step. The parameter that controls the amount of the class 
label information to be incorporated into SLLE was set to 
2.0 in this experiment. The proposed statistical LLE was 
applied to the data set in which each class had been 
divided into six clusters. In the classification stage, 
K-NN classifier (K = 5) was used to classify the reduced 
automatically adjust the parameters, including the 
number of clusters for delineating a class and the 
number of neighbors for defining the neighborhood of a 
sample. The parameters generally vary with different 
data distributions. 
 
ACKNOWLEDGMENTS 
 
The authors would like to thank the participators in 
hand shape recording for their devotion to setting up the 
TSL multi-view hand shape database. Also, the authors 
are grateful to the National Science Council of the 
Republic of China, Taiwan for financially supporting 
this research under Contract No. NSC94-2614-E-006- 
087. 
 
REFERENCES 
 
                                                        
[1] S. C. W. Ong and S. Ranganath, â€œAutomatic sign 
language analysis: a survey and the future beyond lexical 
meaning,â€ IEEE Trans. Pattern Analysis and Machine 
Intelligence, vol. 27, no. 6, pp. 873-891, June 2005. 
[2] K. Fukunaga, Introduction to Statistical Pattern 
Recognition, second ed., New York: Academic Press, 
1990. 
[3] A. K. Jain, R. P.W. Duin and J. Mao, â€œStatistical pattern 
recognition: A review,â€ IEEE Trans. Pattern Analysis 
and Machine Intelligence, vol. 22, no. 1, pp. 4-37, Jan. 
2000. 
[4] R. O. Duda, P. E. Hart and D. G. Stork, Pattern 
Classification, second ed., New York: John Wiley and 
Sons, Inc., 2001. 
[5] S. T. Roweis and L. K. Saul, â€œNonlinear dimensionality 
reduction by locally linear embedding.â€ Science, vol. 290, 
pp. 2323-2326, Dec. 2000. 
[6] D. Ridder, O. Kouropteva, O. Okun, M. PietikÃ¤inen and 
R. P. W. Duin, â€œSupervised locally linear embedding.â€ 
Proc. of Joint Intâ€™l Conf. on ICANN/ICONIP, 2003. 
[7] D. Lian, J. Yang, Z. Zheng and Y. Chang, â€œA facial 
expression recognition system based on supervised 
locally linear embedding,â€ Pattern Recognition Letters, 
vol. 26, pp. 2373-2389, 2005. 
[8] M. H. Yang and N. Ahuja, â€œGaussian mixture model for 
human skin color and its applications in image and video 
databases,â€ Conf. on Storage and Retrieval for Image and 
Video Database, vol. 3656, 1999. 
[9] O. Kouropteva, O. Okun and M. PietikÃ¤inen, 
â€œIncremental locally linear embedding,â€ Pattern 
Recognition, vol. 38, pp. 1764-1767, 2005. 
A traditional snake is a curve w( ) [ ( ), ( )]s x s y s= , 
[0,1]sâˆˆ , which moves through the spatial domain of an 
image to minimize the following energy functional, 
1 2 2
0
1[ w '( ) w ''( ) ] (w( ))
2 ext
E s s E s dsÎ± Î²= + +âˆ« , (1) 
where Î±  and Î²  are weighting parameters that 
control the snakeâ€™s tension and rigidity, respectively, 
and w '( )s  and w ''( )s  denote the first and second 
derivatives of w( )s  with respect to s. The external 
energy function 
extE  is derived from the image so that 
it takes on its smallest values at the features of interest, 
such as boundaries. Given a gray-level image I(x, y), 
which is viewed as a function of continuous position 
variables (x, y), the typical external energies that are 
designed to lead an active contour toward step edges [5] 
are 
 
2(1) ( ,  ) ( ,  )
extE x y I x y= âˆ’ âˆ‡ , (2) 
 
2(2) ( ,  ) [ ( ,  ) * ( , )]
extE x y G x y I x yÏƒ= âˆ’ âˆ‡ , (3) 
where âˆ‡  is the gradient operator and ( , )G x yÏƒ  is a 
two-dimensional Gaussian function with standard 
deviation Ïƒ . From the calculus of variations [11], the 
minimization of the snake function E can be found by 
solving the following Euler equations 
 w''( ) w''''( ) 0
exts s EÎ± Î²âˆ’ âˆ’âˆ‡ = , (4) 
where w ''''( )s  is the fourth derivatives of w( )s . To 
find a solution to (4), the snake is made dynamic by 
treating w( )s as a function of time t. The partial 
derivative of w with respect to t is then set equal to the 
left hand side of (4) as follows,  
 w ( , ) w''( , ) w''''( , )t exts t s t s t EÎ± Î²= âˆ’ âˆ’âˆ‡ . (5) 
When the solution w( ,  )s t stabilizes, the term w ( ,  )t s t  
vanishes and a solution of (4) is achieved. 
 
2.2: Gradient Vector Flow (GVF) Snake 
 
The GVF snake [6] is proposed to achieve better 
contour detection. The basic idea of the GVF snake is to 
extend the influence range of the image force to a larger 
area by generating a GVF field. The GVF field is 
computed from the image. In detail, a GVF field is 
defined as a vector field ( , ) [ ( , ), ( , )]x y u x y v x y=v  for 
any pixel (x,y). The vector field v(x,y) is computed by 
minimizing the energy functional 
2 22 2 2 2( )x y x yu u v v f f dxdyÎµ Âµ= + + + + âˆ‡ âˆ’âˆ‡âˆ«âˆ« v , (6) 
where fâˆ‡  is the gradient of the edge map f derived 
from the input image I(x, y), Âµ is a regularization 
parameter. Using the calculus of variations [11], the 
GVF field can be obtained by solving the corresponding 
Euler equations. 
Similar to (4), the force balance equation of the GVF 
snake can be expressed as 
 w''( ) w''''( ) 0s sÎ± Î²âˆ’ + =v . (7) 
GVF snakeâ€™s larger capture range and concavity 
tracking ability are attributed to the diffusion operation 
shown in (6).  
By replacing both Âµ and 2fâˆ‡ in (6), the generalized 
GVF (GGVF) [7] is defined as the equilibrium solution 
of the following vector partial differential equation 
 
2( ) ( )( )t g f h f f= âˆ‡ âˆ‡ âˆ’ âˆ‡ âˆ’âˆ‡v v v . (8) 
The weighting functions can be selected such that ( )g â‹…  
decreases as ( )h â‹…  increases. The following weighting 
functions are used for GGVF. 
 
( / )( ) f Kg f eâˆ’ âˆ‡âˆ‡ = , ( ) 1 ( )h f g fâˆ‡ = âˆ’ âˆ‡ . (9) 
Using this pair of weighting functions, the GGVF field 
conforms to the edge map gradient at strong edges but 
varies smoothly away from the boundaries.  
We found that the GVF snake often failed to track 
intact hand shapes, especially those associated with 
fingers, in an image sequence.  
 
2.3: Enhanced Active Contour Model 
 
To solve the problem of tracking intact hand shapes 
with fingers, we included an outward pressure force as 
another external force in addition to the GVF snake. The 
pressure force is introduced from the balloon model 
[8][9]. In a balloon model, a pressure force ( )pf s  is 
added with the snake force as a second external force to 
push the curve outward or inward. The pressure force is 
represented as follow: 
 ( ) ( )pf s k s= n , (10) 
where ( )sn  is the normal unit vector to the curve at 
pixel w( )s and k is the amplitude of this force. 
Combining an outward pressure force with the GVF 
snake, the enhanced force balance equation is thus given 
by 
 w ''( ) w ''''( ) ( ) 0ps s f sÎ± Î² Ï†âˆ’ + + =v , (11) 
where v is the GVF external force, and pf  is the 
inflating force and Ï†  is the weight. 
 
3: RECOGNITION SYSTEM 
 
The developed recognition system consists of four 
phases: skin detection, hand shape tracking, hand shape 
representation, and gestures recognition. Flow chart of 
the recognition system is shown in Fig. 1.  
 
3.1: Skin Detection 
 
Color is one of the most special clues in tracking 
objects. In this study, skin color was used to detect 
hands. Color is generally represented as RGB as 
captured from a video camera. Averaging RGB for each 
pixel in a color image produced a gray-level image. 
Besides, the color image was transformed from the RGB 
color space to the YIQ [ 12 ] color space. The 
I-component of YIQ was checked if it was equal to or 
acquired from a digital video camera of 24-bit RGB 
colors and 160Ã—120 resolution for the image segment 
with 30 frames per seconds (FPS). 
 
 
Fig. 5 Hand shapes related to the selected TSL 
sign words. 
 
4.2: Result of Hand Shape Tracking 
 
A video sequence that recorded the shape-changing 
hand gestures in TSL was an input to the developed 
system. The tracking performance was evaluated in 
terms of the Hausdorff distance [14] for the 21 hand 
shapes associated with selected shape-changing gestures. 
Fig. 6 shows that the enhanced ACM gave higher 
accuracy than the GVF snake especially for hand shapes 
3-6 and 15. Note that those hand shapes are composed 
of extended fingers, making concavities along the 
contours. Fig. 7 demonstrates several examples of 
tracking shape-changing hand gestures in TSL using the 
enhanced ACM.  
 
 
Fig. 6 Tracking performance comparison between 
the GVF snake and the enhanced ACM. 
 
4.3: Result of Shape-Changing Hand Gestures 
Recognition 
 
There were 594 training samples acquired from the 
static images for the 21 hand shapes in TSL and 540 
testing image sequences in our experiment. Table 1 
shows the recognition result for the shape-changing hand 
gestures using the GVF snake and the enhanced Active 
Contour Model, respectively. In the process of 
recognition, we included transition probabilities to 
improve the accuracy of gesture recognition. 
 
Fig. 7 Tracking results of TSL sign gestures (a) 
â€˜andâ€™, (b) â€˜feminineâ€™, (c) â€˜cutâ€™, and (d) â€˜messageâ€™. 
 
Table 1 Result of shape-changing hand gestures 
recognition.  
No. Sign Hand 
shape1
Hand 
shape2
Acc (%) 
GVF 
Acc (%) 
Enh. ACM
1 And One Two 56 74
2 Die One Ten 96 96
3 Nice Six Male 100 100
4 Masculine Male Brown 93 93
5 Thanks Male Vice 100 100
6 Feminine Female Brown 89 89
7 Increase Lu Very 100 100
8 Decrease Very Lu 100 100
9 Cut Two Brown 100 100
10 Kick Borrow Five 100 100
11 Have? Hand â€˜10000â€™ 100 100
12 Free Money Five 85 100
13 100 Fist One 81 81
14     Fist Two 63 85
15     Fist Three 67 78
16     Fist Four 63 93
17 Tell Zero Five 52 100
18 Catch Five Fist 96 96
19 Pain Five Together 100 100
20 Message Gentle â€˜10000â€™ 100 100
    Average 87.05 94.25 
 
5: CONCLUSIONS 
 
This study develops a vision-based system for 
recognizing shape-changing hand gestures in TSL. The 
enhanced active contour model that is proposed herein 
improved the performance of hand shape tracking. The 
system uses the Fourier descriptors to effectively 
represent hand shapes regardless of the variance in 
rotation, translation, and scaling. The system also takes 
1.Zero 2.One 3.Two 4.Three 5.Four 6.Five 7.Six 
8.Boy 9.Girl 10.Brown 11.Lu 12.Very 13.Fist 14.Borrow 
15.Money 16.Together 17.Hand 18.â€˜10000â€™ 19.Gentle 20.Ten 21.Vice 
(a) 
(b)
(c) 
(d)
