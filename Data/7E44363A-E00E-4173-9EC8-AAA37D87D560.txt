 
 
 
 
1
ä¸­æ–‡æ‘˜è¦â€”è¨±å¤šå½±åƒç›¸é—œæ‡‰ç”¨éå¸¸ä¾è³´æ™¯ç‰©å…§
å®¹é¡è‰²ï¥§éš¨æ™‚é–“èˆ‡ç©ºé–“è®Šå‹•å¤ªå¤§ä¹‹ç‰¹æ€§ï¼Œä½†å…¶
å…§å»ºæ¼”ç®—æ³•å»å¾€å¾€å¿½ï¥¶å…‰æºå¯ä»¥å°æ™¯ç‰©é¡è‰²é€ 
æˆåŠ‡ï¦Ÿè®Šå‹•ä¹‹äº‹å¯¦ã€‚ï¦µå¦‚æ ¹æ“šé¡è‰²è¾¨ï§¼ç‰©é«”ä¹‹
ç³»çµ±å¯èƒ½é‹ä½œå¤±å¸¸ï¼ŒåŸå› åœ¨æ–¼å…¶ä»°è³´å»ºï§·å¤§ï¥¾
ç‰©é«”åœ¨æ­£å¸¸å…‰æºä¸‹åå°„ä¹‹é¡è‰²è³‡ï¦¾åº«ï¼Œå»é‹ä½œ
æ–¼åï§ªæ­£å¸¸å…‰æºä¹‹ç’°å¢ƒã€‚å°æ–¼é€™ï§æ‡‰ç”¨ï¼Œè‰²å½©
æ†å¸¸ç‚ºé‡è¦ä¹‹å½±åƒå‰ç½®è™•ï§¤ï¼Œå…¶ç›¸é—œç ”ç©¶ä»æ˜¯
ä¸€å€‹è“¬å‹ƒç™¼å±•ä¹‹ï¦´åŸŸï¼Œå¾ç†ŸçŸ¥ä¹‹å½±åƒæ“·å–è£ç½® 
(ï¥©ä½ç›¸æ©Ÿèˆ‡æ”å½±æ©Ÿ)ã€å·¥æ¥­ç•Œä½¿ç”¨ä¹‹æ©Ÿå™¨è¦–
è¦ºã€å­¸è¡“ç•Œç ”ç©¶ä¹‹é›»è…¦è¦–è¦ºã€æ—¥æ¼¸èˆˆç››ä¹‹æ©Ÿå™¨
äººç”šè‡³é†«å­¸ç•Œä¹‹é ç«¯çœ‹è¨ºï¼Œï¨¦å¯æ‰¾åˆ°å…¶æ‡‰ç”¨å ´
åˆï¼Œæ–°çš„æ‡‰ç”¨é æœŸä¹Ÿæœƒæ—¥æ¼¸å¢åŠ ã€‚éš¨è‘—ç›¸é—œç”¢
å“èˆ‡æ‡‰ç”¨è®Šå¾—ç†±é–€ï¼Œç›¸é—œç¡¬é«”ä¹Ÿè·Ÿè‘—è“¬å‹ƒç™¼
å±•ï¼Œé ä¼°ç”¢å“ä¹‹æ•ˆèƒ½ä¹Ÿå°‡æ„ˆå—é‡è¦–ã€‚è€Œæå‡å½±
åƒå“è³ªé™¤ï¦ºé€éç™¼å±•èˆ‡ä½¿ç”¨ï¤å¥½ä¹‹ç¡¬é«”å¤–ï¼Œå¦
ä¸€å€‹å¯ä»¥ï¨‰ä½æˆæœ¬ä¹‹æ–¹å‘ï¥¥æ˜¯å¾æ¼”ç®—æ³•è‘—æ‰‹ï¼Œ
ä½†ç›®å‰æ¼”ç®—æ³•ä¹‹ç™¼å±•å°šæœ‰å¾ˆå¤§ç©ºé–“ï¼Œä»æœ‰è¨±å¤š
é‡è¦ç ”ç©¶é¡Œç›®å€¼å¾—æ¢è¨ã€‚å› æ­¤æˆ‘å€‘è¦åŠƒï¦ºç‚ºæœŸ
ä¸€ï¦ä¹‹ç³»ï¦œç ”ç©¶å­é¡Œï¼Œé™¤ï¦ºé‡å°ç¾æœ‰ä¹‹ç™½å¹³è¡¡
èˆ‡è‰²å½©æ†å¸¸æ¼”ç®—æ³•å¼•å…¥æ¨¡ç³Šç³»çµ±èˆ‡ï§ï¨™ç¶“ç¶²ï¤·
ç™¼å±•æ™ºæ…§å‹æ¼”ç®—æ³•å¤–ï¼Œä¹Ÿå°‡ç™¼å±•å…¶ä»–æ¼”ç®—æ³•ã€‚
æ‰€ç™¼å±•ä¹‹æ¼”ç®—æ³•å°‡æ­é…ï¥©ä½ç›¸æ©Ÿé€²ï¨ˆå¯¦é©—ã€‚ç ”
ç©¶æˆæœå°‡èƒ½å‡ç´šå·¥æ¥­ç•Œè¨­è¨ˆç”Ÿç”¢ç›¸é—œç”¢å“ä¹‹è»Ÿ
é«”æŠ€è¡“ï¼Œä¹Ÿèƒ½æå‡åœ‹å…§å­¸è¡“ç•Œç›¸é—œç ”ç©¶ä¹‹æ°´å¹³ã€‚ 
é—œéµè©ï¼šè‰²å½©æ†å¸¸ã€ç™½å¹³è¡¡ã€ï¥©ä½ç›¸æ©Ÿã€æ¨¡ç³Š
ç³»çµ±ã€ï§ï¨™ç¶“ç¶²ï¤· 
 
Abstractâ€”Functionality and performance of various image 
applications rely on the fact that the colors of the scene do not vary 
with time or location. For those applications, however, the built-in 
software algorithms often ignore that the ambient light could 
significantly changes the (reflected) colors of a scene. For example, 
an algorithm designed to recognized objects of specific color 
depends on a database comprising the colors of various types of 
objects under a standard illuminant (e.g., D65). The algorithm will 
not function properly under a different illuminant. For such 
application where accurate color of a scene is important, color 
constancy is an indispensable imaging pipeline. Color constancy is 
still a field with high R&D activity. It has found application in area 
such as digital still and CCD cameras, machine vision in 
manufacturing industry, computer vision, robotics, remote medical 
diagnosis, etc. The new application is expected to grow. With 
related products and applications becoming popular, supported 
hardware technology will quickly advance. At the same time, the 
performance, mainly the image quality, of a product will receive 
more emphasis. Besides incorporating better hardware technology 
into a product to improve the image quality, another option is 
implementing software with high-performance algorithm. For the 
field of color constancy, there are still many open topics worth 
exploration. Hence, this project will invest one-year duration to 
investigate a series of research topics. We will upgrade the 
â€˜intelligenceâ€™ of existing white balance algorithms by introducing 
fuzzy systems and neural networks into the algorithm develop 
process. We will also examine and exploit new classes of color 
constancy methods. An experimental system based on digital still 
camera will be established and used to develop and justify the 
feasibility and performance of the developed algorithms. 
Keywords: Color constancy, white balance, digital still camera, 
fuzzy system, neural network 
I. INTRODUCTION 
Digital image capturing devices have evolved into a class 
of consumer electronics indispensable for modern family. 
For most image capturing or recording devices, image 
signals from sensors (CCD or CMOS) must be converted 
into physical quantities compatible with storage devices or 
monitors. The conversion should take into account the fact 
that dynamic response of the sensor is different from that of 
the human visual system. That is, the images viewed by 
sensors are different from that by the human eyes. In 
addition, the images captured are actually lights reflected 
from the surface of the objects. Hence, the conversion 
should also consider the effect of the light source. Color 
balance is a class of image processing algorithms developed 
to compensate for the effects of light sources on captured 
images. Images which are not color balanced will appear to 
have been shifted towards one color or another, i.e., have 
color cast. A color balance algorithm adjusts the image 
through red, green, and blue values of the three basic color 
layers so that the hues of a variety of colors are returned to 
normal. Since human eyes are particularly sensitive to the 
neutral (gray or white) colors within an image, compensating 
for such colors has become the main objective of most color 
balance algorithms. Color balance algorithms aiming at 
compensating the white color within captured images are 
also known as white balance algorithms. Most image related 
applications require taking measurement of the colors from 
surrounding objects or scenes, but often neglect the fact that 
the colors of an object or scene may subject to change with 
factors such as ambient light and illuminants. When 
invariance of color measurement to such factors is important 
for an application, white balance algorithm may be 
incorporated into the corresponding image processing 
pipeline to ensure equitable measurement of colors. 
A generic white balance algorithm usually consists of two 
essential steps: (1) estimating the color temperature of the 
light source for a captured image; (2) adjusting the image 
contents to remove the effect of the light source. Many 
high-end digital cameras and camcorders have built-in 
sensors which can measure lighting conditions in real-time 
and make corresponding correction to the captured images. 
On the other hand, the market of consumer electronics relies 
 
 
3 
 
 
11 11 11 21 21 21
1 1 1
12 12 12 22 22 22
2 2 2
1 1 1 2 2
IF ( , , ) AND ( , , ) AND ... 
AND ( , , ) THEN Light source #1
IF ( , , ) AND ( , , ) AND ... 
AND ( , , ) THEN Light source #2
        
IF ( , , ) AND ( ,
M M M
M M M
N N N N N
R G B R G B
R G B
R G B R G B
R G B
R G B R G
ï
2, ) AND ... 
AND ( , , ) THEN Light source #N
N
MN MN MN
B
R G B
 
In practical circumstance, it is not possible to know 
precisely the color or spectral properties of an object or 
illuminant. First of all, a monochromatic object with a 
surface of uniform spectral properties (e.g., transmittance 
and reflectance) hardly exits in real world. Therefore, slight 
variation is expected when taking measurement of the colors 
from different surface area of a monochromatic object. Other 
factors will also contribute to perturbation of ijR , ijG , and 
ijB  values, such as fluctuation in spectral power distribution 
of an illuminant, measurement inaccuracy of the equipment, 
and inference from the environment. Alternatively, ijR , ijG , 
and ijB  may be specified as fuzzy sets which are defined 
over intervals in accordance with their variation ranges. The 
color temperature of the illuminant may also be specified as 
a fuzzy set defined over an interval. Let 1x , 2x , and 3x  
represent one measurement of R , G , and B  components, 
respectively, from an  image subject to an illuminant with 
color temperature y . The following NM  fuzzy inference 
rules may be constructed:  
Rule 1~Rule M: If 1 2 3( , , )x x x  is 11 21 31
i i iA A Aï‚´ ï‚´ , then y  is 
1B , 1,...,i Mï€½ . 
Rule M+1~Rule 2M: If 1 2 3( , , )x x x  is 12 22 32
i i iA A Aï‚´ ï‚´ , then 
y  is 2B , 1,...,i Mï€½ . 
ï  
Rule (N-1)M+1~Rule NM: If 1 2 3( , , )x x x  is 
1 2 3
i i i
N N NA A Aï‚´ ï‚´ , then y  is NB , 1,...,i Mï€½ . 
where ï‚´  denotes taking â€˜ANDâ€™ operation of the fuzzy sets, 
e.g., 1 2 3 1 2 3 1 1 2 2 3 3[ ]( , , ) ( ) ( ) ( )A A A x x x A x A x A xï‚´ ï‚´ ï€½ . Besides, 
1
i
jA , 2
i
jA , and 3
i
jA  represent the fuzzy sets of ijR , ijG , 
and ijB , respectively, corresponding to the ith reference 
object subject to the jth reference illuminant. The outputs of 
the NM  rules may be further combined by a 
defuzzification algorithm. Here the centroid method or 
center average defuzzifier is utilized, i.e., 
 
1 2 3 1 2 3
1 1
1 2 3 1 2 3
1 1
( , , )
( , , )
N M
i i i
j j j cj
j i
N M
i i i
j j j
j i
A A A x x x y
y
A A A x x x
ï€½ ï€½
ï€½ ï€½
ïƒ¦ ïƒ¶ïƒ© ïƒ¹ï‚´ ï‚´ïƒ§ ïƒ·ïƒ« ïƒ»ïƒ¨ ïƒ¸ï€½ ïƒ¦ ïƒ¶ïƒ© ïƒ¹ï‚´ ï‚´ïƒ§ ïƒ·ïƒ« ïƒ»ïƒ¨ ïƒ¸
ïƒ¥ ïƒ¥
ïƒ¥ ïƒ¥
 (1) 
where cjy  denotes the centroid of the fuzzy set jB . The 
formulated fuzzy logic system is such that it accepts the 
values of R , G , and B  components from a captured 
image under an unknown illuminant and is capable of 
making deduction of the color temperature of the illuminant. 
B. Configuration and Training of the Fuzzy Neural 
Network 
To enhance the performance and improve the robustness 
of the fuzzy logic system developed previously. The fuzzy 
logic system may be topologically depicted as a neural 
network as shown in Figure 2. Let ï€¨ ï€©ku  and ï€¨ ï€©ka  be the 
input and the output of the kth layer of the network. The 
functions of the four layers and the corresponding nodes and 
links may be described as follows: 
Layer 1: No computation is done in this layer. Here 1x , 2x , 
and 3x  are the inputs to layer 1 of the neural network, 
which has 3 nodes and transmits the input values directly to 
the next layer, i.e., 
 (1) (1)i ia u xï€½ ï€½  (2) 
Layer 2: This layer has 3NM  nodes and performs the 
fuzzification operation. Each node in this layer consists of 
the fuzzy set, 1
i
jA , 2
i
jA , or 3
i
jA , and each fuzzy set is 
specified as a Gaussian membership function, i.e., 
 ï€¨ ï€©
ï€¨ ï€© 22
2 exp i i
i
u m
a ï³
ïƒ¬ ïƒ¼ïƒ¦ ïƒ¶ï€­ïƒ¯ ïƒ¯ï€½ ï€­ïƒ§ ïƒ·ïƒ­ ïƒ½ïƒ§ ïƒ·ïƒ¯ ïƒ¯ïƒ¨ ïƒ¸ïƒ® ïƒ¾
 (3) 
where im  and iï³  are, respectively, the center (or mean) 
and the width (or variance) of the Gaussian membership 
function of the ith input variable iu . The link weights 
between layer 1 and 2 are set to unity. 
Layer 3: This layer has NM  nodes with each node 
performing the â€˜ANDâ€™ operation, i.e., 
  ï€¨ ï€© ï€¨ ï€©
3
3 3
1
i
i
a u
ï€½
ï€½ïƒ•  (4) 
The output of this layer represents the firing strength of the 
corresponding fuzzy rule. The link weights between layer 2 
and 3 are also set to unity. 
Layer 4: This layer consists of a single node which acts as a 
defuzzifier by integrating all the signals from layer 3 using 
the centroid method, i.e., 
 
(4)
(4) 1
(4)
1
NM
i i
i
NM
i
i
u w
a
u
ï€½
ï€½
ï€½
ïƒ¥
ïƒ¥
 (5) 
where iw  is the centroid of the output membership function 
and can be regarding as the link weights between layer 3 and 
4. 
Training of the FNN involves adjusting the center/width, 
im  and iï³ , of each Gaussian membership function in layer 
2 and the link weights, iw , between layer 3 and 4 such that 
the output generated by the network for a given input pair is 
as close to the reference or desired color temperature as 
 
 
5 
 
may also be estimated according to the estimated color 
temperature from the previous section. To finalize white 
balance, pixel-wise operation in the red, green, and blue 
color separates of the test image is performed according to 
 
65
65
65
,
,
,
awb D c
awb D c
awb D c
R R R R
G G G G
B B B B
ï€½ ï‚´
ï€½ ï‚´
ï€½ ï‚´
 (15) 
where awbR , awbG , and awbB  denote the red, green and 
blue components for the white balanced image. In addition, 
R , G , and B  are the red, green and blue components 
from the test image. 65DR , 65DG , and 65DB  are the 
components of the white object under D65 illuminant, 
whereas cR , cG , and cB  are  the components of the 
white object under the unknown illuminant. 
It is observed that the red or blue color separate of an 
image subject to high or low color temperature tends to have 
lots of image pixels with zero intensity. Those pixels will not 
be affected by (15) and will therefore degrade the white 
balanced image. To solve this issue, (15) may be modified as 
follows: 
 
ï€¨ ï€©ï€¨ ï€©ï€¨ ï€©
ï€¨ ï€©ï€¨ ï€©
ï€¨ ï€©ï€¨ ï€©ï€¨ ï€©
ï€¨ ï€©ï€¨ ï€©
65
65
65
max 1, . . 6500 100
         max 1, . . 6500 100
max 1, 6500 . . 100
         max 1, 6500 . . 100
awb D c
awb D c
awb D c
R R E T R R
E T
G G G G
B B E T B B
E T
ï€½ ï€« ï€­ ï‚´
ï€­ ï€­
ï€½ ï‚´
ï€½ ï€« ï€­ ï‚´
ï€­ ï€­
 (16) 
where . .E T  is the estimated color temperature of the 
unknown illuminant. The idea behind the proposed 
modification is to shift the intensity of the red or blue color 
separate (add a positive constant) when subject to 
illuminants of high or low color temperature, adjust the pixel 
values, and then shift the intensity of the color separate back 
(add a negative constant). 
III. EXPERIMENTAL PROCEDURES AND RESULTS 
Figure 3 illustrates the experimental setup and procedure. 
A color checker containing patches/segments may serve as 
reference objects with different surface colors. A high-end 
digital camera with a native resolution of 3888 2592ï‚´  
pixels is utilized to acquire raw image data. Note that the 
raw image is not affected by the cameraâ€™s built-in color 
balance functions. The raw data is then converted to TIF 
format which preserves the original lighting condition of the 
image. A light booth provides various illuminants with 
known color temperature (A: incandescent of 2856K, U30: 
warm white fluorescent of 3000K, CWF: cool white 
fluorescent of 4150K, and D65: daylight of 6500K) inside 
which the color checker can be placed with desired 
orientation. Among them, D65 is the desired or reference 
illuminant, and the image captured under D65 can be 
regarded as the reference image (with desired white balance). 
Other images captured under A, U30 and CWF are treated as 
test images (to be white balanced). The reference image is 
shown in Figure 4(a), and the test images subject to other 
illuminants are given in Figure 4(b), Figure 4(c), and Figure 
4(d). 
We propose the following method, which takes into 
account statistical variation (both static and dynamic) among 
image pixels, to select a set of reference objects which 
provide samples and initial conditions for training the FNN. 
First, the color checker is positioned properly inside the light 
booth. For each known illuminant, raw image of the color 
checker is collected six times using the high-resolution 
digital camera, with each taken 20 seconds apart. Pixels of a 
specified area ( 370 370ï‚´  pixels) from each color patch on 
the raw image become candidates of training samples. Hence, 
there are a set of 370 370 6ï‚´ ï‚´  candidate pixels 
corresponding to each color patch, which account for time 
and spatial variation of that specific color. For each color 
patch, histograms are generated for the R/G/B components of 
the candidate pixels. Figure 5 demonstrates the histograms 
for two of the color patches subject to D65 illuminant. 
Twenty candidate pixels lying within the interval of one 
standard deviation from the mean are then randomly selected 
as the training samples with respect to an illuminant of 
known color temperature. The means and standard 
deviations of the R/G/B histograms also provide sensible 
initial values of the center and width of the membership 
functions in layer 2 of the FNN. The centroid of the output 
membership function is set to 0. The desired output is set to 
the normalized color temperatures of the known illuminants, 
i.e., [2856,3000,4150,6500] 6500 . For each training cycle 
of the FNN, a training sample and a desired normalized 
color temperature are presented to the network. At the end of 
each training cycle, the square root of (6) or the root mean 
square error (RMSE) is recorded. Note that the learning rate 
ï¨  is set to 0.005, and the number of training cycles is set to 
1000. The RMSE versus training cycle is shown in Figure 6. 
The RMSE is 0.151036 at the end of the first training cycle 
and is reduced to 0.005041 after 1000 training cycles. 
After training of the FNN is complete, test images (see 
Figure 4(b), Figure 4(c), and Figure 4(d)) are then utilized to 
demonstrate the proposed white balance approach. Using the 
method described previously with a threshold of 0.5, the 
estimated color temperatures are 4151K, 2993K, and 2850K, 
which are very close to the actual color temperatures of the 
illuminants. Using the white color patch as the reference 
white object, of which the R, G, and B components under 
various illuminants are listed in TABLE I, the data from 
TABLE I can be curve fitted using polynomials of degree 
two as shown in Figure 7. As a final step, (16) is applied and 
the white balanced images are provided in Figure 8. All the 
white balanced images, i.e., Figure 8(e), Figure 8(f), and 
Figure 8(g), can be concluded to be visually closer to the 
reference image, Figure 8(a), than the original images, i.e., 
Figure 8(b), Figure 8(c), and Figure 8(d). 
A study is made which compares the proposed white 
 
 
7 
 
cG , and cB  may be retrieved instantly using a lookup table. 
When further parametric adjustment of the algorithm is 
requested, e.g., training of the FNN, the user may switch the 
device into special operation mode to carry out the 
corresponding calibration, which will demand longer 
execution time. 
REFERENCES 
[1] G. Buchsbaum, â€œA spatial processor model for object color 
perception,â€ Journal of the Franklin Institute, vol. 310, pp. 1-26, 1980. 
[2] R. Gershon, A. D. Jepson, and J. K. Tsotsos, â€œFrom [R,G,B] to surface 
reflectance: computing color constant descriptors in images,â€ 
Perception, pp. 755-758, 1988. 
[3] John J. McCann, Suzanne P. McKee, and Thomas H. Taylor, 
â€œQuantitative studies in Retinex theory,â€ Vision Research, vol. 16, pp. 
445-458, 1976. 
[4] E. H. Land, â€œRecent advances in Retinex theory,â€ Vision Research, 
vol. 26, pp. 7-21, 1986. 
[5] A. Blake, â€œBoundary conditions for lightness computation in 
Mondrian world,â€ Computer Vision, Graphics, and Image Processing, 
vol. 32, pp. 314-327, 1985. 
[6] A. Hurlbert, â€œFormal connections between lightness algorithms,â€ 
Journal of the Optical Society of America A, vol. 3, pp. 1684-1692, 
1986. 
[7] D. A. Brainard and B. A. Wandell, â€œAnalysis of the Retinex theory of 
Color Vision,â€ Journal of the Optical Society of America A, vol. 3, pp. 
1651-1661, 1986. 
[8] D. Forsyth, â€œA novel algorithm for color constancy,â€ Int. J. Comput. 
Vis., vol. 5, pp. 5â€“36, 1990. 
[9] G. D. Finlayson, â€œColor in perspective,â€ IEEE Trans. Pattern Anal. 
Machine Intell., vol. 18, pp. 1034â€“1038, 1996. 
[10] G. D. Finlayson and S. Hordley, â€œImproving Gamut mapping color 
constancy,â€ IEEE Trans. Image Processing,â€ vol. 9, no. 10, pp. 
1774-1783, 2000. 
[11] S. Tominaga and B. A. Wandell, â€œStandard surface-reflectance model 
and illuminant estimation,â€ Journal of the Optical Society of America 
A, vol. 6, pp. 576-584, 1989. 
[12] H.-C. Lee, â€œMethod for computing the scene-illuminant chromaticity 
from specular highlights,â€ Journal of the Optical Society of America A, 
vol. 3, pp. 1964-1699, 1986. 
[13] M. Dâ€™Zmura and P. Lennie, â€œMechanisms of color constancy,â€ Journal 
of the Optical Society of America A, vol. 3, pp. 1662-1672, 1986. 
[14] S. Tominaga and B. A. Wandell, â€œComponent estimation of surface 
spectral reflectance,â€ Journal of the Optical Society of America A, vol. 
7, pp. 312-317, 1990. 
[15] Z. Wang and A.C. Bovik, Modern Image Quality Assessment, Morgan 
& Claypool Publishers, 2006. 
[16] H.-K. Lam, O. C. Au, and C.-W. Wong, â€œAutomatic white balancing 
using luminance component and standard deviation of RGB 
components,â€ IEEE International Conference on Acoustics, Speech, 
and Signal Processing, Montreal, Canada, pp.493-496, 2004. 
[17] Chikane, and C.-S. Fuh, â€œAutomatic white balance for digital still 
cameras,â€ Journal of Information Science and Engineering, vol.22, 
no.3, pp.497-509, 2006. 
[18] J.-Y. Huo, Y.-L. Chang, J. Wang and X.-X. Wei, â€œRobust automatic 
white balance algorithm using gray color points in images,â€ IEEE 
Transactions on Consumer Electronics, vol.52, no.2, pp.541-546, 
2006. 
[19] P.-M. Wang and C.-S. Fuh, â€œAutomatic white balance with color 
temperature estimation,â€ IEEE International Conference on Consumer 
Electronics, pp. 1-2, 2007. 
[20] C.-L. Chen and S.-H. Lin, â€œFormulating and solving a class of 
optimization problems for high-performance gray world automatic 
white balance,â€ Applied Soft Computing, vol.11, no.1, pp.523-533, 
2011. 
 
 
 
 
TABLE I  
THE R, G, B COMPONENTS OF THE REFERENCE WHITE OBJECT. 
 2856K 3000K 4150K 6500K
Red 255 244 237 212 
Green 179 182 196 208 
Blue 88 106 138 207 
 
 
 
 
TABLE II 
 THE MSE BETWEEN TEST AND REFERENCE IMAGES (IN RGB COLOR SPACE). 
Color temperature Illuminants for the test 
images 4150K 3000K 2856K 
Before being white 
balanced 855.79 1849.67 2836.34
SRM 449.08 1249.71 2076.18
GWM 463.75 995.06 1686.37
Lamâ€™s method 390.37 806.87 1252.19
Chikane's method 319.6 496.46 1513.39
Huo's method 537.4 2023.04 2690.84
Chenâ€™s method 242.44 509.47 835.64 
Wangâ€™s method 214.83 1453.42 2446.12
A
fter being w
hite balanced 
The proposed  
method 134.48 236.55 375.05 
 
 
 
 
TABLE III  
THE MSE BETWEEN TEST AND REFERENCE IMAGES (IN YCBCR COLOR 
SPACE). 
Color temperature Illuminants for the test 
images 4150K 3000K 2856K
Before being white 
balanced 283.9 599.94 943.68
SRM 203.25 503.21 705.31
GWM 170.1 360 612.66
Lamâ€™s method 137.4 260.98 403.55
Chikane's method 97.21 136.39 422.15
Huo's method 159.46 528.45 825.72
Chenâ€™s method 98.49 173.01 274.62
Wangâ€™s method 75.78 459.8 797.9 
A
fter being w
hite balanced The proposed  
method 50.42 84.62 154.29
 
 
 
 
 
9 
 
(a) (b)
(c) (d)
 
Figure 4: A color checker subject to different illuminants (a) 
D65 - 6500K (b) CWF -  4150K (c) U30 â€“ 3000K (d) A â€“ 
2856K. 
 
 
 
Figure 5: Histograms for the R/G/B components of the 
candidate pixels from two of the color patches subject to 
D65 illuminant. 
 
 
0 100 200 300 400 500 600 700 800 900 1000
0
0.02
0.04
0.06
0.08
0.1
0.12
0.14
0.16
0.18
0.2
training cycle
R
M
SE
X: 1000
Y: 0.0002486
R
M
SE
 
Figure 6: Root mean square error versus training cycle. 
2500 3000 3500 4000 4500 5000 5500 6000 6500
80
100
120
140
160
180
200
220
240
260
color temperature (K)
co
lo
r c
om
po
ne
nt
 v
al
ue
s
Red
Green
Blue
co
lo
r c
om
po
ne
nt
 v
al
ue
s
 
Figure 7: Curve fitting the data of the R/G/B components of 
the reference white object under various illuminants. 
(a)
(d)(c)
(g)(f)(e)
(b)
 
Figure 8: Before being white balanced: (a) reference image - 
6500K, (b) test image - 4150K, (c) test image - 3000K, (d) 
test image - 2856K. After being white balanced: (e) test 
image - 4150K, (f) test image - 3000K, (g) test image - 
2856K. 
(i)                         (j)
(a)                         (b) 
(c)                         (d)                       (e)
(f)                         (g)                       (h)
 
Figure 9: (a) Reference image. (b) Test image - 4150K. 
After being white balanced using (c) SRM, (d) GWM, (e) 
Lamâ€™s method, (f) Chikane's method, (g) Huo's method, (h) 
Chenâ€™s method 3, (i) Wangâ€™s method, and (j) the proposed 
method. 
 
 
11 
 
åœ‹ç§‘æœƒè£œåŠ©å°ˆé¡Œç ”ç©¶è¨ˆç•«æˆæœå ±å‘Šè‡ªè©•è¡¨ 
è«‹å°±ç ”ç©¶å…§å®¹èˆ‡åŸè¨ˆç•«ç›¸ç¬¦ç¨‹ï¨ã€é”æˆé æœŸç›®æ¨™æƒ…æ³ã€ç ”ç©¶æˆæœä¹‹å­¸è¡“æˆ–æ‡‰ç”¨åƒ¹
å€¼ï¼ˆç°¡è¦æ•˜è¿°æˆæœæ‰€ä»£è¡¨ä¹‹æ„ç¾©ã€åƒ¹å€¼ã€å½±éŸ¿æˆ–é€²ä¸€æ­¥ç™¼å±•ä¹‹å¯èƒ½æ€§ï¼‰ã€æ˜¯å¦é©
åˆåœ¨å­¸è¡“æœŸåˆŠç™¼è¡¨æˆ–ç”³è«‹å°ˆï§ã€ä¸»è¦ç™¼ç¾æˆ–å…¶ä»–æœ‰é—œåƒ¹å€¼ç­‰ï¼Œä½œä¸€ç¶œåˆè©•ä¼°ã€‚
1. è«‹å°±ç ”ç©¶å…§å®¹èˆ‡åŸè¨ˆç•«ç›¸ç¬¦ç¨‹ï¨ã€é”æˆé æœŸç›®æ¨™æƒ…æ³ä½œä¸€ç¶œåˆè©•ä¼° 
â–ˆ  é”æˆç›®æ¨™ (è£œå……ï¥¯æ˜å¦‚ä¸‹) 
â–¡ æœªé”æˆç›®æ¨™ 
â–¡ å¯¦é©—å¤±æ•— 
â–¡ å› æ•…å¯¦é©—ä¸­æ–· 
â–¡ å…¶ä»–åŸå›  
ï¥¯æ˜ï¼šæœ¬è¨ˆç•«å·²å®Œæˆæ‰€è¦åŠƒä¹‹å·¥ä½œå¤§é …èˆ‡ç›¸é—œå¯¦é©—é©—è­‰ã€‚ 
 
2. ç ”ç©¶æˆæœåœ¨å­¸è¡“æœŸåˆŠç™¼è¡¨æˆ–ç”³è«‹å°ˆï§ç­‰æƒ…å½¢ï¼š 
ï¥æ–‡ï¼šâ–ˆå·²ç™¼è¡¨â–ˆæœªç™¼è¡¨ä¹‹æ–‡ç¨¿â–ˆæ’°å¯«ä¸­ â–¡ç„¡ (è£œå……ï¥¯æ˜å¦‚ä¸‹) 
å°ˆï§ï¼šâ–¡å·²ç²å¾— â–¡ç”³è«‹ä¸­ â–¡ç„¡ 
æŠ€è½‰ï¼šâ–¡å·²æŠ€è½‰ â–¡æ´½è«‡ä¸­ â–¡ç„¡ 
ï¥¯æ˜ï¼šç ”ç©¶æˆæœé™¤ï¦ºï§“çºŒåœ¨åœ‹éš›ç ”è¨æœƒ [1]-[3] é€²ï¨ˆå£é ­å ±å‘Šå¤–ï¼Œå·²ç¶“ç™¼è¡¨ï¥¸
ç¯‡ SCI æœŸåˆŠï¥æ–‡ [4][5]ï¼Œå¦æœ‰ï¥©ç¯‡ï¥æ–‡å°šåœ¨æº–å‚™ä¸­ã€‚ 
 
[1] C.-L. Chen and S.-H. Lin, â€œIntelligent color temperature estimation using fuzzy neural 
network with application to automatic white balance,â€ 2010 IEEE International Conference on 
Systems, Man and Cybernetics, Istanbul, Turkey, pp.796-803, January 2010. (EI) 
[2] S.-H. Lin, C.-L. Chen, and B.-S. You, â€œA fuzzy neural network with optimal parameters 
for compensating the effect of ambient light on digitally captured images,â€ ç¬¬åä¸ƒå±†æ¨¡ç³Šç†
è«–åŠå…¶æ‡‰ç”¨ç ”è¨æœƒ, å°ç£é«˜é›„, December 2009. 
[3] C.-L. Chen and S.-H. Lin, â€œAutomatic white balance based on estimation of light source 
using fuzzy neural network,â€ 4th IEEE Conference on Industrial Electronics and Applications, 
Xiâ€™an, China, pp.1905-1910, May 2009. (EI) 
[4] C.-L. Chen and S.-H. Lin, â€œFormulating and solving a class of optimization problems for 
high-performance gray world automatic white balance,â€ Applied Soft Computing, vol.11, 
no.1, pp.523-533, January 2011. (SCI) 
[5] C.-L. Chen and S.-H. Lin, â€œIntelligent color temperature estimation using fuzzy neural 
network with application to automatic white balance,â€ Expert Systems with Applications, 
vol.38, no.6, pp.7718-7728, June 2011. (SCI) 
 
 
åœ‹ç§‘æœƒè£œåŠ©å°ˆé¡Œç ”ç©¶è¨ˆç•«é …ä¸‹å‡ºå¸­åœ‹éš›å­¸è¡“æœƒè­°å¿ƒå¾—å ±å‘Š 
                                                          æ—¥æœŸï¼š100 ï¦ 10 æœˆ 20 æ—¥ 
 
ä¸€ã€ï¥«åŠ æœƒè­°ç¶“éï¼š 
IEEE SMC Conference ç‚ºæ¯ï¦èˆ‰è¾¦ä¸€æ¬¡ä¹‹åœ‹éš›å­¸è¡“ç ”è¨æœƒï¼Œèˆ‰è¾¦åœ°é»éåŠä¸–ç•Œå„åœ°ã€‚2010 ï¦ä¹‹æœƒ
è­°é¸æ“‡åœ¨åœŸè€³å…¶ä¼Šæ–¯å¦å ¡èˆ‰ï¨ˆï¼Œæœƒè­°æ™‚ç¨‹è¨ˆ 10/10-10/13 å…±å››å¤©ã€‚ç”±æ–¼è©²ç ”è¨æœƒä¹‹ä¸»é¡Œæ¶µè“‹è¨±å¤šæ™ºæ…§
å‹æ¼”ç®—æ³•ç›¸é—œç ”ç©¶ï¼Œé©åˆå¾äººè©²ï¦ï¨ç ”ç©¶æˆæœä¹‹ç™¼è¡¨ï¼Œä¸”é‘’æ–¼ç ”è¨æœƒç™¼è¡¨ä¹‹ï¥æ–‡æœ‰å“è³ªèªè­‰ï¼Œï¨¢å¤šå‹•
æ©Ÿè®“å¾äººç•¶åˆï¥¥è¨ˆç•«æŠ•ç¨¿è©²ç ”è¨æœƒã€‚æ‰€æŠ•ç¨¿ä¹‹ï¥æ–‡è¢«å®‰æ’æ–¼10/11ä¸‹åˆé€²ï¨ˆå£é ­å ±å‘Šã€‚å¾äººæ–¼10/9
è‡ªæ¡ƒåœ’æ©Ÿå ´å‡ºç™¼ï¼Œæ–¼éš”æ—¥ 10/10 ä¸ŠåˆæŠµé”ä¼Šæ–¯å¦å ¡åœ‹éš›æ©Ÿå ´ï¼Œå†æ­ä¹˜å·´å£«æŠµé”ä½å®¿ï¨ªåº—å…¥ä½ã€‚
10/11 æ—¥ä¸Šåˆå‰å¾€æœƒå ´ï¦°è½ï¦º Dr. Paul J. Werbos èˆ‡ Kevin Warwick ä¹‹ keynote speechï¼Œè¬›é¡Œåˆ†åˆ¥
ç‚º Neural Networks: From Toys to Cars to Mind èˆ‡ The Cyborg Experimentsã€‚ä¸‹åˆå‰‡å‰å¾€æœƒå ´å£
é ­å ±å‘Šç™¼è¡¨ä¹‹ï¥æ–‡ã€‚10/12 ä¸­åˆå†ï¦°è½ Dr. Edgar Koerner ä¹‹ keynote speechï¼Œè¬›é¡Œç‚º Learning to 
Behave in a Natural Environmentã€‚æ™šä¸Šå‰‡ï¥«åŠ ç ”è¨æœƒåœ¨èˆ¹ä¸Šèˆ‰è¾¦ä¹‹å¤œå®´ã€‚10/14 ä¸‹åˆæ­ä¹˜ç­æ©Ÿ
å›å°ç£ã€‚ 
äºŒã€èˆ‡æœƒå¿ƒå¾—èˆ‡å»ºè­°ï¼š 
æœ¬æ¬¡æœƒè­°èˆ‰è¾¦åœ°é»ç‚ºä½æ–¼ä¼Šæ–¯å¦å ¡å¸‚å€ä¹‹è»äº‹åšç‰©ï¨¬ï¼Œç¡¬é«”è¨­æ–½é½Šå…¨ï¼Œé€±é‚Šç”Ÿæ´»æ©Ÿèƒ½ä¹Ÿ
ï¥§éŒ¯ï¼Œå”¯æœƒå ´ä¹‹å…¥å£é–‹æ”¾æ™‚é–“æ¨™ç¤ºï¥§æ¸…è®“è¨±å¤šäººç¹ï¦ºå¤§åœˆæ‰å¾—ä»¥é€²å…¥ã€‚ä½†é€²å…¥æœƒè­°ç¾å ´æ¨™ç¤º
é‚„ç®—æ¸…æ¥šï¼Œå„æœƒå ´å‡é…å‚™ï¥§éŒ¯ä¹‹é›»è…¦èˆ‡æŠ•å½±è¨­å‚™ï¼Œä¹Ÿæœ‰æ´¾äººå“¡è¼”åŠ© session chair ä¸»æŒå„å ´å ±
å‘Šã€‚å¯èƒ½å› ä¸»è¾¦åœ°é»ä¹‹è»äº‹æ•æ„Ÿæ€§ï¼Œé€²å‡ºè¦ X å…‰æª¢æŸ¥ï¼Œä¸»è¾¦å–®ä½ï¥¥æ²’æœ‰ï¦Šé‚€å» å•†ï¥«å±•ï¼Œé€ æˆ
æœƒå ´ï¥¶é¡¯ï¤®æ¸…ã€‚å»ºè­°ä¸»è¾¦å–®ä½ç„¡ï¥å¦‚ä½•é‚„æ˜¯æ‡‰é‚€è«‹èˆ‡å¤§æœƒä¸»é¡Œç›¸é—œä¹‹å» å•†è¨­æ”¤ï¼Œé™¤å¯è®“èˆ‡æœƒ
äººå£«ï¦ºè§£æ‡‰ç”¨å±¤é¢ä¹‹æŠ€è¡“äº¦æä¾›ç›´æ¥èˆ‡å» å•†æ´½è«‡åˆä½œæˆ–è³¼è²·å•†å“ä¹‹æ©Ÿæœƒã€‚æœƒè­°ä¹‹ï¥«èˆ‡è€…ï¤­è‡ª
ä¸–ç•Œå„åœ‹ï¼ŒæŠ•ç¨¿ï¥æ–‡ç¸½è¨ˆ 959 ç¯‡ï¼Œè¢«æ¥å—ä¸¦å®Œæˆè¨»å†Šä¹‹ï¥æ–‡ç¯‡æœ‰ 672 ç¯‡ï¼Œå…¶ä¸­ 538 ç¯‡æ˜¯å£é ­
è¨ˆç•«ç·¨è™Ÿ NSC 99-2221-E-005-104 
è¨ˆç•«åç¨± æ™ºæ…§å‹è‰²å½©æ†å¸¸æ¼”ç®—æ³•èˆ‡å…¶åœ¨ï¥©ä½ç›¸æ©Ÿä¹‹æ‡‰ç”¨ 
å‡ºåœ‹äººå“¡
å§“å é™³æ­£ï§” 
æœå‹™æ©Ÿæ§‹
åŠè·ç¨± 
åœ‹ï§·ä¸­èˆˆå¤§å­¸é›»æ©Ÿå·¥ç¨‹å­¸ç³»
(æ‰€)/å‰¯æ•™æˆ 
æœƒè­°æ™‚é–“  99ï¦ 10æœˆ 10æ—¥è‡³  99 ï¦ 10 æœˆ 13 æ—¥ æœƒè­°åœ°é» ä¼Šæ–¯å¦å ¡/åœŸè€³å…¶ 
æœƒè­°åç¨± The 2011 IEEE International Conference on Systems, Man, and Cybernetics 
ç™¼è¡¨ï¥æ–‡
é¡Œç›® 
Intelligent Color Temperature Estimation Using Fuzzy Neural Network with 
Application to Automatic White Balance 
                                      
Intelligent Color Temperature Estimation Using 
Fuzzy Neural Network with Application to Automatic 
White Balance 
 
Cheng-Lun Chen and Shao-Hua Lin 
Department of Electrical Engineering 
National Chung Hsing University 
Taichung 40227, Taiwan 
chenc@dragon.nchu.edu.tw 
 
 
Abstractâ€”In this paper, a novel white balance method is 
proposed, which consists of two fundamental steps, i.e., color 
temperature estimation of the illuminant and adjustment of the 
components of the color separates. A fuzzy logic system is 
constructed to infer the color temperature of an illuminant 
which a digitally acquired image subjected to. The fuzzy logic 
system is further optimized by representing the system as a fuzzy 
neural network and a training scheme of the FNN parameters is 
proposed. The estimated color temperature is then employed to 
determine the required amount of adjustment for each color 
separate of the image. Experimental procedures are outlined and 
performed, which validates the feasibility and performance of 
the proposed method. A comparative study is also made based on 
two quantitative indices. The study shows that the proposed 
approach is preferable to most methods in the literatures in 
terms of performance and robustness to varieties of illuminants 
and scenes. 
Keywords-Color temperature estimation, fuzzy neural network, 
white balance 
I.  INTRODUCTION  
Digital image capturing devices have evolved into a class 
of consumer electronics indispensable for modern family. For 
most image capturing or recording devices, image signals from 
sensors (CCD or CMOS) must be converted into physical 
quantities compatible with storage devices or monitors. The 
conversion should take into account the fact that dynamic 
response of the sensor is different from that of the human 
visual system. That is, the images viewed by sensors are 
different from that by the human eyes. In addition, the images 
captured are actually lights reflected from the surface of the 
objects. Hence, the conversion should also consider the effect 
of the light source. Color balance is a class of image 
processing algorithms developed to compensate for the effects 
of light sources on captured images. Images which are not 
color balanced will appear to have been shifted towards one 
color or another, i.e., have color cast. A color balance 
algorithm adjusts the image through red, green, and blue 
values of the three basic color layers so that the hues of a 
variety of colors are returned to normal. Since human eyes are 
particularly sensitive to the neutral (gray or white) colors 
within an image, compensating for such colors has become the 
main objective of most color balance algorithms. Color 
balance algorithms aiming at compensating the white color 
within captured images are also known as white balance 
algorithms. Most image related applications require taking 
measurement of the colors from surrounding objects or scenes, 
but often neglect the fact that the colors of an object or scene 
may subject to change with factors such as ambient light and 
illuminants. When invariance of color measurement to such 
factors is important for an application, white balance algorithm 
may be incorporated into the corresponding image processing 
pipeline to ensure equitable measurement of colors. 
A generic white balance algorithm usually consists of two 
essential steps: (1) estimating the color temperature of the 
light source for a captured image; (2) adjusting the image 
contents to remove the effect of the light source. Many high-
end digital cameras and camcorders have built-in sensors 
which can measure lighting conditions in real-time and make 
corresponding correction to the captured images. On the other 
hand, the market of consumer electronics relies largely on the 
sale of low-end cameras, which must estimate the lighting 
conditions based on the contents of the captured images using 
software algorithm. Existing white balance algorithms fall 
into the following four categories: gray world method [1][2], 
Retinex method [3]-[7], gamut mapping method [8]-[10], and 
specular reflection method [11]-[14]. Gray world method is 
based on gray world assumption: Suppose that an image has 
abundant colors under standard light source (e.g., D65), the 
average value of its red (R), green (G), and blue (B) separates 
would be gray, i.e., R=G=B. Therefore, adjustment may be 
applied to each color separate to ensure that the modified 
image satisfies the assumption. Retinex method assumes that 
a normal scene contains various objects which reflect full 
intensity of the red, green, and blue components of the light 
source. Hence, the maximum red, green, and blue component 
values from a captured image may be utilized to estimate the 
color of the light source. Gamut mapping method establishes a 
database of the R/G/B components of the light reflected from 
all possible object surfaces under known standard light source, 
which forms a convex hull sH . As next step, various R/G/B 
Â‹,(((
796
                                      
set defined over an interval. Let 1x , 2x , and 3x  represent one 
measurement of R , G , and B  components, respectively, 
from an  image subject to an illuminant with color 
temperature y . The following NM  fuzzy inference rules 
may be constructed:  
Rule 1~Rule M: If 1 2 3( , , )x x x  is 11 21 31
i i iA A Aï‚´ ï‚´ , then y  is 1B , 
1,...,i Mï€½ . 
Rule M+1~Rule 2M: If 1 2 3( , , )x x x  is 12 22 32
i i iA A Aï‚´ ï‚´ , then y  
is 2B , 1,...,i Mï€½ . 
ï  
Rule (N-1)M+1~Rule NM: If 1 2 3( , , )x x x  is 1 2 3
i i i
N N NA A Aï‚´ ï‚´ , 
then y  is NB , 1,...,i Mï€½ . 
where ï‚´  denotes taking â€˜ANDâ€™ operation of the fuzzy sets, 
e.g., 1 2 3 1 2 3 1 1 2 2 3 3[ ]( , , ) ( ) ( ) ( )A A A x x x A x A x A xï‚´ ï‚´ ï€½ . Besides, 
1
i
jA , 2
i
jA , and 3
i
jA  represent the fuzzy sets of ijR , ijG , and 
ijB , respectively, corresponding to the ith reference object 
subject to the jth reference illuminant. The outputs of the 
NM  rules may be further combined by a defuzzification 
algorithm. Here the centroid method or center average 
defuzzifier is utilized, i.e., 
 
1 2 3 1 2 3
1 1
1 2 3 1 2 3
1 1
( , , )
( , , )
N M
i i i
j j j cj
j i
N M
i i i
j j j
j i
A A A x x x y
y
A A A x x x
ï€½ ï€½
ï€½ ï€½
ïƒ¦ ïƒ¶ïƒ© ïƒ¹ï‚´ ï‚´ïƒ§ ïƒ·ïƒ« ïƒ»ïƒ¨ ïƒ¸ï€½ ïƒ¦ ïƒ¶ïƒ© ïƒ¹ï‚´ ï‚´ïƒ§ ïƒ·ïƒ« ïƒ»ïƒ¨ ïƒ¸
ïƒ¥ ïƒ¥
ïƒ¥ ïƒ¥
 (1) 
where cjy  denotes the centroid of the fuzzy set jB . The 
formulated fuzzy logic system is such that it accepts the 
values of R , G , and B  components from a captured image 
under an unknown illuminant and is capable of making 
deduction of the color temperature of the illuminant. 
B. Configuration and Training of the Fuzzy Neural Network 
To enhance the performance and improve the robustness 
of the fuzzy logic system developed previously. The fuzzy 
logic system may be topologically depicted as a neural 
network. Let ï€¨ ï€©ka  be the input and the output of the kth layer 
of the network. The functions of the four layers and the 
corresponding nodes and links may be described as follows: 
Layer 1: No computation is done in this layer. Here 1x , 2x , 
and 3x  are the inputs to layer 1 of the neural network, which 
has 3 nodes and transmits the input values directly to the next 
layer, i.e., 
 (1) (1)i ia u xï€½ ï€½  (2) 
Layer 2: This layer has 3NM  nodes and performs the 
fuzzification operation. Each node in this layer consists of the 
fuzzy set, 1
i
jA , 2
i
jA , or 3
i
jA , and each fuzzy set is specified as 
a Gaussian membership function, i.e., 
 ï€¨ ï€©
ï€¨ ï€© 22
2 exp i i
i
u m
a ï³
ïƒ¬ ïƒ¼ïƒ¦ ïƒ¶ï€­ïƒ¯ ïƒ¯ï€½ ï€­ïƒ§ ïƒ·ïƒ­ ïƒ½ïƒ§ ïƒ·ïƒ¯ ïƒ¯ïƒ¨ ïƒ¸ïƒ® ïƒ¾
 (3) 
where im  and iï³  are, respectively, the center (or mean) and 
the width (or variance) of the Gaussian membership function 
of the ith input variable iu . The link weights between layer 1 
and 2 are set to unity. 
Layer 3: This layer has NM  nodes with each node 
performing the â€˜ANDâ€™ operation, i.e., 
  ï€¨ ï€© ï€¨ ï€©
3
3 3
1
i
i
a u
ï€½
ï€½ïƒ•  (4) 
The output of this layer represents the firing strength of the 
corresponding fuzzy rule. The link weights between layer 2 
and 3 are also set to unity. 
Layer 4: This layer consists of a single node which acts as a 
defuzzifier by integrating all the signals from layer 3 using the 
centroid method, i.e., 
 
(4)
(4) 1
(4)
1
NM
i i
i
NM
i
i
u w
a
u
ï€½
ï€½
ï€½
ïƒ¥
ïƒ¥
 (5) 
where iw  is the centroid of the output membership function 
and can be regarding as the link weights between layer 3 and 
4. 
Training of the FNN involves adjusting the center/width, 
im  and iï³ , of each Gaussian membership function in layer 2 
and the link weights, iw , between layer 3 and 4 such that the 
output generated by the network for a given input pair is as 
close to the reference or desired color temperature as possible. 
Mathematically, the objective is to minimize the error 
function 
 ï€¨ ï€© ï€¨ ï€© ï€¨ ï€©
ï€¨ ï€©
ï€¨ ï€©
ï€¨ ï€©
2
4
2 1
4
1
1 1
2 2
NM
i i
d di
NM
i
i
u w
E t y t y t y t
u
ï€½
ï€½
ïƒ© ïƒ¹ïƒª ïƒºïƒª ïƒºïƒ© ïƒ¹ï€½ ï€­ ï€½ ï€­ïƒ« ïƒ» ïƒª ïƒºïƒª ïƒºïƒ« ïƒ»
ïƒ¥
ïƒ¥
 (6) 
where ï€¨ ï€©dy t  is the desired output and ï€¨ ï€©y t  is the actual 
output. For each training sample, starting at the input nodes, a 
forward pass is used to compute the activity levels of all the 
nodes in the network to obtain the current output ï€¨ ï€©y t  
according to (2)-(5). 
A back-propagation type algorithm is employed to adjust or 
update the three aforementioned set of parameters. With the 
error function defined in (6), the update rules for the free 
parameters in the FNN are summarized as follows: 
(1) Update rule of kw  (the link weight between layer 3 and 
4): The update rule of kw  is 
798
                                      
lots of image pixels with zero intensity. Those pixels will not 
be affected by (15) and will therefore degrade the white 
balanced image. To solve this issue, (15) may be modified as 
follows: 
 
ï€¨ ï€©ï€¨ ï€©ï€¨ ï€©
ï€¨ ï€©ï€¨ ï€©
ï€¨ ï€©ï€¨ ï€©ï€¨ ï€©
ï€¨ ï€©ï€¨ ï€©
65
65
65
max 1, . . 6500 100
         max 1, . . 6500 100
max 1, 6500 . . 100
         max 1, 6500 . . 100
awb D c
awb D c
awb D c
R R E T R R
E T
G G G G
B B E T B B
E T
ï€½ ï€« ï€­ ï‚´
ï€­ ï€­
ï€½ ï‚´
ï€½ ï€« ï€­ ï‚´
ï€­ ï€­
 (16) 
where . .E T  is the estimated color temperature of the unknown 
illuminant. The idea behind the proposed modification is to 
shift the intensity of the red or blue color separate (add a 
positive constant) when subject to illuminants of high or low 
color temperature, adjust the pixel values, and then shift the 
intensity of the color separate back (add a negative constant). 
III. EXPERIMENTAL PROCEDURES AND RESULTS 
A color checker containing patches/segments may serve as 
reference objects with different surface colors. A high-end 
digital camera with a native resolution of 3888 2592ï‚´  pixels 
is utilized to acquire raw image data. Note that the raw image 
is not affected by the cameraâ€™s built-in color balance functions. 
The raw data is then converted to TIF format which preserves 
the original lighting condition of the image. A light booth 
provides various illuminants with known color temperature (A: 
incandescent of 2856K, U30: warm white fluorescent of 
3000K, CWF: cool white fluorescent of 4150K, and D65: 
daylight of 6500K) inside which the color checker can be 
placed with desired orientation. Among them, D65 is the 
desired or reference illuminant, and the image captured under 
D65 can be regarded as the reference image (with desired 
white balance). Other images captured under A, U30 and 
CWF are treated as test images (to be white balanced). The 
reference image is shown in Figure 3(a), and the test images 
subject to other illuminants are given in  Figure 3(b), Figure 3 
(c), and  Figure 3(d). 
We propose the following method, which takes into 
account statistical variation (both static and dynamic) among 
image pixels, to select a set of reference objects which 
provide samples and initial conditions for training the FNN. 
First, the color checker is positioned properly inside the light 
booth. For each known illuminant, raw image of the color 
checker is collected six times using the high-resolution digital 
camera, with each taken 20 seconds apart. Pixels of a 
specified area ( 370 370ï‚´  pixels) from each color patch on the 
raw image become candidates of training samples. Hence, 
there are a set of 370 370 6ï‚´ ï‚´  candidate pixels corresponding 
to each color patch, which account for time and spatial 
variation of that specific color. For each color patch, 
histograms are generated for the R/G/B components of the 
candidate pixels. Twenty candidate pixels lying within the 
interval of one standard deviation from the mean are then 
randomly selected as the training samples with respect to an 
illuminant of known color temperature. The means and 
standard deviations of the R/G/B histograms also provide 
sensible initial values of the center and width of the 
membership functions in layer 2 of the FNN. The centroid of 
the output membership function is set to 0. The desired output 
is set to the normalized color temperatures of the known 
illuminants, i.e., [2856,3000, 4150,6500] 6500 . For each 
training cycle of the FNN, a training sample and a desired 
normalized color temperature are presented to the network. At 
the end of each training cycle, the square root of (6) or the 
root mean square error (RMSE) is recorded. Note that the 
learning rate ï¨  is set to 0.005, and the number of training 
cycles is set to 1000. The RMSE versus training cycle is 
shown in Figure 2. The RMSE is 0.151036 at the end of the 
first training cycle and is reduced to 0.005041 after 1000 
training cycles. 
After training of the FNN is complete, test images (see 
Figure 3(b), Figure 3(c), and Figure 3(d)) are then utilized to 
demonstrate the proposed white balance approach. Using the 
method described previously with a threshold of 0.5, the 
estimated color temperatures are 4151K, 2993K, and 2850K, 
which are very close to the actual color temperatures of the 
illuminants. Using the white color patch as the reference white 
object, of which the R, G, and B components under various 
illuminants are listed in TABLE I, The data from TABLE I 
can be curve fitted using polynomials of degree two. As a 
final step, (16) is applied and the white balanced images are 
provided in Figure 3. All the white balanced images, i.e., 
Figure 3(e), Figure 3(f), and Figure 3(g), can be concluded to 
be visually closer to the reference image, Figure 3(a), than the 
original images, i.e., Figure 3(b), Figure 3(c), and Figure 3(d). 
A study is made which compares the proposed white 
balance method with other methods in existing literature, i.e., 
gray world method (GWM) [1][2], specular reflection method 
(SRM) [11]-[14], Lamâ€™s method [16], Chikane's method [17], 
Huo's method [18], Wang's method [19], and Chenâ€™s method 
[20]. The study employs the same set of reference image and 
test images as given in Figure 3. Each test image is processed 
by each individual algorithm and produces a white balanced 
image. To compare the results quantitatively, two 
performance indices are introduced. The average chromaticity 
(AC), commonly used in the literatures (e.g., [17]-[19]), for a 
white balanced image is given by 
 ï€¨ ï€© ï€¨ ï€©2 2AC Cb Crï€½ ï€«  (17) 
where Cb  and Cr  are mean values of the corresponding Cb 
and Cr color separates. Since calculation of the AC value does 
not involve a reference image (with desired balanced color), it 
is arguable to state that a method producing a white balanced 
image with low value of AC performs better than the others. 
Therefore, another performance index for comparative study 
will be utilized. When a reference/desired image is available, 
it is common practice to use mean square error (MSE) for 
quantitative evaluation of how well an image processing 
algorithm performs [15]. In this study, we have a reference 
image, which is the image digitally captured under desired 
800
                                      
[12] H.-C. Lee, â€œMethod for computing the scene-illuminant chromaticity 
from specular highlights,â€ Journal of the Optical Society of America A, 
vol. 3, pp. 1964-1699, 1986. 
[13] M. Dâ€™Zmura and P. Lennie, â€œMechanisms of color constancy,â€ Journal 
of the Optical Society of America A, vol. 3, pp. 1662-1672, 1986. 
[14] S. Tominaga and B. A. Wandell, â€œComponent estimation of surface 
spectral reflectance,â€ Journal of the Optical Society of America A, vol. 
7, pp. 312-317, 1990. 
[15] Z. Wang and A.C. Bovik, Modern Image Quality Assessment, Morgan 
& Claypool Publishers, 2006. 
[16] H.-K. Lam, O. C. Au, and C.-W. Wong, â€œAutomatic white balancing 
using luminance component and standard deviation of RGB 
components,â€ IEEE International Conference on Acoustics, Speech, and 
Signal Processing, Montreal, Canada, pp.493-496, 2004. 
[17] Chikane, and C.-S. Fuh, â€œAutomatic white balance for digital still 
cameras,â€ Journal of Information Science and Engineering, vol.22, no.3, 
pp.497-509, 2006. 
[18] J.-Y. Huo, Y.-L. Chang, J. Wang and X.-X. Wei, â€œRobust automatic 
white balance algorithm using gray color points in images,â€ IEEE 
Transactions on Consumer Electronics, vol.52, no.2, pp.541-546, 2006. 
[19] P.-M. Wang and C.-S. Fuh, â€œAutomatic white balance with color 
temperature estimation,â€ IEEE International Conference on Consumer 
Electronics, pp. 1-2, 2007. 
[20] C.-L. Chen and S.-H. Lin, â€œFormulating and solving a class of 
optimization problems for high-performance gray world automatic 
white balance,â€ Applied Soft Computing (revision submitted). 
 
 
 
TABLE I. The R, G, B components of the reference white object. 
 2856K 3000K 4150K 6500K 
Red 255 244 237 212 
Green 179 182 196 208 
Blue 88 106 138 207 
 
 
 
TABLE II. The MSE between test and reference images (in YCbCr color 
space). 
Color temperature Illuminants for the test images 4150K 3000K 2856K 
Before being white balanced 283.9 599.94 943.68 
SRM 203.25 503.21 705.31 
GWM 170.1 360 612.66 
Lamâ€™s method 137.4 260.98 403.55 
Chikane's method 97.21 136.39 422.15 
Huo's method 159.46 528.45 825.72 
Chenâ€™s method 98.49 173.01 274.62 
Wangâ€™s method 75.78 459.8 797.9 
A
fter being w
hite 
balanced 
The proposed  method 50.42 84.62 154.29 
 
 
 
TABLE III. The average chromaticity values of the test images. 
Color temperature Illuminants for the test images 
4150K 3000K 2856K 
Before being white balanced 32.81 43.9 52.38 
SRM 20.91 42.23 48.1 
GWM 0.03 0.06 0.4 
Lamâ€™s method 5.25 8.23 9.34 
Chikane's method 9.34 16.05 17.3 
Huo's method 22.23 34.5 45.37 
Chenâ€™s method 2.15 4.79 5.35 
Wangâ€™s method 14.89 38.61 47.68 
A
fter being w
hite 
balanced 
The proposed  method 11.26 10.41 18.09 
 
 
 
TABLE IV. Ranking of various methods. 
Performance Method Time (sec.) Complexity 
MSE Chromaticity 
SRM 6.8156 (2) Low 8 8 
GWM 3.3031 (1) Low 5 1 
Lamâ€™s method 71.1281 (5) Middle 4 3 
Chikane's method 19.0438 (4) High 3 5 
Huo's method 106.7594 (6) Middle 7 7 
Chenâ€™s method 14 (3) High 2 2 
Wangâ€™s method 774.1407 (8) Middle 6 6 
The proposed 
method 268.1813 (7) High 1 4 
 
R G
B
object A
object B
object C
object D
light source #1
light source #2  
Figure 1: The colors reflected from four monochromatic objects (labeled as A, 
B, C, and D) follow different trajectories in RGB color space when subject to 
different illuminants. 
 
 
0 100 200 300 400 500 600 700 800 900 1000
0
0.02
0.04
0.06
0.08
0.1
0.12
0.14
0.16
0.18
0.2
training cycle
R
M
S
E
X: 1000
Y: 0.0002486
R
M
S
E
 
Figure 2: Root mean square error versus training cycle. 
 
(a)
(d)(c)
(g)(f)(e)
(b)
 
Figure 3: Before being white balanced: (a) reference image - 6500K, (b) test 
image - 4150K, (c) test image - 3000K, (d) test image - 2856K. After being 
white balanced: (e) test image - 4150K, (f) test image - 3000K, (g) test image 
- 2856K. 
802
åœ‹ç§‘æœƒè£œåŠ©è¨ˆç•«è¡ç”Ÿç ”ç™¼æˆæœæ¨å»£è³‡æ–™è¡¨
æ—¥æœŸ:2011/10/20
åœ‹ç§‘æœƒè£œåŠ©è¨ˆç•«
è¨ˆç•«åç¨±: æ™ºæ…§å‹è‰²å½©æ†å¸¸æ¼”ç®—æ³•èˆ‡å…¶åœ¨æ•¸ä½ç›¸æ©Ÿä¹‹æ‡‰ç”¨
è¨ˆç•«ä¸»æŒäºº: é™³æ­£å€«
è¨ˆç•«ç·¨è™Ÿ: 99-2221-E-005-104- å­¸é–€é ˜åŸŸ: æ™ºæ…§å‹æ§åˆ¶
ç„¡ç ”ç™¼æˆæœæ¨å»£è³‡æ–™
å…¶ä»–æˆæœ 
(ç„¡æ³•ä»¥é‡åŒ–è¡¨é”ä¹‹æˆ
æœå¦‚è¾¦ç†å­¸è¡“æ´»å‹•ã€ç²
å¾—çé …ã€é‡è¦åœ‹éš›åˆ
ä½œã€ç ”ç©¶æˆæœåœ‹éš›å½±éŸ¿
åŠ›åŠå…¶ä»–å”åŠ©ç”¢æ¥­æŠ€
è¡“ç™¼å±•ä¹‹å…·é«”æ•ˆç›Šäº‹
é …ç­‰ï¼Œè«‹ä»¥æ–‡å­—æ•˜è¿°å¡«
åˆ—ã€‚) 
ç„¡ 
 æˆæœé …ç›® é‡åŒ– åç¨±æˆ–å…§å®¹æ€§è³ªç°¡è¿° 
æ¸¬é©—å·¥å…·(å«è³ªæ€§èˆ‡é‡æ€§) 0  
èª²ç¨‹/æ¨¡çµ„ 0  
é›»è…¦åŠç¶²è·¯ç³»çµ±æˆ–å·¥å…· 0  
æ•™æ 0  
èˆ‰è¾¦ä¹‹æ´»å‹•/ç«¶è³½ 0  
ç ”è¨æœƒ/å·¥ä½œåŠ 0  
é›»å­å ±ã€ç¶²ç«™ 0  
ç§‘ 
æ•™ 
è™• 
è¨ˆ 
ç•« 
åŠ  
å¡« 
é … 
ç›® è¨ˆç•«æˆæœæ¨å»£ä¹‹åƒèˆ‡ï¼ˆé–±è½ï¼‰äººæ•¸ 0  
 
