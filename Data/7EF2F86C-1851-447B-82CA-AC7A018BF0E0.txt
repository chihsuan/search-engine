stock selection has long been identified as a 
challenging and important task. This line of research 
is highly contingent upon reliable prediction of 
future performance of stocks and successful portfolio 
construction. Recent advances in machine learning and 
data mining are leading to significant opportunities 
to solve these problems more effectively. In this 
proposal, we aim at developing a methodology for 
effective stock selection and portfolio optimization 
using support vector regression (SVR) as well as 
genetic algorithms (GA). Plausible steps that may 
accomplish the goal of this project include, for 
instance, first employing the SVR method to generate 
predicted returns of stocks, which in turn serve to 
imply the relative rankings of stocks. The top-ranked 
stocks can thus be selected to form an investment 
portfolio. On the other hand, we will also employ GA 
for optimization of model parameters and feature 
selection for input variables to the SVR model. Based 
upon the preliminary results we have obtained so far, 
we expect this hybrid GA-SVR model to provide an 
effective solution to stock selection. Therefore, in 
this project we intend to conduct an extensive study 
along this line of research. Our ultimate goal is to 
bring about reliable machine-learning models that 
will further our understanding of the complex 
characteristics in stock market and assist us to 
acquire an effective means for stock selection in 
investment. 
è‹±æ–‡é—œéµè©ï¼š Investment, stock selection, machine learning, 
support vector regression, genetic algorithms 
 
                                                                                        
 
è¡Œæ”¿é™¢åœ‹å®¶ç§‘å­¸å§”å“¡æœƒå°ˆé¡Œç ”ç©¶æˆæœå ±å‘Š 
ç·šæ€§è¿´æ­¸èˆ‡éºå‚³æ¼”ç®—æ³•é¸è‚¡æ¨¡å‹ä¹‹æ¯”è¼ƒ 
A Comparative Study of Stock Scoring using Regression and Genetic-based Linear Models 
è¨ˆç•«ç·¨è™Ÿï¼šNSC 100ï¼2221ï¼Eï¼390ï¼033 
åŸ·è¡ŒæœŸé™ï¼š100  å¹´ 8 æœˆ  1 æ—¥è‡³ 101  å¹´ 7 æœˆ 31 æ—¥ 
ä¸»æŒäººï¼šé»ƒå¥å³¯ åœ‹ç«‹é«˜é›„å¤§å­¸è³‡å·¥ç³» 
è¨ˆç•«åƒèˆ‡äººå“¡ï¼šè¬å®—ç”·ã€éƒ­éº—æ•ã€æ—æŸè±ªã€æ´ªå˜‰æ¾¤ã€é»ƒå­å®¹ã€å‘‚è‚²å¦‚ åœ‹ç«‹é«˜é›„å¤§å­¸è³‡å·¥ç³» 
 
ä¸€ã€ ä¸­æ–‡æ‘˜è¦ 
åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘å€‘æ¯”è¼ƒäº†å‚³çµ±ç·šæ€§è¿´æ­¸èˆ‡æ©Ÿå™¨å­¸ç¿’
é¸è‚¡æ¨¡å‹ï¼Œæˆ‘å€‘æ¡ç”¨åœ¨æ©Ÿå™¨å­¸ç¿’æ¨¡å‹ä¸­å·²è¢«ç†ŸçŸ¥
çš„éºå‚³æ¼”ç®—æ³•ä¾†åšåƒæ•¸æœ€ä½³åŒ–å’Œç‰¹å¾µé¸å–æ–¹æ³•ä¾†
é¸æ“‡è¼¸å…¥è®Šé‡ä»¥é€²è¡Œè‚¡ç¥¨è©•åˆ†æ¨¡å‹ï¼Œæˆ‘å€‘è­‰æ˜ï¼Œ
æˆ‘å€‘æå‡ºçš„æ–¹æ³•ï¼Œèƒ½æœ‰æ•ˆæ‰“æ•—å‚³çµ±ç·šæ€§è¿´æ­¸æ¨¡å‹
ä»¥åŠå¤§ç›¤ï¼Œæ ¹æ“šå¯¦é©—çš„æˆæœï¼Œæˆ‘å€‘å¸Œæœ›é€™ç¨®åŸºæ–¼
éºå‚³ç®—æ³•çš„çš„æ–¹æ³•ï¼Œä»¥æ¨å‹•è¡Œç‚ºé‡‘èè»Ÿè¨ˆç®—çš„ç ”
ç©¶ï¼Œä¸¦æä¾›åœ¨å¯¦è¸ä¸­æœ‰æ•ˆè§£æ±ºé¸è‚¡ã€‚ 
é—œéµå­—ï¼šé¸è‚¡ã€è‚¡ç¥¨è©•åˆ†ã€ç·šæ€§è¿´æ­¸ã€éºå‚³æ¼”ç®—
æ³•ã€æœ€ä½³åŒ–ã€æ¨¡å‹é©—è­‰ã€‚ 
 
Abstractâ€”Stock selection has long been a challenging and 
important task in investment and finance. Researchers and 
practitioners in this area often use regression models to tackle 
this problem due to their simplicity and effectiveness. Recent 
advances in machine learning (ML) are leading to significant 
opportunities to solve these problems more effectively. In this 
paper, we present a comparative study between the traditional 
regression-based and ML-based linear models for stock scoring, 
which is crucial to the success of stock selection. In ML-based 
models, Genetic Algorithms (GA), a class of well-known search 
algorithms in the area of ML, is used for optimization of model 
parameters and selection of input variables to the stock scoring 
model. We will show that our proposed genetic-based  method 
significantly outperforms the traditional regression-based 
method as well as the benchmark. As a result, we expect this 
genetic-based methodology to advance the research in machine 
learning for finance and provide an attractive alternative to stock 
selection over the regression-based approach. 
 
Keywords- Stock selection; stock scoring; regression; genetic 
algorithms; optimization; model validation  
 
äºŒã€ å‰è¨€ã€ç ”ç©¶ç›®çš„èˆ‡æ–‡ç»æ¢è¨ 
Investment has long been recognized as a challenging and 
important problem in finance. Researchers and practitioners in 
this area often rely heavily on regression models to study this 
subject due to their simplicity and effectiveness. Examples 
include the testing of the implications of a multi-asset 
equilibrium model [1]; the forecasting of stock market  returns 
using the dividend yield, the earnings growth, and the price-
earnings ratio growth [2]; the investigation of the relationship 
between portfolio diversification and risk reduction [3-4];  the 
classification of winning and losing stocks for portfolio 
construction [5], to name just a few.  
Apart from these traditional regression-based approaches,  
recent advances in computational intelligence and machine 
learning are leading to attractive alternatives to solving these 
problems more effectively. Feasible quantitative models 
include methodologies stemming from soft computing [6] for 
prediction of financial time series, multi-objective 
optimization of expected investment return and risk reduction, 
and portfolio management â€“ selection of investment 
instruments based on asset ranking using a variety of input 
variables and historical data, etc. [7]. All these research efforts 
were in an attempt to facilitate the task of decision-making for 
investment. 
In the research area of stock selection and portfolio 
optimization, several machine learning methodologies have 
been developed, including artificial neural networks (ANNs), 
support vector machines (SVMs), evolutionary algorithms 
(EAs) as well as fuzzy inference models. Quah and Srinivasan 
[8] studied an ANN stock selection system to choose stocks 
that are top-ranked performers. They showed that their 
proposed model outperformed the benchmark model in terms 
of compounded actual returns overtime. Chapados and Bengio 
[9] also trained neural networks for estimation and prediction 
of asset behavior in order to facilitate decision-making in asset 
allocation. Although these models worked in some 
applications, they often suffer from the overfitting problem 
and may tend to fall into a local optimum. 
For portfolio optimization, Kim and Han [10] proposed a 
genetic algorithm (GA) approach to feature discretization and 
the determination of connection weights for ANNs to predict 
the stock price index. They suggested that their approach was 
able to reduce the numbers of attributes and the prediction 
performance was enhanced. In addition, Caplan and Becker 
[11] employed genetic programming (GP) to develop a stock 
ranking model for the high technology manufacturing industry 
in the U.S. More recently, Becker et al. [12] explored various 
single-objective fitness functions for GP to construct stock 
selection models for particular investment specifics with 
respect to risk. In a nutshell, these GP-based models rank 
                                                                                        
 
Zi,j(t) = Ïi,j(t), 
where Ïi,j(t) ïƒ N is the ranking of stock i with respect to 
variable j at time t. Here we denote a stock sorting indicator Ij 
for variable j and consider two cases for the stock sorting 
scheme: 
(1) Ij =0: Ïi,j(t) â‰¥ Ïk,j(t)  iff  vi,j(t) â‰¥ vk,j(t) for iâ‰ k. 
(2) Ij =1: Ïi,j(t) â‰¥ Ïk,j(t)  iff  vi,j(t) â‰¤ vk,j(t) for iâ‰ k. 
In addition, let Wj denote the weight of the j-th variable. 
Then the total score of stock i at time t, yi(t), can be defined as 
ï€  ïƒ¥ï€½
j
jiji tZWty ).()( ,
ï€  (1)ï€ 
C. Stock ranking scheme 
It is worthwhile to mention that the scores calculated for the 
stocks may not necessarily represent the precise values of 
various stocks. Rather, they can serve as surrogates for the 
actual quality to imply the relative rankings of the stocks. 
More specifically, given the scores (yi(t)'s) for all stocks, the 
ranking of a stock can be defined as: 
ï€  ï¡i(t)= Ï(yiï€¨t)),ï€  (2)ï€ 
where Ï(Â·) is a ranking function so that ï¡i(t) ïƒ N is the ranking 
of stock i at time t, and ï¡i(t) ï‚³ ï¡j(t)  iff  yi(t) ï‚³ yj(t). 
The task of stock selection can be accomplished using these 
rankings whereby top-ranked m stocks (stocks corresponding 
to the top m ï¡â€™s) are selected as components of a portfolio. 
The performance of a portfolio can be evaluated by averaging 
the actual returns of the stocks in the portfolio, which is 
defined as:  
ï€  ,))((
1
1
ïƒ¥
ï€½
ï€½
m
i
itt tsR
m
R ï€  (3)ï€ 
where si(t) is the i-th ranked stock at time t; Rt(ïƒ—) is the actual 
return for a stock at time t and tR is the average return over 
all the m stocks in the portfolio at time t. 
In this study we use the cumulative total (compounded) 
return, Rc, to evaluate the performance of a stock selection 
model, where Rc is defined as the product of the average 
annual return, tR , of the constitute stocks in a portfolio over 
n consecutive years as:  
ï€  .
1
t
n
t
c RR
ï€½
ïƒ•ï€½ ï€  (4)ï€ 
D. Model optimization by genetic algorithms 
The performance of the GA-based stock ranking model is 
determined by the set of input features F, the set of stock 
sorting indicators I, the weights of the fundamental variables 
W. Therefore, the selection of optimal subsets of features F, 
and the optimization of I and W will be critical to the 
effectiveness of the stock selection model. In [16], Genetic 
Algorithms were employed for simultaneous optimization with 
respect to these tasks. In the following we briefly describe the 
relevant GA-based optimization scheme for the stock selection 
model. 
Among many paradigms of search algorithms GAs have 
been proven to have an advantage over traditional 
optimization methods in problems with many complex, 
discontinuous constraints in the search space. This 
methodology contributes for a global, population-based search 
in the search space, in contrast with the kind of local, greedy 
search conducted by most rule-induction and decision-tree 
algorithms. Lower computation cost is a general advantage of 
local, greedy search algorithms. However, the solution quality 
achieved by these algorithms can be greatly degraded if there 
exists a considerable degree of feature interactions, which is 
usually the case for real-world problems. Since GAs can be 
designed to perform a global search for various combinations 
of sets of features that improve given optimization criteria, this 
class of algorithms are expected to cope better with feature 
interaction problems.  
Apart from feature selection, two sets of free parameters, I 
and W, are to be provided for the GA-based stock ranking 
model. In [16] the GA was employed for simultaneous 
optimization of these tasks. In the overall encoding design, the 
composition of a chromosome was devised to consist of three 
portions â€• the candidate set of features F, the stock sorting 
indicators I and the weighs W. In Fig. 1, loci 
1
fb  through 
n
fb  
represent candidate features 1 through n, respectively. For 
these features, allele â€˜1â€™ or â€˜0â€™ corresponds to the feature being 
selected or not. Loci 1
ib  through 
n
ib  represent the sorting 
indicators, where 0 represents the variable being used for case 
(1) of the stock sorting scheme, and 1 represents case (2), 
respectively. On the right-hand side of Fig. 1 is the encoding 
of the set of parameters W. Fig. 2 shows the detailed binary 
encoding for the weight of each individual variable, where the 
value of Wi (the weight for variable i) is encoded by loci 1
Wib  
through in
Wib .   
In the coding scheme, the portion in the chromosome 
representing the genotypes of parameter Wi's is to be 
transformed into the phenotype by Eq. (5) for further fitness 
computation. The precision representing each parameter 
depends on the number of bits used to encode it in the 
chromosome, which can be determined as follows: 
 
Figure 1.   Chromosome encoding 
 
Figure 2.  Detailed encoding of the weighting terms 
 
                                                                                        
 
 
å››ã€ çµæœèˆ‡è¨è«– 
To illustrate our proposed GA models with feature selection 
(GAFS), stock data of all the years is used. Stocks are ranked 
based on the scores obtained. Top m stocks are selected and 
the average yearly returns of these selected stocks are 
calculated. Fig. 4 displays the averaged best-so-far values of 
the annualized returns over 50 runs and 50 generations for 
m=10 and 30. The averaged best-so-far curve is calculated by 
averaging the best-so-fars obtained by the GA at each 
generation for all 50 runs, where the vertical bars overlaying 
the curves represent the 95-percent confidence intervals about 
the means. 
    Fig. 5 displays an illustration of the cumulative benchmark 
return (the product of the average yearly returns of the 200 
stocks in the investment universe) and the cumulative returns 
of longing a number of top-ranked stocks recommended by 
the regression-based and GA-based models. This figure 
clearly shows that the GA-based models can significantly 
outperform the regression-based models and the benchmark.  
In order to examine the validity of the GA-based models 
we proposed, further statistical validation is conducted. In 
reality, the learned model has to be tested by unseen data. 
Here, we use the stock data of the first several years to train 
the GA model, and the remaining years are used for testing 
the learned model. Thus the average yearly return of the 
selected stocks for each of the testing year is calculated. The 
average yearly returns are then compounded to obtain the 
cumulative total return of the portfolio over the testing years. 
Notice that this setup is different from the regular cross-
validation procedure where the process of data being split into 
two independent sets is randomly repeated several times 
without taking into account the data's temporal order. 
However, in the stock selection study here, temporal order is 
critical as practically one would like to use all available data 
so far to train the model and to apply the models in the future 
to gain profits. 
Table II. Statistics of the benchmark, regression-based v.s. GA-based stock selection models for 30 stocks    
Training period 
Annualized 
benchmark 
return (%) 
Annualized 
regression-
model return 
(%) 
Mean of 
annualized 
GA-model 
return (%) 
Standard 
deviation of 
annualized 
GA-model 
return (%) 
Testing period 
Annualized 
benchmark 
return (%) 
Annualized 
regression-
model return 
(%) 
Mean of 
annualized  
GA-model 
return (%) 
Standard 
deviation of 
annualized 
GA-model 
return (%) 
1995 -36.5079  -23.5091  -12.6511  0.7489  1996-2009 3.5111  6.6250  19.3132  1.9465  
1995-1996 -10.1106  3.0185  9.1239  0.8107  1997-2009 1.8793  6.2228  15.8839  2.3647  
1995-1997 12.8345  35.8647  57.1157  1.4235  1998-2009 -2.7400  2.7879  11.8631  1.5427  
1995-1998 2.1765  19.3320  36.7931  1.1984  1999-2009 -0.5192  5.9096  13.4321  2.0628  
1995-1999 2.1065  24.9227  39.4048  1.6962  2000-2009 -0.7508  6.4038  10.7420  1.9226  
1995-2000 -0.4645  17.7135  30.4963  1.4909  2001-2009 0.6331  5.0830  11.8939  2.3368  
1995-2001 -8.5626  12.5616  20.7217  1.0137  2002-2009 8.5385  12.4623  18.8043  2.4823  
1995-2002 -5.6438  12.7313  23.0776  0.9618  2003-2009 7.3061  11.4078  19.3081  2.5509  
1995-2003 -3.4626  15.8575  24.9503  0.7549  2004-2009 5.9366  13.6387  16.7977  3.1189  
1995-2004 -2.9502  18.4946  25.3182  0.7039  2005-2009 6.7869  12.4526  14.6793  2.6588  
1995-2005 -2.0844  16.5665  26.0959  0.6210  2006-2009 6.7311  10.4200  11.2700  2.8401  
1995-2006 -0.6369  16.1631  25.4571  0.6748  2007-2009 3.5806  5.3973  10.6500  2.6348  
1995-2007 2.2965  18.0834  28.3132  1.1360  2008-2009 -12.4666  -12.3408  -9.1414  2.1001  
1995-2008 -0.1914  17.6252  24.1399  0.8497  2009 5.7270  3.9852  5.3718  3.2659  
 
 
Figure 4.  Best-so-far curves by the GAFS 
 
 
Figure 5.  Cumulative returns of benchmark v.s. longing top-ranked stocks by 
the regression-based and GA-based models 
                                                                                        
 
returns,â€ Financial Analysts Journal, Vol. 53, No. 6, 
1997, pp. 34-42. 
[19] M. G. Danielson, T. D. Dowdell, â€œThe return-stages 
valuation model and the expectations within a firmâ€™s P/B 
and P/E ratios,â€ Financial Management, Vol. 30, No. 2, 
2001, pp. 93-124. 
[20] J. Lewellen, â€œPredicting returns with financial ratio,â€ 
Journal of Financial Economics, Vol. 74, No. 2, 2004, pp. 
209-235. 
[21] E. F. Fama, K. R. French, â€œAverage returns, B/M, and 
share issue,â€ Journal of Finance, Vol. 63, No. 6, 2008, pp. 
2971-2995. 
[22] E. Hjalmarsson, â€œPredicting global stock returns,â€ 
Journal of Financial and Quantitative Analysis, Vol. 45, 
No. 1, 2010, pp. 49-80. 
[23] M. Omran, â€œLinear versus non-linear relationships 
between financial ratios and stock returns: empirical 
evidence from Egyptian firms,â€ Review of Accounting 
and Finance, Vol. 3, No. 2, 2004, pp. 84-102. 
[24] R. Bauer, N. Guenster, R. Otten, â€œEmpirical evidence on 
corporate governance in Europe: the effect on stock 
returns, firm value and performance,â€ Journal of Asset 
Management, Vol. 5, No. 2, 2004, pp. 91-104. 
[25] M. T. Soliman, â€œThe use of DuPont analysis by market 
Participants,â€ The Accounting Review, Vol. 83, No. 3, 
2008, pp. 823-853. 
[26] W. E. Ferson and C. R. Harvey, â€œFundamental 
determinants of national equity market returns: A 
perspective on conditional asset pricing,â€ Journal of 
Banking & Finance, Vol. 21, 1998, pp. 1625â€“1665. 
[27] T. A. Carnes, â€œUnexpected Changes in quarterly 
financial-statement line items and their relationship to 
stock prices,â€ Academy of Accounting and Financial 
Studies Journal, Vol. 10, No. 3, 2006, pp. 99-116. 
[28] D. Ikenberry, J. Lakonishok, â€œCorporate governance 
through the proxy contest: evidence and implications,â€ 
Journal of Business, Vol. 66, No. 3, 1993, pp. 405-435. 
[29] G. Sadka, R. Sadka, â€œPredictability and the earnings-
returns relation,â€ Journal of Financial Economics, Vol. 
94, No. 1, 2009, pp. 87-93. 
 
 
 
å…­ã€é™„éŒ„: è«–æ–‡ã€å­¸ç”Ÿç•¢æ¥­è«–æ–‡ç™¼è¡¨ 
1. Huang, C.-F., Chang, B. R., Cheng, D.-W. and Chang, 
C.-H. (2012). â€œFeature Selection and Parameter 
Optimization of a Fuzzy-based Stock Selection Model 
using Genetic Algorithms,â€ International Journal of 
Fuzzy Systems 14(1), pp. 65â€“75.(SCI-E, IF=1.157) 
2. Huang, C.-F. (2012). â€œA Hybrid Stock Selection Model 
using Genetic Algorithms and Support Vector 
Regression,â€Applied Soft Computing 12(2), pp. 807â€“
818.  (SCI, IF = 2.612) 
3. Chien-Feng Huang, Tsung-Nan Hsieh, Bao Rong Chang 
and Chih-Hsiang Chang (2102). â€œA Comparative Study 
of Regression and Evolution-based Stock Selection 
Models for Investor Sentiment,â€ Proc. of The 3rd 
International Conference on Innovations in Bio-inspired 
Computing and Applications (IBICA-2012), Kaohsiung, 
Taiwan, Sept. 26-28, 2012, pp. 73â€“78 (EI) 
4. Chien-Feng Huang, Chih-Hsiang Chang, Li-Min Kuo, 
Bo-Hou Lin, Tsung-Nan Hsieh and Bao Rong Chang 
(2012). â€œA Genetic-search Model for First-day Returns 
Using IPO Fundamentals,â€ Proc. of the 2012 
International Conference on Machine Learning and 
Cybernetics (ICMLC 2012), Xiâ€™an, Shaanxi, China, July 
15-17, 2012, pp. 1662â€“1667. (EI) 
5. Huang, C.-F., Chang, C.-H., Chang, B. R. and Hsieh, 
T.-N. (2011). â€œA Genetic-based Stock Selection Model 
using Investor Sentiment Indicators,â€ Proc. of 2011 
IEEE International Conference on Granular 
Computing (GrC 2011), Kaohsiung, Taiwan, Nov. 8â€“10, 
2011, pp. 262â€“267. (EI) 
6. Huang, C.-F., Hsieh, T.-N., Chang, B. R. and Chang, 
C.-H. (2011). â€œA Comparative Study of Stock Scoring 
using Regression and Genetic-based Linear 
Models,â€ Proc. of 2011 IEEE International Conference 
on Granular Computing (GrC 2011), Kaohsiung, 
Taiwan, Nov. 8â€“10, 2011, pp. 268â€“273. (EI) 
7. Huang, C.-F., Chang, B. R. and Cheng, D.-W. 
(2011). â€œTracking Extrema in Dynamic Environments 
using Probability Collectives Multi-agent 
Systems,â€ Proc. of the 2011 International Conference 
on Machine Learning and Cybernetics(ICMLC 2011), 
Guilin, Guangxi, China, July 10-13, 2011, pp. 33â€“39. 
(EI) 
8. Huang, C.-F., Chang, C.-H., Chang, B. R. and Cheng, 
D.-W. (2011). â€œA Study of a Hybrid Evolutionary 
Fuzzy Model for Stock Selection,â€ Proc. of the 2011 
IEEE International Conference on Fuzzy Systems, 
Taipei, Taiwan, June 27-30, 2011, pp. 210â€“217. (EI) 
9. Hsieh, T.-N. (2012). â€œA Hybrid Genetic-Fuzzy Stock 
Selection Model Using Investor Sentiment Indicators,â€, 
Master thesis. Kaohsiung: National University of 
Kaohsiung. 
10. Kuo, L.-M. (2012). â€œA Study of Genetic Algorithms-
based Models for Disposition Effect and First-Day 
Returns Using IPO Fundamentals,â€, Master thesis. 
Kaohsiung: National University of Kaohsiung. 
 2 
çš„å°–ç«¯çŸ¥è­˜ï¼Œä¸¦å¯è—‰ä»¥æ“¬å®šæœªä¾†çš„ç ”ç©¶æ–¹å‘ã€‚ 
 
ä¸‰ã€ç™¼è¡¨è«–æ–‡å…¨æ–‡æˆ–æ‘˜è¦ 
æ‘˜è¦: 
In this paper, we present a study of genetic-based stock selection models using the data of fundamentals 
of initial public offerings (IPOs). The stock selection model intends to derive the relative quality of the 
IPOs in order to obtain their relative rankings. Top-ranked IPOs can be selected to form a portfolio. In 
this study, we also employ Genetic Algorithms (GA) for optimization of model parameters and feature 
selection for input variables to the stock selection model. We will show that our proposed models deliver 
above-average first-day returns. Based upon the promising results obtained, we expect our GA-based 
methodology to advance the research in soft computing for computational finance and provide an 
effective solution to stock selection for IPOs in practice. 
 
å››ã€å»ºè­° 
   åœ‹å…§ç›®å‰é—œæ–¼æ©Ÿå™¨å­¸ç¿’åŠæ™ºæ…§å‹ç³»çµ±æ­¤äºŒå¤§é ˜åŸŸçš„ç ”ç©¶å­¸è€…åŠå·¥æ¥­ç•Œå¾æ¥­äººå“¡æœ‰å¢åŠ çš„è¶¨å‹¢ï¼Œç‰¹åˆ¥
æ˜¯å…¶æ‡‰ç”¨å°‡å¯ç™¼æ®è‡³é›²ç«¯è¨ˆç®—ä¸¦å·²ç¶“æˆç‚ºåœ‹å®¶çš„é‡é»ç™¼å±•é …ç›®ã€‚å› æ­¤å»ºè­°åœ‹ç§‘æœƒå¯å¤šè£œåŠ©åœ‹å…§å­¸è€…åŠ 
å…¥æ­¤ä¸€ç ”ç©¶é ˜åŸŸä¸¦å‡ºå¸­åƒèˆ‡æ­¤é¡åœ‹éš›ç ”è¨æœƒï¼Œä»¥æœŸåŸ¹é¤Šå‡ºæ›´å¤šçš„ä¸€æµå­¸è€…ã€‚ 
 
äº”ã€æ”œå›è³‡æ–™åç¨±åŠå…§å®¹ 
   å›  ICMLC æœ¬å±†ä½œæ¥­æµç¨‹è€½èª¤ï¼ŒICMLC ç›®å‰æ­£åœ¨å°‡ Proceedings of The 2012 International 
Conference on Machine Learning and Cybernetics ä»¥éƒµå¯„æ–¹å¼å¯„è‡³å¾äººçš„å·¥ä½œå–®ä½ã€‚ 
 
å…­ã€å…¶ä»– 
ç„¡ 
 
 
Non-IEEE Member:
Page 2/4
b. We will need the LaTeX or WORD version of your paper (WORD
document is preferable) for English grammar and/or usage editing. Please
revise your paper according to the reviewer comments (shown on the
ICMLC Submission System). Pay special attention to your paper format
and make sure your paper follows the Formatting Guidelines as stated in
the ICMLC website. The LaTeX or WORD version of the paper should be
submitted via the ICMLC Submission System.
c. Fill in the Online Registration Form. The Registration Form can be found
in the ICMLC Submission System. The Oral or Poster presentation will be
assigned according to your preference. Please state your preference for your
paper presentation. You will be notified whether your paper will be
presented in an Oral Session or Poster Session in June 2012.
d. Fill in the IEEE Copyright Form The IEEE Copyright Form can be signed
via the ICMLC Submission System.
Steps b, c and d will need to be completed when you logon to the ICMLC
submission system. (http://www.icmlc.com/icmlcSystem/author/)
(4) After the completion of your registration, you will receive an email attached with
a registration confirmation letter. You need to print it and bring it to the
conference as proof. If you cannot attend the conference and would like to ask
your colleague to pick up the conference proceeding CDROM and one volume
of the proceeding, your colleague must present your registration receipt to the
conference organizer.
(5) You will be informed whether your paper will be invited to participate in the
Conference Awards and/or Ph.D. Colloquia Series in June 2012.
(6) We will confirm your attendance in ICMLC 2012 in June 2012.
(7) If you have any enquiry, please contact the Conference Secretary, Patrick Chan,
at patrickchan@ieee.org. Please indicate your paper ID.
Thank you again for your contribution to the ICMLC, and we look forward to seeing you in
Xian.
Best regards,
ICMLC 2012 Program Committee
Page 4/4
  
	
 
  	
   
  

  
  
     
  
 
 


 
    
   	 
	  
	 
	    
	 !"#$ 
  
	         "# 
	 
   	    
 
%& 
 
 
    
 
	 '
 "#   
 	
 
	

 


 &    
   
  
 

   
	  
 
   "# 
	 
'   
( 
 	 
 )
 * 

  
 
  
  )
 + 

          

  )
 ,      
   )
 - 
   
./  01234546478 
' 
 	     
	 

 

 
    	
 
 
 &	 

(
 
 
   	 
  
 %&    
*  )
 
  	  
     
    9 
	 

    	   
	:   
 
 
	 9 
	       
	     
    
	  

 	   
   
 

 
 

    # 
; 
	  
 
  
 
 
 
	  
 
 
  
  
	   < 
  
 
   
 
 
  
 
   
 

  
	

 
    
  	
  

       	   
 
 
 
 = >
?@AB  

  
 
	 
 ? 
   @   B  >
?@AB
  
  
 
	  @ C?@B 	
 
 ?   B D
   
  
	   	     


 

 !"E< 
$   "E< 
  
   
F 
 
 
	     	   #  

 	    
 !G#&$   
 
	 G#&    
F  
 
	 
    	 
&

 
  
       
   

 
 
  
 
 
  
 
	  @    
  
 
 
? H 
>
?@
 I J?@ 
 J?@ K L    
	 
 ?   
  
@ M 
  
 
 
 N@ 	
  @  
 
 	
  
 
   

H 
!$ N
@
 OH J
?A@
 P J
QA@
  	  C
?A@ 
P C
QA@
 	
 ?RQ 
!*$ N
@
 OH J
?A@ 
P J
QA@
  	  C
?A@ 
S C
QA@ 
	
 ?RQ 
 
  T
@ 

   
	  @U V 
  
 
 
	 
 ? W?!X$   	  
 
$!

Y
Z
@
@?@?
>TTW
  [\] 
 X 
  
 
	   
	   
	 !  
 	
 
 $   
 
 
 
 
  
 
 
   
  	
 
 
    
 	
   9  
    
 	  '  
 
 	
  
   
	  
   	 
H 
  ?^ !X$ O J!W? !X$$  [*$ 
 J!_$    	
 
  ?^ K L    

	 
 ?  ?^ ` ^@ 	  W? ` W@a 
'  
	 
 
      
  
 b 
 !
 

 

  
 b :^$    

 
	  
	

 
' 	
 
	  
	

      
   
	  
   
	

   
	 H 
 
$!


Y
Z
Z
b
?
?
cd
b
d
  [e] 
 c?   ?  
V d!f$     	
  

  
d
    
   b 
   

	

 
      
d
 

   
	
 
	 
 
 
 
 
**  g
 
(
   
 
' 	
 
	  
 
 
  
    
	  	 h   
	 
 
ijjk
lmnoppqrstu nv wxp yz{y |swpms}wrns}~ nsvpmpsop ns Â€}oxrsp Âp}msrst }sq Â‚ÂƒpmspwrouÂ„ Â…r}sÂ„ {Â†Â‡{Âˆ Â‰ÂŠ~Â‚Â„ yz{y
  
  	
    
       !    " #  
$# !%  &' (!$#   ()* !+ 
, ( #    -! ($  ./ #0* 
1. !  /!! ! 20* , 
34#05+(+%+6   , 7 $  8!# 
1,786 (   ( $ ($ 9::;  9:<<+ /  
   ( (!$# #* !    5# 
( #  #* "* #  (!!  " !+ = ( 
$ #    #* (0#* #5 * 
 (  *  >$  # 0 
(!$#   " !+ ?  %   5! 
#! ,0# < 5  ($ (! 0! 
   0 $#* (  !*  #!%  
( # +   !* 50#  "   0 
0*  ( #     # ()* ! 
 5+ /!$   $  $% 
(!$#   $5    !#   
! $  @A &' 5#0# ( ! !*+ 
B  CDEE	  
   5(*  $#%*   
 )5#   $#   ! + ,   
# $# 0*  F?   %  5  0 
>$ 0*  % + /   /%+ G   
G)(#  )5#     (#  ! (  
(! !0)  ! ( %   $% 
  ! ( %+ 
 
HEI B  BJK 	KJLEEK 
 
/ #!  5%  ($  ( ! 
$# 0*  $%  5% ! (  #   " 
0*  F? $#   ( #   "+ ,0# 9 #* 
 !# !%  $#  #   ; &' 1  
M
NOPQR
6 ( 9 S  G)(#   5#+ ?   0   
 %   5% ()* ! (  #  
&'  %   ( #  &' 1  M
TU
6+ , 
# $#   0% >$   % + 
?#*  5% ()* ! (   ; &' 
#  0*  $# # !($  ( #  &' 
0* %  ( 5 ( ! $#+ ?#%!#* 
,0# S #*  !# !% ! $#  #   <: 
&' 1  M
NOPQVW
6 % ( 9 S  G)(#   
5#+ , !# %   #  5% 
()* ! (  #  <: &'  %   
 % 5% ()* ! ( #  &' 
1  M
TU
6 0*  %  ! $#   0 
( 5   "% $%  "+ 
XYZ[C \ YXX]Z^ XC_ ^_C`  ]a XbC _Xcde _C[CdX]ca fc` C[ 
?0!  g  h   g(+ 
.   #* 
&7g 
& ))%  i    4 %    j<9kj<Skj<Gkj<;k 
&lg 
& ))0"  i    4 0" 5#!    j<9kj<Gkj<;kj<mkj<Ak
&.g 
& ))#  i    4 #    j<9k 
&(0#* 
g'7 
g!  -!* 1( >6 i   $ ( > 4 #n -!*  j<@kj<ok 
g'? 
g!   1( >6 i   $ ( > 4 #   j<@k 
'&= 
'% ( $% i %  $ 4  #  j9:k 
p&= 
p ( $% i   $ ( > 4  #  j<ok 
.#5 * 
h7g 
h0))-!*  i # #0# 4 #n -!*  j<@k 
qg 
q!  i  !  4  ! #0#  j<@k 
rg 
r! "  i -! "  4  ! #0#  j<@k 
q 
  5% i % 0(   > 4  >  j9<k 
7(  * 
,g 
5* !5  i   ( % # 4 5% 5*  j<@k 
g,g 
g 50# !5  i    # 4 5%   !  50#  j99k 
 
sttu
vwxyzz{|}~ xÂ€ ÂÂ‚z ÂƒÂ„Â…Âƒ Â†}Âzw}Â‡Â|x}Â‡Âˆ Â‰x}Â€zwz}yz x} ÂŠÂ‡yÂ‚|}z Â‹zÂ‡w}|}~ Â‡}{ Â‰ÂŒÂzw}zÂ|yÂ Â|Â‡}Â Â…ÂÂ‘Â…Â’ Â“Â”ÂˆÂŒÂ ÂƒÂ„Â…Âƒ
  
	
 	 	
	  	 		 
	
    
 !" # $ %
& 	 # $ & '( )** 
		   + 	 	 ,	-  
	
  & . 			 /+& 	 
(,	   0 	 /*1 
		   22!  
 " 3  4& 	 1 	,	 ',	
 	 	 
+ 	,	 &
& 	 	)+ 	- 
05  )& (	 67  8! 
 
 " 9 & 	 : 1	
 ' 		 	  
*		  6$*  	 	
 	 
	)+- 000 3		 	 9 9)+ 6 
8  2 8 
 " # 	 	 : 1+ ';	 	 	
 

	 
	
 	  + +	
 	5- 	< 
=# >?$ 3 : $ $ 1 /@ A0B 
C	 
	
 3& 	   	
 
(		 (* #&
	  278 &  8 
 7" : 1+  . 	 ( ; '+ 	  (	 
		,, 	  
	 
	
 
&
- 	< $ $ 3  1 /@ A0B 
C	 
	
 3& 	  6 C	 
	 0,	 	 6  	
 (		 
(* #&
	  !!! & 8 8 
 2" D E D 	  F	 'C	 
& &  
 @	 	  	 	)+  & 
	  +  	5- 05  )& 
(	 6  8!8 8 
 "  . F	
 '( F* + 	 # 	
 
C	 (
& 	  6 $
	- 
(  	
 6 8 9 8  2722 
8 
 "  . F	
  F &	
 1 $ &	
 	 3 9 F& 
'( C	* + 	 # 	
 	, 
		 	- 	
  8 000 
			 		 	 C	 	
  
8887 8 
 " E + '6 	,	
< 3&   & 
		 	 		   )		 
 - E	  (		
 $& 6 !2 
  8 
 8"  #+&G 	 #  H& : F D '( 
		 	  D	 + 	- 
.		 (	 E	 6 ! 9 !  72 
7 
 !" # C H		 	 3 H H) '3& 	
 
,	  	 & 5	 )&	  I 
J1 	 J0 - .		 #	
	 6 ! 9 
8 !8 8 
 " E ;)	 '	
 	 )& 		 - 
E	  .		 0	 6 7 9 8  
88! 8 
 " 0 FG	 '	
 
* + 	- 
E	  .		 	 4	, (	 6  
9   2 8 
 " C $ E		 $ $ E&		 	 E # # '9) 
,	 	 @ 	 *+  	 + 
	- .		 (	 G	 6! 9  
!8 7 
 7" 0 . . 	 D $ .	& '(,
 	 1J# 
	 & - E	  .		 6 ! 9   
878 82 
 2" # >	 ';	 , 			 	& 
*)	 		  	 + 	<  
,	  0
	 - $,)  (		
 
	 .		 6 ! 9 8 28 8 
 " $ 1 9 C	 $ >
	 '0 ,	 	 
 
,		 	 0< &  	 + 
	  , 	 	- E	  ( 
#	
	 6  9 8  8 
 8" # 3 	 '3&   H	 	 * + 
	- 3& (		
 $,) 6 2! 9 ! 
28!2! 82 
 8" # 9 F	 C '    	 
+   	  	 +	- 
		 E	  	 $& 	 
1	 6 ! 9 !  77272 8 
 88" 3 ( 	 '=	5 &	
 	 K 
			 	  	 & 	&  
+ - (  (		
 	 .		 
 E	 6  9 !  8
 
LMMN
OPQRSSTUVWX QY Z[S \]^\ _VZSPV`ZUQV`a bQVYSPSVRS QV c`R[UVS dS`PVUVW `VT befSPVSZURXg hU`Vg ^ij^k lmaeg \]^\
100ï¦ï¨å°ˆé¡Œç ”ç©¶è¨ˆç•«ç ”ç©¶æˆæœå½™æ•´è¡¨ 
è¨ˆç•«ä¸»æŒäººï¼šé»ƒå¥î¹ è¨ˆç•«ç·¨è™Ÿï¼š100-2221-E-390-033- 
è¨ˆç•«åç¨±ï¼šä¸€å€‹çµåˆéºå‚³æ¼”ç®—æ³•åŠæ”¯æ´å‘ï¥¾æ©Ÿçš„æŠ•è³‡æ¨¡å‹ 
ï¥¾åŒ– 
æˆæœé …ç›® å¯¦éš›å·²é”æˆ
ï¥©ï¼ˆè¢«æ¥å—
æˆ–å·²ç™¼è¡¨ï¼‰
é æœŸç¸½é”æˆ
ï¥©(å«å¯¦éš›å·²
é”æˆï¥©) 
æœ¬è¨ˆç•«å¯¦
éš›è²¢ç»ç™¾
åˆ†æ¯” 
å–®ä½ 
å‚™ è¨» ï¼ˆ è³ª åŒ– ï¥¯
æ˜ï¼šå¦‚ï¥©å€‹è¨ˆç•«
å…±åŒæˆæœã€æˆæœ
ï¦œ ç‚º è©² æœŸ åˆŠ ä¹‹
å° é¢ æ•… äº‹ ...
ç­‰ï¼‰ 
æœŸåˆŠï¥æ–‡ 0 0 100%  
ç ”ç©¶å ±å‘Š/æŠ€è¡“å ±å‘Š 0 0 100%  
ç ”è¨æœƒï¥æ–‡ 0 0 100% 
ç¯‡ 
 
ï¥æ–‡è‘—ä½œ 
å°ˆæ›¸ 0 0 100%   
ç”³è«‹ä¸­ä»¶ï¥© 0 0 100%  å°ˆï§ å·²ç²å¾—ä»¶ï¥© 0 0 100% ä»¶  
ä»¶ï¥© 0 0 100% ä»¶  
æŠ€è¡“ç§»è½‰ 
æ¬Šï§ï¤Š 0 0 100% åƒå…ƒ  
ç¢©å£«ç”Ÿ 4 4 100%  
åšå£«ç”Ÿ 0 0 100%  
åšå£«å¾Œç ”ç©¶å“¡ 0 0 100%  
åœ‹å…§ 
ï¥«èˆ‡è¨ˆç•«äººï¦Š 
ï¼ˆæœ¬åœ‹ç±ï¼‰ 
å°ˆä»»åŠ©ï§¤ 0 0 100% 
äººæ¬¡ 
 
æœŸåˆŠï¥æ–‡ 2 3 100%  
ç ”ç©¶å ±å‘Š/æŠ€è¡“å ±å‘Š 0 0 100%  
ç ”è¨æœƒï¥æ–‡ 6 6 100% 
ç¯‡ 
 
ï¥æ–‡è‘—ä½œ 
å°ˆæ›¸ 0 0 100% ç« /æœ¬  
ç”³è«‹ä¸­ä»¶ï¥© 0 0 100%  å°ˆï§ å·²ç²å¾—ä»¶ï¥© 0 0 100% ä»¶  
ä»¶ï¥© 0 0 100% ä»¶  
æŠ€è¡“ç§»è½‰ 
æ¬Šï§ï¤Š 0 0 100% åƒå…ƒ  
ç¢©å£«ç”Ÿ 0 0 100%  
åšå£«ç”Ÿ 0 0 100%  
åšå£«å¾Œç ”ç©¶å“¡ 0 0 100%  
åœ‹å¤– 
ï¥«èˆ‡è¨ˆç•«äººï¦Š 
ï¼ˆå¤–åœ‹ç±ï¼‰ 
å°ˆä»»åŠ©ï§¤ 0 0 100% 
äººæ¬¡ 
 
