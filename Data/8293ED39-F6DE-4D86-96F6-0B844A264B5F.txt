   
  
Ëá™ÂãïËæ®ÔßºÂÆâÂÖ®Á≥ªÁµ±‰πãÈñãÁôºÁ†îÁ©∂ 
Development and Construction of Automatic  
Recognition Security System 
 
Ë®àÁï´Á∑®ËôüÔºöNSC94-2213-E-014-002 
Âü∑Ô®àÊúüÈôêÔºö94 Ô¶é 08 Êúà 01 Êó•Ëá≥ 95 Ô¶é 07 Êúà 31 Êó• 
Ë®àÁï´‰∏ªÊåÅ‰∫∫: ÈÉùÊ®πËÅ≤ ÂâØÊïôÊéà 
Ë®àÁï´Ô•´Ëàá‰∫∫Âì°ÔºöËÉ°Ê¶ÆÂØå„ÄÅË®±‰∏ñË≥¢ 
Ë®àÁï´Âü∑Ô®àÂñÆ‰Ωç: ‰∏≠Ê≠£Ôß§Â≠∏Èô¢ÈõªÊ©üÂ∑•Á®ãÂ≠∏Á≥ª 
Ê°ÉÂúíÂ§ßÊ∫™ÈéÆ 335 Âì°Ê®πÔß¥‰∏âÂÖÉ‰∏ÄË°ó 190 Ëôü 
ÈõªË©±Ôºö03-3800301 ÂàÜÊ©ü 371ÔºåÂÇ≥ÁúüÔºö03-3801407 
 
E-mail: haoshu@ccit.edu.tw 
ÊëòË¶Å‚ÄîËøëÔ¶éÔ§≠Ôºå‰∫∫Áâ©ÁöÑÂêÑÁ®ÆÁîüÁâ©ÁâπÂæµÔ®¶Â∑≤Á∂ìË¢´Êé°Áî®Ô§≠ÂÅöÁÇ∫ÂÆâÂÖ®Êü•Ê†∏Á≥ªÁµ±ÁöÑÈáçË¶ÅÊØîÂ∞ç‰æù
ÊìöÔºåÊàñËÄÖÊòØÁî®ÊñºË≥áÔ¶æÂ∫´ÁöÑÁÆ°Ôß§ËàáÊü•Ë©¢ÁöÑ‰æùÊìöÔºåÂú®ÈÄô‰∫õÁâπÂæµ‰∏≠Ôºå‰ª•ËáâÈÉ®ÁöÑË≥áË®äÊúÄÂÆπÔß†ÂèñÂæóÔºå
Âõ†ÁÇ∫ÂÆÉ‰∏¶Ô•ßÈúÄË¶ÅË¢´Êü•Ê†∏ËÄÖÁöÑË∫´È´îÊé•Ëß∏Ê∏¨Ô•æÂÑÄË°®ÔºåËÄåÁõÆÂâç‰∏ÄËà¨ÂÆâÂÖ®Áõ£Ë¶ñÁ≥ªÁµ±‰πãÊîùÂΩ±Ê©üÁµïÂ§ßÈÉ®
‰ªΩÂè™ÊúâÁõ£Ë¶ñÔ§øÂΩ±ÁöÑËÉΩÔ¶äÔºåÊú™ËÉΩÂÖÖÂàÜÁôºÊèÆÂÖàÊúüËæ®ÔßºÈ©óË≠âÁöÑÈÄ≤‰∏ÄÊ≠•ÂäüËÉΩÔºåÈö®ËëóÊÅêÊÄñÊ¥ªÂãïËàáÁäØÁΩ™
Ô®àÁÇ∫ÁöÑÂ¢ûÂä†ËàáÊäÄË°ìÁöÑÔ®ùÈÄ≤ÔºåÁõ£ÊéßÁ≥ªÁµ±ÂÖ∑ÊúâÊ≠§‰∏ÄÂäüËÉΩÁöÑËø´Ô®ÄÊÄßËàáÂøÖË¶ÅÊÄßÊÑàÔ§≠ÊÑàÂä†È°ØËëó„ÄÇÂõ†Ê≠§
Êú¨Ë®àÂäÉÁöÑÁõÆÁöÑÂ∞±ÊòØÁ†îÁôºÂª∫Ôß∑‰∏ÄÂ•óÔßùÁî®ÂΩ±ÂÉèË¶ñË®äË≥áË®äÔºåÔ§≠Âæû‰∫ãËá™ÂãïËæ®ÔßºÁöÑÂÆâÂÖ®ÁÆ°Âà∂Á≥ªÁµ±„ÄÇÊú¨
Ë®àÂäÉÁõÆÂâçÊâÄÂª∫ÊßãÂÆåÊàêÁöÑÁ≥ªÁµ±Ê®°ÁµÑË®àÊúâÔºåÂèñÂÉèÊÑüÊáâÊ®°ÁµÑ„ÄÅÂÖ•‰æµÂÅµÊ∏¨Ê®°ÁµÑ„ÄÅËæ®Ë™çÊ†∏ÂøÉËªüÈ´îÊ®°ÁµÑ(Âê´
ÁâπÂæµÊì∑ÂèñËàáËæ®Ë™ç)„ÄÅË≥áÔ¶æÂ∫´Ê®°ÁµÑ‰ª•ÂèäÁõ∏ÈóúÁöÑÁµ±Ë®àËæ®ÔßºÔß§Ô•ÅÂàÜÊûêËàáÁ®ãÂºè‰πãÊí∞ÂØ´„ÄÇÈÄô‰∫õÊ®°ÁµÑÂåñÁöÑ
ÂàÜÁ≥ªÁµ±Ë®≠Ë®àÊú™Ô§≠ÂèØ‰ª•ÂæàÂÆπÔß†ÁöÑÂú®ÂÄãÂà•ÁöÑÊ®°ÁµÑ‰∏≠Âæû‰∫ãÂêÑÁ®ÆÂÅµÈåØ„ÄÅ‰øÆÊîπ„ÄÅÁµÑÂêàËàáÂçáÁ¥ö„ÄÇÊú¨Ë®àÂäÉ
ÁõÆÂâçÂÆåÊàêÁöÑÂπæÂÄã‰∏ªË¶ÅÁõ∏ÈóúÊäÄË°ìÁÇ∫‰∫∫Áâ©ÁâπÂæµÁöÑÊèèËø∞ËàáÊØîÂ∞ç„ÄÅËæ®ÔßºÈåØË™§Ô•°ÁöÑÂàÜÊûê„ÄÅ‰∫∫Áâ©ÁâπÂæµË≥á
Ë®äÁöÑÊ≠£Á¢∫Êì∑ÂèñÊ®ôË®ò„ÄÅË≥áÔ¶æÂ∫´ÁöÑÂª∫Ôß∑ËàáÁâπÂæµÊØîÂ∞çÊºîÁÆóÊ≥ï‰πãÁ†îÁ©∂Á≠âÂπæÂÄã‰∏ªË¶ÅÈÉ®‰ªΩÔºåÊú¨Ë®àÁï´‰πãÊàê
Êûú‰∏¶‰∏îÂàÜÂà•ÁôºË°®Âú®‰∫åÁØáÂúãÈöõËàáÂúãÂÖß‰πãÁ†îË®éÊúÉÔ•ÅÊñá‰∏≠„ÄÇ 
 
 
 
 
Abstract‚ÄîRecently, many applications take the human features as the main clues of the 
biometrics information in the security system. Among these features, facial features are the 
easiest to obtain without requiring the cooperation of the tester. Most of the cameras have only 
record function in lots of the security systems. We are attempting to construct an automatic 
recognition security system with the help of the video camera in this project. We have finished 
the database construction. The intrusion alert algorithm has been developed. We also developed 
the statistical face recognition algorithms and features extraction algorithms. The module 
designed concept is suitable for future debugging, updating and modifying. The key technologies 
are feature extraction and identification, human feature indexing, database construction, and 
related statistical algorithms. The results have been published in two conferences. 
 
 
ÈóúÈçµË©ûÔºöËáâÈÉ®Ëæ®Ôßº„ÄÅÁâπÂæµÊì∑Âèñ„ÄÅÁîüÁâ©Ê∏¨Ô•æÂ≠∏„ÄÅÂÆâÂÖ®Á≥ªÁµ±„ÄÅËá™ÂãïÂÅµÊ∏¨„ÄÅÈåØË™§ÂàÜÊûê 
 
Keywords: Face Recognition, Feature Extraction, Biometrics, Security System, Automatic 
Detection, Error Analysis 
   
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Âúñ‰∏â„ÄÅÂÉèÂ∑ÆÊ≥ïÂãï‰ΩúÂÅµÊ∏¨‰∏Ä 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
ÂúñÂõõ„ÄÅÂÉèÂ∑ÆÊ≥ïÂãï‰ΩúÂÅµÊ∏¨‰∫å 
 
 
 
 
 
 
 
 
 
Âúñ‰∫î„ÄÅÔßùÁî® MontiVision ‰ª•ÂÖâÔßäÊ≥ïÂæû‰∫ãÂÖ•‰æµ
ÂÅµÊ∏¨‰πãÁ≥ªÁµ±ÊñπÂ°äÂúñ 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
ÂúñÔßë„ÄÅÂÖâÔßäÊ≥ïÂãï‰ΩúÂÅµÊ∏¨‰∏Ä 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
Âúñ‰∏É„ÄÅÂÖâÔßäÊ≥ïÂãï‰ΩúÂÅµÊ∏¨‰∫å 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
ÂúñÂÖ´„ÄÅÔßùÁî® MATLAB Âæû‰∫ãÂãï‰ΩúÂÅµÊ∏¨ 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Âúñ‰πù„ÄÅÔßùÁî® MATLAB Âæû‰∫ãÂãï‰ΩúÂÅµÊ∏¨‰πãÁ®ãÂºè 
 
‰ª•‰∏äÊâÄËø∞‰πÉÊòØÔßùÁî®Ô•∏Á®ÆÔ•ßÂêåËªüÈ´îÔ§≠Ë®≠Ë®à‰∏Ä
Â•óÂÖ•‰æµÂÅµÊ∏¨ÁöÑÊ®°ÁµÑ„ÄÇÂÖ∂‰∏≠ÁöÑÂèñÂÉèÊîùÂΩ±Ê©ü‰πÉÊòØ
Â∏ÇÈù¢‰∏äÂèØÂÆπÔß†Ë≥ºÂæóÁöÑLogitech QuickCam‚ÄùÂø´
ÁúãÊ∫ùÈÄöÁâà‚ÄùÔºåÊàñËÄÖÊé°Áî®ÂÖ∂‰ªñÁöÑÁ∂≤Ô§∑ÊáâÁî®ÊîùÂΩ±
Ê©üÔ®¶ÂêåÊ®£ÂèØ‰ª•ÈÅîÂà∞‰∏ÄÊ®£ÁöÑÊïàÊûú„ÄÇ 
 
 
1 
   
Âõõ„ÄÅ    ÁµêÊûúËàáË®éÔ•Å 
 
 Á∏ΩÁµêÊú¨Ô¶éÔ®ÅÁ†îÁ©∂Ë®àÁï´ÊâÄÁç≤Ëá¥ÁöÑÁ†îÁ©∂Êàê
ÊûúÂ¶Ç‰∏ãÔºå‰∏Ä„ÄÅÊòØÂ∞çÊñºÂÖ•‰æµÂÅµÊ∏¨Áç≤Ëá¥‰∏ÄÂàùÊ≠•ÁöÑ
ÊàêÊûúÔºåÂèØ‰ª•ÔßùÁî®ÁèæÊàêÁöÑËªüÈ´îÔ§≠Âπ´Âä©ÊàëÂÄëÂæû‰∫ã
Á†î Á©∂ Ôºå Êàë ÂÄë ÂàÜ Âà• Ôßù Áî® MontiVision Ëàá
MATLAB Ô•∏Á®ÆËªüÈ´îÔ§≠Âæû‰∫ãÁôºÂ±ïÔºåÔ®¶Áç≤ÂæóÂÖ•
‰æµÂÅµÊ∏¨ÁöÑÂàùÊ≠•ÊàêÊûúÔºåÂÖ∂‰∏≠Ô•¥ÊòØËÉΩÂ§†Âä†ÂÖ•
MATLAB ‰πã Video and Image Acquisition 
Blockset ÁöÑË©±ÔºåÔ§ÅÂèØ‰ª•ÁµêÂêà Simulink Âæû‰∫ã
Âç≥ÊôÇÁöÑ‰ªãÈù¢ÊéßÂà∂Ê®°Êì¨ÔºåÊ≠§‰∏ÄÈÉ®‰ªΩÂ∞áÂú®ÂæÄÂæåÁöÑ
Ô¶éÔ®Å‰∏≠ÁπºÁ∫åÊé°Ë≥ºÁõ∏ÈóúÁöÑËªüÁ°¨È´îÂæû‰∫ãÁ†îÁ©∂Áôº
Â±ï„ÄÇ 
‰∫å„ÄÅÊòØË≥áÔ¶æÂ∫´ÁöÑÂª∫Ôß∑ÔºåÊàëÂÄëÂ∑≤Á∂ìÂèØÔßù
Áî®ÂàùÊ≠•ÁöÑÂ†¥ÊôØË¶èÂäÉÂæóÂà∞ÂèóÂùáÂãªËàáÔ•ßÂùáÂãªÂÖâ
ÁÖßÁöÑËáâÈÉ®ÂΩ±ÂÉèÂæû‰∫ãÁ†îÁ©∂ÔºåÊ≠§Ë≥áÔ¶æÂ∫´ÈÉ®‰ªΩÊú™Ô§≠
Â∞áÁπºÁ∫åÁöÑÊé¢Ë®éÂ¶Ç‰ΩïÔ§ÅÔ®ùÊ∫ñÁöÑÊéßÂà∂ÊãçÊîùÁí∞
Â¢ÉÔºå‰ª•ÂèäÊúùÂÖ®Ëá™ÂãïÁöÑË≥áÔ¶æÂ∫´Âª∫Ôß∑Ô§≠ÁôºÂ±ï„ÄÇ 
‰∏â„ÄÅÊòØÁâπÂæµÁöÑÊì∑ÂèñËàáÊØîÂ∞çÊäÄÂ∑ßÊñπÈù¢Ôºå
Êàë ÂÄë ÁõÆ Ââç ÂÖà Ôßù Áî® Â∞è Ê≥¢ ËΩâ Êèõ (Wavelet 
Transform) „ÄÅ Ô¶ä Áü© Ô•ß ËÆä ÊÄß (Moment 
Invariants) „ÄÅ ‰ª• Âèä ‰∏ª ÂÄº ËΩâ Êèõ Ê≥ï (Principle 
Component Transformation)ÔºåÔ§≠Âæû‰∫ãÂΩ±ÂÉèÁâπ
ÂæµÂÄºÁöÑÂª∫Ôß∑ËàáÊØîÂ∞ç‰πãÁ†îÁ©∂ÔºåÊú™Ô§≠ÊàëÂÄëÈô§Ô¶∫Êîπ
ÂñÑÁèæÊúâ‰πãÊñπÊ≥ï‰πãÂ§ñÔºå‰πüÂ∞áÁπºÁ∫åÁ†îÁ©∂ÂÖ∂‰ªñÁöÑÁâπ
ÂæµÂÄºÊØîÂ∞çÊñπÊ≥ï„ÄÇ 
Âõõ„ÄÅÊòØÊé°Áî®‰∫åÁ∂≠ PCA(2DPCA)ÔºåÔ§≠Âæû
‰∫ãÂΩ±ÂÉèÁöÑÊêúÂ∞ãÔºåÂú®ÈÄôÂÄãÊñπÊ≥ï‰∏≠ÊàëÂÄëÔßùÁî®Â•áÔ•¢
ÂÄºÂàÜËß£(Singular Value Decomposition, SVD)
‰πãÊñπÊ≥ïËàáÂÇ≥Áµ±ÁöÑ PCA ÊñπÊ≥ïÂÅöÊØîËºÉÔºåÂØ¶È©óÁµê
ÊûúÈ°ØÁ§∫ 2DPCA Âú®ÊØîÂ∞çÁöÑÊ≠£Á¢∫Ô•°‰∏äÂÑ™Êñº
1DPCAÔºåÂØ¶È©óÈÅéÁ®ã‰∏≠ÊàëÂÄëÊé°Áî®Ô•ßÂêåÁöÑÊ∏¨Ô•æÊåá
Ê®ôÔºåÔ¶µÂ¶ÇÔºöCity Block„ÄÅEuclidean Distance„ÄÅ
Covariance „ÄÅ Mahalanobis Distance „ÄÅ
Correlation Á≠âÔ§≠Âà§Êñ∑ÊØîÂ∞çÁöÑÊ≠£Á¢∫ÊÄßÔºåÁî±ÈÄôÂπæ
Á®ÆÊñπÊ≥ï‰∏≠ÊàëÂÄëÂèØ‰ª•Áü•ÈÅìÊØèÊ¨°ÈÅãÁÆóÁöÑ‰πòÊ≥ïËàá
Âä†Ê≥ïÔ•©ÁõÆÔºåÂ∞çÊñºÊú™Ô§≠ÂØ¶ÈöõÁ°¨È´îÁöÑË®≠Ë®àÊúâÂÖ∂Ë≤¢
Áçª„ÄÇ 
 
Ë®àÁï´ÊàêÊûúËá™Ë©ï 
 
 Êú¨Ë®àÁï´ÔºÇËá™ÂãïËæ®ÔßºÂÆâÂÖ®Á≥ªÁµ±‰πãÈñãÁôºÁ†î
Á©∂,ÔºÇÂü∑Ô®àÂÆåÁï¢‰πãÂæåÁç≤Ëá¥Ô¶∫‰ª•‰∏ãÂπæÈ†Ö‰πãÈáçË¶Å
ÊàêÊûú„ÄÇ(1)ÂÆåÊàêÂÖ•‰æµÂÅµÊ∏¨ÁöÑÂàùÊ≠•Ê®°ÁµÑËàáÂÖ∂Âéü
Ôß§‰πãÊé¢Ë®éÔºå(2)Âª∫Ôß∑ËáâÈÉ®Ë≥áÔ¶æÂ∫´ÊãçÊîù‰πãÂ†¥
ÊôØÔºå‰æùÁÖßÊ≠§‰∏ÄÂ†¥ÊôØÂª∫Ôß∑Ëá™Â∑±ÂØ¶È©óÂÆ§ÁöÑËáâÈÉ®Ë≥á
Ô¶æÂ∫´Ôºå(3)ÊåáÂ∞éÂ≠∏ÁîüÂÆåÊàêÁõ∏ÈóúÁöÑÁï¢Ê•≠Ô•ÅÊñáÔºå
(4) ÂÆåÊàêËæ®ÔßºÔß§Ô•Å‰πãÁ†îÁ©∂ËàáÊé®Â∞é(5) ÂÆåÊàê
ÁâπÂæµÊì∑ÂèñÊºîÁÆóÊ≥ï‰πãÁ†îÁ©∂(6) ÊáâÁî®Á®ãÂºè‰πãÊí∞
ÂØ´ËàáÊï¥Âêà(7)ÊäïÁ®øÂà∞Âú®ÁæéÂúãÂ§èÂ®ÅÂ§∑ËàâÔ®àÁöÑ
ICIS-COMSAR 2006 ÂúãÈöõÊúÉË≠∞‰∏¶‰∏îÁôºË°®Á†î
Á©∂ÊàêÊûú„ÄÇ(8) ÊäïÁ®øÂà∞Âú®Ê°ÉÂúíÂ§ßÊ∫™ËàâÔ®àÁöÑÁ¨¨
19 Â±ÜÈõªËÖ¶Ë¶ñË¶∫„ÄÅÂúñÂ≠∏Êö®ÂΩ±ÂÉèËôïÔß§Á†îË®éÊúÉ
(CVGIP 2006) ‰∏¶‰∏îÁôºË°®Á†îÁ©∂ÊàêÊûú 
 Êú¨Ë®àÁï´Âü∑Ô®àÂÆåÁï¢ÂæåÂ∑≤ÈÅîÊàêË®àÁï´Êõ∏ÊâÄÔ¶ú
ËàâÁöÑÂêÑÈ†ÖÈ†êË®àÈÅîÊàêÁõÆÊ®ôÔºåÊâÄÊ†∏ÂÆö‰∏ãÔ§≠ÁöÑÂêÑÈ†Ö
Á∂ìË≤ªÔºåÈô§Ô¶∫Âá∫Â∏≠ÂúãÈöõÊúÉË≠∞‰πãÁ∂ìË≤ªÔºåÂõ†‰∏ªÊåÅ‰∫∫
Ô•´Âä†ÊúÉË≠∞ÊôÇÈñìËàáÂ≠∏Ê†°Â≠∏Ë°ìÂßîÂì°ÊúÉÊíûÊúüÔºåÂõ†Ê≠§
Ëá™Ë≤ªË®ªÂÜäÁôºË°®Ô•ÅÊñá‰∏¶Êú™Âá∫Â∏≠Ë©≤Á†îË®éÊúÉÂè™Êúâ
ÂàäÁôªÔ•ÅÊñáÔºåÊú¨È†ÖÂá∫Â∏≠ÂúãÈöõÊúÉË≠∞Ê†∏ÂÆöÁ∂ìË≤ªÊñ∞Âè∞
Âπ£‰∫îËê¨ÂÖÉÊï¥Ôºå‰æùÁÖßÁ®ãÂ∫èÁπ≥ÂõûÂúãÁßëÊúÉÔºåÂÖ∂È§òÊ¨æ
È†ÖÂ∑≤Á∂ì‰æùÁ®ãÂ∫èÂÖ®ÈÉ®ÊîØÁî®ËàáÁµêÂ†±ÂÆåÁï¢„ÄÇ 
 ÂæåÁ∫åÁöÑÁ†îÁ©∂‰∏ªÈ°åÂ∞á‰ª•Êú¨Ë®àÁï´‰πãÁ†îÁôºÊàê
Êûú ÁÇ∫ Âü∫ Á§é Áπº Á∫å Êúù ‰∏ã Ô¶é Ô®Å Ë®à Áï´ NSC 
95-2221-E-014-015ÔºÇÊáâÁî®ÊñºÁõ£ÊéßÁ≥ªÁµ±‰πãÁâπ
ÂæµÊì∑ÂèñËàáËæ®ÔßºÊºîÁÆóÊ≥ï‰πãÈñãÁôºÔºÇÁöÑË®àÁï´ÁõÆÊ®ô
‰∏äÁπºÁ∫åÊîπÈÄ≤„ÄÇ 
 
Ô•´ËÄÉÊñáÁçª 
 
[1]Rahul Sukthankar, ‚ÄúArgus: The Digital 
Doorman,‚Äù IEEE Intelligent Systems, 
March/April 2001, pp. 14-19. 
[2] Anil K. Jain, Arun Ross and Salil 
Prabhakar,‚Äù An Introduction to Biometric 
Recognition‚Äù, IEEE transactions on Circuits 
and Systems for Video Technology, vol. 14, no. 
1, January 2004, pp. 4-20. 
[3] Shu-Sheng Hao and Meng-Syuan Ye, 
‚ÄúFacial Features Detection on Uneven 
Illumination Images,‚Äù has been submitted to 
2005 IEEE-EURASIP Workshop on Nonlinear 
Signal and Image Processing, May 18-20, 
2005, Sapporo, Japan 
[4]R. F. Hwu, Ôºå M. S. Ye Ôºå S. S. 
Hao, ‚ÄùAutomatic Facial Feature Detection 
on Security System‚Äù Ôºå National Defense 
Conference (ND-14)ÔºåNov 24-25, 2005, Acer 
Aspire Park, Lung-Tang, TaoYuan, Taiwan 
[5]J. C. Goswami and A. K. Chan, 
Fundamentals of Wavelets,Theory, Algorithms, 
and Applications, John-Wiley & Sons, Inc., 
1999. 
[6]J. F. Yang S. S. Hao and P. C. Chung,‚Äù 
Color Object segmentation using Fuzzy 
C-Means with Eigen-subspace Projections‚Äù, 
vol. 82, pp.461-472, Signal Processing, 2002. 
[7] M. K. Hu,‚ÄùVisual ‚ÄúPattern Recognition 
by Moment Invariants,‚Äù IRE Transactions 
on Information Theory, pp.179-187,1962. 
[8]Shu-Sheng Hao,‚ÄùImage Features 
Extraction for Multimedia Database 
Content Description,‚Äù Proceedings of the 5th 
IEEE/ACIS International Conference on 
Computer and Information Science 
(ICIS-COMSAR‚Äô06), Honolulu, Hawaii 10-12 
July 2006 pp.327 ‚Äì 332. 
[9]Rong-Fuh Hwu and Shu-Sheng Hao,‚ÄùThe 
Performance Evaluation of Various 
Classifiers with PCA and 2DPCA in Face 
Recognition,‚Äù 19th Computer Vision, 
Graphics and Image Processing (CVGIP 
2006), TaShim TaoYuan, 13-15 August 2006, 
Session D3-5, pp-562-565. 
DataBase
Images
Query
Image Image
Normalization
Principle
Component
Transformation
Wavelet
Decomposition
Moment
Invariants
wp
wv
wm
6
Search
Result
condition. In this paper, we use previous 
developed algorithm to locate the face region and 
refine the search. Most standard compresses image 
such as JEPG can be used to simulate in our 
proposed algorithms. Without influencing by the 
uneven lighting or occultation, the proposed 
algorithm can effectively extract the distinguishing 
image features. First, we will describe the system 
function block. Three feature extraction methods: 
Moment Invariants (MI), Principle Component 
Transformation (PCA) and Wavelet 
Decomposition (WD) will be described 
accordingly. Next, we propose a simple weighting 
method to combine the different coefficients from 
three algorithms. Following, we will refine our 
search by focusing on the facial region to obtain 
better results. Finally, we will show the simulation 
results and make a conclusion. 
2. System Function Block Diagram 
IQ
ID
Query
Image 
Features
Database
Image 
Features
(Bicubic Interpolation)
x y
System function block diagram is shown in 
Figure 1. The query image IQ can be any standard 
compressed image format such as JPEG, TIFF, 
BMP and GIF etc. The input query image can be 
arbitrary size. We use a normalization procedure to 
resize IQ into a fixed size image. 
Figure 1. Function Block Diagram 
We propose three image feature extraction 
methods to extract the feature coefficients from 
the query image. Three proposed algorithms are (1) 
Moment Invariants (MI) (2) Principle Component 
Analysis (PCA), and (3) Wavelet Decomposition
(WD). After the related features have been 
extracted, we will multiply different weights to 
these feature coefficients to obtain a judge factor. 
The judge factor taken as the query index is 
inputted to the database for comparison. A 
threshold is set according to all the judge factors. 
Image with judge factor below the query threshold 
are extracted. 
3. Moment Invariants  
How to efficiently generate and correctly match 
the features between the search item and database 
has gain lots of interests by many researchers. 
There are different features such as (1) curve 
features (2) region features, and (3) transform 
domain features can be used to identify the pattern 
[5]. They all have different advantages and 
limitations. In this paper we first choose the 
moment invariants methods based on region 
features proposed by Hu [6] to generate the 
features and search the closest object in the 
database. There are totally seven moments need to 
generate. The two dimensional moment of order 
p+q of a (N x M) discretized image I(x,y) is 
defined as follows: 
 
1 1
0 0
,
M N
p q
pq
y x
m x y I
 
  
 ¬¶¬¶ (1) 
With 0p q  , we can define the zeroth order 
moment which represents the mass as follows: 
 
1 1
00
0 0
,
M N
y x
m I
 
  
 ¬¶¬¶ x y (2) 
The center of the mass  ,x y  can be obtained 
from two first order moments m10 and m01. The 
coordinates of the center of mass are shown as 
follows: 
10 01
00 00
,m mx y
m m
   (3) 
If the object is coincident with the origin of the 
field of view 0x  and 0y   then the 
moments are referred to as central moments 
designed as pqP . The central moments of order 
three  3p q   which are invariant to rotation, 
translation and scale are given by 
M1 20 0P 2P 
 2 24M
(4a) 
2 20 02 11P P P  
   2 2033 3M P P P P   
   2 24 30 12 21 03M P P P P   
 (4b) 
3 30 12 21  (4c) 
 (4d) 
Proceedings of the 5th IEEE/ACIS International Conference on Computer and Information Science and 1st IEEE/ACIS  
International Workshop on Component-Based Software Engineering, Software Architecture and Reuse (ICIS-COMSAR‚Äô06) 
0-7695-2613-6/06 $20.00 ¬© 2006 IEEE 
32 2
1
ÀÜ ÀÜD Q D QP i
i
iF E v
 
¬™ ¬∫   ¬´ ¬ª¬¨ ¬º ¬¶x x v

 (11) 
The vector composes the three 
eigenvectors of database image 
and
 1 2 3, ,D D D Di v v v v
 1 2 3, ,Q Q QQi v v v v  composes the three 
eigenvectors of query image. The factor 
PF represents the PCA comparison result.  
5. Wavelet Decomposition 
Wavelet transform is a multiresolution 
analysis method in transform domain [9]. The 
original signal feeds through the lowpass and 
highpass filter and downsamples to obtain the 
approximate and detail coefficients. Different level 
of details can be repeated with the same way 
through the highpass route. The decomposition 
process is shown in Figure 2. In this figure, Fi and 
Gi, represents the outputs of lowpass 
and highpass filter respectively. After 
downsampling with F
1i  "N
i and Gi, we will obtain the 
detail and approximation coefficients at level i. We 
can divide the original signal into N details 
1 2 and one approximation 
signals .
, , , ND D D"
NA
p2
p2 p2
p2
S
D1
A1 D2
A2
High Pass
Filter
Low Pass
Filter
High Pass
Filter
Low Pass
Filter
F1
G1 F2
G2
Approximation
Coefficients
Detail
Coefficients
Signal
S
D1A1
A2
AN
D2
DN
Approximation
Coefficients
Detail
Coefficients
Figure 2. Wavelet Decomposition
In our simulation, we take the Daubechies 
wavelet for the scaling function ,D MI [9]. For
m=2 case, the Daubechies wavelet can be 
described as in (12)-(14). 
      20 1 ,
2
m jz
G z S z z e
Z
   (12) 
If , then  2m  
   1 2 3
1 3
S z z  
 
(13) 
 0
2 3
1 3 1 3
1 4 4
2 1 3 1 3
4 4
z
G z
z z
 

 
 
 
¬ß ¬∑
¬® ¬∏
¬®
¬® ¬∏¬® ¬∏¬© ¬π
¬∏  (14) 
Inspecting the simulation results, we find that 
the detail coefficients of the image can do a great 
help on querying the candidate images. We define 
the approximate coefficients as andQiA
D
iA for 
the query and database image. The different level 
of detail coefficients can be defined as 
andQkiD
D
kiD  where k is the decomposition detail 
level and i is the coefficient number. The 
approximation factor wA  and detail factor
can be defined as follows: 
F wDF
1
M
Q
wA i i
i
F
 
 ¬¶ A AD  (15) 
1
,   at level 
M
Q D
wD ki ki
i
F k
 
 ¬¶ D D  (16) 
where M is the coefficient number.  
6. Query Image Based on Feature 
Weightings 
The four feature coefficients are 
, , ,P wA wDF F F F' related to the MI, PCA and WD 
methods. First, we perform the coefficient 
normalization to restrict the coefficients in a small 
dynamic range. We take the query image 
coefficients , , ,Q Q Q Qp wA wDF F F F' as the denominators 
to normalize the coefficients , , ,D D D Dp wA wDF F F F'  of 
the database images. The process can be described 
as follows: 
, , ,
D DD D
wA wDP
P wA wDQ Q Q Q
P wA wD
F FF FF F F F
F F F
'
'
'
c c c c    
F
(17) 
Then, we multiply all the coefficients with 
different weights . The final 
image features can be represented as follows: 
, , ,m p vA vDw w w w
D
j m p P vA wA vDW w F w F w F w F' wDc c c    c (18) 
where DjW is the jth image judge factor. In order to 
compare the factor between the query image IQ
Proceedings of the 5th IEEE/ACIS International Conference on Computer and Information Science and 1st IEEE/ACIS  
International Workshop on Component-Based Software Engineering, Software Architecture and Reuse (ICIS-COMSAR‚Äô06) 
0-7695-2613-6/06 $20.00 ¬© 2006 IEEE 
The extracted facial regions are shown in Figure 8. 
The extracted images below the threshold are 
shown in Figure 9. It is shown that the images in 
Figure 8(1,2) are closest matched with the query 
image.  
Head-and-
Shoulder
RGB Images Color Model 
Transformation
Principal Component 
Analysis (PCA)
YUV Color 
Image
Select candidate 
pixels from  skin 
area randomly
Edge 
Detection
Noise and 
Signal Planes
Hough
Transform (HT)
Binary
Image
Morphological 
Image Processing 
Binary Image 
dilated
Define Search 
Region
Circle Center 
and Radius
Threshold on
YUV planes 
Skin Region 
EigenVectors
Formation
Candidate Facial Region
Figure 7. Facial region extraction block diagram 
(1) (2) (3) (4)
(5) (6) (7) (8)
(9) (12)(11)(10)
Query
Image
Figure 8. Extracted facial regions 
Image Number
Feature Judge Factor
Figure 9. The search results 
8. Conclusions 
We propose an algorithm composed of MI, PCA 
and WD to search the correlated images in 
database. The related feature coefficients are 
combined with different weights. We use the judge 
factor as an index to select the similar image. We 
can further refine the search results with the help 
of the extracted facial region. The facial region 
can be defined by our previous research 
algorithms. There are two critical settings in our 
simulation. One is threshold level and the other is 
weightings of the extraction coefficients. Different 
threshold level is related to how strictly the search 
results will be obtained. Different weightings can 
be used to emphasis on some particular extraction 
results. We are devising an automatic threshold 
and weights setting method now. Inspecting the 
final simulation results, we have proved the 
effectiveness of our proposed algorithms. 
References: 
[1] A. K. Jain, A. Ross and S. Prabhaker, ‚ÄùAn 
Introduction to Biometric Recognition‚Äù IEEE 
transactions on circuits and systems for video 
technology, vol. 14, no. 1, pp. 4-20, January 2004. 
[2] R. Sukthankar and R. Stockton,‚ÄùArgus: The 
Digital Doorman,‚Äù IEEE intelligent system, 
pp.14-19, March/April 2001. 
[3] S. S. Hao and M. S. Ye, ‚ÄúFacial Features 
Detection on Uneven Illumination Images‚Äù, 
International Workshop on Nonlinear Signal and 
Image Processing 2005 (NSIP 2005) 19PM2A-01, 
May18-20, 2005, Sapporo, Japan 
[4] R. F. Hwu,«¥M. S. Ye«¥S. S. Hao, ‚ÄùAutomatic 
Facial Feature Detection on Security System‚Äù«¥
National Defense Conference (ND-14)«¥Nov 24-25, 
2005, Acer Aspire Park, Lung-Tang, TaoYuan, 
Taiwan 
[5] B. M. Mehtre, M. S. Kankanhalli and W.F. Lee, 
‚ÄúShape Measures for Content Based Image 
Retrival: A Comparison,‚Äù Information Processing 
and Management, Vol. 33, No. 3, pp. 319-337, 
1997 
[6] M. K. Hu,‚ÄùVisual Pattern Recognition by 
Moment Invariants,‚Äù IRE Transactions on 
Information Theory, pp.179-187,1962 
[7] S. Theodoridis and K. Koutroumbas, Pattern 
Recognition, Academic Press, 2003 
[8] J. F. Yang S. S. Hao and P. C. Chung,‚Äù Color 
Object segmentation using Fuzzy C-Means with 
Eigen-subspace Projections‚Äù, vol. 82, pp.461-472, 
Signal Processing, 2002 
[9] J. C. Goswami and A. K. Chan, Fundamentals 
of Wavelets,Theory, Algorithms, and Applications,
John-Wiley & Sons, Inc., 1999. 
Proceedings of the 5th IEEE/ACIS International Conference on Computer and Information Science and 1st IEEE/ACIS  
International Workshop on Component-Based Software Engineering, Software Architecture and Reuse (ICIS-COMSAR‚Äô06) 
0-7695-2613-6/06 $20.00 ¬© 2006 IEEE 
data, The equation for singular value decomposition of 
X is as follows:  
 
X=USVT                                                                                        (1) 
where U is an n x m matrix, S is an m x m diagonal 
matrix, and VT is also an m x m matrix. The columns of 
U are called the left singular vectors which are 
eigenvectors for face recognition. The vectors set {uk}, 
form an orthonormal basis for assay expression profiles. 
The rows of VT contain the elements of the right 
singular vectors. The vectors set {vk} form an 
orthonormal basis for the gene transcriptional responses. 
The matrix S has only nonzero elements called the 
singular values appeared on the diagonal, S = 
diag(s1,...,sn). Furthermore, sk > 0 for 1 ‚â§ k ‚â§ r, and sk = 
0 for (r+1) ‚â§ k ‚â§ n. The ordering of the singular vectors 
is determined by high-to-low sorting of singular values. 
The highest singular values are in the upper left of the S 
matrix. For a square, symmetric matrix X, singular 
value decomposition is equivalent to diagonalization or 
eigenvalue solution problem. With matrix U, we obtain 
new projected feature vector Y=UTX, which is an m x m 
dimension matrix. The form of Y=UTX is described as 
follows: 
 
‚é•‚é•
‚é•
‚é¶
‚é§
‚é¢‚é¢
‚é¢
‚é£
‚é°
‚é•‚é•
‚é•
‚é¶
‚é§
‚é¢‚é¢
‚é¢
‚é£
‚é°
‚é•‚é•
‚é•
‚é¶
‚é§
‚é¢‚é¢
‚é¢
‚é£
‚é°
‚Ä¢
‚é•‚é•
‚é•
‚é¶
‚é§
‚é¢‚é¢
‚é¢
‚é£
‚é°
=
‚é•‚é•
‚é•
‚é¶
‚é§
‚é¢‚é¢
‚é¢
‚é£
‚é°
‚é•‚é•
‚é•
‚é¶
‚é§
‚é¢‚é¢
‚é¢
‚é£
‚é°
‚é•‚é•
‚é•
‚é¶
‚é§
‚é¢‚é¢
‚é¢
‚é£
‚é°
nm
m
n
T
nmn
m
mm
m
m x
x
x
x
uu
uu
y
y
y
y
,
1,
,1
1,1
,,1
1,1,1
,
1,
,1
1,1
#"#
"
#%#
"
#"#   (2)               
 
3. METHOD OF 2DPCA 
 
If we obtain an m by n random image matrix A and let 
X nxdR‚àà   be a matrix with orthonormal columns, where 
n‚âßd. Projecting A onto X yields an m by d matrix Y = 
AX. In 2DPCA, the total scatter of the projected 
samples was used to determine a good projection matrix 
X to obtain optimal matrix Xopt. We adopt the following 
criterion: 
 
J(X) = trace{E[(Y-EY)(Y-EY)T]} 
= trace{E[(AX-E(AX))(AX-E(AX))T]} 
= trace{XTE[(A-EA)T(A-EA)] X}               (3) 
 
Defining the image covariance matrix G= E[(A-
EA)T(A-EA)], which is an n by n nonnegative definite 
matrix. Suppose that there are M training face images, 
denoted by m by n matrices Ak (k=1,2,‚Ä¶,M), and 
express the average image as  
‚àë=
k
kM
AA 1                                                         (4) 
Then G can be calculated by 
‚àë
=
‚àí‚àí= M
k
kkM 1
T )()(1 AAAAG                              (5) 
It has been proven that the optimal value for the 
projection matrix Xopt is composed by the orthonormal 
eigenvectors X1,‚Ä¶,Xd of G corresponding to the d 
largest eigenvalues, i.e. Xopt =[ X1,‚Ä¶,Xd]. 
 
Fig.1. Diagram of 2DPCA 
 
Because the size of G is only n by n, it is very efficient 
to compute its eigenvectors.  
The process of 2DPCA is shown in Fig 1, every 
image covariance matrix Gk (k=1,‚Ä¶,M) represents 
individual element of (5). The sum of all Gk produced 
the global image covariance matrix G to form the 
optimal eigenvectors Xopt. 
The optimal projection vectors of 2DPCA, 
X1,‚Ä¶,Xd  are used for feature extraction. For a given 
image represented by A. Let us define  
 
Yk=AXk, k=1,2,‚Ä¶,d.                                            (6) 
 
Then, we obtain a family of projected feature vectors, 
Y1,‚Ä¶,Yd, which are called the principal component 
(vectors) of the sample image A. It should be noted that 
each principal component of 2DPCA is a vector, 
whereas the principal component of PCA is a scalar. 
The obtained principal component vectors are used to 
form an n x d matrix B=[Y1,‚Ä¶,Yd], which is called the 
feature matrix or feature image of the image A. 
 
4. METRICS OF CLASSIFICATION 
 
In this paper, we use five classification metrics [6] to 
evaluate the performance of face recognition for PCA 
and 2DPCA. The performances of face recognition can 
be evaluated by recognition rate and speed. These five 
recognition metrics have two forms. One form is 
distance which measures the separate between feature 
vectors and another form is a similarity measure. We 
will describe five metrics in the following sections. 
 
4.1. City block 
 
The city block is a distance measure, also called L1 
norm. It sums up the absolute difference between 
feature vectors. The L1 norm of an image A and image 
B is defined as follows: 
 
‚àë
=
‚àí= N iiL
1i
1 )( BABA,                                         (7) 
G1 
GM 
Xopt G z  z  
z  
z  
z  
z  
563
