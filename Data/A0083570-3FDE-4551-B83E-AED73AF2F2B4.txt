ÁîüÁâ©Â∫èÔ¶úÁâπÂæµÂêëÔ•æ‰πãË®≠Ë®à 
Design of feature vector for biological sequence 
Ë®àÁï´‰∏ªÊåÅ‰∫∫ÔºöÈÉ≠ÁÖåÊîø 
ÂÖº‰ªªÁ†îÁ©∂Âä©Ôß§ÔºöÔß°ÂÆóÔßÑ„ÄÅÊõæÂÆáÊ≠£„ÄÅÂë®ÂüπÂÖÉ„ÄÅË≥¥ÂºòÂø†„ÄÅËî°‰Ω©Êàê 
ÂúãÔß∑ÂòâÁæ©Â§ßÂ≠∏Ë≥áË®äÂ∑•Á®ãÂ≠∏Á≥ª 
ÊëòË¶Å 
ÂÖàÂâçÁ†îÁ©∂ÊàêÊûúÔºö 
Âú®ËøëÂçÅÔ¶éÔ§≠ÔºåÂ∞çÊñºÁîüÁâ©Â∫èÔ¶úÁöÑÁõ∏‰ººÊêúÂ∞ãÂèóÂà∞Áõ∏Áï∂Â§ßÁöÑÊ≥®ÊÑèÔºåÂ∞§ÂÖ∂ÊòØ‰∫∫ÔßêÂü∫Âõ†È´îË®àÁï´ÂÆåÊàê‰πã
ÂæåÔºåÁî±ÊñºÂ∫èÔ¶úË≥áÔ¶æÂ∫´ÁöÑÂø´ÈÄüÊàêÈï∑ÔºåÂ¶Ç‰ΩïÂÅöÂà∞Âø´ÈÄüÁöÑÁõ∏‰ººÊêúÂ∞ãÔ••ÊàêÁÇ∫Êó•Ô®óÈáçË¶ÅÁöÑ‰∏ÄÂÄãË≠∞È°å„ÄÇ
Èô§Ô¶∫Áõ¥Êé•Â∞çÂéüÂßãÂ≠êÂ∫èÔ¶úÂª∫Ôß∑Ô•™ÂºïÁöÑÊñπÊ≥ïÂ§ñÔºåÂÖàÂ∞áÂ≠êÂ∫èÔ¶úËΩâÊèõÊàêÔ•©Â≠óÂêëÔ•æÔºåÂú®ÈÄôÊàëÂÄëÁ®±‰πãÁÇ∫
Â∫èÔ¶úÊèèËø∞Â≠êÔºåÁÑ∂ÂæåÂÜçÂ∞á‰πãÁΩÆÂÖ•Â§öÁ∂≠Ô•™ÂºïÁµêÊßã‰ºº‰πé‰πüÊòØ‰∏ÄÂÄãÂèØÔ®àÁöÑÊñπÊ≥ï„ÄÇÁï∂ÊàëÂÄëË¶ÅÈÄ≤Ô®àÁõ∏‰ºº
Â∫èÔ¶úÁöÑÊêúÂ∞ãÊôÇÔºåÊàëÂÄëÂ∞áÂ∞çÊñºÊü•Ë©¢Â∫èÔ¶úÂÖ∑ÊúâËºÉÁõ∏‰ººÁöÑÂ∫èÔ¶úÊèèËø∞Â≠êÁöÑÂéüÂßãÂ∫èÔ¶úÈÅéÔ¶ÑÂá∫Ô§≠ÔºåÁÑ∂Âæå
ÂÜçÈÄ≤Ô®àÔ§ÅÔ®ùÁ¢∫ÁöÑÊéíÊØîÂãï‰ΩúÔºåËóâÁî±Â∞çÂéüÂßãÂ∫èÔ¶úËΩâÊèõÊàêÔ•©Â≠óÂêëÔ•æÁöÑÁ∏ùÂØÜÂÆöÁæ©ÔºåÊàëÂÄëÈ†êÊúüËÉΩÈÅîÂà∞
Áõ∏Â∞çÊñºÊü•Ë©¢Â∫èÔ¶úÂÖ∑ÊúâËºÉÁõ∏‰ººÁöÑÂ∫èÔ¶úÊèèËø∞Â≠êÁöÑÂ∫èÔ¶ú‰πüÊúÉÂÖ∑ÊúâËºÉÈ´òÁöÑÂ∫èÔ¶úÁõ∏‰ººÔ®Å„ÄÇ 
ÊàëÂÄëÂÖàÂâçÊèêÂá∫ÊâÄÊèêÂá∫ÁöÑÂ∫èÔ¶úËΩâÊèõÊñπÊ≥ïÔºåÂÆÉÊòØ‰ΩøÁî®ÂéüÂßãÂ∫èÔ¶úÁöÑÂ§öÈáçÁâπÂæµÔºåÂåÖÂê´Ë®òÔ•©ÔºåÁõ∏
Â∞ç‰ΩçÁΩÆÂàÜÊï£Ô®ÅÂíåÁµïÂ∞ç‰ΩçÁΩÆÂàÜÊï£Ô®ÅÔºåÔ§≠ÊèèËø∞ÂéüÂßãÂ∫èÔ¶úÔºåÁõ∏Â∞çÊñº q-gram ËΩâÊèõÊñπÊ≥ïÊàëÂÄëÂèØ‰ª•ÈÅøÂÖç
ÂêëÔ•æÂ§ßÂ∞èÂëàÊåáÔ•©ÂûãÊàêÈï∑ÁöÑÂïèÈ°å„ÄÇÂè¶Â§ñÊàëÂÄë‰πüÊèêÂá∫Ô¶∫‰∏ÄÂÄãÂàÜÊÆµËΩâÊèõÊ≥ïÔºåÂÆÉÊòØÂÖàÂ∞áÂéüÂßãÂ∫èÔ¶úÈÅû
Ëø¥Âú∞ÂàÜÂâ≤ÊàêÁ≠âÈï∑ÁöÑÂ≠êÂ∫èÔ¶úÔºåÂú®Â∞áÂÆÉÂÄëÂêÑÂà•ËΩâÊèõÁÇ∫Ô•©Â≠óÂêëÔ•æ‰πãÂæåÁõ¥Êé•Ô¶öÁµêËµ∑Ô§≠„ÄÇ 
Êú¨Ë®àÁï´Á†îÁ©∂ÊàêÊûúÔºö 
Êú¨Ë®àÁï´ÂÖßÂÆπÂàÜÔ•∏ÈÉ®ÂàÜÔºö 
1. Ë™øÈÅ©ÂºèÔºöÊàëÂÄëÁâπÂæµÂêëÔ•æ‰∏≠Êúâ‰∏âÁµÑÁâπÂæµÔºåÁÇ∫Ô¶∫‰ΩøÔ•∏Â∫èÔ¶úÁâπÂæµÂêëÔ•æÈñì‰πãÁõ∏‰ººÔ®ÅÔ§ÅËÉΩ
Ô®ùÊ∫ñÁöÑÂèçÊáâÂá∫ÂéüÂßãÂ∫èÔ¶úÈñì‰πãÁõ∏‰ººÔ®ÅÔºåÂú®Ë®àÁÆóÁõ∏‰ººÔ®ÅÊôÇÔºåÊàëÂÄë‰ª• DNA Â∫èÔ¶ú‰∏≠ÂêÑ
ÈπºÂü∫ÁöÑÂá∫ÁèæÈ†ªÔ•°ÔºåË≥¶‰∫àÁâπÂæµÂêëÔ•æÂêÑÁµÑÁâπÂæµÔ•ßÂêåÁöÑÊ¨äÈáç„ÄÇ 
2. Âü∫Âõ†ÊºîÁÆóÊ≥ï‰πãÊáâÁî®ÔºöÔßùÁî®Âü∫Âõ†ÊºîÁÆóÊ≥ïË®ìÔ¶ñÂêÑÁµÑÁâπÂæµ‰πãÊ¨äÈáçÔºå‰ΩøÊ¨äÈáç‰πãÂàÜÈÖçÊúÄ‰Ω≥
ÂåñÔºåÂæóÂà∞ÊúÄ‰Ω≥‰πãÁØ©ÈÅ∏ÊïàÊûú„ÄÇ 
 
Abstract 
Previous study result: 
Study on biological sequence database similarity searching has received substantial attention 
in the past decade, especially after human genome project completed. Because the sizes of the 
databases are getting larger and larger, fast similarity search is becoming an important issue. In 
addition to indexing on subsequences, transforming sequences into numerical vectors, called 
sequence descriptors, for storing in a multidimensional data structure is a promising method for 
indexing bio-sequences. 
Previously, we presented an effective sequence transformation method, called SD (Sequence 
Descriptor), which uses multiple features of a sequence including Count, RPD (Relative Position 
Dispersion) and APD (Absolute Position Dispersion) to represent the original sequence data. In 
  
ADAPTIVE WEIGHTING DISTANCE FOR FEATURE VECTORS OF 
BIOLOGICAL SEQUENCES 
HUANG-CHENG KUO1, PEI-YUAN JOU 1, JEN-PEN HUANG 2 
1 Department of Computer Science and Information Engineering, National Chiayi University, Chiayi City 600, Taiwan 
2 Department of Information Management, Southern Taiwan University, Tainan 710, Taiwan 
E-MAIL: {hckuo, s0940317}@mail.ncyu.edu.tw, jehuang@mail.stut.edu.tw 
Abstract: 
Similarity search in biology sequences has attention in the 
recent studies. Sequence alignment is the essential task for 
similar sequence search in bioinformatics. The biological 
sequence databases have getting larger in past decade, finding 
sequences similar to the query sequence is a time consuming 
task. By transforming sequences into numeric feature vectors, 
we can quickly filter out sequences whose feature vectors are 
distant to the feature vector of the query sequence.  
We proposed an adaptive weighting distance which is 
based on feature vector that contains three groups of features: 
Count, Extended Relative Position Dispersion (XRPD), and 
Extended Absolute Position Dispersion (XAPD) of a DNA 
sequence [5]. Each group has four dimensions for A, C, T, G. 
When computing distance between two feature vectors, 
Euclidean distance and L1 distance are commonly used.  
In this paper, we use weighted L1 distance for computing 
the distance between two feature vectors. We derive weights 
for the four nucleotides from the Count group, and apply the 
weights to both XRPD and XAPD. In other words, if a certain 
kind of nucleotide appears much frequent than the other kinds 
of nucleotides, the weight for the kind of nucleotide should 
also be large in XRPD and XAPD groups. Experiments show 
that such distance of feature vectors helps reflect the distance 
between sequences. 
Keywords: 
DNA Sequence, Weight Assignment, Feature Vector. 
1. Introduction 
In biological sequence databases, searching for 
sequences having high alignment scores with the query 
sequence is an essential task. Similar bio-sequences of 
different species usually imply the relationship of function 
and evolution etc. Moreover, there is implicit structural 
information for protein data. For instance, sequence 
similarity analysis has assisted the detection of certain 
strains of Escherichia coli (E. coli) bacteria, often 
responsible for infant diarrhea and gastroenteritis [16]. 
Study on biological sequence database similarity 
searching has received substantial attention in the past 
decade, especially after the sequencing of the human 
genome. As a result, with larger and larger increases in 
database sizes, fast similarity search is becoming an 
important issue. 
Dynamic programming (DP) alignment algorithm, 
such as Smith-Waterman Method [14], was adopted to 
solve the problem of sequence similarity search. Although 
the traditional DP alignment algorithm guarantees the 
optimal alignment result, it is impractical because it 
requires O(mn) (m and n are the lengths of the two input 
sequences) in both time and space. Therefore, several 
heuristics have been developed, such as BLAST [2], [3], 
Pattern Hunter [6], [8], and FASTA [7], [11], [12], etc.  
The common main idea of these heuristic methods is 
that similar sequences must have similar subsequences. 
These methods not only provide good accuracy, but also 
execute efficiently. 
Particularly, BLAST is the most popular method 
because of its excellent accuracy and speed. However, a 
study of the performance of BLAST shows that BLAST is 
becoming 64% slower each year because of the 
exponentially growth of biological databases [4]. 
As the biological databases become larger and larger, 
even the heuristics are no longer feasible. Therefore, a new 
method of filtration has been developed. Researchers 
transform original sequence data into numerical vector 
space [13], and filter out the distant potential dataset via 
distance calculations. 
After the filtration phase, DP or another heuristic 
algorithm is used to align the small number of selected 
sequences with the query sequence. 
Transforming bio-sequence data into a frequency 
domain is a general method for designing feature vector, 
also denoted as sequence descriptor. Some variants of it are 
still constructed on frequency domains. Q-gram frequency 
transformation [10] is the most general one. For instance, a 
DNA sequence S = ‚ÄúACGGTCAGAA‚Äù can be transformed 
  
For example, the DNA sequence S is 
‚ÄúACGGTCAGAA‚Äù and the Count(S) is [4/n, 2/n, 1/n, 3/n] 
= [0.4, 0.2, 0.1, 0.3]. 
XRPD indicates the degree of relative dispersion of 
symbol Œ±‡≠ß. Below illustrates the definition: 
Definition 2 (Extended Relative Position Dispersion, 
XRPD):  
The extended relative position dispersion of S, called 
XRPD(S) is defined as: XRPD(S) = ‡µ£‡±®‡∞≠R ,
‡±®‡∞Æ
R , ‚Ä¶ ,
‡±®‡±´
R ‡µß, where R 
is the sum of r. The ›à ‡≠ß,‡≠® is a difference value between the 
j-th position and the ·à∫›Ü ‡µÖ ﬂú·àª -th position of symbol Œ± 
(ﬂú ﬂ≥ ‘∫‡¨æ·àª. The quantity ‡£¢‡≠ß which is the volume of those 
difference positions equal to |Œ±‡≠ß| ‡µÜ ﬂú. The value of r‡≠ß is 0 
when ‡£¢‡≠ß ‡µë 0; the value of r‡≠ß is 
‚àë ·âÜ ‡∞≠‡≥ó‡±ü,‡±†
·âá‡£¢‡∞≠‡±†‡∞∏‡∞≠
‡£¢‡∞≠
 when ‡£¢‡≠ß > 0. 
In the above DNA sequence S is ‚ÄúACGGTCAGGAA‚Äù, 
for instance, the XRPD(S) is [ ‡¨Ω
‡∞Æ‡¨æ‡¨∏‡∞Æ
·à∫‡¨∏‡¨ø‡¨∂·àª‡µàR
, 0, 0, ‡¨π
‡∞Æ‡¨æ‡¨π‡∞Æ
·à∫‡¨∏‡¨ø‡¨∂·àª‡µàR
] = 
[0.6599, 0, 0, 0.3401] when ﬂú is 2. 
Definition 3 (Extended Absolute Position Dispersion, 
XAPD): 
Extends Absolute Position Dispersion of S, denoted 
XAPD(S) is defined as: XAPD·à∫S·àª ‡µå ‡µ£‡±™‡∞≠T ,
‡±™‡∞Æ
T , ‚Ä¶ ,
‡±™‡±´
T ‡µß, where T 
is the sum of t. The symbols ›å‡≠ß denote the positions of Œ±‡≠ß 
in order. A group ‘ã‡≠ß=·àºF‡≠ß,‡¨µ, ‘ã‡≠ß,‡¨∂, ‚Ä¶ , ‘ã‡≠ß,‡≠©‡±ü·àΩ, that be satisfied of 
four conditions: i) ›á‡Øú ◊ê ‘∫‡¨æ, k‡≠ß ‡µë c‡≠ß, and ‡µõ‘ã‡≠ß,‡≠∑ ‡µç ·àº◊é·àΩ ‡∏´ y ‡µë
k‡≠ß·àΩ; ii)·àº·à∫›å‡≠ß,‡≠∂ ◊ê ‘ã‡≠ß,‡≠´·àª ◊™ ·à∫›å‡≠ß,‡≠∂ ◊ë ‘ã‡≠ß,‡≠¨·àª | x ‡µë c‡≠ß, y ‡µë k, and m ‡µç
n·àΩ; iii) ·àº›åŒ±‡±ü,‡≠• ‡µè ›åŒ±‡±ü,‡≠¶ | ›åŒ±‡±ü,‡≠• ◊ê GŒ±‡±ü,‡≠∑ and ›åŒ±‡±ü,‡≠¶ ◊ê GŒ±‡±ü,‡≠∑‡¨æ‡¨µ·àΩ; and 
iv) ‚àë ‡∏´›åŒ±‡±ü,‡≠∂ ‡µÜ ›åŒ±‡±ü,‡≠∂‡¨æ‡¨µ ‡µÜ 1‡∏´‡≠¥◊êGŒ±‡±ü,‡±Ø ‡µë Œº  where Œº ◊ê ‘≥ . The 
value of t‡≠ß is ‚àë ·âÄ‚àë ›å‡≠ß,‡≠¥‡≠¥‡Æ´‘ã‡±ü,‡±ò ·âÅ
‡¨∂
/c‡≠ß
‡≠©
‡≠†‡≠Ä‡¨µ . 
The above DNA sequence S is ‚ÄúACGGTCAGGAA‚Äù. 
For example, the four symbol group are ‘ãA ‡µå ·àº‘ãA,‡¨µ, ‘ãA,‡¨µ·àΩ, 
‘ãC ‡µå ·àº‘ãC,‡¨µ, ‘ãC,‡¨∂·àΩ , ‘ãT ‡µå ·àº‘ãT,‡¨µ·àΩ , and ‘ãG ‡µå ·àº‘ãG,‡¨µ, ‘ãG,‡¨∂·àΩ , 
where are ‘ãA,‡¨µ ‡µå ·àº1·àΩ  , ‘ãA,‡¨∂ ‡µå ·àº7, 10, 11·àΩ , ‘ãC,‡¨µ ‡µå ·àº2·àΩ , 
‘ãC,‡¨∂ ‡µå ·àº6·àΩ , ‘ãT,‡¨µ ‡µå ·àº5·àΩ , ‘ãG,‡¨µ ‡µå ·àº3, 4·àΩ , and ‘ãG,‡¨∂ ‡µå ·àº8, 9·àΩ 
when Œº ‡µå 2. The XAPD(S) = [‡¨µ
‡∞Æ‡¨æ·à∫‡¨ª‡¨æ‡¨µ‡¨¥‡¨æ‡¨µ‡¨µ·àª‡∞Æ
‡¨∏‡µàT
, ‡¨∂
‡∞Æ‡¨æ‡¨∫‡∞Æ
‡¨∂‡µàT
, ‡¨π
‡∞Æ
‡¨µ‡µàT
,
·à∫‡¨∑‡¨æ‡¨∏·àª‡∞Æ‡¨æ·à∫‡¨º‡¨æ‡¨Ω·àª‡∞Æ
‡¨∏‡µàT
] = [0.6608, 0.0337, 0.0210, 0.2845]. 
The feature vector of above DNA sequence S in XSD 
is [0.4, 0.2, 0.1, 0.3, 0.6599, 0, 0, 0.3401, 0.6608, 0.0337, 
0.0210, 0.2845]. 
4. Adaptive Weighting 
Let a sequence be a skewed sequence if the number of 
residues of a certain symbol in the sequence is much more 
than the numbers of other symbols. When we align two 
sequences, there are two possibilities to make them similar. 
First, two skewed sequences are very likely to have a very 
high DP score, if their dominant residues are same. If their 
dominant residues are different, they will have a very low 
DP score. Second, if a certain symbol is dominant in Count, 
the symbol will be more representative in XPRD and 
XAPD in terms of computing similarity between two 
sequences. 
Therefore, we design an adaptive weight mechanism 
to weight the distance between two feature vectors in the 
light of these two possibilities. For assigning weights to the 
symbols of Count, we could adapt the entropy to increase 
the weight of partial group of XSD. Entropy could measure 
disorder of a set of objects. The value of entropy be smaller, 
the objects is much more disorder; the objects is nearly the 
same on the contrary. Theoretically, the average value of 
two feature vectors is in the range between 0 and 2. 
Actually, we have found the value of entropy is in the range 
from 1.06 to 2. Therefore, according to the value of entropy, 
we could adaptive weighting on neither of three groups. 
First, we obtain the entropy from the Count group. For 
example, given Count(S) = [0.4, 0.2, 0.1, 0.3], the entropy 
value is 1.8464. We could get two entropy values between 
two sub-sequences. Then, the average entropy E‡≠ü‡≠¥‡≠• is a 
value which average two values of entropy. We also acquire 
the maximal entropy E‡≠´‡≠ü‡≠∂  that obtains from 
sub-sequences of well-known sequences. Last, According 
to formula (1) with the above entropies, the value of 
weighted AW we obtain. And then by formula (2) and (3), 
we gain the primary weighted W‡≠Æ with the weighted AW 
and the secondary also do. The master weighted is multiple 
on the distance between the Count group of two feature 
vectors. And the secondary weighted is multiple on the 
distance between the XRPD and XAPD groups of two 
feature vectors. 
AW ‡µå  cos·à∫œâ ‡µÖ ‡≤ò‡∞Æ ‡µà
E‡±ó‡±¨‡±ù
E‡±£‡±ó‡±Æ
·àª            (1) 
W‡≠Æ ‡µå AW ‡µà Œ≤ ‡µÖ Œ≥                  (2) 
W‡≠± ‡µå ·à∫1 ‡µÜ W‡≠Æ·àª/2                  (3) 
For example, the parameters are ﬂú ‡µå 1 , Œº ‡µå 2 , 
œâ ‡µå ‡µÜ0.4 , Œ≤ ‡µå 0.9 , and Œ≥ ‡µå 0.1 . The sequence SQ  is 
‚ÄúGTTAAAATGAACAACA‚Äù and the sequence SDB  is 
‚ÄúAGAGTGGGAGAAAATA‚Äù. The feature vector XSD of 
query is [0.5625, 0.1250, 0.1875, 0.1250, 0.3829, 0.0000, 
0.6171, 0.0000, 0.4857, 0.4308, 0.0351, 0.0485] and the 
feature vector XSD of database is [0.5000, 0.0000, 0.1250, 
0.3750, 0.7524, 0.0000, 0.0000, 0.2476, 0.7282, 0.0000, 
0.1291, 0.1427]. The value of entropy of sequence SQ is 
1.6697; the value of entropy of sequence SDB is 1.4056. 
The value of the average entropy E‡≠ü‡≠¥‡≠• is (1.6697 + 1.4056) 
/ 2 = 1.5377. The weighted AW is 0.3894; the master 
weighted is 0.4505, and the secondary weighted is 0.2748. 
  
Acknowledgements 
This work was partially supported by grant NSC 
95-2221-E-415-013- from National Science Council, 
Taiwan. 
References 
[1] S. Alireza Aghili, Divyakant Agrawal and Amr El 
Abbadi. ‚ÄúFiltration of string proximity search via 
transformation,‚Äù IEEE International Symposium on 
Bioinformatics and Bio-engineering, 2003, pp. 
149-157. 
[2] S. F. Altschul, W. Gish, W. Miller, E. W. Myers and 
D. J. Lipman. ‚ÄúBasic local alignment search tool,‚Äù J. 
Mol. Biol., 1990, pp. 403-410. 
[3] S. F. Altschul, T. L. Madden, A. A. Schaffer, J Zhang, 
Z Zhang, W Miller and D. J. Lip-man. ‚ÄúGapped 
BLAST and PSI-BLAST: a new generation of protein 
database search programs,‚Äù Nucleic Acids Res, 1997, 
pp. 3389-3402. 
[4] Michael Cameron, Hugh E. Williams and Adam 
Cannane, "Improved gapped alignment in BLAST," 
IEEE/ACM Transactions on Computational Biology 
and Bioinformatics (TCBB) archive Vol. 1, No. 3, 
2004, pp. 116-129. 
[5] Te-Wen Hsieh, Huang-Cheng Kuo and Jen-Peng 
Huang. ‚ÄúFiltering bio-sequence based on sequence 
descriptor,‚Äù Workshop on Data Mining for 
Biomedical Applications, 2006, pp. 14-23. 
[6] M. Li, B. Ma, D. Kisman and J. Tromp. ‚ÄúPattern 
hunter II: highly sensitive and fast homology search,‚Äù 
J. Bioinformatics and Computational Biology, Vol. 2, 
No. 3, 2004, pp. 417-439. 
[7] D. J. Lipman and W. R. Pearson. ‚ÄúRapid and 
sensitive protein similarity searches,‚Äù Science 227, 
1985, pp. 1435-1441. 
[8] B. Ma, J. Tromp and M. Li. ‚ÄúPattern hunter: faster 
and more sensitive homology search,‚Äù Bioinformatics, 
Vol. 18, No. 3, 2002, pp. 440-445. 
[9] S. B. Needleman and C. D. Wunsch. ‚ÄúA general 
method applicable to the search for similarities in the 
amino acid sequences of two proteins,‚Äù J. Mol. Biol. 
48, 1970, pp. 443-453. 
[10] O. Ozturk and H. Ferhatosmanoglu. ‚ÄúEffective 
indexing and filtering for similarity search in large 
biosequence databases,‚Äù IEEE International 
Symposium on Bioinformatics and Bioengineering, 
2003, pp. 359-366. 
[11] W. R. Pearson. ‚ÄúFlexible sequence similarity 
searching with the FASTA3 program package,‚Äù 
Methods Mol Biol. 132, 1999, pp. 185-219. 
[12] W. R. Pearson and D. J. Lipman. ‚ÄúImproved tools for 
biological sequence analysis,‚Äù Natl. Acad. Sci, 85, 
1988, pp. 2444-2448. 
[13] Kim R. Rasmussen, Jens Stoye, Eugene W. Myers. 
‚ÄúEfficient q-gram filters for finding all 
epsilon-matches over a given length,‚Äù International 
Conference on Research in Computational Molecular 
Biology, 2005, pp. 189-203. 
[14] T. F. Smith and M. S.Waterman. ‚ÄúIdentification of 
common molecular subsequences,‚Äù J. Mol. Biol. 147, 
1981, pp. 195-197. 
[15] J. Zhang and T. L. Madden. ‚ÄúPowerBLAST: a new 
network BLAST application for interactive or 
automated sequence analysis and annotation,‚Äù 
Genome Research, Vol. 7, No. 6, 1997, pp. 649-656. 
[16] About - E. coli, http://www.about-ecoli.com/. 
[17] National Center for Biotechnology Information 
(NCBI), http://www.ncbi.nlm.nih.gov/. 
and G are nearly equal. In order to improve accuracy, the
weight for Count group is decreased when A, C, T, G oc-
cur almost the same times, whereas the weight is increased
when one of two of A, C, T, and G occur much more then
the others. In the distance function of two feature vectors,
the weights for the three groups of features are adaptive to
the Count feature.
2. Related Work
In a typical sequence similarity search application, there
are two commonly used query types: (i) k-Nearest Neighbor
(k-NN), which asks for the most similar k sequences to the
query sequence; and the (ii) -range query, which asks for
sequences sufficiently similar to the query sequence.
Sequence alignments are classified into two categories:
i) global alignment: When the two aligned sequences are
known and have almost the same length, we can predict
that they are just a little different and use global align-
ment to compute the degree of similarity between them;
ii) local alignment: When we want to search the similar-
ity between an unknown sequence and a known sequence
database or between a short sequence segment and a very
long sequence, we can use local alignment to compute the
degree of similarity between them.
Mutations occur not only due to the change of single
residue, but also due to the insertions and deletions of
residues. Therefore gaps are added in sequence alignments
in order to simulate this situation. There are some com-
monly used alignment tools such as Needleman-Wunsch al-
gorithm [11], Smith-Waterman algorithm [16], FASTA, and
BLAST and its variants Gapped BLAST, PSI-BLAST and
Power BLAST [4, 17].
In [12], frequency transformation of a biosequence S into
N-gram, FT#N(S) is defined as a vector of frequencies of
N-grams. FT1(S) has 4 dimensions and FT2(S) has 16 di-
mensions. Because there is more information about the po-
sitions of the characters relative to other characters stored
as N grows, the feature vector distance will be more re-
lated to the DP score. N-gram Frequency Wavelet Trans-
formation, denoted as WT#N(S), combines FT#N(S) and
Wavelet Transformation. After dividing the sequence S into
SŒ± and SŒ≤ , WT#N(S) computes the transformations VŒ±
=FT#N(SŒ±) and VŒ≤ =FT#N(SŒ≤). Then it concatenates the
addition and subtraction of those two vectors, i.e., [VŒ±+VŒ≤ ,
VŒ± ‚àí VŒ≤]. Q-gram frequency transformation can also be
combined with Fourier Transformation [1].
3. Sequence Feature Vector
SD is comprised of three features from a biosequence
including Count, Relative Position Dispersion (RPD) and
Absolute Position Dispersion (APD). Their definitions are
as follows:
Definition 1 (Count):
Let S = < s1, s2, . . . , sn > be a sequence over the al-
phabet Œ£u = {Œ±1, Œ±2, . . . , Œ±u}, then the Count of S, called
C(S), is defined as: C(S) = [C1, C2, . . . , Cu], where Ci
(‚â• 0) corresponds to the total number of Œ±i in S, and‚àëu
i=1 Ci = |S| = n.
Definition 2 (Relative Position Dispersion, RPD):
Let S = < s1, s2, . . . , sn > be a sequence over the al-
phabet Œ£u = {Œ±1, Œ±2, . . . Œ±u}, and Ni be the number of Œ±i
in S. For symbol Œ±i in S, let lŒ±i,j be the difference of posi-
tions of the jth Œ±i and (j + 1)th Œ±i. So, there are NŒ±i ‚àí 1
values of position differences for symbol Œ±i. Relative Posi-
tion Dispersion of S, called RPD(S), is defined as: RPD(S)
= [
(lŒ±1,1)
2+...+(lŒ±1,NŒ±1‚àí1)
2
NŒ±1‚àí1 , . . . ,
(lŒ±u,1)
2+...+(lŒ±u,NŒ±u‚àí1)
2
NŒ±u‚àí1 ].
RPD indicates the degree of relative dispersion of each
kind of base in a biosequence.
Definition 3 (Absolute Position Dispersion, APD):
Let S = < s1, s2, . . . , sn > be a sequence over
the alphabet Œ£u = {Œ±1, Œ±2, . . . Œ±u}, and Ni be the
number of Œ±i in S. Let the positions of Œ±i in S
be pŒ±i,1, pŒ±i,2, . . . , pŒ±i,NŒ±i . Absolute Position Disper-
sion of S, called APD(S), is defined as: APD(S) =
[
(pŒ±1,1)
2+...+(pŒ±1,NŒ±1‚àí1)
2
NŒ±1
, . . . ,
(pŒ±u,1)
2+...+(pŒ±u,NŒ±u‚àí1)
2
NŒ±u
].
APD indicates the degree of absolute dispersion of each
base in a biosequence.
4. Adaptive Weighting Distance
A sequence is skewed if the number of residues of a cer-
tain symbol in the sequence is much more than the numbers
of other symbols. When we align two sequences, there are
two possibilities to make them similar. First, two skewed se-
quences are very likely to have a very high DP score, if their
dominant residues are the same. If their dominant residues
are different, they will have a very low DP score. Second, if
the number of four symbles of Count are the same, the sym-
bol will be more representative in RPD and APD in terms
of computing similarity between two sequences.
4.1. Adaptive Weighting Distance Mecha-
nism
We design an adaptive weighting distance to compute the
distance between two feature vectors in the light of these
two possibilities. First of all, we compute the average en-
tropy of Count of query feature vector and database‚Äôs fea-
ture vectors. Entropy indicates the distribution of a set of
objects. The value of entropy small, the objects is much
more disorder. For this reason, we use entropy to compute
Figure 1. True Positives for k-NN of FW#2, SD
and AW-SD
Figure 2. True Positives for k-NN of SSD and
AW-SSD
[2] R. Agrawal, C. Faloutsos, and A. Swami Efficient simi-
larity search in sequence databases, Proceedings of the
4th International Conference on Foundations of Data
Organization and Algorithms, pp. 69-84, 1993.
[3] S. F. Altschul, W. Gish, W. Miller, E. W. Myers and D.
J. Lipman. Basic local alignment search tool, J. Mol.
Biol., 1990, pp. 403-410.
[4] S. F. Altschul, T. L. Madden, A. A. Schaffer, J Zhang,
Z Zhang, W Miller and D. J. Lip-man. Gapped BLAST
and PSI-BLAST: a new generation of protein database
search programs, Nucleic Acids Res, 1997, pp. 3389-
3402.
[5] Te-Wen Hsieh, Huang-Cheng Kuo and Jen-Peng
Huang. Filtering bio-sequence based on sequence de-
scriptor, Workshop on Data Mining for Biomedical
Applications, 2006, pp. 14-23.
[6] Bi Jin and Gang Rong BTS: a Fast Approach for Simi-
larity Search in Sequences, World Congress on Intelli-
gent Control and Automation, 2006, pp. 5933- 5937.
[7] M. Li, B. Ma, D. Kisman and J. Tromp. Patternhunter
II: highly sensitive and fast homology search, J. Bioin-
formatics and Computational Biology, Vol. 2, No. 3,
2004, pp. 417-439.
[8] D. J. Lipman and W. R. Pearson. Rapid and sensi-
tive protein similarity searches, Science 227, 1985, pp.
1435-1441.
[9] Zbigniew Michalewicz. Genetic Algorithms + Data
Structures = Evolution Programs, Springer-Verlag,
third edition, 1999.
[10] B. Ma, J. Tromp and M. Li. Patternhunter: faster and
more sensitive homology search, Bioinformatics, Vol.
18, No. 3, 2002, pp. 440-445.
[11] S. B. Needleman and C. D.Wunsch. A general method
applicable to the search for similarities in the amino
acid sequences of two proteins, J. Mol. Biol. 48, 1970,
pp. 443-453.
[12] O. Ozturk and H. Ferhatosmanoglu. Effective indexing
and filtering for similarity search in large biosequence
databases, IEEE International Symposium on Bioin-
formatics and Bioengineering, 2003, pp. 359-366.
[13] W. R. Pearson. Flexible sequence similarity searching
with the FASTA3 program package, Methods Mol Biol.
132, 1999, pp. 185-219.
[14] W. R. Pearson and D. J. Lipman. Improved tools for
biological sequence analysis, Natl. Acad. Sci, 85, 1988,
pp. 2444-2448.
[15] Kim R. Rasmussen, Jens Stoye, Eugene W. Myers.
Efficient q-gram filters for finding all epsilon-matches
over a given length, International Conference on Re-
search in Computational Molecular Biology, 2005, pp.
189-203.
[16] T. F. Smith andM. S.Waterman. Identification of com-
mon molecular subsequences, J. Mol. Biol. 147, 1981,
pp. 195-197.
[17] J. Zhang and T. L. Madden. PowerBLAST: a new net-
work BLAST application for interactive or automated
sequence analysis and annotation, Genome Research,
Vol. 7, No. 6, 1997, pp. 649-656.
[18] About - E. coli, http://www.about-ecoli.com/.
[19] National Center for Biotechnology Information
(NCBI), http://www.ncbi.nlm.nih.gov/.
A Gradational Reduction Approach for Mining
Sequential Patterns
Jen-Peng Huang1, Guo-Cheng Lan1, and Huang-Cheng Kuo2,
1 Department of Information Management
Southern Taiwan University of Technology
jehuang@mail.stut.edu.tw
2 Department of Computer Science and Information Engineering
National Chiayi University
hckuo@mail.ncyu.edu.tw
Abstract. The technology of data mining is more important in recent
years, and it is generally applied to commercial forecast and decision
supports. Sequential pattern mining algorithms in the Ô¨Åeld of data min-
ing play one of the important roles. Many of sequential pattern mining
algorithms were proposed to improve the eÔ¨Éciency of data mining or
save the utility rate of memory. So, our major study tries to improve the
eÔ¨Éciency of sequential pattern mining algorithms.
We propose a new algorithm - GRS (A Gradational Reduction Ap-
proach for Mining Sequential Patterns) which is an eÔ¨Écient algorithm of
mining sequential patterns. GRS algorithm uses gradational reduction
mechanism to reduce the length of transactions and uses GraDec func-
tion to avoid generating large number of infrequent sequential patterns;
and it is very suitable to mine the transactions of databases whose record
lengths are very long. The GRS algorithm only generates some sequences
which are very possible to be frequent. So, the GRS algorithm can de-
crease a large number of infrequent sequences and increase the utility
rate of memory.
Keywords: data mining, sequential patterns, algorithm.
1 Introduction
Recent developments in computing technologies have resulted in computerizing
enterprises which were recorded by hand. For example, customers‚Äô records in
enterprises, patients‚Äô records in hospitals, transaction records in sales . . . etc.,
those data are transferred and stored in Ô¨Åles or database format which make
the maintenance easier, more convenient and more eÔ¨Écient than before by using
sorting, indexing and relationship between tables.
As people use computer to deal with diÔ¨Äerent kinds of aÔ¨Äairs, the amount of
data are stored and accumulated in surprising speed. Those large amounts of
data need new technologies and tools to analyze and extract useful information
 Corresponding author.
H.G. Okuno and M. Ali (Eds.): IEA/AIE 2007, LNAI 4570, pp. 562‚Äì571, 2007.
c¬© Springer-Verlag Berlin Heidelberg 2007
564 J.-P. Huang, G.-C. Lan, and H.-C. Kuo
element of the sequence. We denote an element of a sequence by (x1, x2, . . . , xm),
where xj is an item. An item can occur only once in an element of a sequence,
but can occur multiple times in diÔ¨Äerent elements. An itemset is considered to
be a sequence with a single element.
A sequence < a1a2 . . . an > is a sub-sequence of another sequence b1b2 . . . bm if
there exist integers i1 < i2 < . . . < in such that a1 ‚äÇ bi1, a2 ‚äÇ bi2, . . . , an ‚äÇ bin.
For example, the sequence < (3), (4, 5), (8) > is a sub-sequence of <(7), (3, 8),
(9), (4, 5, 6), (8)>, since (3) ‚äÇ (3, 8), (4, 5) ‚äÇ (4, 5, 6), and (8) ‚äÇ (8). However,
the sequence < (3), (5) > is not a sub-sequence of < (3, 5) >. The problem of
mining sequential patterns is to Ô¨Ånd all sequences whose support is greater than
the user-speciÔ¨Åed minimum support. Each such sequence represents a sequential
pattern, also called a frequent sequence.
The AprioriAll[2] algorithm is a level-wise technique. In the mining sequen-
tial patterns, AprioriAll must repeatedly scan the database and generate the
candidate sets until there are no frequent sequences to be found.
The GSP[6] (Generalized Sequential Pattern) algorithm eÔ¨Äectively reduces the
number of candidate sets, and modiÔ¨Åes the join phase of candidate generation in
the mining sequential patterns. However, because the GSP algorithm will spend
a great deal of time to perform the processes of candidate sets reducing, and
GSP also needs to scan the database repeatedly, the performance of GSP is not
good.
FreeSpan[8] (Frequent pattern-Projected Sequential Pattern Mining) uses the
frequent items to project many small projected databases from original database.
Next, FreeSpan only scans and decomposes the small projected databases, and
then discover the sequential patterns. Because FreeSpan does not scan the orig-
inal database repeatedly, the mining eÔ¨Éciency is better than the Apriori-based
algorithms. However, FreeSpan may suÔ¨Äer from the following two nontrivial costs
under some conditions: (a) FreeSpan will waste unnecessary memory to build
these projected databases. (b) FreeSpan will generate many unnecessary candi-
date sets.
To improve the defects of FreeSpan[8], PreÔ¨ÅxSpan[9] (PreÔ¨Åx-projected Sequen-
tial Pattern Mining) recursively uses divide-and-conquer and projected-based to
discover the sequential patterns, the performance of PreÔ¨ÅxSpan is better than
the Apriori-based algorithms when patterns are long. However, PreÔ¨ÅcSpan must
set up many large projected databases when the items are distributed equally
in the database. Thus it easily causes insuÔ¨Écient memory problems.
3 Gradational Reduction Approach for Mining Sequential
Patterns, GRS
When the lengths of sequence records are long or the minimum supports are
low, the past algorithms [2][10][8][9] need to spend a great deal of time to dis-
cover the frequent sequences. Therefore, to improve the mining eÔ¨Éciency, we
propose a new algorithm GRS (Gradational Reduction Approaches for Mining
Sequential Patterns). GRS is a level-wise technique, and the algorithm uses the
566 J.-P. Huang, G.-C. Lan, and H.-C. Kuo
subset ‚ÄúA(BC)‚Äù is a frequent sequence, the function GraDec generates all of the
4-sequences of ‚ÄúA(BC)DE‚Äù which contain ‚ÄúA(BC)‚Äù. Thus the function GraDec
returns ‚ÄúA(BC)D‚Äù and ‚ÄúA(BC)E‚Äù. Fig. 1(a) shows the processes of infrequent
sequences Ô¨Åltering.
Next, the function GraDec sets the mask value to ‚Äú11011‚Äù. The subset which
consists of the preceding 3 items of ‚ÄúA(BC)DE‚Äù with the mask value ‚Äú11011‚Äù
is ‚ÄúABD‚Äù. In the same way, the function GraDec needs to determine whether
‚ÄúABD‚Äù is a frequent 3-sequence in L3. Because the subset ‚ÄúABD‚Äù is not a
frequent 3-sequence in L3, the function GraDec directly sets the mask value
to ‚Äú10111‚Äù. Fig. 1(b) shows the processes. The subset which consists of the
preceding 3 items of ‚ÄúA(BC)DE‚Äù with the mask value ‚Äú10111‚Äù is ‚ÄúACD‚Äù. The
function GraDec needs to determine whether ‚ÄúACD‚Äù is a frequent 3-sequence in
L3. Because the subset ‚ÄúACD‚Äù is not a frequent 3-sequence in L3, the function
GraDec directly sets the mask value to ‚Äú01111‚Äù. Fig. 1(c) shows the processes.
The subset which consists of the preceding 3 items of ‚ÄúA(BC)DE‚Äù with the mask
value ‚Äú01111‚Äù is ‚Äú(BC)D‚Äù. The function GraDec needs to determine whether
‚Äú(BC)D‚Äù is a frequent 3-sequence in L3. Because the subset ‚Äú(BC)D‚Äù is not a
frequent 3-sequence in L3, we stop the processes of sequences generating. Fig.
1(d) shows the processes.
Fig. 1. GraDec function on A(BC)DE
In Fig 1(e) we can discover that GRS only generates sequences which are
very possible to be frequent via the mechanism of infrequent sequences Ô¨Åltering
in tempST. Thus GRS can eÔ¨Äectively increase the eÔ¨Éciency and the utility rate
of memory.
3.2 Process of Gradational Reduction Mechanism
Although the function GraDec can generate all of the possible frequent sequences
of speciÔ¨Åed length, in order to reduce the lengths of transactions in every phase,
568 J.-P. Huang, G.-C. Lan, and H.-C. Kuo
The function GraDec continues to generate all of the possible frequent 3-
sequences and use user-speciÔ¨Åed minimum supports to Ô¨Ånd all of the frequent
3-sequences from temp DB and save in FST[2]. After Ô¨Ånding the frequent 3-
sequences, we save all of the items of FST[2] into tempFST. The items which
are saved in tempFST are possible elements of frequent sequences which will be
found in next phase. Next, we delete the items of temp DB which are not in
tempFST, and then accumulate and save the rest in temp DB. Fig. 2(c) shows
the processes and result.
We perform the above processes repeatedly. There are no frequent 4-sequences
in FST[3], the process of Ô¨Ånding frequent sequences stops. Fig. 2(d) shows the
processes of the Ô¨Åltration mechanism.
4 Experimental Results
4.1 Experiment Environment
All the experiments are performed on the following environment: ¬°br¬ø Intel Pen-
tium IV 2.8GHz CPU, 512MB DDR RAM, Windows 2000 Server, IBM Data
Generator[6], J2SDK 1.4.2 Programming Language.
The experiments are pursued on synthetic data sets which are generated by
IBM Data Generator[6] with the following factors. S: Average transactions per
customer. T: Average items per transactions. II : Average length of maximal
pattern. IT : Average length of maximal pattern. N: Total number of diÔ¨Äerent
items. D: Total number of transactions.
4.2 Comparison Algorithms
Our proposed algorithms are to discover the sequential patterns, so our ex-
periment includes the famous algorithms such as AprioriAll[2] and PreÔ¨ÅxS-
pan[9]. In addition, we also consider the version based on pseudo-projection
name PreÔ¨ÅxSpan-2 in the experiment. The PreÔ¨ÅxSpan-2 algorithm uses a struc-
ture to link all of the customer sequences in a projection database. This mecha-
nism can reduce the costs on projecting databases when the projected database
can be built in the main memory. Besides, to avoid external factors causing the
diÔ¨Äerence of performances, each algorithm is written in Java2 SDK 1.4.2 and
performed on the same environments.
To be the fairness of the performance, we need to show the performances of our
implemented algorithm PreÔ¨ÅxSpan is not worse than the original one. Because
the AprioriAll algorithm is not our main competitive algorithm, we omit the
performance Ô¨Ågure comparison. We use the performance Ô¨Ågure of study which
is proposed by Pei[9] et al., to compare the performance with our implemented
algorithms.
In Fig. 3 they use dataset S8T8I8N1KD10K and the diÔ¨Äerent minimum
supports to test the performance of PreÔ¨ÅxSpan. Because we do not have original
PreÔ¨ÅxSpan[9], we try our best to implement PreÔ¨ÅxSpan. The result of execution
on dataset S8T8I8N1KD10K within min sup range between 0.5% and 3% are
570 J.-P. Huang, G.-C. Lan, and H.-C. Kuo
database. Thus the performance of AprioriAll is the worst algorithm among algo-
rithms. The performance of GRS is better than others. Because it can eÔ¨Äectively
Ô¨Ålter infrequent sequences via their own Ô¨Åltration mechanisms. In addition, be-
cause PreÔ¨ÅxSpan-1 and PreÔ¨ÅxSpan-2 use the projection techniques to discover the
frequent sequences, the algorithms need to spend a great deal of memory building
the projections. Therefore their performances are not good.
Comparison of utility rate of memory in diÔ¨Äerent parameters S. In
this experiment, we use dataset N10K-D100K-T2.5-IS4-IT1.25 and min sup 0.5%
within S range between S3 and S11 to evaluate the utility rate of memory of algo-
rithms in diÔ¨Äerent number of transactions per sequence (S). We observe that the
memory usage is increasing when the S is increasing. Because both PreÔ¨ÅxSpan-1
and PreÔ¨ÅxSpan-2 use projection techniques to discover the frequent sequences,
the algorithms spend more memory building these projection databases when
S is increasing. Thus the utility rates of memory are not better than others.
Because AprioriAll is a level-wise method, AprioriAll can release unnecessary
memory space in each phase. Thus the utility rate of memory is very good. Be-
cause GRS can eÔ¨Äectively reduce the number of infrequent sequences via the
Ô¨Åltration mechanisms, the algorithm can save a good deal of memory to increase
memory utility rates.
Comparison of the algorithms in diÔ¨Äerent parameters D. In this ex-
periment, we use dataset S10-N10K-T2.5-IS4-IT1.25 and min sup 0.75% within
D range between 100K and 500K to evaluate the performance of algorithms in
diÔ¨Äerent sizes of datasets (D). We discover that the execution time is increas-
ing when D is increasing. The execution time of AprioriAll is rapidly increasing
when D is increasing. The reason is that AprioriAll spends more time counting
supports of candidate sets when D is increasing. Besides, when D is greater than
500K, the execution of AprioriAll is very long. Therefore, we remove AprioriAll
from algorithms and continue to compare the performance with others.
5 Conclusion
One of the characters of GRS algorithm is the gradational reduction mechanisms.
The main mining method of GRS algorithm is similar to Apriori-like algorithm
which is level by level, but the GRS algorithm does not need to generate can-
didate sequential patterns during the mining processes. At the same time, it
can shorten the length of sequences and compress the size of database in every
phase so it can reduce a great number of infrequent sequences eÔ¨Äectively, and
then increase the eÔ¨Éciency and the utility rate of memory substantially.
The advantages of GRS algorithm are as follows:
1. Because the GRS algorithm will release the memory of storing infrequent
sequences and the shortening length and the size compressing of database in
every phase, it only generates the sequences that are the most possible to be
frequent sequences. Therefore, the GRS algorithm can increase the utility
rate of memory eÔ¨Äectively.
