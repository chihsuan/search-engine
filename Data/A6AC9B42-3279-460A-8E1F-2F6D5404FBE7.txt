A Concurrency Control Design in B-trees for
Flash-Memory Storage Systems
Chin-Hsien Wu
Department of Electronic Engineering
National Taiwan University of Science and Technology, Taipei, Taiwan
chwu@mail.ntust.edu.tw
Abstractâ€” Since huge-capacity flash-memory is now an eco-
nomic solution for various portable devices and embedded
systems, a NAND flash-based storage system has replaced a hard-
disk drive in many applications. Recently, the implementation
of database systems on NAND flash-based storage systems has
become an important research topic. In particular, the B-tree
index is an important data structure on database systems. With
the very distinctive characteristics of flash-memory, previous
work focuses on the performance improvement of the B-tree
index structures but the concurrency control problems in NAND
flash-based storage systems are not addressed. In the project,
we will propose a concurrency control design. The objective is
not only to resolve the concurrency control problems but also
to improve the system throughput of NAND flash-based storage
systems.
I. INTRODUCTION
Flash-memory has become a popular alternative in stor-
age systems, due to its advantages in non-volatility, shock-
resistance, and low power consumption. In recent years, flash-
memory devices have advanced along with the wave of
consumer electronics and embedded systems. Flash-memory
could be considered as an alternative to hard-disk drives in
many applications. For example, a flash-based solid state drive
(SSD) that is a data storage device has become popular and
has replaced hard-disk drives in many applications. Many
Manufacturers (such as SanDisk, STEC, Samsung, Mtron,
and PNY) have released huge-capacity flash-based SSD (e.g.,
64GB SSD) in the markets. Now, the implementation of B-tree
index structures on flash-based storage systems has become an
important research topic. However, with the distinctive imple-
mentation of B-tree index structures on flash-based storage
systems, the concurrency control problems could result in
execution incorrectness and performance degradation.
In the project, we will propose a concurrency control design
in B-trees for flash-memory storage systems. In other words,
we must consider that two or more processes could access the
same B-tree index structures so that any execution incorrect-
ness should be avoided. Furthermore, the system performance
should be improved when many processes are simultaneously
running. Therefore, we propose a locking protocol and prove
that the locking protocol can work correctly with the existing
implementation when two or more processes simultaneously
access the same data. We also propose a concurrency buffer
control that aims to increase the system throughput. A con-
currency buffer control maintains two buffers: operation buffer
and free buffer. The two buffers can hold the most-recent used
B-tree nodes and replace the least used B-tree nodes by a LRU-
based replacement method and a priority-based replacement
method. In particular, a priority-based replacement method
adopts four priority cases to efficiently locate and predict to-
be-used B-tree nodes.
The rest of this project is organized as follows: Section II
introduces an overview of flash-memory. Section III is the
related work and Section IV is the motivation. Section V
introduces a concurrency control design. Section VI provides
performance evaluation of the proposed method. Section VII
is the conclusion.
II. FLASH-MEMORY CHARACTERISTICS
A NAND1 flash-memory chip consists of many blocks, and
each block is of a fixed number of pages. A block is the
smallest unit for erase operations, while reads and writes are
done in pages. A page contains a user area and a spare area,
where the user area is for the storage of a logical block, and
the spare area stores ECC and other house-keeping information
(i.e., LBA). The typical sizes of the user area and spare area of
a page are 512B and 16B, respectively. The typical block size
of a NAND flash-memory chip is 16KB [1], [14]. Because
flash-memory is write-once, we do not overwrite data on each
update. Instead, data are written to free space, and the old
versions of data are invalidated and considered as dead. Such
an update strategy is called â€œout-placeâ€ or â€œwrite-onceâ€ update.
In other words, any existing data on flash-memory could not
be over-written (updated) unless its residing block is erased.
Pages that store live data and dead data are called â€œvalid pagesâ€
and â€œinvalid pagesâ€, respectively.
After a number of page writes, free space on flash-memory
would become low. Activities that consist of a series of reads,
writes, and erases with the intention to reclaim free spaces
will start. The activities are called â€œgarbage collectionâ€ and
considered as overheads in flash-memory management. The
objective of garbage collection is to recycle invalid pages
scattered over blocks so that they could become free pages
after erasings. How to smartly choose blocks for erasing
1There are two major types of flash-memory in the market: NAND flash-
memory and NOR flash-memory. NAND flash-memory is mainly for data
storage, and NOR flash-memory is often for EEPROM replacement. In this
research, we focus our discussions on NAND flash-memory because it is more
suitable to the designs of file/storage systems.
1
IV. MOTIVATION
When a process needs to access data via B-tree index
structures in NAND flash-based storage systems, the process
could need to lock adequate internal nodes and leaf nodes
before accessing. When other processes would access the
locked nodes, they would be stalled. This is called the concur-
rency control of the B-tree. However, in previous work, some
research papers [8], [9], [10], [11] focus on the performance
improvement of the B-tree index structures but the concurrency
control problems in NAND flash-based storage systems are
not addressed. Although previous research results [12], [13]
have focussed on the concurrency control design in disk-based
storage systems, they could not be directly applied to flash-
memory storage systems due to the distinctive flash-memory
characteristics. In particular, BFTL is designed by considering
the flash-memory characteristics so that the implementation of
BFTL is different from those for disk-based storage systems.
As a result, while the B-tree index structures (maintained by
BFTL) are adopted in NAND flash-based storage systems,
the concurrency control problems must be considered and
investigated. In the project, we will propose a concurrency
control design. The design is not only to resolve the problem
that two or more processes could access data simultaneously
but also to improve the system throughput of NAND flash-
based storage systems.
V. A CONCURRENCY CONTROL DESIGN
A. Overview
Concurrency Buffer Control
Flash menory
B-tree-related Applications
Other
Apps
File
system
operation Buffer
Flash-Memory Translation Layer
The commit policy
Node Trans.
Table
free Buffer
A Locking
Protocol
Fig. 4. Architecture
In the section, we will propose a concurrency control design
in B-trees for flash-memory storage systems. The design not
only provides the efficient implementation of B-tree index
structures but also guarantees the concurrency control in B-
trees to increase the system throughput. As shown in Figure
4, the design consists of a locking protocol for node translation
table, a concurrency buffer control, and a commit policy. A
locking protocol can provide data integration when two or
more processes would simultaneously access the B-tree index
structures that are maintained by BFTL. A concurrency buffer
control maintains two buffers: operation buffer and free buffer.
A 2-layer replacement policy (i.e., a LRU-based replacement
method and a priority-based replacement method) is also
proposed for the two buffers to efficiently locate and predict
to-be-used B-tree nodes. The commit policy is similar to that
of BFTL. However, the commit policy of the design should
cooperate with the concurrency buffer control and should have
a different design.
B. A Locking Protocol for Node Translation Table
	
	 		

   
 
  

 
 ! " # $ %



 
!
%



 
 
&
	'
	(		'
Fig. 5. A Locking Protocol for Node Translation Table
pre-lock read-lock operation-lock
pre-lock
âˆš âˆš
Ï‡
read-lock
âˆš âˆš
Ï‡
operation-lock Ï‡ Ï‡ Ï‡
TABLE Iâˆš
MEANS THAT DIFFERENT PROCESSES CAN ACCESS THE SAME NODE AT
A TIME. Ï‡ MEANS THAT DIFFERENT PROCESSES CAN NOT ACCESS THE
SAME NODE AT A TIME.
Since the index units of a B-tree node could be scattered
over flash-memory by BFTL, node translation table is adopted
to help a collection of the index units of a B-tree node. As
shown in Figure 5, when node B will be accessed, four sectors
whose logical addresses are 42, 34, 100, and 53 will be read
for constructing node B. In particular, a sector could store
index units that belong to different nodes due to BFTL. For
example, a sector whose logical address is 34 stores index
units that belong to node B and node E. As a result, a locking
protocol should be proposed for node translation table when
two or more processes would simultaneously access the B-tree
index structures that are maintained by BFTL.
The locking protocol provides three locks: pre-lock, read-
lock, and operation-lock. Note that the three kinds of locks
are very common in popular locking protocols [12], [13].
When a node is read into the concurrency buffer from flash-
memory, the node will be locked with pre-lock by setting
the corresponding entry in the node translation table. If the
node will be updated, the nodeâ€™s pre-lock should be changed
to operation-lock. Furthermore, if the node is read only, the
nodeâ€™s pre-lock can be changed to read-lock. When the update
or read operation is finished, the lock will return to pre-lock.
3

  

	 	 
 
 

 
 













	 
	 	
	 	       
   
 
 




 !"
 
 

  

 	# 	#	 




 !"

 !"
 !" 
!
"	
 $%&'()
$"*+,)
Fig. 7. A 2-Layer Replacement Policy
â€¢ Case2: Those sets of index units (whose parent nodes
in operation buffer) have the second highest priority.
Because its parent nodes are in operation buffer, its child
nodes in free buffer could be used later. As shown in
Figure 7, because node A and node B have been in
operation buffer, node D and node E meet Case2. Note
that because node C has met Case 1, node C should not
be considered in the case.
â€¢ Case3: Those B-tree nodes (that need the maximum
sector reads to be constructed when they are replaced)
have the third highest priority. As shown in Figure 7, if
node I is replaced, three sectors (i.e., logical addresses
are 2, 100, and 15) will be read to construct node I .
However, if node H is replaced, only two sectors (i.e.,
logical addresses are 15 and 100) will be read. As a result,
node I meets Case3.
â€¢ Case4: In addition to Case1, Case2, and Case3, the
remaining sets of index units in free buffer have the
lowest priority. For example, node H in free buffer meets
Case4.
If any sets of index units in free buffer have been modi-
fied, they should be written to flash-memory when they are
replaced. The operation can be handled by the commit policy.
The commit policy is to pack index units efficiently into a
few sectors to reduce the number of page physically written.
The commit policy of the proposed method is similar to that
of BFTL. The difference of the commit policy between BFTL
and the proposed method is that BFTL will flush out all dirty
index units to flash-memory but the proposed method will only
flush out the replaced index units according to the four priority
cases.
VI. PERFORMANCE EVALUATION
A. Experiment Setup and Performance Metrics
A NAND-based system prototype was built to evaluate
the performance of the currency control design. The size of
a page was 2KB and the size of a block was 128 pages.
The operation buffer was configured to hold 240 index units
and the free buffer were also configured to hold among 600,
1,200, and 2,400 index units. Note that a ratio rs was used
to control the value distribution of the inserted keys: when
rs equals zero, all of the keys were randomly generated.
If rs equals 1, the value of the inserted keys were in an
ascending order. Consequently, if the value of rs equals 0.5,
the values of one-half of the keys were in an ascending
order, while the other keys were randomly generated. We also
implemented a LRU-based policy for the operation buffer and
the free buffer as a baseline. Note that the proposed method
is a 2-layer replacement policy that includes a LRU-based
replacement method for the operation buffer and a priority-
based replacement method for the free buffer.
Initially, we inserted 40,000 records to an empty B-tree
index structure under different rs from 0.1 to 0.9. After
the creating, 20,000 keys were randomly generated for the
searching of the B-tree index structure. Therefore, we will
measure the number of sector reads for the creating and
searching of B-tree index structures. Note that sector reads
were issued by an original B-tree index structure. These sector
reads were translated into page reads to physically access the
NAND flash-memory. The fanout of the B-tree used in the
experiments was 100, and the size of a B-tree node fitted in
a sector (i.e., 2KB).
Free buffer is configured to hold 600 index units.
0
50000
100000
150000
200000
250000
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9
rs
N
u
m
b
er
 o
f 
S
ec
to
r 
R
ea
d
s
LRU
Concurrency
Control Design
Free buffer is configured to hold 1,200 index units.
0
50000
100000
150000
200000
250000
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9
rs
N
u
m
b
er
 o
f 
S
ec
to
r 
R
ea
d
s
LRU
Concurrency
Control Design
Free buffer is configured to hold 2,400 index units.
0
50000
100000
150000
200000
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9
rs
N
u
m
b
er
 o
f 
S
ec
to
r 
R
ea
d
s
LRU
Concurrency
Control Design
Free buffer is configured to hold 600 index units
0
50000
100000
150000
200000
0 0.1 0.20.3 0.4 0.5 0.6 0.70.8 0.9 1
rs
N
u
m
b
er
 o
f 
S
ec
to
r 
R
ea
d
s
LRU
Concurrency
Control Design
Free buffer is configured to hold 1,200 index units.
0
50000
100000
150000
200000
0 0.10.20.30.40.50.60.70.80.9 1
rs
N
u
m
b
er
 o
f 
S
ec
to
r 
R
ea
d
s
LRU
Concurrency
Control Design
Free buffer is configured to hold 2,400 index units.
0
50000
100000
150000
0 0.10.20.30.40.50.60.70.80.9 1
rs
N
u
m
b
er
 o
f 
S
ec
to
r 
R
ea
d
s
LRU
Concurrency
Control Design
(a) Number of Sector Reads During the
Creating of B-tree Index Structures
(b) Number of Sector Reads During the
Searching of B-tree Index Structures
Fig. 8. Experimental Results
B. Creating of B-tree Index Structures
As shown in Figure 8.(a), the concurrency control design
can decrease the number of sector reads when B-tree index
5
7??????
???????????????????????????
?????????????????????????????
?????????????????????????????
??????????? B-Tree????? NAND ???????
?????????????????????????????
????????????? B-Tree????????????
?????????????????????????????
????????????????????????????
B-Tree??????????????????????????
B-Tree??????????????????????????
ç¼“è¡å€æ§åˆ¶????????????????é€™å€‹ä¸¦è¡Œçš„ç¼“è¡å€
??????: åˆ†åˆ¥æ˜¯é‹ä½œç¼“è¡å€(operation buffer)è·Ÿè‡ªç”±ç¼“è¡
?(free buffer)??????????????????????
???æˆ‘å€‘å¸Œæœ›é€™å…©å€‹ç¼“è¡å€èƒ½ä¿ç•™ç¶“å¸¸ä½¿ç”¨çš„ B-Tree?????
????? B-Tree?????????????????????
????????????? Journal of Systems and Software
??????????????
ç„¡è¡ç”Ÿç ”ç™¼æˆæœæ¨å»£è³‡æ–™
å…¶ä»–æˆæœ 
(ç„¡æ³•ä»¥ï¥¾åŒ–è¡¨é”ä¹‹æˆ
æœå¦‚è¾¦ï§¤å­¸è¡“æ´»å‹•ã€ç²
å¾—çé …ã€é‡è¦åœ‹éš›åˆ
ä½œã€ç ”ç©¶æˆæœåœ‹éš›å½±éŸ¿
ï¦ŠåŠå…¶ä»–å”åŠ©ç”¢æ¥­æŠ€
è¡“ç™¼å±•ä¹‹å…·é«”æ•ˆï¨—äº‹
é …ç­‰ï¼Œè«‹ä»¥æ–‡å­—æ•˜è¿°å¡«
ï¦œã€‚) 
A. éƒ¨ä»½è¨ˆç•«å…§å®¹å·²æŠ•æåˆ°åœ‹éš›æœŸåˆŠ Journal of Systems and Software (JSS)
 
B. æœ¬è¨ˆç•«çš„è²»ç”¨ä¹Ÿæ”¯æ‡‰ä»¥ä¸‹çš„å‡ºåœ‹è²»ç”¨åŠï¥æ–‡åˆŠç™»è²»: 
1. C. H. Wu, H. H. Lin(S), and T. W. Kuo(T), ``An Adaptive Flash 
Translation Layer for High-Performance Storage Systems,ï¼‡ï¼‡ IEEE 
Transactions on Computer-Aided Design of Integrated Circuits and Systems 
(IEEE TCAD), Vol. 29, No. 6, June 2010. 
2. J. H. Hu(S), C. H. Wu, and C. H. Lin(T), ``A Middleware Design for 
Multiple Embedded Database Systems,ï¼‡ï¼‡ accepted and to appear in the 
14th IEEE International Symposium on Consumer Electronics, June 7-10, 
2010, Braunschweig, Germany (IEEE ISCE 2010). 
 
 æˆæœé …ç›® ï¥¾åŒ– åç¨±æˆ–å…§å®¹æ€§è³ªç°¡è¿° 
æ¸¬é©—å·¥å…·(å«è³ªæ€§èˆ‡ï¥¾æ€§) 0  
èª²ç¨‹/æ¨¡çµ„ 0  
é›»è…¦åŠç¶²ï¤·ç³»çµ±æˆ–å·¥å…· 0  
æ•™æ 0  
èˆ‰è¾¦ä¹‹æ´»å‹•/ç«¶è³½ 0  
ç ”è¨æœƒ/å·¥ä½œåŠ 0  
é›»å­å ±ã€ç¶²ç«™ 0  
ç§‘ 
æ•™ 
è™• 
è¨ˆ 
ç•« 
åŠ  
å¡« 
é … 
ç›® è¨ˆç•«æˆæœæ¨å»£ä¹‹ï¥«èˆ‡ï¼ˆé–±è½ï¼‰äººï¥© 0  
