 
ç¾å ´ï¤“è¼¯é™£ï¦œé–˜ç¡¬é«”å¹³å°æ–¼è‡‰éƒ¨è¡¨æƒ…è¾¨ï§¼èˆ‡ 
æƒ…ç·’åˆ†æç³»çµ±ä¹‹ç ”ç©¶èˆ‡è¨­è¨ˆ 
 
ï§´ç¶ç”Ÿ 
åœ‹ï§·å‹¤ï¨—ç§‘æŠ€å¤§å­¸  è³‡è¨Šå·¥ç¨‹ç³» 
 
äºŒã€ ä¸­æ–‡æ‘˜è¦ 
æœ¬ç ”ç©¶æå‡ºï¦ºä»¥å°æ³¢è½‰æ›å’Œï§å°è…¦ç¡¬é«”æ¨¡
å‹æ¶æ§‹ï¤­é€²ï¨ˆè‡‰éƒ¨è¡¨æƒ…è¾¨ï§¼ï¼Œä¸¦ä½¿ç”¨è‘—åçš„
JAFFE è³‡ï¦¾åº«é€²ï¨ˆè¡¨æƒ…çš„è¨“ï¦–èˆ‡æ¸¬è©¦ã€‚æœ¬ç³»çµ±
å…±ä½¿ç”¨ï¦ºï§‘ç¨®è¡¨æƒ…ï¼Œåˆ†åˆ¥æ˜¯é«˜èˆˆã€ç”Ÿæ°£ã€é›£éã€
é©šè¨ã€ææ‡¼å’Œç„¡è¡¨æƒ…ç­‰ã€‚é€²ï¨ˆè‡‰éƒ¨è¡¨æƒ…è¾¨ï§¼å‰ï¼Œ
æˆ‘å€‘å¿…é ˆå…ˆé‡å° JAFFE è³‡ï¦¾åº«çš„å½±åƒé€²ï¨ˆå‰è™•
ï§¤çš„å‹•ä½œï¼ŒåŒ…å«ï¦ºå½±åƒé›œè¨Šç§»é™¤ï¼Œå½±åƒå¢å¼·ï¼Œé‚Š
ç·£åµæ¸¬ï¼Œè‡‰éƒ¨ä½ç½®æ“·å–ç­‰ç­‰ã€‚é€éå‰è™•ï§¤çš„æ–¹å¼
å°‡é‡è¦çš„è³‡è¨Šä¿ï§ï¼Œéå¿…è¦ä¹‹è³‡è¨Šç§»é™¤ã€‚ 
é¦–å…ˆæˆ‘å€‘å…ˆä»¥ MATLAB è»Ÿé«”é€²ï¨ˆæ¼”ç®—æ³•ä¹‹
æ¸¬è©¦èˆ‡é©—è­‰ï¼Œç•¶è¾¨ï§¼ï¥¡é”åˆ°æˆ‘å€‘çš„éœ€æ±‚å¾Œï¼Œé€é
ç¡¬é«”æè¿°èªè¨€å°‡æ¼”ç®—æ³•ç§»æ¤åˆ° FPGA ç¡¬é«”ä¸Šé€²
ï¨ˆæ¸¬è©¦ã€‚æœ€å¾Œé€é Visual Basic èˆ‡ FPGA ï¤­é€²ï¨ˆ
äººè‡‰è¡¨æƒ…ä¹‹è¨“ï¦–èˆ‡æ¸¬è©¦ã€‚æœ¬å¯¦é©—æ‰€æå‡ºä¹‹æ–¹æ³•åœ¨
è¾¨ï§¼ï¥¡æœ€é«˜å¯é”åˆ° 88.3%ã€‚ 
 
é—œéµè©ï¼šå°æ³¢è½‰æ›ã€ï§å°è…¦æ¨¡å‹ï¼Œè¡¨æƒ…è¾¨ï§¼ï¼Œ
FPAG é››å‹è¨­è¨ˆ 
 
Abstract 
In this research, we proposed a hardware 
system with Field Programmable Gate Array 
(FPGA) for facial expression recognition, in which 
the Haar Discrete Wavelet Transform (DWT) and 
Cerebellar Model Articulation Controller (CMAC) 
were used. The proposed method has been tested 
and trained in the process of hardware emulation 
with the famous JAFFE (Japanese Female Facial 
Expression) database in the proposed hardware. 
The testing facial images must be preprocessed to 
remove noises, enhance the contrast, and cut the 
image to normalize the facial images for the 
training and recognition phases.  
   Firstly, the facial expression features are 
automatically extracted and preprocessed from 
given still images in the JAFFE database in which 
the frontal view of faces are contained. A 2D DWT 
is then used to focus the key information of 
expression characteristics in order to decrease the 
size of images. Thirdly, a block size of the lower 
frequency of DWT coefficients is rearranged as 
input vectors with binary manner to send into the 
proposed CMAC IP that can rapidly obtain output 
using non-linear mapping with look-up table in 
training or recognizing phase. Finally, the 
experimental results in hardware emulation 
demonstrated the promising recognition rates with 
various block size of coefficients for six 
expressions, including happiness, sadness, surprise, 
anger, disgust and natural in lower frequency. 
 
ä¸‰ã€ ç·£ç”±èˆ‡ç›®çš„ 
äººï§çš„æƒ…æ„Ÿè¡¨é”æ–¹æ³•æœ‰å„å¼å„æ¨£æ–¹å¼ï¼Œè€Œå¤§
éƒ¨åˆ†ï¨¦æ˜¯å¾æœ¬èº«æ„ï§¼ä¸­ç™¼å‡ºï¼Œåœ¨é†«å­¸ä¸Šå·²ç¶“æœ‰è¨±
å¤šç”Ÿï§¤è¨Šè™Ÿçš„åæ‡‰ï¼Œå¦‚ç•¶äººç”Ÿæ°£çš„æ™‚å€™èº«é«”çš„è…
ä¸Šè…ºç´ æœƒå¢åŠ ï¼Œå¿ƒè·³åŠ é€Ÿï¼Œä»¥åŠå‘¼å¸åŠ é€Ÿï¼Œåˆ¤æ–·
ï¦Šä¸‹ï¨‰ï¼Œè€Œç•¶äººé«˜èˆˆçš„æ™‚å€™ï¼ŒæœƒåŠ é€Ÿè¡€æ¶²å¾ªç’°ï¼Œ
è¡€å£“å®¹ï§ å‡é«˜ã€‚é€™äº›ç”Ÿï§¤åæ‡‰èƒ½é€éè¦–è¦ºæˆ–è½è¦º
çš„æ–¹å¼æ„Ÿå—åˆ°å°æ–¹æƒ…ç·’ä¸Šçš„è®ŠåŒ–ï¼Œå¦‚èƒ½å¾è²éŸ³ï¼Œ
è‡‰éƒ¨è¡¨æƒ…æˆ–æ˜¯æ€ªï¥¢çš„ï¨ˆç‚ºèˆ‰æ­¢ä¸Šç™¼ç¾ã€‚ 
éš¨è‘—ç§‘æŠ€çš„é€²æ­¥ï¼Œæ¶ˆè²»æ€§ç”¢å“ä¹Ÿè¶Šï¤­è¶Šå¤š
å…ƒåŒ–ï¼Œè¨±å¤šç”¢å“ä¹Ÿæ¼¸æ¼¸çš„é–‹å§‹æœäººæ€§åŒ–ç™¼å±•ã€‚åœ¨
äººæ©Ÿäº’å‹•çš„æ–¹é¢ï¼Œæƒ³è¦è®“ç”¢å“èˆ‡äººäº’å‹•çš„ï¤ç‚ºè±
å¯Œï¼Œå¿…é ˆè—‰ç”±åŠ è£æ„Ÿæ¸¬å™¨çš„æ–¹å¼ï¤­ï¦ºè§£äººçš„å¤šæ¨£
æ€§åæ‡‰ã€‚é€éæ„Ÿæ¸¬å™¨æŠ“å–è³‡ï¦¾ä¸¦é€²ï¨ˆè³‡ï¦¾çš„åˆ¤
æ–·ï¼Œå†ç¶“éäººå·¥æ™ºæ…§(AI) çš„ä»‹é¢ï¤­åˆ¤æ–·ç”¢å“è¦
å¦‚ä½•èˆ‡ä½¿ç”¨è€…ä¹‹é–“åšæœ€ä½³äº’å‹•ã€‚åœ¨é€™æ–¹é¢æ‡‰ç”¨çš„
ï¦´åŸŸæœ€å»£æ³›çš„å‰‡æ˜¯åœ¨æ©Ÿå™¨äººä¸Šï¼Œè¨±å¤šå¸‚é¢ä¸Šçš„å•†
å“å¤§éƒ¨åˆ†ï¨¦åªæœƒæ ¹æ“šç³»çµ±çš„è¨­å®šï¤­é€²ï¨ˆå‹•ä½œï¼Œæ ¹
æ“šä½¿ç”¨è€…ä¸‹é”ä¹‹å‘½ï¦¨ï¤­æ±ºå®šè©²ç”¢å“è¦åšå“ªäº›
äº‹ã€‚è€Œé€™æ–¹é¢ç”±æ–¼æœ¬èº«ç¼ºä¹æ„Ÿæ¸¬å™¨ï¼Œå› æ­¤ç„¡æ³•èˆ‡
ä½¿ç”¨è€…é€²ï¨ˆï¥¼å¥½çš„äº’å‹•ã€‚ 
è¡¨æƒ…è¾¨ï§¼é™¤ï¦ºæ‡‰ç”¨åœ¨æ©Ÿå™¨äººä¹‹å¤–ï¼Œé‚„å¯æ‡‰ç”¨
åœ¨é†«ï§ç…§è­·æ–¹é¢ï¼Œç”±æ–¼ç¤¾æœƒå·²æ¼¸æ¼¸é‚å…¥é«˜é½¡åŒ–çš„
æ™‚ä»£ï¼Œï¤´ï¦äººçš„ç…§è­·è®Šå¾—éå¸¸é‡è¦ï¼Œï¤å› ç‚ºå°‘å­
åŒ–çš„é—œä¿‚ï¼Œé€ æˆç¤¾æœƒï¨›ï§èˆ‡å…¬å…±è¨­æ–½çš„è²¡æºåŒ±
ä¹ã€‚åœ¨ï¤´ï¦äººç…§è­·æ–¹é¢ï¼Œç”±æ–¼ï¤¯å‹•äººï¥©ä¾›çµ¦ï¥§
è¶³ï¼Œç›¸å°çš„ä¹Ÿæœƒé€ æˆé†«ï§ç…§è­·äººå“¡äººï¦Šï¥§è¶³ä¹‹å•
é¡Œã€‚å› æ­¤åœ¨ç…§è­·ï¤´ï¦äººæ–¹é¢ï¼Œå¿…é ˆè¦ä¾è³´å…¶ä»–é
äººï¦Šè³‡æºçš„æ–¹å¼ï¼Œæ‰èƒ½å¤ æ¸›ç·©äººï¦Šï¥§è¶³å•é¡Œã€‚ï¤´
ï¦äººé€šå¸¸æœ€éœ€è¦æ³¨æ„çš„æ˜¯æ„å¤–çš„ç™¼ç”Ÿï¼Œç¤¾æœƒä¸Šè¨±
å¤šï¤´ï¦äººç¶“å¸¸ï¨¦æ˜¯è‡ªå·±ä¸€å€‹äººåœ¨å®¶ï¼Œå¦‚æœèº«é«”çª
ç„¶ï¥¢å¸¸ï¼Œå¾€å¾€æœƒéŒ¯éæœ€ä½³æ€¥æ•‘æ™‚é–“ã€‚å› æ­¤ï¼Œå¦‚æœ
 
åœ– 3. Virtex-4 ML40x å¹³å° 
 
âˆ‘ âˆ‘
= =
Ã—Î¨+âˆ’Ã—Î¨=Î¨
2/
1 1
),2(),12(),('
m
x
n
y
yxyxyx  
   (1) 
âˆ‘ âˆ‘
= =
âˆ’Ã—Î¨âˆ’âˆ’Ã—Î¨=+Î¨
2/
1 1
),12(),12(),2/('
m
x
n
y
yxyxymx
   (2) 
âˆ‘ âˆ‘
= =
Ã—Î¨+âˆ’Ã—Î¨=
m
x
n
y
yxyxyxX
1
2/
1
)2,(')12,('),(  
   (3) 
âˆ‘ âˆ‘
= =
Ã—Î¨âˆ’âˆ’Ã—Î¨=+
m
x
n
y
yxyxnyxX
1
2/
1
)2,(')12,(')2/,(
 (4) 
ç”±æ–¼ CMAC æ¶æ§‹å¿…é ˆä½¿ç”¨åˆ°å¤§ï¥¾çš„è¨˜æ†¶
é«”ï¼Œç¤™æ–¼ Block Ram çš„ç©ºé–“æœ‰é™ï¼Œå› æ­¤æˆ‘å€‘ä½¿ç”¨
Sram çš„è¨˜æ†¶é«”ï¤­å­˜æ”¾æˆ‘å€‘ CMAC çš„æ¬Šé‡çš„ä½
ç½®ã€‚è€Œåœ¨é€²ï¨ˆ CMAC è¨“ï¦–æˆ–æ¸¬è©¦å‰ï¼Œå¿…é ˆä»¥åœ–
2 é›»ï¤·å…ˆå°‡ DWT é‹ç®—å®Œä¹‹å¾Œçš„çµæœé€²ï¨ˆ CMAC
è¼¸å…¥è³‡ï¦¾è½‰æ›ã€‚ 
åœ– 3 æ˜¯ç”±ï¥¸å€‹å­é›»ï¤· Conv Control èˆ‡ Conv 
Operation ä»¥åŠ Block Ram æ‰€æ§‹æˆã€‚åœ¨ç¶“é DWT
è½‰æ›å¾Œï¼Œæˆ‘å€‘å–å‡ºä½é »çš„è³‡ï¦¾ï¼Œä»¥æ¯ä¸€å¡Š 2x2
çš„å€å¡ŠåŠ èµ·ï¤­ç„¶å¾Œåˆ†æˆä¸‰ç­‰åˆ†ï¼Œæ¯ä¸€ç­‰åˆ†ç•¶ä½œ
CMAC çš„è¼¸å…¥è³‡ï¦¾ã€‚è€Œ Conv Control å‰‡æ˜¯è² è²¬
Rowå’ŒColumnçš„æ§åˆ¶ï¼Œä¸¦ä¸”æ ¹æ“šRowå’ŒColumn
ç•¶ä½œ Block Ram çš„è¨˜æ†¶é«”ä½ç½®ï¤­é€²ï¨ˆï¥šå–å‹•
ä½œã€‚è€Œ Conv Operation å‰‡æ˜¯è² è²¬å°‡ Block Ram ï¥š
å–å‡ºï¤­çš„è³‡ï¦¾é€²ï¨ˆåŠ ç¸½ï¼Œä¸¦ä¸”å°‡åŠ ç¸½å®Œå¾Œçš„çµæœ
åˆ†æˆä¸‰ç­‰åˆ†ï¼Œåˆ†åˆ¥çš„å¯«å…¥æ‰€å°æ‡‰åˆ°çš„ Block Ram
è¨˜æ†¶é«”ä½ç½®ä¸Šã€‚ 
 
 
åœ– 3. DWT ä½é »è³‡ï¦¾è½‰æ› CMAC è¼¸å…¥è³‡ï¦¾æ–¹
å¡Šåœ– 
 
3.3 CMAC IP 
CMAC ï§ï¨™ç¶“ç¶²ï¤·[12-14]ä¸»è¦æ˜¯ä»¿æ•ˆäººï§
å°è…¦çš®è³ªåˆ†å±¤å„²å­˜è¨Šæ¯çš„æ¶æ§‹(çš®è³ªåˆ†å±¤å…±åˆ†æˆ
åˆ†å­å±¤ã€ç´°èƒå±¤ã€ï§¹ï§ºå±¤)ï¼Œå®ƒæ˜¯ç”± J. S. Albus æ ¹
æ“š Marr æ‰€ç™¼è¡¨ä¹‹å°è…¦æ¶æ§‹æ–¼ 1975 ï¦æå‡º
[12]ã€‚æ­¤æ¶æ§‹æ˜¯ï§ç”¨å¤šå±¤è¶…ï§·æ–¹å¡Š(hypercube)
èˆ‡è¨˜æ†¶ç´°èƒ(memory cell)çš„æ¦‚ï¦£ï¼Œä¸¦ï§ç”¨æ˜ å°„
(mapping)çš„æŠ€å·§ï¼Œå°‡ï¥§åŒï§ºæ…‹çš„è³‡è¨Šå„²å­˜æ–¼å¤š
å±¤è¶…ï§·æ–¹å¡Šæ‰€å°æ‡‰çš„è¨˜æ†¶ç´°èƒä¸­ã€‚å› æ­¤å¿…é ˆè¦è¦
åŠƒæ¨¡æ“¬å°è…¦å„²å­˜è¨Šæ¯çš„è¨˜æ†¶é«”ï¼Œä¸¦æ ¹æ“šå­¸ç¿’éç¨‹
ä¸­ï¼Œä¾æ“šè¼¸å‡ºçš„æœŸæœ›å€¼ï¤­èˆ‡å¯¦éš›è¨˜æ†¶é«”çš„æ¬Šé‡ï¤­
æ”¹è®Šæ¬Šé‡å¤§å°åœ¨é€²ï¨ˆè¾¨ï§¼ä¹‹å‰ï¼Œé¦–å…ˆ CMAC çš„
ç¬¬ä¸€æ­¥å°±æ˜¯é€²ï¨ˆè¨˜æ†¶é«”è¨“ï¦–çš„æ­¥é©Ÿï¼Œé€éè¼¸å…¥çš„
ï¥«è€ƒè³‡ï¦¾é€²ï¨ˆè¨˜æ†¶é«”æ¬Šé‡ä¹‹èª¿æ•´ã€‚è€Œåœ– 4 ä¸­ï¼Œä¸»
è¦æ˜¯åŒ…å«ï¥¸å€‹å­é›»ï¤·ï¼Œåˆ†åˆ¥ç‚º Yout Calc é›»ï¤·å’Œ
Weighting Adjust é›»ï¤·ã€‚Yout Calc é›»ï¤·ä¸»è¦æ˜¯è¨ˆ
ç®—ç›®å‰è©²è¡¨æƒ…æ‰€å°æ‡‰åˆ°å…¨éƒ¨è¨˜æ†¶é«”ä¹‹ç¸½å’Œã€‚é€é
ç°¡å–®çš„è¨˜æ†¶é«”ï¥šå–å‹•ä½œèˆ‡ï¥åŠ å™¨çš„é›»ï¤·ï¼Œå°‡è¨˜æ†¶
é«”ä¹‹ç¸½å’Œè¨ˆç®—å‡ºï¤­ã€‚è€Œ Weighting Adjust é›»ï¤·ä¸»
è¦æ˜¯æ ¹æ“šå…¬å¼(5)é€²ï¨ˆè¨˜æ†¶é«”æ¬Šé‡ä¹‹èª¿æ•´ï¼Œï§ç”¨
è¨ˆç®—å‡ºï¤­ä¹‹ Yout èˆ‡è¼¸å…¥ä¹‹ï¥«è€ƒè³‡ï¦¾æ‰€å°æ‡‰åˆ°çš„
è¨˜æ†¶é«”ä½ç½®ä¹‹å€¼é€²ï¨ˆèª¿æ•´èˆ‡è¨˜æ†¶é«”ï¤æ–°ã€‚ 
G
yyWWWW diii )(11 âˆ’+=Î”+= âˆ’âˆ’ Î²       
  (5) 
i  ï¼šç¬¬ i æ¬¡çš„å­¸ç¿’ 
G ï¼šæ¯å€‹å–æ¨£ï§ºæ…‹é»æ‰€å°æ˜ ä¹‹è¨˜æ†¶é«”å–®å…ƒçš„
å€‹ï¥© 
ydï¼šï§¤æƒ³çš„æœŸæœ›å€¼ 
y  ï¼šè¨˜æ†¶é«”å€‹ï¥©ä¹‹ç¸½å’Œ 
Î²  ï¼šå­¸ç¿’ï¥¡(learning rate) 
 
è¡¨ 2. CMAC åˆ†ç¾¤ 4 ä½å…ƒä¹‹è¾¨ï§¼çµæœ 
 é«˜èˆˆ é›£é 
é©š
è¨ 
ç”Ÿ
æ°£ 
å™
å¿ƒ 
ç„¡
è¡¨
æƒ…
è¾¨ï§¼
ï¥¡ 
é«˜èˆˆ 10 0 0 0 0 0 100%
é›£é 0 9 1 0 0 0 90% 
é©šè¨ 0 1 8 0 0 0 80% 
ç”Ÿæ°£ 0 1 0 7 2 0 70% 
å™å¿ƒ 0 0 0 7 9 0 90% 
ç„¡è¡¨
æƒ… 0 0 0 0 0 10 100%
å¹³å‡ 88.3%
 
è¡¨ 3. åˆ†ç¾¤ 6 ä½å…ƒä¹‹è¾¨ï§¼çµæœ 
 
é«˜
èˆˆ 
é›£
é 
é©š
è¨ 
ç”Ÿ
æ°£ 
å™
å¿ƒ 
ç„¡ 
è¡¨æƒ… è¾¨ï§¼ï¥¡
é«˜èˆˆ 0 1 0 0 0 1 80% 
é›£é 0 8 0 0 0 2 80% 
é©šè¨ 0 0 7 0 0 3 70% 
ç”Ÿæ°£ 0 2 1 6 0 1 60% 
å™å¿ƒ ï¼‘ 2 0 0 7 0 70% 
ç„¡è¡¨æƒ… 0 0 0 0 0 10 100% 
å¹³å‡ 76.6% 
 
æœ¬ï¥æ–‡æ‰€æå‡ºä¹‹äººè‡‰è¡¨æƒ…è¾¨ï§¼ï¼Œåœ¨è‘—åçš„
JAFFE äººè‡‰è³‡ï¦¾åº«ä¸Šï¼Œè¾¨ï§¼ï¥¡ä¸Šæœ€é«˜å¯é”åˆ°
88.3%ï¼Œè€Œåœ¨æ¼”ç®—æ³•çš„ç¡¬é«”ç§»æ¤ä¸Šä¹Ÿç§»æ¤çš„éå¸¸
æˆåŠŸï¼Œåœ¨è‡ªï¨ˆé–‹ç™¼ä¹‹å°æ³¢è½‰æ› IP èˆ‡ï§å°è…¦æ¨¡å‹
IPï¼Œæ‡‰ç”¨åœ¨è¡¨æƒ…è¾¨ï§¼ä¸Šå¹¾ä¹èˆ‡æ¨¡æ“¬ä¹‹çµæœä¸€æ¨¡ä¸€
æ¨£ã€‚ 
åœ¨æœªï¤­ç ”ç©¶æ–¹é¢ï¼Œæˆ‘å€‘å°‡è‘—æ‰‹é€²ï¨ˆå‹•æ…‹å½±åƒè³‡ï¦¾
åº«ä¸Šé€²ï¨ˆäººè‡‰è¾¨ï§¼ï¼Œç”±æ–¼åœ¨éœæ…‹å½±åƒè¾¨ï§¼ä¸Šï¼Œç„¡
éœ€è€ƒæ…®åˆ°å…‰æºçš„å¼·å¼±æ‰€é€ æˆè¾¨ï§¼çš„çµæœï¼Œå¦‚ç•¶å…‰
ç·šï¥§è¶³æ™‚ï¼Œåœ¨äººè‡‰å½±åƒè³‡è¨Šæœƒéå°‘ï¼Œä¸”é›œè¨Šé
å¤šï¼Œä½¿å¾—åœ¨è¾¨ï§¼ä¸Šå®¹ï§ é€ æˆèª¤åˆ¤çŸ¥å•é¡Œã€‚å› æ­¤å¦‚
ä½•é€²ï¨ˆå…‰æºè£œå„Ÿæ˜¯æœªï¤­ç ”ç©¶ä¹‹èª²é¡Œã€‚å¦å¤–å†è¨˜æ†¶
é«”å„²å­˜éƒ¨åˆ†ï¼Œç”±æ–¼ç›®å‰æ˜¯æ¡ç”¨ SRAM èˆ‡ Block 
RAM ç•¶ä½œè¨˜æ†¶é«”å„²å­˜è£ç½®ï¼Œåœ¨è™•ï§¤å½±åƒä¸Šï¼Œåª
å¯è™•ï§¤åœ¨ 256 x 256 å½±åƒä¹‹å¤§å°ï¼Œä¸”å°æ–¼è¼ƒè¤‡é›œ
ä¹‹å½±åƒè™•ï§¤ï¼Œæœƒé€ æˆè¨˜æ†¶é«”ï¥§è¶³ä¹‹å•é¡Œï¼Œæœªï¤­æˆ‘
å€‘å°‡ç ”ç™¼ DDR SDRAM ï¤­ç•¶ä½œæˆ‘å€‘å„²å­˜è£ç½®ï¼Œ
ä»¥ï¥¥é€²ï¨ˆå…¶ä»–ç›¸é—œæ¼”ç®—æ³•ä¹‹é–‹ç™¼ã€‚ 
 
äº”ã€ï¥«è€ƒæ–‡ç» 
[1] M. Lyons, S. Akamasku, M. Kamachi, 
and J. Gyoba, â€œCoding facial expressions 
with Gabor wavelets,â€ In Proceedings of 
International Conference on Face and 
Gesture Recognition, 1998. 
[2] Y. Tian, T. Kanade, and J. Cohn. 
â€œ Eye-state action unit detection by 
Gabor waveletsâ€ . In Proceedings of 
International Conference on Multi-modal 
Interfaces (ICMI 2000), pp. 143-150, 
Sept, 2000. 
[3] Z. Zhang, M. Lyons, M. Schuster, and S. 
Akamatsu, â€œComparison between 
geometry- based and 
gabor-wavelets-based facial expression 
recognition using multi-layer perceptron,â€ 
In International Workshop on Automatic 
Face and Gesture Recognition, pp. 
454-459, 1998. 
[4] Xiao-xu Qi, JIANG Wei. â€œApplication of 
Wavelet Energy Feature in Facial 
Expression Recognition,â€œ In 
Auti-counterfeiting, Security, 
Identification, 2007 IEEE International 
Workshop, pp. 169-174, 2007. 
[5] Ying-li Tian Takeo Kanade and Jeffery F. 
Cohn,â€ Evaluation of 
Gabor-Wavelet-Based Facial Action Unit 
Recognition in Image Sequences of 
Increasing Complexity,â€ Proceedings of 
the Fifth IEEE International Conference 
on Automatic Face and Gesture 
Recognition, 2002. 
[6] P. Ekman and W.V. Friesen, â€œThe facial 
action coding system: a technique for the 
measurement of facial movement,â€œ San 
Francisco: Consulting Psychologists 
Press, 1978. 
[7] H.A. Rowley, S. Baluja, T. Kanade, 
â€œNeural network-based face 
detection,â€œ IEEE Trans. Pattern Analysis 
and Machine Intelligence, vol.20, no.1, 
pp. 23-38, Jan, 1998. 
[8] H.A Rowley. S. Baluja, T, Kanade, 
â€œRotation Invariant neural network-based 
face detection,â€œ Proc. IEEE Conf, 
Computer Vision and Pattern 
Recognition, pp. 38-44, 1998. 
[9] Xilinx Virtex-4 ç›¸ é—œ è³‡ ï¦¾ , 
http://www.xilinx.com/ 
support/documentation/virtex-4.htm. 
[10] A. Grossmann, J. Morlet, 
â€œDecomposition of hardy functions into 
square integrable wavelets of constant 
shape,â€ SIAM Math Anal. Vol.15, pp. 
723-736, 1984. 
[11] A. Grossmann, J. Morlet, 
â€œDecomposition of functions into 
wavelets of constant shape and related 
transforms in mathematics and physics,â€ 
é™„ï¤¿A å‡ºå¸­åœ‹éš›å­¸è¡“æœƒè­°å¿ƒå¾—å ±å‘Š 
 
è¨ˆç•«ç·¨è™Ÿ ï¼šNSC96-2221-E-167019-MY2 
è¨ˆç•«åç¨±ï¼šç¾å ´ï¤“è¼¯é™£ï¦œé–˜ç¡¬é«”å¹³å°æ–¼è‡‰éƒ¨è¡¨æƒ…è¾¨ï§¼èˆ‡ 
æƒ…ç·’åˆ†æç³»çµ±ä¹‹ç ”ç©¶èˆ‡è¨­è¨ˆ 
 
å‡ºåœ‹äººå“¡å§“å ï§´ç¶ç”Ÿ 
æœå‹™æ©Ÿé—œåŠè·ç¨± åœ‹ï§·å‹¤ï¨—ç§‘æŠ€å¤§å­¸ è³‡è¨Šå·¥ç¨‹ç³»æ•™æˆ 
æœƒè­°æ™‚é–“åœ°é» 2009 8/18 â€“ 8/20    ä¸­åœ‹å¤§ï§“  è¥¿å®‰ 
æœƒè­°åç¨± 2009 Fifth  International Conference on 
Information Assurance and Security 
ç™¼è¡¨ï¥æ–‡é¡Œç›® Facial Expression Recognition Based on Field 
Programming Gate Array 
 
ä¸€ã€ï¥«åŠ æœƒè­°ç¶“é 
2009 Fifth  International Conference on Information Assurance and 
Securityæ–¼2009ï¦08/18-08/20åœ¨å¤§ï§“è¥¿å®‰èˆ‰è¾¦ï¼Œæœ¬äººç‚ºè©²ç ”è¨æœƒB02:Multimedia 
Processing and Multimedia Interaction è­°ç¨‹ä¸»å¸­ã€‚æœ¬äººå¸¶ï¦´åšå£«ç­å­¸ç”Ÿå»–åˆå„€åŒå­¸
ï¥«èˆ‡ï¼Œæ–¼ 08/18 æŠµé”è¥¿å®‰ã€‚08/19 ï¥«èˆ‡è­°ç¨‹å§”å“¡æœƒè­°å¾Œï¼Œï¥«èˆ‡å„ç ”è¨æœƒå ´ä¹‹å ±å‘Šã€‚
08/19 é™¤ä¸»æŒ Multimedia Processing and Multimedia Interaction è­°ç¨‹å¤–ï¼Œå»–åˆå„€åŒ
å­¸å ±å‘Šå…¶ï¥æ–‡ä¸¦ï¥«èˆ‡å„ç ”è¨æœƒå ´ä¹‹å ±å‘Šã€‚08/19 ï¥«èˆ‡å„ç ”è¨æœƒå ´ä¹‹å ±å‘Šã€‚ 
 
äºŒã€èˆ‡æœƒå¿ƒå¾— 
æœ¬æ¬¡æœƒè­°ä¸­æ‰€å®‰æ’çš„ä¸»è¦ç ”ç©¶èˆ‡è¨ï¥çš„ä¸»é¡Œå¦‚ä¸‹ï¼š 
1. Facial Expression Recognition Based on Field Programming Gate Array 
2. Analysis and Evaluation of Contrast Enhancement Methods in Digital Images 
3. Contrast Enhancement Method Based on Average Luminance with Weighted 
Histogram Equalization 
4. Application of Averaged Learning Subspace Method in MRI Classification 
5. Low Bit Rate ROI-Based SAR Image Compression 
6. Optimal Information Rates of Novel Graph Based Access Structures 
7. A Rapid Algorithm and its implementation for Modular Inversion 
 
ä¸‰ã€æ”œå›è³‡ï¦¾åç¨±åŠå…§å®¹ 
æœ¬æ¬¡æœƒè­°æ”œå›2009 Fifth  International Conference on Information Assurance and 
Securityçš„ï¥æ–‡é›†ä¸€æœ¬ï¼Œå…§å®¹ç‚ºå„ä¸»é¡Œæœƒè­°ä¸­æ‰€ç™¼è¡¨çš„ï¥æ–‡ã€‚ 
 
 
 
 
 
Facial Expression Recognition Based on Field Programmable Gate Array 
Jzau-Sheng Lin*, Shao-Han Liou*, Wu-Chih Hsieh*, Yu-Yi Liao*, HongChao Wang**, and QingHua Lan** 
*Department of Computer Science and Information Engineering 
National Chin-Yi University of Technology,
No. 35, Lane 215, Sec. 1, Chung-Shan Rd., Taiping, Taichung, Taiwan. 
TEL: 886-4-23924505 ext 7311 FAX: 886-4-23917331
E-mail: jslin@ncut.edu.tw, liou@ncut.edu.tw   
**Embedded Laboratory, Huaxia Vocation College, Xiamen, China 
Abstract 
In this paper, we proposed a hardware system with 
Field Programmable Gate Array (FPGA) for facial 
expression recognition which used Haar Discrete 
Wavelet Transform (DWT) and Cerebellar Model 
Articulation Controller (CMAC).  
 Firstly, the facial expression features are 
automatically extracted and preprocessed to obtain the 
frontal view of faces. A 2D DWT IP is then used to 
decrease the size of images. Thirdly, a block size of the 
lower frequency of DWT coefficients is rearranged as 
input vectors with binary manner to send into the 
proposed CMAC IP that can rapidly obtain output 
using non-linear mapping with look-up table in 
training or recognizing phase. Finally, the 
experimental results demonstrated recognition rates 
with a block size of coefficient in lower frequency to 
recognize six expressions, including happiness, 
sadness, surprise, anger, disgust and natural to show 
promising recognition results. 
Key words: CMAC, FPGA, Facial expression 
recognition, Feature extraction 
1. Introduction 
Human being is a social animal and their facial 
expressions play a significant role in communication. 
Facial expressions are facial movements in response to 
the internal affective state, psychological state, and 
cognitive activity of a man. In recent years facial 
expression recognition has become an active research 
topic and a number of methods have been proposed in 
the literature [1-4].  
Ekman and Friesen [5] proposed the six basic 
emotions that possess each a distinctive content 
together with a unique facial expression for the 
standard of classification of recognition in 1971 and 
developed the well-known Facial Action Coding 
System (FACS) for facial expression description. The 
FACS provides 46 Action Units (or AUs) to describe 
any facial expression of human being and indicates 
eyebrows, eyes and mouth that are the key features for 
facial expression recognition. 
The two dimensional DWT is often used in signal 
and image compression, because it can concentrate the 
most of signal information into low frequency 
components. It also had been utilized in 2D facial 
expression recognition in recent years. In reference 3, 
they used the entire facial image to obtain 2D DWT 
coefficients to facial expression recognition. 
The CMAC was proposed by Albus [6]. It is a 
supervised neural network of associative memory 
based on table look-up method. The advantages of 
CMAC are fast learning, simple computation, local 
generalization, non-linear mapping, and can be easily 
implemented by the hardware. In this paper, hardware 
implementation of a recognition technique with FPGA 
is proposed, which used the 2D DWT over the entire 
face image as a facial expression feature extractor and 
the CMAC with clustering memory as a classifier. 
2. The 2D DWT and the proposed CMAC 
network (DWT-CMAC) 
The facial expression recognition system based on 
2D DWT and the CMAC network is proposed in order 
to recognize facial expression, in which a difference 
image by subtracting a neutral image from a given 
expression image was obtained  
Wavelet transformations are a method of 
representing signals into conversion of time-frequency 
2009 Fifth International Conference on Information Assurance and Security
978-0-7695-3744-3/09 $25.00 Â© 2009 IEEE
DOI 10.1109/IAS.2009.266
547
4.1. DWT IP 
The block diagram of the proposed DWT module is 
shown as Figure 3. The DWT module can be divided 
into two modules such as controller module and 
operation module respectively. The input image was 
normalized with a size of 128128 u . The DWT 
module did wavelet transformation when signal 
DWT_Done was changed to high state. The 
transformation process was divided into horizontal and 
vertical phases in accordance with Haar transformation. 
In the block RAM, 16k bytes are used to store an 
image while the other 16k bytes are used as the 
processing buffer.  
Figure 3 Block diagram of the DWT module
In the DWT Controller module, the column and 
row locations of the transformed image and memory 
address are generated. As obtained Row and Column, 
we can get the memory with ColumnRow u128  in 
accordance with the base address. The base addresses 
are 0 and 16384 (for a 128128 u  image) for 
horizontal and vertical transformation individually.   
Figure 4 CMAC Training circuit
4.2. CMAC IP 
The input data of the CMAC IP was extracted from 
the low-frequency band of Haar DWT transformation. 
Owing to huge memory to be used for the CMAC and 
limited space of block RAM, an external SRAM was 
selected to store weighting parameters of the CMAC.  
In the proposed system, the LL-band data of the DWT 
occupies 3232 u  bytes. Therefore, we have 
819283232  uu  bits for the CMAC input layer. In 
order to simplifier the input coding circuit of the 
CMAC, we divided a nun-overlap 22 u  block as a 
training sample for the 3232 u  LL-band data and 
selected an SRAM to store the coding addresses with a 
size of 3072121616  uu bits. Figure 4 shows the 
block diagram of CMAC training circuit. 
In the recognition phase, the unknown input data 
are mapped into memory by using the Weight 
Summation Module shown as in Figure 5 to find the 
weights and sum them as total weights to express the 
intensities for different facial expressions. Then, we 
used the Max module in Figure 5 to find the maximum 
facial-expression intensity. A block size of 22u  was 
summed and divided as three branches as partial data 
in CMAC input ports. Therefore, a tested image 
occupied 12288 memory words for 768 input data 
( 76834
1024  u ) and 16 locations for each data.  
5. Experimental results 
The facial express patterns were obtained from 
JAFFE database and transmitted through the image 
interface in an FPGA SoC platform with Virtex IV-
ML40X. The six facial expressions include neutral (N), 
happiness (H), sadness (S), anger (A), disgust (D), and 
surprise (P) of 10 Japanese female models in JAFFE 
database were used in our experiments. Each person 
was recoded three images for each expression. In our 
simulation experiments, two images of each expression 
were used for network training and the remainder 
images were used for testing, namely 120 subjects for 
training and 60 subjects for testing. For the CMAC 
network, learning rate was set 0.005 and the sizes of 
cluster were set 2, 4, and 6 bits, respectively. If the 
cluster size is small, the CMAC will have more 
clusters. Tables 5.1 and 5.2 show the recognition rates 
with 4-bit and 6-bit clusters. From the experimental 
results, we find that a CMAC hard IP with 4-bit cluster 
can obtain better recognition rate than other cluster 
sizes. 
549
