 2 
å·¥ä½œä¸­ï¼Œåœ¨æ¯å€‹é‹ç®—ç¯€é»çš„æœ€é•·ï¤·å¾‘ï¼Œä¸¦é¸æ“‡
æ“æœ‰æœ€çŸ­çš„æœ€é•·ï¤·å¾‘çš„é‹ç®—ç¯€é»ï¤­æ”¾ç½®è¢«è€ƒ
æ…®çš„å­å·¥ä½œã€‚è€ŒCSï¼Œé™¤ï¦ºè€ƒæ…®å¾èµ·å§‹å­å·¥ä½œåˆ°
è¢«è€ƒæ…®æ’ç¨‹çš„å­å·¥ä½œå¤–(PSçš„ä½œæ³•)ï¼Œé‚„è€ƒæ…®å¾
è¢«æ’ç¨‹çš„å­å·¥ä½œåˆ°çµæŸå­å·¥ä½œçš„æœ€é•·ï¤·å¾‘ï¼Œå°‡
è¢«è€ƒæ…®æ’ç¨‹çš„å­å·¥ä½œæ”¾åœ¨å…·æœ‰é€™ï¥¸å€‹å€¼çš„æœ€
å°åŠ ç¸½å€¼çš„é‹ç®—ç¯€é»ä¸Šã€‚CDæ’ç¨‹æ¼”ç®—æ³•ï§ä¼¼CS
æ’ç¨‹æ¼”ç®—æ³•ï¼Œä½†æ˜¯CDèˆ‡PSã€CSï¥§åŒçš„æ˜¯ï¼ŒCD
æœƒå‹•æ…‹å»è¨ˆç®—æ–°çš„å„ªå…ˆåºè€Œï¥§æ˜¯ä½¿ç”¨éœæ…‹çš„
rankå€¼ï¤­æ’ç¨‹å·¥ä½œã€‚ 
 
ä¸€å€‹BOT applicationåŒ…å«ï¦ºè¨±å¤šçš„
independent tasksï¼Œè€Œé€™äº›å·¥ä½œä¹‹é–“ä¸¦æ²’æœ‰
ç›¸ä¾æ€§å­˜åœ¨ï¼Œæ‰€ä»¥ä¹Ÿæ²’æœ‰åŸ·ï¨ˆå…ˆå¾Œçš„é™åˆ¶ã€‚BOT
ä¾æ“šç‰¹æ€§çš„ï¥§åŒå¯ä»¥åˆ†ç‚ºCBOT (computa-
tionally intensive BOT application)ä»¥åŠ
DBOT(data intensive BOT application)ã€‚åœ¨
[3]ä¸­ï¼Œé‡å°é€™ï¥¸ç¨®ï§å‹çš„BOTåˆ†åˆ¥æå‡ºæ’ç¨‹æ¼”
ç®—æ³•ï¼Œç¨±ç‚ºMQD(Multiple Queues with Du-
plication)èˆ‡SLI (Share-Input-data-based 
Listing)ï¼ŒMQDæ’ç¨‹æ¼”ç®—æ³•è™•ï§¤CBOTè€ŒSLIè™•ï§¤
DBOTã€‚MQDæ’ç¨‹æ¼”ç®—æ³•è—‰ç”±ä¸€å€‹é‹ç®—ç¯€é»å·¥ä½œ
å…¨éƒ¨åŸ·ï¨ˆå®Œç•¢å¾Œï¼Œä¾è©²é‹ç®—ç¯€é»åŸ·ï¨ˆå‰ä¸€å€‹å·¥
ä½œæ™‚çš„æ•ˆèƒ½ï¼Œçµ¦äºˆè©²é‹ç®—ç¯€é»ä¸€å€‹rankå€¼ï¼Œåš
ç‚ºåˆ†é…ä¸‹ä¸€å€‹å·¥ä½œçµ¦è©²é‹ç®—ç¯€é»çš„ï¥«è€ƒï¼Œå¦‚æœ
é‹ç®—ç¯€é»çš„rankå€¼è¼ƒé«˜ï¼Œå°±è™•ï§¤é‹ç®—ï¥¾å¤§çš„å·¥
ä½œï¼Œè€Œrankå€¼ç›¸å°è¼ƒä½çš„é‹ç®—ç¯€é»å‰‡è™•ï§¤é‹ç®—
ï¥¾è¼ƒå°çš„å·¥ä½œã€‚å¦å¤–åœ¨æŸäº›æƒ…æ³ï¼Œæœƒè§¸ç™¼task 
duplicationçš„æ©Ÿåˆ¶ï¼Œç›®çš„åœ¨æ–¼ï¨‰ä½æ•´é«”å·¥ä½œ
åŸ·ï¨ˆæ™‚é–“(makespan)ã€‚SILè—‰ç”±æ€è€ƒå·¥ä½œä¹‹é–“
share-inputçš„æƒ…æ³å»ºï§·ä¸€å€‹task listï¼Œæœ‰åŒ
æ¨£share inputçš„taskè¼ƒæœ‰å¯èƒ½è¢«åˆ†é…åˆ°åŒä¸€
å€‹é‹ç®—å€(site)ï¼Œè€Œæ­¤listæœƒåœ¨æ¼”ç®—æ³•åŸ·ï¨ˆé
ç¨‹ä¸­å‹•æ…‹çš„é‡çµ„ã€‚SILä¹Ÿè·ŸMQDä¸€æ¨£ï¼Œåœ¨æŸäº›æƒ…
æ³ä¹Ÿè§¸ç™¼task duplicationã€‚æœ¬ç¯‡æå‡ºçš„é€™ï¥¸
å€‹æ¼”ç®—æ³•å…·æœ‰ä¸€äº›è¼ƒç‰¹æ®Šçš„ç‰¹æ€§ï¼š(1)é€™ï¥¸å€‹
æ¼”ç®—æ³•ï¨¦ï¥§éœ€è¦çŸ¥é“å­å·¥ä½œåœ¨æŸå€‹é‹ç®—ç¯€é»
ä¸Šé ä¼°çš„åŸ·ï¨ˆæ™‚é–“ï¼Œå› ç‚ºï¥§æœƒè—‰ç”±å·¥ä½œé ä¼°æ™‚
é–“ï¤­è€ƒæ…®æ’ç¨‹ï¼Œæ‰€ä»¥ï¥§ç”¨æ“”å¿ƒé ä¼°åŸ·ï¨ˆæ™‚é–“ç”¢
ç”Ÿèª¤å·®çš„æ™‚å€™å°æ¼”ç®—æ³•æ•ˆèƒ½é€ æˆçš„è¡æ“Šã€‚(2)
å‚³çµ±çš„list based æ’ç¨‹æ¼”ç®—æ³•æ˜¯å°‡å·¥ä½œæ’æˆ
listä¸¦ä¸”çµ¦äºˆæ¯å€‹å·¥ä½œrankå€¼ï¼Œè€ŒMQDå‰‡æ˜¯çµ¦
äºˆé‹ç®—ç¯€é»rankå€¼ï¼Œè€Œé‹ç®—ç¯€é»çš„rankå€¼æœƒéš¨
è‘—å…ˆå‰åŸ·ï¨ˆå·¥ä½œçš„è¡¨ç¾å‹•æ…‹çš„æ”¹è®Šã€‚ 
 
å››ã€ç ”ç©¶æ–¹æ³• 
 
åœ¨æœ¬ç ”ç©¶ä¸­ï¼Œï¥¸ï§çš„ Models å¿…é ˆäº‹å…ˆå®š
ç¾©æ‰èƒ½é‡å°è³‡æºé‡æ–°é…ç½®çš„ç¶²æ ¼é‹ç®—å¹³å°æ
å‡ºé©ç”¨çš„ç­–ï¥¶ï¼Œç¬¬ä¸€ï§ç‚ºTask Modelï¼Œæ­¤Model
é™¤ï¦ºç”¨æ–¼æè¿°ä¸€å€‹å·¥ä½œä¸­æ‰€æœ‰å­å·¥ä½œ
(subtasks)çš„é‹ç®—ï¥¾èˆ‡è³‡ï¦¾ç›¸ä¾æ€§ï¼Œæˆ‘å€‘å°‡ç´
å…¥ä¸€èˆ¬æ€§ç¨‹å¼èªè¨€å°é€šä¿¡èªæ³•çš„è¦ç¯„ï¼Œé€™æˆ–è¨±
æœƒå° Task Model æ‰€æè¿°çš„å­å·¥ä½œåŸ·ï¨ˆé‹ç®—çš„
æ¨¡å¼æœ‰æ‰€é™åˆ¶ï¼Œä½†æˆ‘å€‘èªç‚ºåªè¦æ­¤ Task Model
èƒ½å¢åŠ æ•ˆèƒ½é æ¸¬ä¸Šçš„ï¨æº–ï¨ï¼Œä¸”ï¥§æœƒå› æ­¤é€ æˆ
æ‡‰ç”¨ç¨‹å¼è¨­è¨ˆä¸Šçš„å›°é›£ï¨åŠè©²ç¨‹å¼çš„æ™‚é–“è¤‡
é›œï¨ä¹‹ä¸‹ï¼Œæˆ‘å€‘ä»èªç‚ºé€™æ˜¯ä¸€å€‹æœ‰åƒ¹å€¼çš„Task 
Modelã€‚æˆ‘å€‘å°‡ä¸€å€‹åˆ†æ•£å¼çš„å·¥ä½œè¦–ç‚ºå¯åˆ†è§£
æˆä¸€å€‹èµ·å§‹å­å·¥ä½œ(entry subtask)ã€ä¸€å€‹çµ
æŸå­å·¥ä½œ(exit subtask)å’Œè¨±å¤šçš„ä»‹æ–¼è€…ï¥¸
è€…ä¹‹é–“çš„å­å·¥ä½œ(intermediate subtasks)çš„
é›†åˆã€‚èµ·å§‹å­å·¥ä½œç‚ºæ‰€æœ‰å­å·¥ä½œä¸­ç¬¬ä¸€å€‹è¢«åŸ·
ï¨ˆçš„ï¼Œä¹Ÿå°±æ˜¯åˆ†æ•£å¼å·¥ä½œçš„èµ·å§‹é»ã€‚è€Œæ‰€éœ€çš„
è¼¸å…¥è³‡ï¦¾æœƒè¢«å­˜æ”¾åœ¨å…¶é‹ç®—ç¯€é»çš„ local 
storageã€‚çµæŸå­å·¥ä½œç‚ºåˆ†æ•£å¼å·¥ä½œå®Œæˆä¹‹
å‰ï¼Œæœ€å¾Œä¸€å€‹åŸ·ï¨ˆçš„å­å·¥ä½œã€‚è€Œåˆ†æ•£å¼å·¥ä½œåŸ·
ï¨ˆå®Œç•¢çš„çµæœå°‡å­˜æ”¾åœ¨çµæŸå­å·¥ä½œæ‰€å±¬çš„é‹
ç®—ç¯€é»çš„ local storageã€‚åœ¨ä¸€èˆ¬çš„æƒ…æ³ï¼Œå­å·¥
ä½œçš„è¼¸å‡ºé€šå¸¸ç‚ºå¦å¤–æŸäº›å­å·¥ä½œçš„è¼¸å…¥è³‡
ï¦¾ã€‚å¦‚æœå­å·¥ä½œ j éœ€è¦å­å·¥ä½œ i å®Œæˆæ™‚æ‰€ç”¢ç”Ÿ
çš„è¼¸å‡ºä½œç‚ºè¼¸å…¥è³‡ï¦¾ï¼Œæˆ‘å€‘ç¨±å­å·¥ä½œ i ç‚ºå­å·¥
ä½œ j çš„ predecessorï¼Œè€Œå­å·¥ä½œ j ç‚ºå­å·¥ä½œ i çš„
successorã€‚å°‡å­å·¥ä½œæ‰€éœ€çš„è¼¸å…¥è³‡ï¦¾ä»¥ä¸€å€‹è¨Š
æ¯(message)å‚³é€ã€‚ç•¶å­å·¥ä½œåŸ·ï¨ˆå®Œç•¢ä¹‹å¾Œï¼Œæ‰
èƒ½å°‡è©²å­å·¥ä½œæ‰€ç”¢ç”Ÿè¼¸å‡ºä»¥è¨Šæ¯å‚³é€çµ¦å­å·¥
ä½œçš„ successorsã€‚ä¸€å€‹å­å·¥ä½œå¿…é ˆç­‰åˆ°å…¶æ‰€éœ€
çš„æ‰€æœ‰è¼¸å…¥è³‡ï¦¾ï¨¦å·²ç¶“æ¥æ”¶åˆ°ï¦ºæ‰èƒ½é–‹å§‹åŸ·
ï¨ˆã€‚åœ¨è¨±å¤šå¹³ï¨ˆç¨‹å¼çš„è¨­è¨ˆï¦µå­ä¸­ï¼Œå¦‚
MPI[4]ï¼Œå­å·¥ä½œèˆ‡ï¥©å€‹å…·æœ‰ç›¸ä¾æ€§çš„å­å·¥ä½œé€š
è¨Šæ™‚ï¼Œå¿…é ˆè¦è©³ç´°æŒ‡æ˜è¨Šæ¯å‚³é€çš„é †åºï¼Œè€Œæ¥
æ”¶è¨Šæ¯çš„é †åºä¸¦ï¥§ç”¨è©³ç´°ï¥¯æ˜ã€‚åœ¨ç‚ºå­å·¥ä½œæŒ‡
æ´¾é‹ç®—ç¯€é»æ™‚ï¼Œå¦‚æœæ²’æœ‰è€ƒæ…®ï¤­æºç«¯çš„è¨Šæ¯å‚³
é€é †åºï¼Œå¯èƒ½æœƒä½¿åˆ†æ•£å¼å·¥ä½œçš„åŸ·ï¨ˆæ™‚é–“å¢
åŠ ã€‚ç‚ºï¦ºåœ¨è¨­è¨ˆå·¥ä½œæ’ç¨‹æ¼”ç®—æ³•æ™‚ï¼Œè€ƒæ…®è¨Šæ¯
å‚³é€çš„é †åºï¼Œæˆ‘å€‘åœ¨å·¥ä½œæ¨¡å‹ä¸­ä½¿ç”¨ï¥«ï¥© Ïƒå®š
 4 
successors é›†åˆä»¥åŠ predecessors é›†åˆã€‚åœ¨
ranking phase ä¸­ï¼Œæœƒä½¿ç”¨åˆ°ï¥¸å€‹ï¥«ï¥©ï¼šå‘ä¸Šè¨ˆ
ç®—çš„å±¬æ€§å€¼ rankuèˆ‡å‘ä¸‹è¨ˆç®—çš„å±¬æ€§ rankdã€‚ï¦¨
å­å·¥ä½œ vi èˆ‡å­å·¥ä½œ vj åˆ†åˆ¥è¢«åˆ†é…åœ¨é‹ç®—ç¯€é»
pr èˆ‡ psï¼Œä¸¦ä¸”å‡è¨­ï¥¸è€…ä¹‹é–“æœ‰ç›¸ä¾é—œä¿‚(vi ç‚º
vjçš„ predecessor)ã€‚åœ¨æ­¤æƒ…æ³ä¸‹ï¼Œå­å·¥ä½œ vi å‚³é€
è³‡ï¦¾åˆ°å­å·¥ä½œ vj çš„é€šè¨ŠèŠ±è²»è¢«å®šç¾©ç‚º cij = 
dij/Brsï¼Œå…¶ä¸­ dijè¡¨ç¤ºå­å·¥ä½œ vi å‚³é€åˆ°å­å·¥ä½œ vj
çš„è³‡ï¦¾ï¥¾ï¼Œè€Œ Brs ä»£è¡¨é‹ç®—ç¯€é» pr èˆ‡ psä¹‹é–“çš„
é »å¯¬ã€‚å¦å¤–ï¼Œï¦¨å­å·¥ä½œ viå‚³é€åˆ°å­å·¥ä½œ vj çš„å¹³
å‡é€šè¨ŠèŠ±è²»ç‚º Bdc ijij /= ï¼Œå…¶ä¸­ B ä»£è¡¨æ‰€æœ‰é‹
ç®—ç¯€é»é–“çš„å¹³å‡å‚³è¼¸é »å¯¬ã€‚rankuèˆ‡ rankd è©³ç´°
è¨ˆç®—æ–¹å¼å¦‚ä¸‹ï¼š 
 
ranku(vi) = })({max )( ijjuvsuccvi cvrankw ij ++ âˆˆ  
rankd(vi)= })({max )( jijjdvpredv cwvrankij ++âˆˆ  
 
åœ¨æ’ç¨‹éšæ®µï¼ŒHEFT ä»¥åŠ CPOP æœƒï§ç”¨ï¥«ï¥©
IRT(vj) (Input Data Ready Time)ä»£è¡¨å­å·¥ä½œ vj
æœ€å¾Œä¸€ç­†æ‰€éœ€çš„è¼¸å…¥è³‡ï¦¾åˆ°é” vj æ‰€åœ¨çš„é‹ç®—
ç¯€é»çš„æ™‚é–“ï¼Œå…¶ç®—æ³•ç‚º 
 
IRT(vj) = })({max )( ijivpredv cvAFTji +âˆˆ  
 
è€Œ AFT(vi)ç‚ºå­å·¥ä½œ vi åœ¨æŸå€‹é‹ç®—ç¯€é»ç¢º
ï¨€çš„çµæŸæ™‚é–“ï¼Œç‚ºï¦ºå°‡å­å·¥ä½œåˆ†é… vi åˆ°æœ€æ°ç•¶
çš„é‹ç®—ç¯€é»ï¼ŒHEFT ä»¥åŠ CPOP å®šç¾©ï¦ºæœ€æ—©åŸ·
ï¨ˆçš„é æ¸¬æ™‚é–“æ‰€ä»£è¡¨çš„ï¥«ï¥© EST(vi, pr)ï¼Œä»¥åŠ
æœ€æ—©å®Œæˆçš„é æ¸¬æ™‚é–“çš„ï¥«ï¥© EFT(vi, pr)ï¼Œåœ¨æ’
ç¨‹éšæ®µæ™‚æœƒè¢«ç”¨ï¤­è©•ä¼°å­å·¥ä½œ vi åœ¨æ¯å€‹é‹ç®—
ç¯€é»çš„å®Œæˆæ™‚é–“ï¼Œå…¶ä¸­ pr <â‰¤0 ã€‚EST(vi, pr)
çš„å®šç¾©ç‚º max{avail(pr), IRT(vi)}è€Œ EFT(vi, pr)
çš„å®šç¾©ç‚º wirï¼‹EST(vi, pr)ã€‚ 
 
åœ¨æ­¤ç ”ç©¶ä¸­ï¼Œæˆ‘å€‘æå‡ºï¥¸å€‹å·¥ä½œæ’ç¨‹æ¼”ç®—
æ³• ï¼š COB(communication order base) ä»¥ åŠ
DDR(delayed downward ranking)ã€‚ï¥¸å€‹å·¥ä½œæ’
ç¨‹æ¼”ç®—æ³•åœ¨æ’ç¨‹æ™‚çš†è€ƒæ…®ï¦ºæˆ‘å€‘çš„æ¨¡å‹åœ¨å‚³
è¼¸ä¸Šæ‰€çµ¦äºˆçš„é™åˆ¶ã€‚åœ¨æˆ‘å€‘çš„æ’ç¨‹æ¼”ç®—æ³•ä¸­ï¼Œ
å¦‚æœå­å·¥ä½œå¯ä»¥è¢«æ’ç¨‹ï¼Œä»£è¡¨å…¶æ‰€æœ‰çš„
predecessors ï¨¦å·²ç¶“è¢«æ’ç¨‹å¥½ï¦ºã€‚è€Œå­å·¥ä½œåœ¨
å¯ä»¥è¢«æ’ç¨‹ä¹‹å‰ï¼Œå…¶ rank å€¼æœƒï¥§æ–·çš„è®Šï¤ã€‚
æˆ‘å€‘åœ¨ ranking phaseï¼Œä¸¦ï¥§æ˜¯ä½¿ç”¨ ranku èˆ‡
rankdï¤­è¨ˆç®—å­å·¥ä½œçš„ rank å€¼ï¼Œæˆ‘å€‘å°‡å…¶ä¿®æ”¹
æˆç¬¦åˆæœ¬ç ”ç©¶ä¸­ Grid Model æ‰€å®šç¾©çš„å‚³è¼¸æ¨¡
å¼ï¼Œå‘½åç‚º myranku å’Œ myrankdï¼Œï¥¸å€‹å…¬å¼çš„
æè¿°å¦‚ä¸‹ï¼š 
 
myranku(vi)=
i
vsuccvj
ijjuvsuccv wcvmyrank
ij
ij
++ âˆ‘
âˆˆ
âˆˆ
)(:
)( )}({max  
myrankd(vi)= âˆ‘
âˆˆ
âˆˆ +
)(:
)( )}({max
ij
ij
vpredvj
jijvpredv cvmyAFT  
 
å…¶ä¸­ myAFT(vi)ç‚ºåœ¨æˆ‘å€‘çš„é‹ç®—æ¨¡å‹ä¸­ï¼Œå­å·¥
ä½œ vj ç¢ºï¨€å®Œæˆæ™‚é–“ã€‚åœ¨æ’ç¨‹éšæ®µï¼Œå› ç‚ºä½¿ç”¨
IRT(vj)æ‰€è¨ˆç®—å‡ºï¤­çš„æ™‚é–“èˆ‡æˆ‘å€‘çš„é‹ç®—æ¨¡å‹
ï¥§ç¬¦åˆï¼Œæ‰€ä»¥æˆ‘å€‘çš„æ¼”ç®—æ³•ä¸¦æ²’æœ‰ä½¿ç”¨ IRT(vj)
ï¤­ç‚ºå­å·¥ä½œ vi é¸æ“‡æœ€é©åˆçš„é‹ç®—ç¯€é»ã€‚æˆ‘å€‘çš„
æ¼”ç®—æ³•è¨ˆç®—å­å·¥ä½œ vi çš„çµæŸæ™‚é–“æœƒï¥«è€ƒï¥¸å€‹
å› ç´ ï¼Œç¬¬ä¸€å€‹å› ç´ ç‚ºè³‡ï¦¾ï¤­æºç«¯ (ä¹Ÿå°±æ˜¯
predecessor)åœ¨ ISI æ¨¡å¼åº•ä¸‹ï¼Œè¼¸å‡ºè³‡ï¦¾çš„å‚³é€
é †åºã€‚ç¬¬äºŒå€‹å› ç´ ç‚ºè€ƒæ…® agent ï¥§èƒ½å¤ åŒæ™‚å‚³
é€å¤šç­†è¨Šæ¯æˆ–è€…æ˜¯åŒæ™‚æ¥æ”¶å¤šç­†è¨Šæ¯çš„é™
åˆ¶ã€‚å› æ­¤ï¼Œæˆ‘å€‘æå‡ºæ–°çš„ï¥«ï¥© myIRT(vj)ã€
myEST(vi, pr) ä»¥åŠ myEFT(vi, pr)ï¼Œç›¸é—œçš„å®šç¾©
å¦‚ä¸‹ï¼š 
myIRT(vj)= })({max
)(:
)( âˆ‘
âˆˆ
âˆˆ +
ji
ji
vpredvi
ijivpredv cvmyAFT  
myEST(vi, pr) = max{avail(pr), myIRT(vi)} 
myEFT(vi, pr) = wirï¼‹myEST(vi, pr)ã€‚ 
 
COB å·¥ä½œæ’ç¨‹æ¼”ç®—æ³•ä»‹ç´¹å¦‚ä¸‹ï¼š 
å› ç‚ºæˆ‘å€‘çš„å·¥ä½œæ¨¡å‹é‡å°è³‡ï¦¾å‚³è¼¸çš„é †
åºæœ‰å…¶é™åˆ¶ã€‚ä¹Ÿå°±æ˜¯ï¥¯ï¼Œå¦‚æœå­å·¥ä½œçš„ï¥¸å€‹
successors vièˆ‡ vjï¼Œå…¶ä¸­ vjçš„ subtask ID æ¯” vi
å¤§ï¼Œé‚£å­å·¥ä½œæœƒå…ˆå‚³é€ vi æ‰€éœ€çš„è¼¸å…¥è³‡ï¦¾ï¼Œå‚³
é€å®Œç•¢å†å‚³é€ vj æ‰€éœ€çš„è¼¸å…¥è³‡ï¦¾ã€‚ä»¥ä¸Šæƒ…æ³ï¼Œ
æˆ‘å€‘ç¨± vi å° vj ï¤­ï¥¯æ˜¯è¼ƒï¦å¹¼çš„å…„å¼Ÿ(younger 
sibling)å­å·¥ä½œï¼Œè€Œ vj å° viï¤­ï¥¯æ˜¯è¼ƒï¦é•·çš„å…„å¼Ÿ
(elder sibling)å­å·¥ä½œã€‚COB æœƒè€ƒæ…®å­å·¥ä½œå¿…é ˆ
å…ˆå° younger sibling ï¤­ä½œå‚³è¼¸çš„æ¨¡å¼ä¸¦ä¸”è¨ˆç®—
ç›¸é—œæ‰€éœ€çš„å‚³è¼¸æ™‚é–“ã€‚å¦‚æœå­å·¥ä½œ vi åœ¨è¢«æ’ç¨‹
æ™‚ï¼Œå…¶æ‰€æœ‰çš„ younger sibling ï¨¦å·²ç¶“æ’ç¨‹å®Œ
 6 
æ¨¡å‹ä»¥åŠå·¥ä½œæ¨¡å‹çš„ï¥«ï¥©ï¼Œæ·±å…¥åˆ†ææ¯å€‹æ¼”ç®—
æ³•çš„æ•ˆèƒ½ã€‚å¯¦é©—è¨­å®šé‹ç®—ç¯€é»çš„è®ŠåŒ–ï¥¾ç‚º 4, 6, 
8, 10, 12ã€‚é‹ç®—ç¯€é»é–“çš„é »å¯¬åœ¨ 1 åˆ° 50 ä¹‹é–“ï¤›
ï¥©å¹³å‡åˆ†ä½ˆã€‚ç‚ºï¦ºé”åˆ°èˆ‡ HEFT ä»¥åŠ CPOP æ¯”
è¼ƒçš„ç›®çš„ï¼Œä¸€äº›ç”¨ï¤­æ§åˆ¶æ•´å€‹åˆ†æ•£å¼å·¥ä½œçš„ï¥«
ï¥©è¨­å®šå‰‡ï¥«è€ƒ[1]ã€‚ä»¥ä¸‹ç°¡ä»‹å¹¾å€‹å¯¦é©—ä¸­è¼ƒç‚º
é‡è¦çš„ï¥«ï¥©ï¼š 
z Sv ç‚ºåˆ†æ•£å¼å·¥ä½œçš„å­å·¥ä½œï¥©ï¥¾ä¹‹é›†åˆã€‚åœ¨
å¯¦é©—ä¸­ï¼Œæˆ‘å€‘è®ŠåŒ– Sv ç‚º{60, 80, 100, 120, 
140} 
z SCCRç”¨ï¤­è¡¨ç¤ºå­å·¥ä½œå¹³å‡å‚³è¼¸èŠ±è²» tcommèˆ‡
å¹³å‡é‹ç®—èŠ±è²» tcomp çš„æ¯”å€¼ã€‚åœ¨å¯¦é©—ä¸­ï¼Œæˆ‘
å€‘è®ŠåŒ– SCCR ç‚º{0.1, 0.5, 1.0, 1.5, 2.0} 
z Sout-degree ç”¨ï¤­ä»£è¡¨é™¤ï¦ºçµæŸå­å·¥ä½œä»¥å¤–çš„
æ¯å€‹å­å·¥ä½œæ‰€æ“æœ‰çš„ successors ï¥©ï¥¾ã€‚å¯¦
é©—ä¸­ï¼Œæˆ‘å€‘è®ŠåŒ– Sout-degree ç‚º{1, 2, 3, 4, 5} 
z åœ¨æœ‰ p å€‹é‹ç®—ç¯€é»çš„ï¥§ä¸€è‡´ï¥¢è³ªç³»çµ±ä¸­ï¼Œ
é€éæ¼”ç®—æ³• alg å¯ä»¥é”åˆ°åŠ é€Ÿæ¯”å®šç¾©å¦‚ä¸‹ã€‚ 
SP(alg, P) = 
makespan
w
Vvi ijPpj ij
}{min
:: âˆ‘ âˆˆâˆˆ  
 
ç™¼ç¾åœ¨è€ƒæ…®é€šè¨Šæ¨¡å¼çš„é™åˆ¶æ™‚ï¼ŒDDR èˆ‡ COB
åœ¨å¤§å¤šï¥©çš„å¯¦é©—ç’°å¢ƒä¸‹è¡¨ç¾è¼ƒ HEFT èˆ‡ CPOP
ä½³ã€‚è—‰æ­¤æˆ‘å€‘å¯ä»¥å¾—çŸ¥ï¼Œï¥§ï¥æ˜¯è€ƒæ…®è¨Šæ¯å‚³é€
çš„é †åºæˆ–è€…æ˜¯ï§ç”¨å·²ç¶“æ’ç¨‹å®Œç•¢çš„å·¥ä½œæ‰€æ
ä¾›çš„è¨Šæ¯ï¤­é‡æ–°è¨ˆç®—å°šæœªæ’ç¨‹çš„å·¥ä½œçš„è€ƒæ…®
é †åºï¼Œå°æ–¼æå‡å·¥ä½œçš„åŸ·ï¨ˆæ•ˆèƒ½ï¼Œï¨¦æ˜¯æœ‰å¹«åŠ©
çš„ã€‚ 
 
 
ï§‘ã€ï¥«è€ƒæ–‡ç» 
 
[1] H. Topcuoglu, S. Hariri, and M.Y Wu, â€œPer-
formance-effective and low-complexity task 
scheduling for heterogeneous computing,â€ 
IEEE Trans. Parallel and Distributed Sys-
tems, vol. 13, no. 3, March 2000. 
[2] M. Maheswaran and H.J. Siegel, â€œA dynamic 
matching and scheduling algorithm for het-
erogeneous computing systems,â€ in Proc. 
Heterogeneous Computing Workshop, 1998. 
[3] Y.C. Lee and A. Y. Zomaya, â€œPractical 
scheduling of bag-of-tasks applications on 
grids with dynamic resilience,â€ IEEE Trans. 
Computers, vol. 56, no. 6, June 2007. 
[4] P. S. Pacheco, Parallel Programming with 
MPI, Morgan Kaufmann Publishers, 1997. 
[5] C.-C. Lin and C.-H. Hsu, â€œAlgorithms for 
scheduling distributed tasks of ordered 
communication on a realistic model of het-
erogeneous grids,â€ pp. 500-505, in Proc. 
IEEE/ACIS Intl, Conf. Computer and Infor-
mation Science, 2009. 
[6] C.-C. Lin, C.-W. Shih and C.-H. Hsu, 
â€œAdaptive Dynamic Scheduling Algorithms 
for Mapping Ongoing M-Tasks to PR2 
Grid,â€ accepted by Journal of Information 
Science and Engineering. 
 
 
ä¸ƒã€è¨ˆç•«æˆæœè‡ªè©• 
 
æ­¤è¨ˆç•«ç ”ç©¶æˆæœç›®å‰å·²æœ‰ä¸€ç¯‡ï¥æ–‡åœ‹éš›ç ”è¨
æœƒç™¼è¡¨[5]ï¼Œä¸€ç¯‡æ¥å—æ–¼ SCIE æœŸåˆŠ[6]ï¼Œç¸½é«”ï¤­
ï¥¯ï¼Œæ­¤è¨ˆç•«çš„åŸ·ï¨ˆæˆæ•ˆå„ªï¥¼ï¼Œç›®å‰æ­£è—‰ç”±ä¸‹ä¸€
ï¦ï¨çš„è¨ˆç•«å°‡å·²ç™¼å±•å‡ºï¤­çš„æŠ€è¡“æ•´åˆã€‚å¸Œæœ›è—‰
ç”±ï¤­ï¦è¬›å¸«ç´šç ”ç©¶åŠ©ï§¤çš„åŠ å…¥èƒ½é€²ä¸€æ­¥èª¿æ•´
ä¸¦æ•´åˆå·²ç™¼å±•å‡ºçš„æ©Ÿåˆ¶ï¼Œæ­¤ä¹ƒä¸‹ä¸€éšæ®µé‡è¦ç›®
æ¨™ã€‚ 
 
Algorithms for Scheduling Distributed Tasks of Ordered Communication on
a Realistic Model of Heterogeneous Grids
Cho-Chin Lin and Chih-Hsuan Hsu
Department of Electronic Engineering
National Ilan University
Yilan, Taiwan
cclin@niu.edu.tw
Abstract
Grid computing provides a platform for users to access
the worldwide distributed resources. To meet the timing and
quality requirements imposed by the tasks running on the
grid, the resources required by the tasks needs to be carefully
scheduled. In the last decade, a lot of scheduling algorithms
have been proposed to squeeze the computing power from a
grid. However, many of them do not consider the message-
sending order imposed by the programming syntax or do not
employ the information provided by the scheduled subtasks.
In this paper, two scheduling algorithms COB and DDR
which take the useful information into consideration are
proposed. The COB schedules tasks according to the commu-
nication restriction imposed by the programming syntax. The
DDR schedules tasks by incrementally computing the rank
values of the subtasks based on the information provided
by the scheduled subtasks. In this paper, the usefulness and
effectiveness are demonstrated by comparing our algorithms
with the well known scheduling algorithms HEFT and
CPOP.
1. Introduction
Grid computing platform integrates worldwide computa-
tion resources into a virtual supercomputer based on the
Internet infrastructure. There are two advantages of the
platform: easy access to powerful computing facilities and
effective use of the distributed resources. The resource
scheduler of a grid is responsible for assigning computing
nodes to a task. To squeeze the computing power from the
distributed computing nodes, a practical and efficient task
scheduler is needed by the resource broker. The task sched-
uler takes the task diverseness and resource heterogeneity
into consideration while assigning the tasks to the most
suitable computing nodes.
Many scheduling algorithms have been proposed to meet
the timing and quality requirements imposed by the tasks
running on the grid. In [7], the scheduling algorithms MQD
and SIL were proposed for computation intensive and data
intensive applications, respectively. Since it is hard to exactly
know the computing power of the nodes when a task is sub-
mitted to the grid, the authors proposed a strategy to estimate
the computing power for each node by combining the history
record of the nodes with their current status. The algorithms
also employ duplication heuristics to further reduce the
execution time. In [4], the algorithms called Minmin and
Maxmin were proposed. First, the algorithms identify the
most suitable computing node for each unscheduled subtask.
The most suitable computing node can finish the subtask
and its original loading in the earlier time. Next, Minmin
selects the subtask with minimum finish time and assigns
the subtask to its most suitable computing node, whereas
the Maxmin selects the subtask with maximum finish time
and assigns the subtask to its most suitable computing node.
The process is repeated until all the subtasks are scheduled.
In [2], the authors proposed a scheduling algorithm for a par-
allel application called DAGMap. DAGMap consists of three
phases: prioritizing, grouping and scheduling. DAGMap
not only uses list-based strategy but also uses clustering
technique to improve performance. In [6], a static list-based
algorithm called DCP was proposed. It is developed for
scheduling subtasks to unlimited number of fully-connected
identical processors. In [1], the fault-tolerant scheduling
algorithm DFTS was proposed. The DFTS chooses a set
of n candidate sites for the arriving job, where the value
of n is decided by the job submitter. When the number
of available candidate sites is less than n, the DFTS still
schedules the job but reserves sites for further replication. In
[8], the authors proposed a fault-tolerant scheduling policy.
Performance evaluation of scheduling policy is used to
identify the reliability of grid. The number of duplicated
tasks is according to the reliability of the grid at the time.
In [9], an algorithm called QM was proposed. The algorithm
coarsens an application graph until the number of tasks is
less than a threshold. Then, each subtask in the coarsened
graph is mapped on a randomly chosen computing node. To
improve the mapping quality by reassigning the subtasks to
other computing nodes, the theorem regarding the candidate
node selection is provided for minimizing the search time.
In [10], The authors developed a scheduling strategy which
adopted the dynamic task flow and a genetic algorithm to
  







 

 
 
 



	




















ï¬€ï¬
ï¬‚

ï¬ƒ

 !
ï¬‚
 
Figure 2. Comparisons on the performances of HEFT
achieved on different models.
node. The communication agent sends (receives) an entire
message to (from) its target (source) computing node before
it starts to send (receive) the next message. The commu-
nication agent is always running at the computing node for
sending/receiving a message or waiting for the next message.
We assume the communication agent can send and receive
messages simultaneously. However, an agent cannot send
messages to or receive messages from multiple computing
nodes at the same time. Many scheduling algorithms have
shown to be very successful for their targeting computation
model. Nevertheless, a scheduling algorithm can present
very different performances on various computation models.
Figure 2 compares the performances achieved by the well
known scheduling algorithm HEFT [11] on its original
model and our realistic computing model. The original
model can send and receive multiple messages concurrently.
The figure is drawn for 60 subtasks running on 3 computing
nodes. Each of the subtasks has three successors and the
communication to computation ratio (CCR) varies from
0.1 to 2. The figure shows that the achieved speedup of
employing HEFT on our model is less than that on its
original model.
3. Related Work
In this paper, our scheduling algorithm will compare
with two well-known list scheduling algorithms: HEFT and
CPOP [11]. A list scheduling algorithm usually consists
of two phases: ranking and scheduling. The ranking phase
decides the ranks of the subtasks in a list using a rank
function. The second phase schedules subtasks to computing
nodes according to the ranks of the tasks in the list.
Let succ(vi) and pred(vi) denote the sets of viâ€™s suc-
cessors and viâ€™s predecessors, respectively. There are two
rank attributes upward rank ranku(vi) and downward rank
rankd(vi) to be computed in the ranking phase for subtask
vi. Let subtasks vi and vj are assigned to computing
nodes pr and ps. The communication cost of transferring
data from subtask vi to vj is denoted as cij = eij/Brs,
where eij is the number of data sent from subtask vi to
subtask vj and Brs is the bandwidth between computing
nodes pr and ps. Let cij =
âˆ‘
i<j;i,j<p dij/B, where
B is the average transfer rate among all the computing
nodes. Two types of ranking functions are given as follows:
ranku(vi) = wÂ¯i + maxvjâˆˆsucc(vi){ranku(vj) + cÂ¯ij} and
rankd(vi) = maxvjâˆˆpred(vi){rankd(vj) + wj + cji}. Note
that we define ranku(v|V |âˆ’1) = w|V |âˆ’1 and rankd(v0) =
0. In the scheduling phase, the subtasks are extracted in
the order of decreasing rank. Let IRT (vj) denote the time
that all the input data needed by task vj are ready and it
equals maxviâˆˆpred(vj){AFT (vi) + cij}, where AFT (vi) is
the actual finish time of task vi. To assign subtask vi to
the most suitable computing node, the earliest start times
EST (vi, pr) and the earliest finish times EFT (vi, pr) are
computed for 0 â‰¤ r < p. EST (vi, pr) is defined as
max{avail(pr), IRT (vi)}, where avail(pr) is the time for
pr to complete all the subtasks assigned to it. EFT (vi, pr) is
defined as wir+EST (vi, pr). Based on the above notations,
HEFT and CPOP algorithms are briefly described as follows.
HEFT: The ranking phase of HEFT computes ranku(vi)
for 0 â‰¤ i < |V |. The task list is generated by
sorting the tasks in the order of decreasing ranku
value. In scheduling phase, HEFT assigns task
vi to computing node pr if EFT (vi, pr) has the
smallest values compared with EFT (vi, pk) for
0 â‰¤ k < p and k 6= r. The HEFT algorithm
not only considers the available time of computing
node, but also uses insertion based method to put
a subtask in the earliest idle time slot of two
already-scheduled subtasks. If the time slot is big
enough and precedence constraints is preserved,
the subtask is assigned in that slot.
CPOP: The CPOP computes both ranku(vi) and
rankd(vi) in the ranking phase. The subtasks in
the critical path have the same largest ranku(vi)+
rankd(vi) value [13]. Before we go to the
scheduling phase, the subtasks in the critical
path vÏ(0), vÏ(1), vÏ(2), Â· Â· Â· , vÏ(a) are extracted and
assigned to pr which is selected such thatâˆ‘a
i=0 wÏ(i)r â‰¤
âˆ‘a
i=0 wÏ(i)k for 0 â‰¤ k < p
and k 6= r. In the scheduling phase, the remain-
ing subtasks which are ready for execution are
immediately extracted and put into a set Sready.
Simultaneously, the task in Sready with the largest
ranku+rankd value is selected and assigned to the
most suitable computing node pr. The computing
node pr satisfies EFT (vi, pr) â‰¤ EFT (vi, pk) for
0 â‰¤ k < p and k 6= r. The insertion-based
scheduling policy is also employed.
4. Scheduling Algorithms
In this paper, we propose two new scheduling algorithms:
communication-order based (COB) and delayed downward
step, more than one subtask can have the prede-
cessors scheduled. In this case, the rank values of
the recently ready subtasks can be computed and
added into the list Lready.
5. Experimental Results and Analysis
The experiments are conducted by intensive simulations
on various parameter settings for the task graph and compu-
tation model. The numbers of computing nodes used in the
simulations are set for 4, 6, 8, 10 and 12. The bandwidths
of the links are randomly selected within the range of 1 to
50. For comparison purpose, some of the parameters used
by [11] to control the task graph are also adopted in the
simulations. The parameter settings of the task graphs are
described as follows.
â€¢ SV is the set of the numbers of subtasks in a dis-
tributed task. In the simulations, we have SV =
{60, 80, 100, 120, 140}
â€¢ The height of a task is randomly generated from a
uniform distribution with a mean value âˆšnv , where
nv âˆˆ SV . For the task, the number of subtasks in a level
is also randomly selected from a uniform distribution
with mean value equal to âˆšnv . If the generated task
with the number of total subtasks less or more than nv,
then subtasks are added to or deleted from randomly
selected levels.
â€¢ wij has been previously defined as the cost of running
subtask vi on computing node pj . It is randomly
selected within the range of wi/4 and 5wi/4. In the
simulations, the mean value wi is randomly selected
within the range of 1 and 1000.
â€¢ SCCR is the set of the values used to define task average
communication cost tcomm to task average computation
cost tcomp ratio. In the simulations, we have SCCR =
{0.1, 0.5, 1.0, 1.5, 2.0}
â€¢ Soutâˆ’degree is the set of integers used to define the
numbers of successors of a subtask, except the exit
subtask. In the simulations, we have Soutâˆ’degree =
{1, 2, 3, 4, 5}.
â€¢ The weights of the edges are randomly selected
from a uniform distribution with mean value equal
to Btcompnccr, where B is the average transfer rate
among all the computing nodes, tcomp is task average
computation cost and nccr âˆˆ SCCR.
The speedup achieved by scheduling algorithm alg on
a disharmonious heterogeneous system with p computing
nodes is defined as follows.
SP (alg, P ) =
minj:pjâˆˆP {
âˆ‘
i:viâˆˆV
wij}
makespan
The comparisons of the algorithms CPOP, HEFT, COB and
DDR are given in Figure 3. A 4-tuple (|V |, |P |, CCR,OD)
is used by each figure to characterize the parameter set-
tings in the simulations, where OD refers the number of
out degrees. The data given in each figure are the aver-
age of 100 experimental results. In Figure 3(a), 3(b) and
3(c), we observe that SP (COB,P ) > SP (DDR,P ) >
SP (HEFT, P ) > SP (CPOP,P ). There are several rea-
sons for DDR and COP to achieve better performances than
HEFT and CPOP. The first reason is that the computation
of the rank values and subtask assignment in the COB and
DDR consider the capability imposed by the communication
agents running on the computing nodes. The second reason
is that DDR uses more precise information in the scheduling
step. Since the downward rank of a subtask is computed
after the predecessors of the subtask are scheduled, the rank
values for the ready subtasks can precisely capture the order
to schedule a subtask. Note that the scheduling algorithm
CPOP which assigns the subtasks on a critical path to a
single node is worse than HEFT. This also gives an evidence
that the ranku and rankd computed by CPOP for estimating
a critical path may not be appropriate for a disharmonious
heterogeneous computing system. The third reason is the
COB takes the programming syntax into consideration. In
Figure 3(d), the speedups achieved by DDR is better than
that of COB for small CCR values. The reason is that when
the task is computation intensive, the communication order
imposed by programming syntax becomes an insignificant
factor for achieving high speedup.
6. Concluding Remarks
In this paper, the task model which characterizes the
communication order imposed by the programming syntax is
proposed. Then, the computation model which captures the
limited bandwidth imposed by the communication agents
in the computing nodes is given. Based on the models,
two scheduling algorithms COB and DDR are developed
for effectively scheduling tasks to computing nodes of a
disharmonious heterogeneous computing system. The results
of our simulations have demonstrated that our algorithms
outperform the well known CPOP and HEFT algorithms
under our realistic computation model. In the future, we
consider to integrate the strategy used by COB and DDR
to squeeze the computing power for further enhance the
performance of the disharmonious heterogeneous computing
system.
Acknowledgement
This research is supported by National Science Council
under the grant 97-2221-E-197-012.
