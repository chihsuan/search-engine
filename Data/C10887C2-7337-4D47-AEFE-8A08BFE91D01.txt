1 
ç›®ï¤¿ 
 
ä¸€ã€ä¸­æ–‡æ‘˜è¦......................................................................................................................................2 
äºŒã€Abstract ........................................................................................................................................2 
ä¸‰ã€ç·£ç”±èˆ‡ç›®çš„..................................................................................................................................2 
å››ã€è¨ˆç•«å…§å®¹......................................................................................................................................3 
1. åµŒå…¥å¼ç”ŸæŠ€ç¢Ÿç‰‡æª¢æ¸¬æ•´é«”æ¶æ§‹.............................................................................................3 
2. å…‰æ©Ÿæª¢æ¸¬ä¼ºæœæ©Ÿæ§‹èˆ‡å£“é›»å¾®å‹•å¹³å°.....................................................................................3 
3. ç”Ÿé†«å½±åƒä¹‹åµŒå…¥å¼æ§åˆ¶ç³»çµ±.................................................................................................4 
4. å…‰å­¸æ”¾å¤§è®Šç„¦æª¢æ¸¬æ¶æ§‹.........................................................................................................4 
5. å£“é›»è‡´å‹•å…‰å­¸ï¨€ç‰‡æª¢æ¸¬æ¶æ§‹.................................................................................................4 
äº”ã€è¨ˆç•«æˆæœè‡ªè©•..............................................................................................................................5 
ï§‘ã€ï¥«è€ƒæ–‡ç»......................................................................................................................................5 
 3
æ¥µé€²ï¨ˆç ”ç™¼ã€‚ç›®å‰æ¥­ç•Œç‚ºæ±‚ï¨‰ä½ç–¾ç—…æª¢æ¸¬æ‰€éœ€
è€—è²»æ™‚é–“èˆ‡ï¤ŠéŒ¢æˆæœ¬ï¼Œè¶¨å‘ç¸®å°å¤šç¨®ç”Ÿç‰©åæ‡‰
éç¨‹åœ¨ä¸€å€‹å¾®å°æ™¶ç‰‡å…§é€²ï¨ˆï¼Œè—‰ä»¥å¤§å¹…æ¸›å°‘æ‰€
éœ€æ¸¬è©¦æ¶ˆè€—æ¨£å“ï¥¾ï¼ŒåŒæ™‚å¢å¿«ç”Ÿç‰©åæ‡‰é€Ÿï¨ç¸®
çŸ­æª¢æ¸¬åæ‡‰æ™‚é–“ï¼Œé€²è€Œé”åˆ°ï¨‰ä½æª¢æ¸¬éç¨‹æˆ
æœ¬ï¼Œå› æ­¤éå»ï¥©ï¦å·²æœ‰å¤šå€‹åœ‹å®¶æŠ•å…¥ç”Ÿç‰©æ™¶ç‰‡
(Biochip)ç›¸é—œç ”ç©¶äº¦ç²é¡¯è‘—æˆæœã€‚ 
ç”±æ–¼ç”Ÿç‰©æ™¶ç‰‡ç”¢è£½éœ€æŠ•å…¥é‰…é¡è³‡ï¤Šï¼Œä¸”å…¶
æª¢æ¸¬éç¨‹éœ€é€éç‰¹å®šé¾å¤§æˆ–æ˜‚è²´å„€å™¨å®Œæˆï¼Œè®Š
æˆç›®å‰å±…å®¶ç”Ÿæ´»çœ‹è­·æ‰€äºŸéœ€å³æ™‚ç”ŸæŠ€æª¢æ¸¬æœª
èƒ½å¯¦ç¾ä¸»å› ã€‚åµŒå…¥å¼å¯æ”œç”ŸæŠ€ç¢Ÿç‰‡æª¢æ¸¬ç³»çµ±ï¥´
èƒ½è€ƒæ…®ï¨‰ä½æˆæœ¬æé«˜å¤§ï¥¾ä½¿ç”¨æ„é¡˜ï¼ŒåŠ ä¸Šå¾®æ©Ÿ
é›»è£½ç¨‹èˆ‡å°è£æŠ€è¡“è“¬å‹ƒç™¼å±•æ¼¸è¶¨æˆç†Ÿï¼Œç”ŸæŠ€ç¢Ÿ
ç‰‡è£½ç¨‹åŠæª¢æ¸¬æ©Ÿé›»å…ƒä»¶æŠ€è¡“å¤§å¹…æå‡ï¼Œæ˜¯ä»¥
BioCD æœªï¤­å…·æœ‰æ¥µä½³ç™¼å±•ç©ºé–“ã€‚ 
ä¸€èˆ¬è¨€ BioCD çµæ§‹å­˜æœ‰å¤šç¨®å¾®ï§Šé“è¨­è¨ˆ
èˆ‡ï¥§åŒè‡´å‹•æ–¹å¼ï¼Œä½†å¤§é«”ä¸Šï¨¦ä»¥æ—‹è½‰ï§ªå¿ƒï¦Šæ©Ÿ
åˆ¶ç‚ºé©…å‹•åŸºç¤ï¼Œæˆ–è¼”ä»¥å…¶å®ƒç‰©ï§¤æˆ–ç”ŸåŒ–ä½œç”¨ï¦Š
ä¸¦ï¨ˆï¼Œä¸»è¦å› å…¶æª¢æ¸¬æ©Ÿåˆ¶å…·æœ‰é«˜è§£æç”Ÿé†«é¡¯å½±
èˆ‡æ“ä½œï¥¥ï§æ€§ï¼Œæ˜¯ä»¥ BioCD æœªï¤­å…·æœ‰æ¥µä½³æ‡‰
ç”¨ç©ºé–“ã€‚åŸºæ–¼ä¸Šè¿°ç”ŸæŠ€ç¢Ÿç‰‡çš„ï¥¥ï§æ€§åŠç¸®æ¸›æˆ
æœ¬å„ªå‹¢ï¼Œå°‡æœƒæˆç‚ºå®¶åº­èˆ‡å€‹äººé†«ï§å¹³å¸¸ç”Ÿæ´»ä¸€
ç’°ï¼Œå› æ­¤æœ¬è¨ˆç•«è¨­å®šæ¢è¨å…¶ç›¸é—œè¦æ ¼èˆ‡æª¢æ¸¬æ©Ÿ
åˆ¶ï¼Œä¸»è¦è‘—çœ¼å…¶å°‡æœƒæ˜¯æœªï¤­ï¥©ï¦ï¼Œæˆç‚ºè§£æ±ºäºº
ï§ç–¾ç—…èˆ‡èº«é«”ä¿å¥æ–¹é¢é‡è¦ç ”ç©¶ä¸»é¡Œã€‚ 
å››ã€è¨ˆç•«å…§å®¹ 
æœ¬è¨ˆç•«ï¦ï¨åŸ·ï¨ˆåŒ…æ‹¬åµŒå…¥å¼å¹³å°å»ºï§·ã€å³
æ™‚GUI æ§åˆ¶ä»‹é¢ã€ç¡¬é«”æ¨¡çµ„ç ”ç™¼ï¼ŒåŠå…‰æ©Ÿæª¢
æ¸¬ç›£æ§ç­–ï¥¶é–‹ç™¼ã€‚æœ¬è¨ˆç•«é€™ä¸€ï¦ï¨ç ”ç©¶æ–¹å‘ï¼Œ
è‘—é‡åœ¨ç”ŸæŠ€æª¢æ¸¬åµŒå…¥å¼æ§åˆ¶ç³»çµ±é–‹ç™¼ã€æª¢é«”å½±
åƒæ“·å–è¾¨ï§¼åˆ†æã€å£“é›»è‡´å‹•è®Šç„¦è¿´æˆæ§åˆ¶ã€åŠ
é››å‹æª¢æ¸¬å¹³å°å¯¦ä½œï¼Œè—‰ä»¥é…åˆå…¶ç”ŸæŠ€ç¢Ÿç‰‡æª¢æ¸¬
ç³»çµ±é©…å‹•æ¶æ§‹é€²ï¨ˆå·¥ä½œï¼Œä¸»è¦åˆ†ç‚ºä»¥ä¸‹å¹¾å€‹éƒ¨
åˆ†ï¥¯æ˜ã€‚ 
1. åµŒå…¥å¼ç”ŸæŠ€ç¢Ÿç‰‡æª¢æ¸¬æ•´é«”æ¶æ§‹ 
ç”±æ–¼ç›®å‰å·¥æ¥­ç•Œèµ°å‘åµŒå…¥å¼ç³»çµ±æ§åˆ¶è¶¨
å‹¢ï¼Œæœ¬ç³»çµ±è»Ÿç¡¬é«”ç™¼å±•ä»¥ ARM ç³»ï¦œç¡¬é«”åšç‚º
å·¥ä½œå¹³å°ï¼Œæ‡‰ç”¨ä¸–ç•Œè»Ÿé«”è¶¨å‹¢é–‹æ”¾åŸå§‹ç¢¼è³‡
æºï¼Œåœ¨æ§åˆ¶æ ¸å¿ƒç¡¬é«”å¹³å°å…§åµŒ Linux ä½œæ¥­ç³»
çµ±ï¼Œä¸¦é–‹ç™¼åœ–å‹ä½¿ç”¨è€…ä»‹é¢(GUI)æ§åˆ¶ç³»çµ±ã€‚
åœ– 1 æ‰€ç¤ºç‚ºæœ¬ç ”ç©¶åµŒå…¥å¼æ§åˆ¶ç³»çµ±èˆ‡å„å­ç³»
çµ±ç›¸å°é—œä¿‚ã€‚ 
 
åœ–1 ç”ŸæŠ€ç¢Ÿç‰‡æª¢æ¸¬åµŒå…¥å¼æ§åˆ¶æ•´é«”æ¶æ§‹ 
è©²åµŒå…¥å¼æ§åˆ¶ç³»çµ±é€é ARM åµŒå…¥æ§åˆ¶
å¹³å°èˆ‡ 8051 å¾®è™•ï§¤å™¨ï¼Œæ“æ§é¦¬é”ä¼ºæœæ©Ÿæ§‹èˆ‡
å£“é›»å¾®å‹•å¹³å°å¦‚åœ– 2 æ‰€ç¤ºï¼Œå¯æ§åˆ¶é€é¡çµ„èˆ‡ç‰©
é¡èšç„¦æ·±ï¨ç²å¾—é¡çµ„è®Šç„¦æ•ˆæœï¼Œä¸¦å¯é€éå…±è»›
ç„¦æ¶æ§‹é‡å­”é€²ï¨ˆç©ºé–“ï¦„æ³¢ï¼Œæ“·å–ï¥§åŒç„¦å¹³é¢å½±
åƒï¼Œç²å¾—è©²æª¢æ¸¬ç³»çµ±å…‰å­¸ï¨€ç‰‡ç‰¹æ€§ã€‚ 
 
åœ–2 åµŒå…¥ç¨‹å¼ç¢¼åŸ·ï¨ˆæª¢æ¸¬æ©Ÿå°é¡é‹å‹• 
2. å…‰æ©Ÿæª¢æ¸¬ä¼ºæœæ©Ÿæ§‹èˆ‡å£“é›»å¾®å‹•å¹³å° 
æœ¬è¨ˆåŠƒå®Œæˆé–‹ç™¼å£“é›»è®Šç„¦ç”ŸæŠ€ç¢Ÿç‰‡å…‰æ©Ÿ
æª¢æ¸¬é››å½¢å¹³å°ï¼Œå¦‚åœ–3æ‰€ç¤ºï¼ŒåŒ…æ‹¬å°ç„¦èˆ‡å¾®å‹•
å­ç³»çµ±ã€è®Šç„¦çµæ§‹ç³»çµ±ã€å£“é›»è‡´å‹•ä¹‹å¾®å‹•å¹³
 5
 
åœ– 6 å£“é›»è‡´å‹•å¹³å°å¾®å°ä½ç§»è¿´æˆé›»å£“ 
æœ¬ç ”ç©¶æ‡‰ç”¨å…±è»›ç„¦é¡¯å¾®æŠ€è¡“ï¼Œæ‡‰ç”¨è©²å£“é›»
è‡´å‹•å™¨é©…å‹•ä¸€ç¶­å¾®å‹•å¹³å°ï¼Œé€²ï¨ˆç¸±è»¸æ–¹å‘å¾®å‹•
ä½ç§»æ”¹è®Šå…¶ç‰©é¡èšç„¦æ·±ï¨ï¼Œå¯æ“·å–æ¨£æœ¬ï¥§åŒæ·±
ï¨å½±åƒï¼Œé”åˆ°å…‰å­¸ï¨€ç‰‡åŠŸèƒ½ã€‚å…¶ä¸­ï¼Œè©²å…‰å­¸ç³»
çµ± Z è»¸è§£æï¨ Zmin åŠèšç„¦æ·±ï¨ DOFï¼Œæ ¹æ“šæ¡
ç”¨é¡ç‰‡çµ„è¦æ ¼èˆ‡å¹¾ä½•è¨­è¨ˆï¼Œåˆ†åˆ¥ä¾ç¿’çŸ¥å…‰å­¸å…¬
å¼è¨ˆç®—å¦‚ä¸‹ã€‚ 
0
min 2 2 2 2
obj
0.88 0.88 1.518 0.55Z 1.11878 m
NA 1.518 1.518 1.25
Î·Î» Ã— Ã—= = = Î¼Î·âˆ’ Î· âˆ’ âˆ’ âˆ’
 
0
2 2
obj
1.518 0.55DOF 0.267168 m
2NA 2(1.25)
Î·Î» Ã—= Â± = Â± = Â± Î¼  
å› æ­¤ï¼Œæœ¬å¯¦é©—æª¢æ¸¬ç”Ÿé†«æ¨£æœ¬ï¥§åŒï¨€é¢ï¼Œå…¶
å¾®å‹•è·ï§ªé ˆå¤§æ–¼è©²ç¸±è»¸è§£æï¨ï¼Œä¸¦åœ¨è©²èšç„¦æ·±
ï¨ç¯„åœå…§æ–¹èƒ½æ¸…æ¥šè§€æ¸¬æ¨£æœ¬å½±åƒã€‚ 
 æœ¬ç³»çµ±å¯¦æ–½å…±è»›ç„¦é¡¯å¾®æŠ€è¡“ï¼Œå¯è—‰ç”±å…‰
å­¸æ¶æ§‹åŠ ç½®é‡å­”(pinhole)æ©Ÿåˆ¶ï¼Œé”åˆ°è§€æ¸¬æ¨£æœ¬
ç‰¹å®šï¨€é¢çš„æ¸…æ™°çµæ§‹ç›®çš„ï¼Œä¸»è¦å¯ï§ç”¨ï¥‰å°„ç©¿
é€é™¶ç“·åŸºæ¿æŠ€è¡“ï¼Œè£½ä½œå­”å¾‘ 200 mÎ¼ é‡å­”é€²ï¨ˆ
æ¨£æœ¬è§€æ¸¬ã€‚ç³»çµ±è—‰ç”±å£“é›»é©…å‹•ç‰©é¡åŠè©²
pinhole é€²ï¨ˆå¾®å‹•ï¼Œå°ä¸€è¡€æ¶²å¡—ç‰‡åšè¡€çƒæ¨£æœ¬
æ“·å–å½±åƒè§€å¯Ÿï¼Œå¦‚åœ– 7 æ‰€ç¤ºï¼Œå…¶åƒ…èƒ½è§€æ¸¬åˆ°æœª
åŠ å…¥é‡å­”å½±åƒæŸä¸€å±¤é¢ï¼Œäº¦å³éƒ¨åˆ†éç„¦å¹³é¢å…‰
å·²è¢«ï¦„é™¤ã€‚å› æ­¤ï¼Œéœ€é€éå£“é›»ç¸±è»¸å¾®å‹•å¹³å°ï¼Œ
å¯å–å¾—å¾…æ¸¬æ¨£æœ¬ï¥§åŒèšç„¦å¹³é¢å…‰ç·šï¼Œäº¦å³ç²å¾—
ï¥§åŒæ¨£æœ¬å±¤é¢ä¹‹å…‰å­¸æ©«ï¨€é¢å½±åƒã€‚ 
 
åœ– 7 å…·æœ‰é‡å­”æ©Ÿåˆ¶ä¹‹è¡€æ¶²å½±åƒ 
äº”ã€è¨ˆç•«æˆæœè‡ªè©• 
æœ¬ç ”ç©¶è¨ˆç•«ï¦ï¨åŸ·ï¨ˆéç¨‹ï¼Œå®Œæˆç”ŸæŠ€ç¢Ÿç‰‡
æª¢æ¸¬çµæ§‹æœ¬é«”ã€å£“é›»è‡´å‹•è®Šç„¦æ©Ÿæ§‹ã€åµŒå…¥æ§åˆ¶
æŠ€è¡“è£½ä½œã€èˆ‡å½±åƒæ¸…æ™°ï¨è¾¨ï§¼è¨­è¨ˆã€ç”ŸæŠ€ç¢Ÿç‰‡
è®Šç„¦æª¢æ¸¬ç³»çµ±æ•´åˆã€åµŒå…¥å¼éŸŒé«”æºé€šæ©Ÿåˆ¶å»º
ï§·ã€åŠè»Ÿé«”æ§åˆ¶ç¨‹å¼é–‹ç™¼ç­‰ã€‚ 
ç”±æ–¼ IC è£½ç¨‹ã€å…‰å­¸å„€å™¨ã€åŠç”ŸåŒ–ç§‘æŠ€è¨­
å‚™ï¼ŒäºŸéœ€é–‹ç™¼è¼•å·§ã€å¿«é€Ÿä¸”ï¨å¯†ä½ç§»è‡´å‹•å™¨ï¼Œ
å¾—ä»¥ç ”è£½å°é«”ç©ï¥­æˆæœ¬é«˜æ€§èƒ½ç”¢å“ï¼Œå› æ­¤æœ¬è¨ˆ
ç•«æ‰€ç ”ç™¼å£“é›»è‡´å‹•è®Šç„¦å‹ç”ŸæŠ€ç¢Ÿç‰‡æª¢æ¸¬ç³»çµ±
ï¼ˆIIï¼‰ï¼Œå¯å°ç›¸é—œç”¢æ¥­å…·æœ‰å¯¦å‹™æ€§è²¢ç»ï¼ŒåŠ é€Ÿ
åœ‹å…§ç”Ÿé†«æª¢æ¸¬ç³»çµ±è‡ªï¨ˆç ”ç™¼è¨­å‚™è…³æ­¥ã€‚ 
å¦å¤–ï¼Œï¥«èˆ‡æœ¬è¨ˆç•«ä¹‹äººå“¡å°‡å¯ç¶“ç”±æœ¬ç³»çµ±
è¨­è¨ˆã€åˆ†æã€è£½ä½œã€æ¸¬è©¦ã€åŠæˆæœè©•ä¼°éç¨‹ä¸­ï¼Œ
ç­è§£æ•´å€‹å…‰ã€æ©Ÿã€é›»ã€æ§åœ¨ç³»çµ±é…åˆé—œä¿‚ï¼Œä¸¦
å¯é€éåŸ·ï¨ˆï¥ç©ç›¸é—œçŸ¥ï§¼ç¶“é©—ï¼Œè—‰ä»¥é”åˆ°åŸ¹è¨“
å…‰æ©Ÿé›»ç³»çµ±æ•´åˆäººæ‰ç›®çš„ï¼Œå¯æ‡‰ç”¨æ–¼æœªï¤­é–‹ç™¼
å„ç¨®æ–°å‹ç”Ÿé†«å…‰å­¸æª¢æ¸¬ç³»çµ±ã€‚ 
ï§‘ã€ï¥«è€ƒæ–‡ç» 
[1]  æ¥Šè‡ªæ£®ï¼Œ"åˆ†å­ç”Ÿé†«å…‰é›»ç§‘å­¸èˆ‡æŠ€è¡“"ï¼Œç‰©ï§¤é›™æœˆ
åˆŠï¼Œå»¿ä¸ƒå·äº”æœŸï¼Œpp. 670-686ï¼Œ2005ã€‚ 
[2]  å³æ˜­ç©ï¼Œç”ŸæŠ€ç¢Ÿç‰‡åŠç”Ÿç‰©å¿«é€Ÿæª¢æ¸¬è©¦åŠ‘ä¹‹è¦–è¦ºåŒ–
åŠè‡ªå‹•åŒ–ï¥¾æ¸¬ç³»çµ±ï¼Œé€¢ç”²å¤§å­¸ï¼Œè‡ªå‹•æ§åˆ¶å·¥ç¨‹æ‰€
ç¢©å£«ï¥æ–‡ï¼Œ2003ã€‚ 
[3]  å¼µç‘‹èŒœï¼ŒåµŒå…¥å¼ç”Ÿé†«è³‡è¨Šç›£æ§è£ç½®ç ”ç™¼ï¼Œåœ‹ï§·å°
ç£å¤§å­¸ï¼Œæ©Ÿæ¢°å·¥ç¨‹ç ”ç©¶æ‰€ç¢©å£«ï¥æ–‡ï¼Œ2005ã€‚
 
ï¨ˆæ”¿é™¢åœ‹å®¶ç§‘å­¸å§”å“¡æœƒè£œåŠ©åœ‹å…§å°ˆå®¶å­¸è€…å‡ºå¸­åœ‹éš›å­¸è¡“æœƒè­°å ±å‘Š 
                                                               97 ï¦ 7 æœˆ 23 æ—¥ 
å ±å‘Šäººå§“å  è”£éŠ˜é” 
 
å°±ï¥šæ ¡é™¢
ï¼ˆç§‘ç³»æ‰€ï¼‰
                     â– åšå£«ç­ç ”ç©¶ç”Ÿ 
è¯æ¢µå¤§å­¸æ©Ÿé›»å·¥ç¨‹å­¸ç³» 
                     â–¡ç¢©å£«ç­ç ”ç©¶ç”Ÿ 
     æ™‚é–“ 
æœƒè­° 
     åœ°é» 
7/13/2008-7/16/2008 
 
éŸ“åœ‹ å¤§ç”° 
æœ¬æœƒæ ¸å®š
è£œåŠ©æ–‡è™Ÿ
NSC-97-2922-I-211-001 
(è¨ˆç•«ç·¨è™Ÿï¼šNSC 96-2221-E-211-005) 
æœƒè­° 
åç¨± 
 (ä¸­æ–‡)ç¬¬ï§‘å±† IEEE å·¥æ¥­è³‡è¨Šåœ‹éš›ç ”è¨æœƒ 
 (è‹±æ–‡) 6th IEEE International Conference on Industrial Informatics 
ç™¼è¡¨ 
ï¥æ–‡ 
é¡Œç›® 
 (ä¸­æ–‡)ç”Ÿé†«ç¢Ÿç‰‡æª¢æ¸¬åµŒå…¥å¼æ§åˆ¶ä¹‹ç™¼å±• 
 (è‹±æ–‡) Development of an Embedded Controller for BioCD Inspections 
(ä¸­æ–‡)ç”Ÿé†«ç¢Ÿç‰‡æª¢æ¸¬ä¹‹å…‰æ©Ÿé›»è£ç½®ç ”è£½ 
 (è‹±æ–‡) Prototyping of an Optomechanical Apparatus for BioCD Specimen Image 
Inspections 
 
å ±å‘Šå…§å®¹åŒ…æ‹¬ä¸‹ï¦œå„é …ï¼š 
ä¸€ã€ï¥«åŠ æœƒè­°ç¶“é 
    2008 IEEE å·¥æ¥­è³‡è¨Šåœ‹éš›ç ”è¨æœƒ(IEEE International Conference on Industrial Informatics 
-2008) å·²æ–¼ 2008 ï¦ 7 æœˆ 13 æ—¥è‡³ 2008 ï¦ 7 æœˆ 16 æ—¥åœ¨éŸ“åœ‹å¤§ç”°èˆ‰ï¨ˆã€‚æ­¤æ¬¡å¤§æœƒä¿‚ç”±éŸ“åœ‹ RMIT
å¤§å­¸é›»æ©Ÿå·¥ç¨‹ç³»ä¸»è¾¦ï¼Œå¤§æœƒç´„æœ‰ä¸€ç™¾å¤šä½å­¸è€…ã€å°ˆå®¶ï¥«èˆ‡æœ¬æ¬¡ç››æœƒã€‚ IEEEå·¥æ¥­ç™¼å±•ä¹‹ç³»çµ±æ§
åˆ¶ã€åµŒå…¥å¼ç³»çµ±ã€æ„Ÿæ¸¬å™¨èˆ‡æ©Ÿå™¨äººç³»çµ±åœ‹éš›ç ”è¨æœƒæ¶µè“‹æ¥µå»£ï¼Œæ­¤æ¬¡æœƒè­°ä¸­ï¼Œï¥æ–‡ä¸»è¦åˆ†ç‚ºï¥¸å¤§
å€å¡Šå…± 27 å€‹ï¦´åŸŸï¼Œåˆ†åˆ¥ç‚ºï¼š 
SS-TCL Tracking, communication and laser technology 
SS-IPSC Image processing and system control 
SS-EIS Embedded and intelligent systems 
SS-RF RF devices design and wireless technology 
SS-LIE Logistics and industry engineering 
SS-DES Dependable embedded systems 
SS-IEC Future Developments of IEC 61499 Standard 
SS-ITE IT and Energy: Applications and test beds 
SS-ISS Intelligent sensing and sensors 
SS-IR    Intelligent Robot 
SS-IRA Industrial robot and its application 
SS-PCCT Practice of computational intelligence techniques in engineering 
SS-PAC Production automation and control. Innovative future manufacturing 
TT-ISST Information Security, Safety and Trust 
TT-SCT Sensing and Communication Technologies 
TT-SOA Service-Oriented Architecture 
TT-SCML Supply Chain Management and Logistics 
TT-MR Mechatronics and Robotics 
TT-BNA Buildings, Networks and Automation 
TT-CCI Cognitive and Computational Intelligence in Industrial Informatics 
 
 
 
æœƒèƒ½å¤šçµ¦äºˆæ©Ÿé›»ç ”ç©¶è€…æŠ•å…¥é€™ä¸€ï¦´åŸŸç›¸è¼”ç›¸æˆå¤šäºˆé¼“ï¥¿ã€‚ 
å››ã€æ”œå›è³‡ï¦¾åç¨±åŠå…§å®¹ 
ÂŒ 2008 IEEE International Conference on Industrial Informaticsï¼ŒINDIN 2008) ï¥æ–‡å…‰ç¢Ÿç‰‡ã€‚ 
ÂŒ 2008 IEEE å·¥æ¥­è³‡è¨Šåœ‹éš›ç ”è¨æœƒè­°ï¥æ–‡é›†ã€‚ 
 
 
II. EMBEDDED CONTROLLER DEVELOPMENT
For the embedded controller, most developing and 
debugging jobs are conducted in the host end, which is 
usually an x86 system. On the x86 platform in this case, 
codes for image processing and sharpness evaluation 
algorithms are developed, and the Borland C++ tool are used 
to introduce human-machine interfacing GUI mechanisms.   
The GUI performs designed communication functions for 
image processing, serial data exchanging, zooming motor 
commanding, etc., as autofocusing the inspected biological 
sample precisely at the demanded location.  Once the 
developed codes are completely debugged and tested, they 
can be transplanted onto the targeted ARM platform, as 
shown in Fig. 1, and then executed to accomplish the 
programmed tasks entirely within the embedded controller. 
Fig. 1 Embedded controller development procedures 
A. Image sharpness evaluation 
For this prototype, sharpness evaluation is very critical as 
acquiring useful samples image from a BioCD during 
autofocusing stages, and it depends heavily that the targeted 
sample is precisely focused through the optical lenses system.  
To successfully achieve the optimal image quality goal, 
adequately exercising geometric optics principles, effectively 
evaluating image sharpness, and accordingly arranging the 
lenses mechanism definitely are imperative on autofocusing 
the inspected samples on a BioCD. 
B. Processing of acquired sample images  
Regarding the sample image manipulation schemes, 
mathematical methodologies using the wavelet and image 
processing computations are attempted to summarize the 
image sharpness comparisons.  The assumed approaches are 
coded in the BCB environment for subsequent controller 
embedment procedures.  In the meanwhile, coefficients of 
the adopted image sharpness evaluation algorithms are 
experimented and adjusted to obtain a satisfactory set.  A 
developed BCB human-machine interface template is shown 
in Fig. 2 once the autofocusing procedures are followed.     
Fig. 2 BCB human-man interface in autofocusing 
III. LINUX-BASED CONTROLLER DEVELOPMENT
This study adopted the Linux 2.4 OS kernel as developing 
the application codes for the x86 platform, where a virtual 
Linux OS environment is setup first with the aids of a 
VMWare tool. 
C. Platform-crossing GUI development tool 
A platform-crossing tool, Qt, provides a necessary 
framework for developing graphic user interfaces in C++ for 
applications. The object-oriented Qt tool, which symbolizes 
relatively portable and expandable, is usually engaged in 
developing GUI modules for platform- crossing applications, 
and is adopted here to fit in with the Linux OS arrangement 
on the ARM processor.  
Furthermore, a QT/Embedded utility which is a Qt C++ 
API tool, is exercised in this study.  The QT/Embedded 
utility, which contains class libraries and signal-slot 
mechanisms, as shown in Fig. 3, for developing embedded 
system, can provide a visualized approach to design the 
graphic user interfaces, and facilitate procedures to simulate 
the embedded system display functions based upon its virtual 
buffer packet mechanism. 
D. Object-oriented signal-slot mechanism 
To replace conventional feedback and information 
reflection mechanism, the object-oriented signal-slot 
mechanism initiates a signal as an event occurs within the Qt 
window, and the signal corresponds to a functional slot for 
executing a designated command.  The signal-slot 
mechanism features in no communications required for detail 
information exchanged among various classes, and remains in 
communicated states regardless of the differences of types. 
XX[W
Fig. 4 Image processing and displaying procedures 
On the other hand, the Pixmap functions illustrate the 
acquired images schematically on display devices.  These 
two functions are utilized alternatively in the prototype, such 
as performing the grayed and binary operations using the 
QImage functions, and then illustrating these information on 
the display screen using the Pixmap functions.    
J. Linux-based serial port communications 
An RS232 serial port establishes communications between 
the ARM embedded controller and the motor driver circuits, 
and a designated library is added with parameter tuned for a 
terminal of the Linux system,  The addressed terminal 
device is accessed to trigger its interrupt code in fulfilling 
read/write tasks, which are intended to control the motors 
through the communication protocol.  
On the other end, the ARM platform receives motor 
controlling signals from the COM1 port, and transmits the 
processed commands to the motor driver circuits through the 
COM2 port, as shown in Fig. 5.  Thus scheduled motor 
movements for the BioCD come into operation, and the 
functioning stats are precisely scheduled.  
Fig. 5 Communications between PC and ARM  
IV. THE DEVELOPED EMBEDDED CONTROLLER
The embedded controller uses an S3C2410X processor 
based ARM920T platform, along with its peripheral devices 
to construct the overall controller board.  Sample images on 
a BioCD are acquired by a CMOS image sensor attached to 
the ARM platformâ€™s USB port, and then processed using the 
embedded image sharpness evaluation module. Based upon 
each evaluation result, the embedded controller sends serial 
commands to corresponding peripherals, i.e., the motor driver 
and the piezoactuator driver circuits, as to command these 
actuators for optimal distances among the lens groups in 
autofocusing.  
Meanwhile, each captured BioCD sample image is 
consecutively displayed on the LCD through the embedded 
controller, and user reactions are managed by exercising these 
developed GUI functions.  Fig. 6 shows the activated LCD 
touch panel, which helps carry out various instructions in 
order to accurately displace lenses for acquiring desired 
sample images.  The coded embedded controller along with 
the BioCD inspection prototype [17] are shown in Fig. 7.
Fig. 6 LCD touch panel displaying acquired images 
Fig. 7 The overall BioCD optical inspection system 
V. CONCLUSIONS
This study has experimentally established an embedded 
controller to inspect BioCD samples through an optical 
apparatus, and the controller is designed mainly to manipulate 
the optical apparatus to accomplish autofocusing tasks.  
Within the embedded controller, image acquisitions are 
triggered consecutively to evaluate each image sharpness, and 
each processed image frame is also displayed on the LCD.  
XX[Y
Prototyping of an Optomechanical Apparatus  
for BioCD Specimen Image Inspections 
Fu-Shin Lee  Rou-Jiun Shiu  Ming-Da Chiang 
Mechatronical Engineering Department  
Huafan University 
Huafan University, 223, Shihtin, Taipei County, TAIWAN. 
fslee@huafan.hfu.edu.tw 
Abstract-An optical inspection apparatus was prototyped 
for examining BioCD samples, and an automatic focusing 
mechanism using an embedded bio-image feedback 
mechanism was built in to control the focusing lenses system 
as to obtain adequate images on the image sensing chip, where 
sharpness of the captured images are evaluated and compared 
for subsequent motor movements. Over the motor course 
motion intervals, piezoactuator minute adjustments are 
henceforth triggered in fine movements to obtain clear images 
of the designated layer within inspected BioCD samples.  The 
prototype is featured in its Linux OS based application on an 
ARM platform, which can execute a variety of servo-motions, 
including fine motions through implementing piezo-actuations, 
once the assistances of processed bio images are employed.  
I. INTRODUCTION
Since biotechnology breakthroughs continuously 
promoted advancements in the biomedical industry, biochip 
and BioCD have become important research topics during 
last ten years.  Correspondingly, diverse inspection 
approaches for BioCDs and biochips have also drawn 
intensive attentions.    
Generally, techniques to inspect biological specimen 
include electrochemical means, refractive index 
measurements, fluorescence detections, optical spectra 
examinations, and mass spectra analyses, and image 
acquisitions for fluorescence indications seem most 
prospective for applications in BioCD specimen inspections.  
For example, a frequency counter alone with a strobe light 
source were used to investigate micro-fluids on a rotating 
BioCD [1], and thus the specimen images during reactions 
can be captured by a CCD.  
On the other hand, clear and serviceable specimen 
images need to be earned through properly designed optical 
lens systems, and adequate magnifications alone with 
image processing techniques behind are inevitable for 
successful specimen examinations.  Hence, mathematical 
formula for designing optical systems [2], which are 
composed of thin lenses or thick lenses, have been 
constantly employed to design optical apparatus for 
inspecting biological samples.  Furthermore, lenses 
assembled in optical apparatus have also been categorized 
into stationary lens groups, magnifying lens groups, and 
focusing lens groups [3] as to achieve their autofocusing 
goals.  
As for image processing and pattern recognizing for the 
fluorescence detections of inspected specimens, automatic 
virus identification methods [4] have been proposed using 
hierarchical approaches, in which acquired image features 
are decomposed into corresponding spectra. Thus, the 
feature information is analyzed through the Discrete 
Fourier Transform (DFT), and the existences of variances 
between the viruses can be observed.  Researches also 
showed that iterative adapting optimal thresholds for 
binarizing biochip sample images is an acceptable 
alternative,  since it can effectively eliminate blotches or 
distortions from acquisition noises [5].   
Meanwhile, non-invasive fluorescence detections are 
improved using the random work theory [6], and target 
positions are thus gauged based upon the emitted 
fluorescence spectrum bands.  Bayesian networks were 
employed to investigate the features of facula (light spots) 
[7], including their sizes, roughness, alignments, intensities, 
background noises, and color bleeding, in order to 
characterize the examined biological specimens.  
Researchers [8] also acquired images using a high-speed 
CCD, which is intended to identify specific micro-channels, 
and the feedback information is utilized to control a 
micro-fluid pumping system for separating designated 
cells.
There have been a variety of autofocusing algorithms 
studied recently for applications inspecting biological or 
industrial samples.  For example in a specific application, 
once an acquired image is segmented into several regions, a 
focus depth evaluation method is employed over the whole 
regions to calculate each regionâ€™s sharpness and reconstruct 
the surface profile of a target [9].  Then, separate 
processed regions with their corresponding most clearest 
portions are recombined to form a virtual 3D image in 
X\]`
{ÂÂŒGplllGpÂ•Â›ÂŒÂ™Â•ÂˆÂ›ÂÂ–Â•ÂˆÂ“GjÂ–Â•ÂÂŒÂ™ÂŒÂ•ÂŠÂŒGÂ–Â•G
pÂ•Â‹ÂœÂšÂ›Â™ÂÂˆÂ“GpÂ•ÂÂ–Â™Â”ÂˆÂ›ÂÂŠÂšGOpukpuGYWW_P
kjjSGkÂˆÂŒÂ‘ÂŒÂ–Â•SGrÂ–Â™ÂŒÂˆGqÂœÂ“Â GXZTX]SGYWW_
`^_TXT[Y[[TYX^XT_VW_VKY\UWWGâ“’YWW_Gplll
study for the samples and the adequate one was 
implemented into the embedded controller.  
IV. DEVELOPMENT OF AN BIOCD INSPECTION PROTOTYPE
In the prototyped system, the motor and piezoactuator 
control algorithms are executed through a single-chip 
microprocessor once the commands are issued from the 
ARM embedded controller to control the BioCD inspection 
structure, which is formed by those optical lenses and 
accessories.
A. Construction of the BioCD optical Inspection structure 
The optical inspection module is a three-group lens 
architecture with the first group formed by three lenses, and 
the second as well as the third group agglutinated by a 
plastic lens each.  During the magnification courses, the 
third group lens remains stationary in front of the image 
detector chip as the first and the second group are 
conducing linear motions on the optical axis.  The first 
and second group of lenses serve to earn magnified images 
and the third one attends to focus the light beams.  The 
prototype is equipped with an oil-immersed object lens to 
examine tiny samples, and a mercury-arc lamp is employed 
as the light source, whose light beams are projected on the 
inspected sample, and then collected by the image detector 
chip.
The overall structure of the optical inspection prototype 
[12] is shown in Fig. 3, where motor A and motor B are 
used to control the first group and the second group of 
lenses, respectively, for magnification purposes.  On the 
other end, motor C attends to control the object lens to 
perform image focusing.  Label (1) ~ (3) represent the first 
lens group to the third lens group, respectively.  Label (D) 
and (E) stand for the piezoactuator and the high 
magnification factor oil-immersed object lens, respectively.  
B. Design of the embedded controller for the lenses 
To control the BioCD inspection structure, the embedded 
controller uses an S3C2410X processor based ARM920T 
platform, along with its peripheral devices forming the 
overall controller board.  Sample images on a BioCD are 
acquired by a CMOS image sensor attached to the ARM 
platformâ€™s USB port, and then processed using the 
embedded image sharpness evaluation module. Based upon 
each evaluation result, the embedded controller sends serial 
commands to corresponding peripherals, i.e., the motor 
driver and the piezoactuator driver circuits, as to command 
these actuators for optimal distances among the lens groups 
in autofocusing.  
Meanwhile, each captured BioCD sample image is 
consecutively displayed on the LCD through the embedded 
controller, and user reactions are managed by exercising 
these developed GUI functions.  The activated LCD touch 
panel helps carry out various instructions in order to 
accurately displace lenses for acquiring desired sample 
images.   
Fig. 3.  The overall prototyped optical inspection structure 
C. Testing the peripheral circuit for the piezoactuator 
The piezoactuator is driven in a range of -35V ~ +160V, 
and is limited due to its saturation characteristics in 
deformation.  Fig. 4 shows the generated deformation 
measured for the tested piezoactuator once a laser 
interferometer is employed, and the resultant maximum 
stroke provided by the piezoactuator is 22Ó´m.   
Ë€ËƒËËƒË„
Ë€ËƒËËƒËƒËˆ
Ëƒ
ËƒËËƒËƒËˆ
ËƒËËƒË„
ËƒËËƒË„Ëˆ
ËƒËËƒË…
ËƒËËƒË…Ëˆ
Ëƒ
ËƒË
ËƒË„
ËƒË
ËƒË†
ËƒË
ËƒË‡
ËƒË
ËƒËˆ
ËƒË
ËƒËŠ
ËƒË
ËƒË‹
ËƒË
ËƒËŒ
ËƒË
Ë„Ë„
ËƒË
Ë„Ë…
ËƒË
Ë„Ë‡
ËƒË
Ë„Ëˆ Ê»Ì†Ë¸Ë¶Ê¼
Ê»Ì€Ì€Ê¼ Ë£Ë­Ë§Ê³Ë—Ë¼Ì†Ì‡Ë´ÌË¶Ë¸
Fig. 4.  Laser interferometer measured piezoactuator displacements
D. Design of the BioCD image inspection architecture 
The designed BioCD inspection architecture consists of 
six modules, as shown in Fig. 5, including an image 
processing module, a GUI interface module, an optical 
inspection module, an image feedback module, a motor 
X\^X
B. Experiments for image zooming and specimen transecting 
An standard specimen for testifying optical lens systems 
is employed in this experiment to verify the magnification 
and focusing performances.  As exercising the prototyped 
apparatus, the relative distances between the lens groups 
and the corresponding magnification factors are shown in 
TABLE I.
To exercise the built-in confocal mechanism, several 
images transected from an onion epidermis sample are 
shown in Fig. 9, in which reflected light beams from 
different on-focus planes are captured to display the 
textures, and existence of structure diversities within the 
images indicates the validity of confocal principle.  
TABLE I 
RELATIVE DISTANCES BETWEEN THE LENS GROUPS IN MAGNIFICATIONS 
1st and 2nd 2nd and 3rd 3rd and focus  
100X 34mm 26mm  10mm 
200X 23mm 26mm  10mm 
Fig. 9.  Transected onion epidermis images due to piezoactuator motions 
VI. CONCLUSION
The prototyped optical apparatus to inspect samples on a 
BioCD has been successfully implemented on the 
ARM-Linux based platform, where sample images are 
acquired, processed, analyzed, and compared.  Meanwhile, 
the embedded controlled effectively commands the motors 
and the piezoactuator to displace the lenses mechanism 
based upon the image feedback and sharpness 
computations.  Course motions are performed by the 
motors for magnifications and autofocusing purposes, and 
fine motions are executed by the piezoactuator for the 
confocal advantages.  Accordingly, high resolution 
transected sample images at prescribed on-focus planes are 
obtained with designated magnification factors, and the 
experimental apparatus to verify the designed mechanism is 
thus successfully built.  
ACKNOWLEDGMENT
The authors are grateful to the National Science Council, 
Taiwan, for partial financial support under 
Grant No.: NSC 96-2221-E-211-005. 
REFERENCES
[1] S. Lai, Design and Fabrication of Polymer-Based Micro-Fluidic 
Platforms for Bio-Mems Applications, Ph. D. thesis, Graduate 
Program, Chemical Engineering Department, Ohio State University, 
2003. 
[2] R. E. Stephens, â€œThe Design of Triplet Anastigmatic Lenses of the 
Taylor Type,â€ Journal of The Optical Society of America, vol. 38, no. 
12, pp. 1032-1038, 1948. 
[3] T. Chunkan, â€œDesign of zoom system by the varifocal differential 
equation,â€ Optical Society of America, vol. 31, no. 13, pp.2265-2273, 
1992. 
[4] B. Matuszewski and L. Shark, "Hierarchical Iterative Bayesian 
Approach to Automatic Recognition of Biological Viruses in 
Electron Microscope Images,â€ Proceedings of 2001 International 
Conference on Image Processing, vol. 2, pp. 347-350, 2001. 
[5] T . Kaifel, C. Schiekel, and T. Kampke, "Spotting approaches for 
biochip arrays,â€ Proceedings of 15th International Conference on 
Pattern Recognition, vol. 4, pp. 356-356, 2000. 
[6] A. H. Gandjbakhche and I. Gannot, "Quantitative fluorescent 
imaging of specific markers of diseased tissue,â€ IEEE Journal of 
Selected Topics in Quantum Electronics ,vol. 2, no. 4, 1996. 
[7] S. Hautaniemi, H. Edgren, P. Vesanen, A. JÃ¤rvinen, M. Wolf, O. 
Monni, J. Astola and O. Yli-Harja, â€œA novel strategy for CDNA 
microarray quality control using Bayesian networks,â€ Bioinformatics, 
vol. 19, no. 16, pp. 2031-2038, 2003. 
[8] W. K. Wu1, C. K. Liang, J. Z. Huang, â€MEMS-Based Flow 
Cytometry: Microfluidics-Based Cell Identification System by 
Fluorescent Imaging,â€ EMBC 2004 Conference Proceedings, 26th 
Annual International Conference of the Engineering in Medicine and 
Biology Society, vol. 4, pp. 2579-2581, 2004. 
[9] C. T. Lee, White Light Interferometer for 3D Profile 
Reconstruction â€“Pro-processing Technique, master thesis, Mech. 
Eng. Dept., Yuan Ze University, Taiwan, 2005. 
[10] Y. C. Chen, Fuzzy Auto- Focus Approaches for Digital Cameras, 
master thesis, Mech. Eng. Dept., National Chung Hsing University, 
Taiwan, 2004. 
[11] http://www.microscopyu.com. 
[12] W. Y. Zheng, Prototyping of a Confocal Zooming Apparatus for 
Biomedical Inspection, master thesis, Mechatronical Eng. Dept., 
Huafan University, Taiwan, 2007. 
X\^Z
TT-DENC Distributed, Embedded and Networked Control 
TT-SME e-Learning for Small and Medium Enterprises SME 
TT-EPT Emerging Platform Technologies in Industrial Informatics 
TT-ENIE Engineering e-Networked Industrial Ecosystems 
TT-FA Factory Automation 
TT-HCM Human Computer and Machine HCMI Interface 
TT-IIA Industrial Informatics Applications 
 
ç­†è€…ï¥æ–‡[Fu-Shin Lee, Rou-Jiun Shiu, Ming-Da Chiang, Development of an Embedded 
Controller for BioCD Inspections.]å®‰æ’åœ¨ 7 æœˆ 14 æ—¥ 17:05 to 17:25 æ–¼ã€ŒTT-DENC1 Distributed, 
Embedded and Networked Control 1)ã€ä¸»é¡Œå ±ä½œè¬›è¿°ï¼Œæœ¬ç¯‡ï¥æ–‡æ‰€ç ”è£½ç”Ÿé†«æª¢æ¸¬ç³»çµ±ï¼Œä¸»è¦ç‚º
çµåˆå…‰æ©Ÿé›»æ•´åˆæŠ€è¡“ï¼ŒåŠåµŒå…¥å¼æ§åˆ¶å¹³å°å…‰å­¸å­ç³»çµ±æ¶æ§‹ï¼Œé”æˆå½±åƒå°ç„¦å®Œæˆè§€æ¸¬æ¨£æœ¬ç›®çš„ã€‚
æœ¬ï¥æ–‡ä¸»è¦æ¡ç”¨åµŒå…¥å¼ç³»çµ± ARM Linuxï¼Œåšç‚ºæª¢æ¸¬ç³»çµ±ä¹‹å¾®æ§åˆ¶å¹³å°ï¼Œå…¶æ§åˆ¶å¹³å°åŒ…æ‹¬å½±åƒ
è™•ï§¤èˆ‡è‡ªå‹•å°ç„¦å­ç³»çµ±ï¼Œå¯è—‰ä»¥åˆ¤å®šè¿´æˆä¹‹æ¨£æœ¬å½±åƒæ¸…æ™°ï¨ï¼›äº¦åŒ…æ‹¬é€±é‚Šé©…å‹•å­ç³»çµ±ï¼Œå¯æ§åˆ¶
è¨Šè™Ÿè¼¸å‡ºä¸¦é©…å‹•é¦¬é”ï¼Œé€²è€Œæ”¹è®Šå…¶å…‰å­¸é¡é ­ä½ç½®ï¼Œé”æˆå…‰å­¸æ¶æ§‹è®Šå€å°ç„¦ä¹‹åŠŸèƒ½ã€‚ å®Œæˆå°ç„¦
å‹•ä½œå¾Œï¼Œå†é€éåµŒå…¥å¼æ§åˆ¶å¹³å°ï¼Œè¼¸å‡ºæ§åˆ¶è¨Šè™Ÿè‡³å£“é›»è‡´å‹•å™¨ï¼Œï§ç”¨å…¶å£“é›»å¾®å‹•ä½ç§»ç‰¹æ€§ï¼Œè§€
å¯Ÿæ¨£æœ¬ï¥§åŒå±¤ä¹‹ï¨€ç‰‡æ•ˆæœã€‚ 
æ­¤å¤–ï¼Œç­†è€…ï¥æ–‡ [Fu-Shin Lee, Rou-Jiun Shiu, Ming-Da Chiang, Prototyping of an 
Optomechanical Apparatus for BioCD Specimen Image Inspections.]å®‰æ’åœ¨ 7 æœˆ 14 æ—¥ 15:45 to 
16:05 æ–¼ã€ŒTT-IIA3 Industrial Informatics Applications 3)ã€ä¸»é¡Œå ±ä½œè¬›è¿°ï¼Œæœ¬ç¯‡ï¥æ–‡æ‰€ç ”è£½ç”Ÿé†«
æª¢æ¸¬ç³»çµ±ï¼Œä¸»è¦ç‚ºçµåˆå…‰æ©Ÿé›»æ•´åˆæŠ€è¡“ï¼ŒåŠåµŒå…¥å¼æ§åˆ¶å¹³å°å…‰å­¸å­ç³»çµ±æ¶æ§‹ï¼Œé”æˆå½±åƒå°ç„¦å®Œ
æˆè§€æ¸¬æ¨£æœ¬ç›®çš„ã€‚æœ¬ï¥æ–‡ä¸»è¦æ¡ç”¨åµŒå…¥å¼ç³»çµ± ARM Linuxï¼Œåšç‚ºæª¢æ¸¬ç³»çµ±ä¹‹å¾®æ§åˆ¶å¹³å°ï¼Œå…¶
æ§åˆ¶å¹³å°åŒ…æ‹¬å½±åƒè™•ï§¤èˆ‡è‡ªå‹•å°ç„¦å­ç³»çµ±ï¼Œå¯è—‰ä»¥åˆ¤å®šè¿´æˆä¹‹æ¨£æœ¬å½±åƒæ¸…æ™°ï¨ï¼›äº¦åŒ…æ‹¬é€±é‚Šé©…
å‹•å­ç³»çµ±ï¼Œå¯æ§åˆ¶è¨Šè™Ÿè¼¸å‡ºä¸¦é©…å‹•é¦¬é”ï¼Œé€²è€Œæ”¹è®Šå…¶å…‰å­¸é¡é ­ä½ç½®ï¼Œé”æˆå…‰å­¸æ¶æ§‹è®Šå€å°ç„¦ä¹‹
åŠŸèƒ½ã€‚ è©²ç³»çµ±å®Œæˆå°ç„¦å‹•ä½œå¾Œï¼Œå†é€éåµŒå…¥å¼æ§åˆ¶å¹³å°ï¼Œå¯è¼¸å‡ºæ§åˆ¶è¨Šè™Ÿè‡³å£“é›»è‡´å‹•å™¨ï¼Œä¸¦
ï§ç”¨å…¶å£“é›»å¾®å‹•ä½ç§»ç‰¹æ€§ï¼Œè§€å¯Ÿæ¨£æœ¬ï¥§åŒå±¤ä¹‹ï¨€ç‰‡æ•ˆæœã€‚æœ¬ï¥æ–‡æ‰€ç ”è£½æª¢æ¸¬ç³»çµ±ï¼Œä¸»è¦ä»¥å½±åƒ
è³‡è¨Šåšç‚ºè¿´æˆè¨Šè™Ÿï¼Œè¨­è¨ˆä¸€è‡ªå‹•å°ç„¦çš„æ§åˆ¶ï§Šç¨‹ï¼Œå°‡å½±åƒè³‡è¨Šç¶“ç”±å½±åƒå‰è™•ï§¤åŠæ¸…æ™°ï¨åˆ¤å®šï¼Œ
å…¶ä¸­å½±åƒæ¸…æ™°ï¨åˆ¤å®šå¯è—‰ç”±æ¸…æ™°ï¨å‡½ï¥©è¨ˆç®—å½±åƒæ¸…æ™°ï¨å€¼ï¼Œä¸¦ä¾æ­¤å®Œæˆè©²æª¢æ¸¬ç³»çµ±è‡ªå‹•å°ç„¦ç¨‹
åºã€‚  
 
 
 
 
äºŒã€èˆ‡æœƒå¿ƒå¾— 
åœ¨é€™å››å¤©å¤§æœƒä¸­ï¼Œç­†è€…è¸´èºï¥«åŠ å„ç¨®ï¥§åŒï¦´åŸŸçš„ç ”è¨æœƒï¼Œå¾ä¸­æˆ‘å€‘å¯ä»¥ï¦ºè§£ç›®å‰ä¸–ç•Œå„åœ‹
ä¹‹å·¥æ¥­ç™¼å±•ä¹‹ç³»çµ±æ§åˆ¶ã€åµŒå…¥å¼ç³»çµ±ã€æ„Ÿæ¸¬å™¨èˆ‡æ©Ÿå™¨äººç³»çµ±ä¹‹ç ”ç©¶ç¾æ³åŠé€²å±•ï¼Œä¸¦è—‰ç”±èˆ‡ä¸–ç•Œ
å„åœ‹å­¸è€…é¢å°é¢çš„è¨ï¥åŠæºé€šï¼Œäº¦èƒ½ï¦ºè§£ä¸–ç•Œå„åœ‹åœ¨æ­¤ï¦´åŸŸç ”ç©¶ä¹‹è¶¨å‹¢ï¼Œæ­¤å°åœ‹å…§å¾äº‹å·¥æ¥­ç™¼
å±•ä¹‹ç³»çµ±æ§åˆ¶ã€åµŒå…¥å¼ç³»çµ±ã€æ„Ÿæ¸¬å™¨èˆ‡æ©Ÿå™¨äººç³»çµ±ç›¸é—œç ”ç©¶æœ‰ç›¸ç•¶ä¹‹å¹«åŠ©ã€‚ç‰¹åˆ¥æ˜¯ç­†è€…å°æ–¼åœ¨
æ­¤æ¬¡ç ”è¨æœƒä¸­æ‰€ç²å¾—ä¹‹æ–°çŸ¥å°è±¡ç‰¹åˆ¥æ·±åˆ»ï¼Œå°æ•™å­¸åŠç ”ç©¶å‡æœ‰è«å¤§ä¹‹åŠ©ï¨—ï¼Œç‰¹åˆ¥æ„Ÿè¬åœ‹ç§‘æœƒè³‡
åŠ©ç­†è€…ï¥«åŠ æ­¤æ¬¡æœƒè­°ï¼Œå¸Œæœ›åœ‹ç§‘æœƒèƒ½å¤šæä¾›æ©Ÿæœƒï¼Œçµ¦äºˆç ”ç©¶ç”Ÿå¤šï¥«åŠ æ­¤ï§åœ‹éš›ç ”è¨æœƒï¼Œç›¸ä¿¡å°
æ ¡å…§å·¥æ¥­ç™¼å±•ä¹‹ç³»çµ±æ§åˆ¶ã€åµŒå…¥å¼ç³»çµ±ã€æ„Ÿæ¸¬å™¨èˆ‡æ©Ÿå™¨äººç³»çµ±ç›¸é—œæ•™å­¸åŠç ”ç©¶æœ‰ç›¸ç•¶å¤§çš„å¹«åŠ©ã€‚ 
 
 
 
INDIN2008 æœƒå ´çš„ç…§ç‰‡ 
ä¸‰ã€å»ºè­° 
æˆ‘åœ‹è¿‘ï¦ï¤­ï¼Œç”±æ–¼æ”¿åºœå¤§ï¦Šæ”¯æŒå­¸è¡“ç ”ç©¶ï¼Œä¸¦åœ¨æ•™è‚²éƒ¨å…¨ï¦Šæ¨å‹•ä¸‹ï¼Œå­¸è¡“ç ”ç©¶èƒ½ï¦Šå¤§å¹…æå‡ï¼Œ
ä½†æ˜¯åœ¨æ¥­ç•Œç”¢å“åµŒå…¥å¼èˆ‡äººæ©Ÿä»‹é¢è™›æ“¬ç§‘æŠ€æ•´åˆä¹‹ç ”ç©¶ï¼Œä¼¼ä¹é‚„æœ‰å†åŠ å¼·çš„åœ°æ–¹ï¼Œæ˜¯ä»¥å¸Œæœ›åœ‹ç§‘
Development of an Embedded Controller  
for BioCD Inspections 
Fu-Shin Lee  Rou-Jiun Shiu  Ming-Da Chiang 
Mechatronical Engineering Department  
Huafan University 
Huafan University, 223, Shihtin, Taipei County, TAIWAN. 
fslee@huafan.hfu.edu.tw 
Abstract-In this study, optical-mechatronical techniques are 
integrated to develop an embedded controller for BioCD image 
sample inspections.  The Linux-based OS is loaded on an ARM 
platform to code the mandatory embedded controller functions, 
including image sharpness evaluations for feedback calculations, 
lenses-carried motor activations for magnifications or 
autofocusing, piezoactuator displacements for transected sample 
imaging, human-machine interfacing (Graphic User Interface, 
GUI) for accepting user instructions, and touch panel LCD 
displays for instant image realizations.  The developed 
embedded controller has verified its performances in an 
experimental BioCD setup. 
I. INTRODUCTION
The main issues of successfully developing an embedded 
controller solely depend on the application objectives, and 
effective eliminations of unnecessary modules selectively 
simplify a prototyped system for accomplishing necessary 
tasks efficiently within a limited time [1][2][3][4][5].
In the aspects of building biological sample inspection 
systems, researchers attempted focusing processes in a PC 
platform using the Borland C++ Builder interface [6], in 
which stepping motors along with precision linear guides are 
employed to build an autofocusing stage, and a CCD is used 
to receive the cell images for samples cultivated through 
tissue engineering.  During the processes, each frame of 
several continuously acquired images is similarly segmented 
into several regions.  Then, the processed regions with the 
clearest portions are recombined to present a virtual 3D image 
representing the original cell image.   
There have been a variety of autofocusing algorithms 
studied recently for applications inspecting biological or 
industrial samples.  For example in a specific application, 
once an acquired image is segmented into several regions, a 
focus depth evaluation method is employed over the whole 
regions to calculate each regionâ€™s sharpness and reconstruct 
the surface profile of a target [7].  Then, separate processed 
regions with their corresponding most clearest portions are 
recombined to form a virtual 3D image in representing the 
original one.  Fuzzy focusing algorithms were also 
developed to enhance autofocusing functions [8], and fault 
tolerances due to environmental factors can be established in 
an optical image acquisition system.   
To facilitate the focusing processes, several optimal focus 
algorithms have also been studied.  A discrete difference 
equation prediction model predicting the focusing curve trend 
is employed [9] to reduce the search time on moving the 
lenses for an optimal focus configuration.  For various 
application environments, a scheme for rating image 
sharpness is presented [10] based upon the DCT 
computational algorithms, and it is united with a high-speed 
searching means to effectively reduce the autofocusing time 
and to improve the focusing accuracy.  
As to effectively evaluate image sharpness of common 
examined samples, several approaches to differentiae image 
sharpness are assumed [11][12][13][14], including the well 
known Fourier Transform Method, Discrete Cosine 
Transform Method, and Discrete Wavelet Transform Method 
in the frequency domain, and the Steepest Gradient Method, 
the Total Difference Coefficient Method, the Standard 
Deviation Method, and the Entropy Method. 
In the research conducted by Yao et. al [15], various 
sharpness functions are evaluated and compared to appraise 
their values in all kinds of image acquisition applications, and 
the steepest gradient method is verified to be the most 
effective one, and finally merged with a rule-based searching 
method [16] to secure the optimal focus configuration.    
The object of this study is to develop an embedded 
controller for optical inspections of samples on BioCDs .  
Linux operation systems is employed as the designated 
embedded platform due to its availability of abundant open 
sources and exploitation of interfacing features.  To exercise 
the interfacing techniques between two kernels and to 
examine the performances of the converted codes on two 
different platforms are also important motivations to conduct 
this research.   
XXZ`
{ÂÂŒGplllGpÂ•Â›ÂŒÂ™Â•ÂˆÂ›ÂÂ–Â•ÂˆÂ“GjÂ–Â•ÂÂŒÂ™ÂŒÂ•ÂŠÂŒGÂ–Â•G
pÂ•Â‹ÂœÂšÂ›Â™ÂÂˆÂ“GpÂ•ÂÂ–Â™Â”ÂˆÂ›ÂÂŠÂšGOpukpuGYWW_P
kjjSGkÂˆÂŒÂ‘ÂŒÂ–Â•SGrÂ–Â™ÂŒÂˆGqÂœÂ“Â GXZTX]SGYWW_
`^_TXT[Y[[TYX^XT_VW_VKY\UWWGâ“’YWW_Gplll
Hence, this research employed that mechanism to develop 
required functional slots with no format limitations, and 
hence facilitated corporative code executions among different 
formats of components.     
Fig. 3 Signal-slot communication mechanism 
E. Mechanisms for hardware accessions   
The graphic engine at the bottom layer of the 
QT/Embedded utility is basically a â€œframbufferâ€ interface, 
which is used to convert the display device into an abstract 
â€œframebufferâ€ block, as described for its role in Table I.
Table I!The embedded controller architecture  
Application 
Qt API 
QT/Embedded
Framebuffer 
Linux kernel 
Hence, users recognize these blocks as memory images 
with program addresses, and perform read/write tasks directly 
onto the imaged display screen.  As a result, the 
â€œframebufferâ€ blocks are realized as abstract entrances for the 
display devices, and executions of the application codes on 
the top layer consistently access the â€œframebufferâ€ block 
areas.
F. GUI developments for BioCD inspections 
In this prototype, the Linux OS is built first on the x86 
platform, and the Qt toolkit is then established on the Linux 
OS.  Three utilities, including Tmake, Qt/Embedded 2.3.7, 
and Qt 2.3.2 for X11, are used in developing the embedded 
controller system 
Once setting up the environment, parameters for building 
the embedded codes are defined to link mandatory files, and 
required crossing libraries are directed to in performing the 
correct linking and compilation processes.  Then, the 
developed codes are embedded into the target platform for 
subsequent executions in the controller.   
In short, the procedures for accomplishing a QT/Embedded 
GUI are briefed as design a graphic user interface, produce 
necessary files for the â€œMakefileâ€ stage, code a command file 
to generate a â€œMakefileâ€, write the main program, and then 
compile the overall codes for this application.   
G. Linux-based BioCD image acquisitions  
 Since the embedded controller is performed on the 
ARM-Linux platform, an image acquisition IC device 
supported by a Linux-supported driver is imperative, and 
therefore a WEBEYE 2000 image processing chip is used as 
the device driver chip in this image acquisition setup.   
As for the employed API, this research utilized various 
hardware based driver functions, such as for the TV card, the 
image acquisition card, the USB CCD, etc. In order to acquire 
satisfactory BioCD sample images, once the hardware devices 
came with drivers to provide compatible functions, the 
research utilized these gadgets and coded required firmware 
to command the integrated image acquisition system for 
successful inspections.    
H. Image acquisition procedures 
In the Linux system, all hardware devises, including the 
image acquisition devices, are treated as virtual files and 
invoked through function calls to acquire sample images.  
The procedures for operating the device are briefly describe 
as: initiate the image acquisition device, read messages from 
the device, acquire sample images from the device, process 
each acquired image frame, and then close the image 
acquisition device.   
Since obtaining image frames is through direct memory 
mappings, this approach is achieved by direct accesses to the 
common shared memory blocks in the kernel. Due to the 
convenient and efficient interfacing mechanism for image 
conversions, the embedded controller in this study can 
therefore readily control the image acquisition device to 
perform efficient assignments.  
I. GUI design for BioCD sample image display 
The prototype also exercises image conversion functions 
after each frame of image are captured, and then exhibits it 
through the QT/Embedded graphic user interface. The flow 
charts shown in Fig. 4 illustrates the procedures that the 
controller processes and displays the acquired BioCD sample 
images, where the QImage functions are intended to convert 
the captured 24-bit full color BMP image files into their 
corresponding 32-bit RGB ones for subsequent processing 
steps.
XX[X
The feedback from each resolved image sharpness then 
effectively commands the motors and the piezoactuator to 
displace the lens groups for exact autofocusing.   
To fulfill the BioCD sample inspection purpose, the 
embedded controller comprising the modules to control the 
autofocusing motors along with the fine-motion piezoactuator, 
the image evaluation  together with the focus searching 
algorithms, the motion control techniques, the communication 
protocols for the peripheral LCD display, and the 
QT/Embedded GUI interfacings, has been successfully 
developed and tested on the ARM-Linux based platform.   
ACKNOWLEDGMENT
The authors are grateful to the National Science Council, 
Taiwan, for partial financial support under 
Grant No.: NSC 96-2221-E-211-005. 
REFERENCES
[1] M. H. Berge, B. Orlic, and J. F. Broenink, â€œCo-simulation of networked 
embedded control systems, a csp-like process-oriented approach,â€  
Proc. IEEE Int. Symposium on Computer Aided Control Systems Conf.,
Munich, CACSD, pp. 434â€“439, 2006 
[2] T. A. Khan, â€œEmbedded Linux systems for accelerator control 
applications,â€ 10th ICALEPCS Int. Conf. on Accelerator & Large Expt. 
Physics Control Systems, Geneva, Oct. 10â€“14, 2005. 
[3] F. M. Proctor and W. P. Shackleford, â€œEmbedded real-time Linux for 
cable robot control,â€ Proc. of DETC'02 ASME 2002 Design
Engineering Technical Conf. & Computers & Information in 
Engineering Conference, Montreal, Canada, Sep. 29â€“Oct. 2, 2002. 
[4] V. Yodaiken, P. Cloutier, D. Schleef, P. N. Daly, R. Rajkumar, and B. 
Kuhn, â€œDevelopment of RTOSes and the position of Linux in the 
RTOS and embedded market,â€ Proc. 21st Symposium on Real-Time 
Systems (RSS-00), Los Alamitos, CA, No. 27â€“Nov. 30, 2000. 
[5] Q. Peng, K. C. P. Wang, Y. Qiu, Y. Pu, X. Luo, and B. Shuai, â€œFatigue 
Detecting Embedded System Based on S3C44Box,â€ Int. Conf. on 
Transportation Eng. (ICTE 2007), July 22â€“24, Chengdu, China, 2007. 
[6] F. S. Huang, The Application of Image Processing Techniques in 
Bio-Medical Detection, master thesis, Mech. Eng. Dept., National Chung 
Hsing University, Taiwan, 2002.  
[7] C. T. Lee, White Light Interferometer for 3D Profile 
Reconstruction â€“Pro-processing Technique, master thesis, Mech. Eng. 
Dept., Yuan Ze University, Taiwan, 2005. 
[8] Y. C. Chen, Fuzzy Auto- Focus Approaches for Digital Cameras, master 
thesis, Mech. Eng. Dept., National Chung Hsing University, Taiwan, 
2004. 
[9] H. C. Chuang, Design and Application of the Auto-Focus Search 
Algorithm Based on Discrete Difference Equation Prediction Model for 
Digital Camera, master thesis, Mechatronic Tech. Dept. National 
Taiwan Normal University, Taiwan, 2004. 
[10] C. C. Huang, High-Speed Passive Autofocus Technique, master thesis, 
Mech. Eng. Dept., Yuan Ze University, Taiwan, 2001.  
[11] M. Subbarao and J.-K. Tyan, "Selecting the Optimal Focus Measure for 
Autofocusing and Depth-From-Focus," IEEE Trans. on Pattern Analysis 
and Machine Intelligence, vol. 20, no. 8, pp. 864-870, 1998. 
[12] N. K. Chern, P. A. Neow and M. H. Ang, Jr., "Practical Issues in 
Pixel-Based Autofocusing for Machine Vision," Proc. IEEE Int. Conf. 
on Robotics and Automation, vol. 3, pp. 2797-2796. 
[13] K. S. Choi, J. S. Lee, and S. J. Ko, "New autofocusing technique using 
the frequency selective weighted median filter for video cameras," IEEE 
Trans. on Consumer Electronics, vol. 45, pp. 820-827, 1999. 
[14] C. F. Batten, , Autofocusing and Astigmatism Correction in the Scanning 
Electron Microscope, , master thesis, University of Cambridge 
Engineering, 2000. 
[15] Y. Yao, B. Abidi, and M. Abidi, "Evaluation of sharpness measures and 
search algorithms for the auto-focusing of high magnification images," 
SPIE, vol. 6246, pp. G.1-G.12, 2006. 
[16] N. Kehtarnavaz, H. J. Oh, "Development and real-time implementation 
of a rule-based auto-focus algorithm," Real-Time Imaging, vol. 9, 
pp. 197â€“203, 2003. 
[17] W. Y. Zheng, Prototyping of a Confocal Zooming Apparatus for 
Biomedical Inspection, master thesis, Mechatronical Eng. Dept., Huafan 
University, Taiwan, 2007. 
XX[Z
representing the original one.  Fuzzy focusing algorithms 
were also developed to enhance autofocusing functions 
[10], and fault tolerances due to environmental factors can 
be established in an optical image acquisition system.   
II. BASIC PRINCIPLE FOR OPTICAL LENSES
A. Sharpness curves for images through a lens 
According to the basic lens maker formula in (1), where 
 is the object distance,  is the image distance, and u v f
is the focus length of the lens,  different images for the 
object are obtained at location A, B, or C, and sharpest 
image should be captured at location B since all light 
beams emitted from the object is focused at this location 
through the lens.   
1 1 1
u v f
   (1) 
However, that on-focus condition is not gained at 
location A or C and the corresponding images are relatively 
fuzzy.  No matter which image sharpness calculation 
algorithm is adopted, a typical sharpness curve illustrated 
in Fig. 1.  usually shows the sharpness value hits its peak, 
i.e., the acquired image is clearest, when the image plane is 
located at the focus point, and the sharpness value 
decreases gradually along with fuzzier images when the 
image plane moves away from the on-focus point.   
B. The confocal mechanism for an optical system 
As light beams transmit through a lens, the refractive 
rays project onto an inspected sample and on-focus as well 
as out-of-focus rays from the sample are reflected to the 
detector.  Reflected light beams with the strongest 
intensity are from the on-focus plane transecting the 
inspected sample, as compared with what others are at 
out-of-focus planes.  Once a pinhole is employed to block 
away the reflected light beams from other out-of-focus 
planes, only the selectively transected sample portion on 
the on-focus plane is captured by the image detector chip 
[11], as shown in Fig. 2.  Based upon the confocal 
principle, this mechanism is built in to minutely activate the 
piezoactuator for adjusting the on-focus plane position, and 
therefore to optically acquire sliced images on various 
depths within inspected samples.  
III. BIOCD SPECIMEN IMAGE SHARPNESS EVALUATION
Generally, human visual perceptions do not differentiate 
two frames of very similar images easily, but it is not 
difficult to distinguish them by certain image features, such 
as calculations for abrupt edge changes, line widths, pattern 
areas, overall sharpness, etc. within the evaluated images.  
Typically, an inspected BioCD sample image gets sharper 
if its feature patterns get more eroded, and gets fuzzier if its 
featured patterns get more dilated.  This observation helps 
starting image sharpness evaluation later on within the 
embedded controller   
Fig. 1.  Sharpness curve for varying im e m  plane positions.  ag for
A
ing
B C
Fig. 2.  The confocal principle for an optical system 
A. Image sharpness evaluation algorithms 
To fulfill the goal in evaluating image sharpness of 
examined biological samples, several image sharpness 
calculations are assumed in this study, including the 
Fourier Transform Method, the Discrete Cosine Transform 
Method, and the Discrete Wavelet Transform Method in 
frequency domains, and the Steepest Gradient Method, the 
Total Difference Coefficient Method, the Standard 
Deviation Method, and the Entropy Method in spatial 
domains.   
B. Optimal sharpness searching algorithms 
During the autofocusing process to calculate the 
sharpness of an image, there are several searching 
methodologies to reach the optimal one, including the 
Global Search Method, the Binary Search Method, and the 
Fibonacci Search Method.  All of them were tested in this 
X\^W
control module, and a piezoactuator control module.  The 
optical inspection module grabs biological sample images 
with an image detector chip.  The image processing 
module together with the image feedback module evaluate 
and compare sharpness of acquired image frames in the 
Linux-ARM platform.  The motor control module together 
with the piezoactuator control module drive the lenses 
mechanism to perform the course and fine motions for 
autofocusing and confocal actions, respectively.  In the 
meantime, the GUI module accepts user supervising 
instructions and displays the acquired sample images on the 
LCD screen.   
E. Prototyping of the BioCD image inspection system   
Based upon the design approach, the experimental 
BioCD inspection prototype, as composed of the optical 
inspection mechanism, the embedded controller, and the 
peripherals, is presented in Fig. 6.  In the experimental 
setup, a GUI human-machine interface is also 
supplemented as to display the feedback images and to 
receive user instructions, as shown in Fig. 7.
Fig. 5.  The BioCD inspection architecture illustration 
Fig. 6.  The experimental BioCD inspection prototype
Fig. 7.  The developed GUI touch panel module for acquired images 
V. EXPERIMENTS FOR THE BIOCD INSPECTION PROTOTYPE 
A. Implementation of the autofocusing procedures 
The simplified focusing procedures, as shown in Fig. 8,
are stated as: grabbing an original sample image from the 
image detector chip, processing, evaluating, and comparing 
its sharpness with previous images within the embedded 
ARM controller, and then sending out adequate commands 
for proper motor as well as piezoactuator actions to 
displace the lenses system.  The procedures are repeated 
until a satisfactory autofocusing depth for the inspected 
sample is obtained.  During the fine motion intervals, 
driving voltage for the piezoactuator is delivered to 
minutely displace the confocal mechanism, and only 
deliberately transected images within the inspected sample 
reach the optical detector. 
Fig. 8.  The autofocusing procedures for the BioCD inspection prototype 
X\^Y
