21 Introduction
This paper deals with sensitivity analysis of parametric vector optimization problems.
We first give some notations and definitions.
Let f : P Ã—X â†’ Y be a vector function and let C : P â‡’ X be a multifunction,
where P,X, Y are Euclidean spaces equipped with the usual norms. Let F : P â‡’ Y
be a multifunction given by
F (p) := f(p, C(p)) = {f(p, x) : x âˆˆ C(p)}. (1)
Let K âŠ‚ Y be a pointed, closed, convex cone with apex at the origin. The cone K
induces a partial order K on Y, i.e.,
y K yâ€² â‡” yâ€² âˆ’ y âˆˆ K, y, yâ€² âˆˆ Y. (2)
Definition 1.1 We say that y âˆˆ A is an extremum of a subset A âŠ‚ Y with respect to
K if and only if (yâˆ’K)âˆ©A = {y}. The set of extrema of A is denoted by extrKA.We
stipulate that extrKâˆ… = âˆ…. If K equals (or contains, is contained in) the nonnegative
(in the sense of (2)) orthant of Y , then the set of extrema of A is denoted by minKA;
if K equals (or contains, is contained in) the nonpositive (in the sense of (2)) orthant
of Y , then the set of extrema of A is denoted by maxKA.
We consider the following parametric vector optimization problem:
F(p) := extrK
{
f(p, x) : x âˆˆ C(p)} = extrKF (p), (3)
where x is the unknown (decision variable) and p âˆˆ P a parameter.
Remark 1.1 In the literature, especially that related to the economic applications,
the elements of extrKA are called efficient points. For each p, the image F(p) of the
multifunction F : P â‡’ Y , defined by problem (3), is the set of extrema of (3). The
multifunction F is called here extremum multifunction (in the literature, it is known
also as efficient point multifunction).
Sensitivity analysis in vector optimization problems, that is, the behavior of the
extremum multifunction F is analyzed by using certain concepts of generalized deriva-
tives for multifunctions. The papers by Tanino [1, 2] are among the first results in this
field. In those papers, the author has studied the behavior of F via the concept of
contingent derivative introduced by Aubin [3]. The notion of contingent epiderivative
in vector optimization with multifunctions has been introduced by Jahn and Rauh [4].
Various sensitivity analysis results in this direction can be found in Shi [5, 6], Kuk,
Tanino, and Tanaka [7, 8]. Generalized contingent epiderivatives have been indepen-
dently introduced by Chen and Jahn [9] and by Bednarczuk and Song [10]; the study
of sensitivity of a family of parametric optimization problems with multifunctions has
been examined in the latter paper. Later, Song and Wan [11] used this concept to de-
rive some sensitivity results on parametric vector optimization problems. Namely, the
authors gave a representation of generalized contingent epiderivative of F in terms of
4Definition 2.1 (i) A multifunction F is upper locally Lipschitz at pÂ¯ âˆˆ domF if there
exist U âˆˆ N (pÂ¯) and a real number M > 0 such that
F (p) âŠ‚ F (pÂ¯) +M ||pâˆ’ pÂ¯||BY , âˆ€p âˆˆ U.
(ii) F is pseudo-Lipschitz at (pÂ¯, yÂ¯) âˆˆ gphF if there exist U âˆˆ N (pÂ¯) and V âˆˆ N (yÂ¯)
and a real number M > 0 such that
F (p1) âˆ© V âŠ‚ F (p2) +M ||p1 âˆ’ p2||BY , âˆ€p1, p2 âˆˆ U.
Definition 2.2
(i) F is said to be convex if
Î±F (p) + (1âˆ’ Î±)F (pâ€²) âŠ‚ F (Î±p+ (1âˆ’ Î±)pâ€²), âˆ€p, pâ€² âˆˆ P, âˆ€Î± âˆˆ [0, 1].
(ii) F is said to be K-convex if
Î±F (p) + (1âˆ’ Î±)F (pâ€²) âŠ‚ F (Î±p+ (1âˆ’ Î±)pâ€²) +K, âˆ€p, pâ€² âˆˆ P, âˆ€Î± âˆˆ [0, 1].
It is known (see e.g. [2]) that F is convex if and only if gphF is a convex set in
P Ã— Y. According to [15, Lemma 14.8], F is K-convex if and only if epiF is a convex
set in P Ã— Y.
In this paper, we make the following assumptions:
(A) C in (3) is convex and f in (3) is K-convex;
(B) F in (1) is K-convex.
As shown in [2, Proposition 2.1], (A) implies (B). Given a subset â„¦ âŠ‚ Y , we denote
the interior and the closure of â„¦ by intâ„¦ and clâ„¦. When â„¦ is convex and nonempty,
the set
0+â„¦ := {y âˆˆ Y : â„¦ + y âŠ‚ â„¦}
is called the recession cone of â„¦. Let yÂ¯ âˆˆ clâ„¦. The Bouligand tangent cone (or con-
tingent cone) and the Clarke tangent cone to â„¦ at yÂ¯ are defined by
TB(â„¦; yÂ¯) := {v âˆˆ Y : âˆƒ{tn} âŠ‚ (0,+âˆ), tn â†’ 0,âˆƒ{vn} âŠ‚ Y, vn â†’ v, with yÂ¯ + tnvn âˆˆ â„¦, âˆ€n},
TC(â„¦; yÂ¯) := {v âˆˆ Y : âˆ€{yÂ¯n} âŠ‚ â„¦, yÂ¯n â†’ yÂ¯, âˆ€{tn} âŠ‚ (0,+âˆ), tn â†’ 0,âˆƒ{vn} âŠ‚ Y, vn â†’ v,
with yÂ¯n + tnvn âˆˆ â„¦, âˆ€n}.
It is well known that these cones are closed and TC(â„¦; yÂ¯) is convex. Moreover,
TC(â„¦; yÂ¯) âŠ‚ TB(â„¦; yÂ¯) and TC(â„¦; yÂ¯) = TB(â„¦; yÂ¯) when â„¦ is a convex set.
In what follows, we also use projections of the Bouligand tangent cone and the
Clarke tangent cone to sets in the product space P Ã— Y on the space Y . Given a
subset â„¦Ëœ âŠ‚ P Ã— Y, for (pÂ¯, yÂ¯) âˆˆ clâ„¦Ëœ, we define the corresponding projections at u âˆˆ P
by
Î uT
B(â„¦Ëœ; (pÂ¯, yÂ¯)) := {y âˆˆ Y : (u, y) âˆˆ TB(â„¦Ëœ; (pÂ¯, yÂ¯))},
Î uT
C(â„¦Ëœ; (pÂ¯, yÂ¯)) := {y âˆˆ Y : (u, y) âˆˆ TC(â„¦Ëœ; (pÂ¯, yÂ¯))}.
6Proposition 2.2 Let (pÂ¯, yÂ¯) âˆˆ gphF. If
Î 0TP(gphF ; (pÂ¯, yÂ¯)) := {y âˆˆ Y : (0, y) âˆˆ TP(gphF ; (pÂ¯, yÂ¯))} = {0}, (6)
then F is directionally compact at (pÂ¯, yÂ¯).
Proof. We consider arbitrary sequences {tn} âŠ‚ (0,+âˆ), tn â†’ 0, {hn} âŠ‚ P, hn â†’
h âˆˆ P, {yn} âŠ‚ Y with yÂ¯ + tnyn âˆˆ F (pÂ¯+ tnhn) for all n. Since Y is finite-dimensional,
it is sufficient to show that the sequence {yn} is bounded. Suppose by contradiction
that lim
nâ†’âˆ
||yn|| =âˆ. Set
yËœn =
yn
||yn|| , hËœn =
hn
||yn|| , tËœn = tn||yn||.
Then, tËœnyËœn = tnyn, tËœnhËœn = tnhn, ||yËœn|| = 1 for all n and hËœn â†’ 0, tËœnhËœn â†’ 0. By taking
a subsequence if necessary, we may assume that lim
nâ†’âˆ
yËœn = yËœ with ||yËœ|| = 1. Putting
pË†n = pÂ¯+ tËœnhËœn, yË†n = yÂ¯ + tËœnyËœn, tË†n =
1
tËœn
,
we have yË†n âˆˆ F (pË†n) for all n and pË†n â†’ pÂ¯, tË†n(pË†n âˆ’ pÂ¯, yË†n âˆ’ yÂ¯) â†’ (0, yËœ). This means
that (0, yËœ) âˆˆ TP(gphF ; (pÂ¯, yÂ¯)), contrary to the assumption Î 0TP(gphF ; (pÂ¯, yÂ¯)) = {0}.
Thus the proof is complete. 2
Note that the condition (6) has served well as a qualification condition for having
the so-called protodifferentiability of F in [13].
Definition 2.5 (i) The set â„¦ âŠ‚ Y is said to satisfy the domination property if
â„¦ âŠ‚ extrKâ„¦ +K.
(ii) We say the domination property holds for F around pÂ¯ âˆˆ P if there exists U âˆˆ N (pÂ¯)
such that
F (p) âŠ‚ extrKF (p) +K, âˆ€p âˆˆ U.
3 Generalized Clarke Epiderivatives of the Extremum
Multifunction without Constraints
In this section, we provide the formulas for computing and/or estimating the gen-
eralized Clarke epiderivative of the extremum multifunction F in (3) via the Clarke
tangent cone to the graph of F in (1). To do this, we need first to compute or estimate
the generalized Clarke epiderivative of the multifunction F.
Proposition 3.1 Let assumption (B) be satisfied and let (pÂ¯, yÂ¯) âˆˆ gphF. We have
DCF (pÂ¯, yÂ¯)(u) âŠ‚ extrKÎ uTC(gphF ; (pÂ¯, yÂ¯)), âˆ€u âˆˆ P, (7)
and the converse inclusion holds if
epiDCF (pÂ¯, yÂ¯) = TC(epiF ; (pÂ¯, yÂ¯)). (8)
8Thus,
(u, y âˆ’ b) âˆˆ TB(epiF ; (pÂ¯, yÂ¯)).
As epiF is a convex set, we get (u, y âˆ’ b) âˆˆ TC(epiF ; (pÂ¯, yÂ¯)). So,
y âˆ’ b âˆˆ Î uTC(epiF ; (pÂ¯, yÂ¯)). (12)
Since y âˆ’ b K y and y âˆ’ b 6= y, (12) contradicts the fact that
y âˆˆ extrKÎ uTC(epiF ; (pÂ¯, yÂ¯)).
Therefore, our claim follows, i.e., lim
nâ†’âˆ
kn
tn
= 0. Taking into account (10), we have
(u, y) âˆˆ TC(gphF ; (pÂ¯, yÂ¯)) and thus (9) is satisfied.
We now show that, for each u âˆˆ P,
Î uT
C(gphF ; (pÂ¯, yÂ¯)) +K âŠ‚ Î uTC(epiF ; (pÂ¯, yÂ¯)). (13)
Take any y âˆˆ Î uTC(gphF ; (pÂ¯, yÂ¯)) and k âˆˆ K. Since TC(gphF ; (pÂ¯, yÂ¯)) âŠ‚ TB(gphF ; (pÂ¯, yÂ¯)),
we have y âˆˆ Î uTB(gphF ; (pÂ¯, yÂ¯)). Then, there exist sequences {(un, yn)} âŠ‚ P Ã— Y,
(un, yn)â†’ (u, y) and {tn} âŠ‚ (0,+âˆ), tn â†’ 0 such that
yÂ¯ + tnyn âˆˆ F (pÂ¯+ tnun), âˆ€n.
Let yÂ¯n = yn + k for all n. Then, (un, yÂ¯n)â†’ (u, y + k) and
yÂ¯ + tnyÂ¯n = yÂ¯ + tnyn + tnk âˆˆ F (pÂ¯+ tnun) +K, âˆ€n.
Hence,
(u, y + k) âˆˆ TB(epiF ; (pÂ¯, yÂ¯)) = TC(epiF ; (pÂ¯, yÂ¯)),
where the equality holds by the convexity of epiF. So y+ k âˆˆ Î uTC(epiF ; (pÂ¯, yÂ¯)) and
thus (13) has been established. Combining (9) with (13) gives
DCF (pÂ¯, yÂ¯)(u) âŠ‚ Î uTC(gphF ; (pÂ¯, yÂ¯)) âŠ‚ Î uTC(epiF ; (pÂ¯, yÂ¯)).
This justifies (7).
If epiDCF (pÂ¯, yÂ¯) = TC(epiF ; (pÂ¯, yÂ¯)), then it follows from (13) that
Î uT
C(gphF ; (pÂ¯, yÂ¯)) +K âŠ‚ Î uTC(epiF ; (pÂ¯, yÂ¯)) = DCF (pÂ¯, yÂ¯)(u) +K, âˆ€u âˆˆ P.
Combining this with (7) gives us
extrKÎ uT
C(gphF ; (pÂ¯, yÂ¯)) +K âŠ‚ DCF (pÂ¯, yÂ¯)(u) +K
âŠ‚ extrKÎ uTC(gphF ; (pÂ¯, yÂ¯)) +K, âˆ€u âˆˆ P.
Thus,
extrKÎ uT
C(gphF ; (pÂ¯, yÂ¯)) âŠ‚ DCF (pÂ¯, yÂ¯)(u), âˆ€u âˆˆ P,
and the proof is complete. 2
We now give a condition ensuring the equality (8).
10
Hence,
TC(epiF ; (pÂ¯, yÂ¯)) = TC(epiF ; (pÂ¯, yÂ¯)).
This implies that, for each u âˆˆ P,
Î uT
C(epiF ; (pÂ¯, yÂ¯)) = Î uTC(epiF ; (pÂ¯, yÂ¯));
thus, DCF(pÂ¯, yÂ¯)(u) = DCF (pÂ¯, yÂ¯)(u). To complete the proof, it remains to apply
Proposition 3.1. 2
As a consequence of Theorem 3.1 and Proposition 3.2, we have the following result.
Corollary 3.1 Let assumption (B) be satisfied and let (pÂ¯, yÂ¯) âˆˆ gphF . Suppose that
the domination property holds for F around pÂ¯. If DCF (pÂ¯, yÂ¯)(0) 6= âˆ…, then
DCF(pÂ¯, yÂ¯)(u) = extrKÎ uTC(gphF ; (pÂ¯, yÂ¯)), âˆ€u âˆˆ P.
4 Generalized Clarke Epiderivatives of Extremum
Multifunction with Constraints
We consider now the problem (3) with constraint mapping C : P â‡’ X. Define CËœ :
P Ã— Y â‡’ X as follows:
CËœ(p, y) = {x âˆˆ C(p) : y âˆ’ f(p, x) âˆˆ K}. (18)
In this section, our first auxiliary result is the following.
Proposition 4.1 Let pÂ¯ âˆˆ P and xÂ¯ âˆˆ C(pÂ¯). Suppose that f is FreÂ´chet differentiable
at (pÂ¯, xÂ¯). If assumption (B) is satisfied, then
{âˆ‡f(pÂ¯, xÂ¯)(p, x) : (p, x) âˆˆ TC(gphC; (pÂ¯, xÂ¯))}+K âŠ‚ Î pTC(epiF ; (pÂ¯, yÂ¯)), âˆ€p âˆˆ P,
(19)
where âˆ‡f(pÂ¯, xÂ¯) is the FreÂ´chet derivative operator of f at (pÂ¯, xÂ¯) and yÂ¯ = f(pÂ¯, xÂ¯).
Furthermore, if assumption (B) is replaced by assumption (A) and CËœ defined in (18)
is directionally compact at ((pÂ¯, yÂ¯), xÂ¯), then the converse inclusion of (19) is valid, i.e.,
{âˆ‡f(pÂ¯, xÂ¯)(p, x) : (p, x) âˆˆ TC(gphC; (pÂ¯, xÂ¯))}+K = Î pTC(epiF ; (pÂ¯, yÂ¯)), âˆ€p âˆˆ P.
(20)
Proof. We first show that
{âˆ‡f(pÂ¯, xÂ¯)(p, x) : (p, x) âˆˆ TC(gphC; (pÂ¯, xÂ¯))} âŠ‚ Î pTB(gphF ; (pÂ¯, yÂ¯)), âˆ€p âˆˆ P. (21)
For each p âˆˆ P, let (p, x) âˆˆ TC(gphC; (pÂ¯, xÂ¯)). This implies that (p, x) âˆˆ TB(gphC; (pÂ¯, xÂ¯));
thus, there exist sequences {tn} âŠ‚ (0,+âˆ), tn â†’ 0 and {(pn, xn)} âŠ‚ PÃ—X, (pn, xn)â†’
(p, x) with xÂ¯+ tnxn âˆˆ C(pÂ¯+ tnpn), for all n. We have
f(pÂ¯+ tnpn, xÂ¯+ tnxn) âˆˆ F (pÂ¯+ tnpn), âˆ€n.
12
Corollary 4.1 Let assumption (A) be satisfied and let pÂ¯ âˆˆ P, xÂ¯ âˆˆ C(pÂ¯). Suppose that
f is FreÂ´chet differentiable at (pÂ¯, xÂ¯). Let one of the following requirements be fulfilled:
(i) C is upper locally Lipschitz at pÂ¯ âˆˆ domC, with C(pÂ¯) = {xÂ¯}.
(ii) Î 0T
C(gphC; (pÂ¯, xÂ¯)) = {0}.
(iii) CËœ defined in (18) is upper locally Lipschitz at (pÂ¯, yÂ¯) âˆˆ domCËœ, with CËœ(pÂ¯, yÂ¯) =
{xÂ¯} where yÂ¯ = f(pÂ¯, xÂ¯).
(iv) Î (0,0)T
C(gphCËœ; ((pÂ¯, yÂ¯), xÂ¯)) = {0}, where yÂ¯ = f(pÂ¯, xÂ¯).
Then, (20) holds.
Proof. Since C is convex and f is K-convex, we have that gphC and gphCËœ are
convex sets. Thus, TC(gphC; (pÂ¯, xÂ¯)) = TP (gphC; (pÂ¯, xÂ¯)) and TC(gphCËœ; ((pÂ¯, yÂ¯), xÂ¯)) =
TP (gphCËœ; ((pÂ¯, yÂ¯), xÂ¯)). The desired result is now immediate from Propositions 2.1, 2.2,
4.1 and Remark 4.1. 2
Proposition 4.2 Let assumption (A) be satisfied and let pÂ¯ âˆˆ P, xÂ¯ âˆˆ C(pÂ¯). Suppose
that f is FreÂ´chet differentiable at (pÂ¯, xÂ¯). If CËœ defined in (18) is pseudo-Lipschitz at
((pÂ¯, yÂ¯), xÂ¯), where yÂ¯ = f(pÂ¯, xÂ¯), then (20) holds.
Proof. In view of Proposition 4.1, it suffices to prove that
Î pT
C(epiF ; (pÂ¯, yÂ¯)) âŠ‚ {âˆ‡f(pÂ¯, xÂ¯)(p, x) : (p, x) âˆˆ TC(gphC; (pÂ¯, xÂ¯))}+K, âˆ€p âˆˆ P.
(23)
For each p âˆˆ P, take any y âˆˆ Î pTC(epiF ; (pÂ¯, yÂ¯)), i.e., (p, y) âˆˆ TC(epiF ; (pÂ¯, yÂ¯)). It fol-
lows that (p, y) âˆˆ TB(epiF ; (pÂ¯, yÂ¯)). Then, there exist sequences {tn} âŠ‚ (0,+âˆ), tn â†’
0 and {(pn, yn)} âŠ‚ P Ã— Y, (pn, yn)â†’ (p, y) with
yÂ¯ + tnyn âˆˆ F (pÂ¯+ tnpn) +K, âˆ€n.
On the other hand, since CËœ is pseudo-Lipschitz at ((pÂ¯, yÂ¯), xÂ¯), there exist U1 âˆˆ N (pÂ¯), U2 âˆˆ
N (yÂ¯), V âˆˆ N (xÂ¯), and M > 0 such that
CËœ(p1, y1) âˆ© V âŠ‚CËœ(p2, y2) +M(||p1 âˆ’ p2||2 + ||y1 âˆ’ y2||2) 12BX ,
âˆ€p1, p2 âˆˆ U1,âˆ€y1, y2 âˆˆ U2. (24)
Choose Î´ > 0 such that pÂ¯+ Î´BP âŠ‚ U1, yÂ¯ + Î´BY âŠ‚ U2. It follows from (24) that
xÂ¯ âˆˆ CËœ(pÂ¯, yÂ¯) âˆ© V âŠ‚CËœ(pÂ¯+ tpâ€², yÂ¯ + tyâ€²) +Mt(||pâ€²||2 + ||yâ€²||2) 12BX ,
âˆ€t âˆˆ (0, Î´),âˆ€pâ€² âˆˆ P, ||tpâ€²|| â‰¤ Î´,âˆ€yâ€² âˆˆ Y, ||tyâ€²|| â‰¤ Î´. (25)
Since tn â†’ 0 and (pn, yn) â†’ (p, y), without loss of generality we may assume that
there exists M1 > 0 such that (||pn||2 + ||yn||2) 12 â‰¤ M1 and tn âˆˆ (0, Î´), ||tnpn|| â‰¤
Î´, ||tnyn|| â‰¤ Î´, for all n. So, by (25), there exists {xn} âŠ‚ CËœ(pÂ¯ + tnpn, yÂ¯ + tnyn) such
that ||xÂ¯âˆ’ xn|| â‰¤MM1tn, for all n. Set xË†n = xnâˆ’xÂ¯tn . Then ||xË†n|| â‰¤MM1, for all n, and
xn = xÂ¯+ tnxË†n âˆˆ CËœ(pÂ¯+ tnpn, yÂ¯ + tnyn), âˆ€n. (26)
14
5 Application to Semi-Infinite Programming
In this section, we consider the problem (3) with the constraint mapping C : P â‡’ X
defined by
C(p) := {x âˆˆ X : gt(p, x) â‰¤ 0, t âˆˆ T}, (27)
where T is an arbitrary index set and for each t âˆˆ T, gt : P Ã—X â†’ R is proper, lower
semicontinuous (l.s.c.) and convex.
It is well known that models of semi-infinite optimization cover, e.g., pollution con-
trol models, optimal experimental design in regression and the popular semi-definite
programming. Semi-infinite optimization programming and its wide applications have
attracted much attention from many researchers. We refer the reader to the book by
Goberna and LoÂ´pez [18] for more details and discussions and to some recent papers
[19, 20â€“24] for references.
Denote by R(T ) (respectively R(T )+ ) the collection of all the functions Î» : T â†’ R
taking nonzero (respectively nonnegative) values only at finitely many points of T,
and supp Î» := {t âˆˆ T : Î»t 6= 0}. Given u âˆˆ R(T ) and Î» âˆˆ R(T )+ , we put ã€ˆÎ», uã€‰ =âˆ‘
tâˆˆsupp Î» Î»tut. The normal cone to a convex set Î˜ âŠ‚ X at xÂ¯ âˆˆ Î˜ is defined by
N(Î˜; xÂ¯) := {v âˆˆ X : ã€ˆv, xâˆ’ xÂ¯ã€‰ â‰¤ 0, âˆ€x âˆˆ Î˜}.
The polar cone of the Clarke tangent cone TC(Î˜; xÂ¯), denoted by NC(Î˜; xÂ¯), is called
the Clarke normal cone to Î˜ at xÂ¯, i.e.,
NC(Î˜; xÂ¯) := TC(Î˜; xÂ¯)â—¦ = {v âˆˆ X : ã€ˆv, xã€‰ â‰¤ 0, âˆ€x âˆˆ TC(Î˜; xÂ¯)}.
We denote by cone(Î˜) the convex conical hull of Î˜. The conjugate function Ï•âˆ— : X â†’
R to Ï• : X â†’ R is defined by Ï•âˆ—(v) := sup {ã€ˆv, xã€‰ âˆ’ Ï•(x) : x âˆˆ X}.
In connection with (27), we use the set of active constraint multipliers defined by
A(pÂ¯, xÂ¯) := {Î» âˆˆ R(T )+ : Î»tgt(pÂ¯, xÂ¯) = 0, âˆ€t âˆˆ supp Î»}.
The following proposition gives us a criterion for computing the Clarke tangent
cone to the graph of the constraint mapping C at a given point.
Proposition 5.1 Let (pÂ¯, xÂ¯) âˆˆ gphC. Suppose that the following Farkas-Minkowski
constraint qualification (FM, see e.g. [24]) for (27) is satisfied, that is, the set
cone
(â‹ƒ
tâˆˆT
epigâˆ—t
)
is closed in P Ã—X Ã— R. (28)
Then,
TC
(
gphC; (pÂ¯, xÂ¯)
)
=
{
(p, x) âˆˆ P Ã—X :
âˆ‘
tâˆˆsupp Î»
Î»tâˆ‚gt(pÂ¯, xÂ¯)(p, x) â‰¤ 0, âˆ€Î» âˆˆ A(pÂ¯, xÂ¯)
}
(29)
where the symbol âˆ‚ stands for the subdifferential in the sense of convex analysis.
16
gt(p, x) = tpâˆ’ tx1 âˆ’ (1âˆ’ t)x2, âˆ€x = (x1, x2) âˆˆ R2, âˆ€p âˆˆ R.
We consider the problem (3) with C defined in (27). By simply computing, one can
find
C(p) = {(x1, x2) âˆˆ R2 : x1 â‰¥ p, x2 â‰¥ 0},
F (p) = {y = (y1, y2) âˆˆ R2 : y1 â‰¥ 2p, y2 â‰¥ 0}, âˆ€p âˆˆ P.
Therefore, we observe that the domination property holds for F , âˆ€p âˆˆ P. Moreover,
for pÂ¯ = 0,
C(pÂ¯) = {(x1, x2) âˆˆ R2 : x1 â‰¥ 0, x2 â‰¥ 0},
F (pÂ¯) = {(y1, y2) âˆˆ R2 : y1 â‰¥ 0, y2 â‰¥ 0},
and thus xÂ¯ = (0, 0) âˆˆ C(pÂ¯) as well as yÂ¯ = f(pÂ¯, xÂ¯) = (0, 0) âˆˆ F(pÂ¯). For each t âˆˆ T,
âˆ€x = (x1, x2) âˆˆ R2, p âˆˆ R, we have
gâˆ—t (p, x) =
{
0, if (p, x) = (t,âˆ’t, tâˆ’ 1)
+âˆ, if (p, x) 6= (t,âˆ’t, tâˆ’ 1),
epigâˆ—t = {t} Ã— {âˆ’t} Ã— {tâˆ’ 1} Ã— R+,
and hence cone
(â‹ƒ
tâˆˆT epig
âˆ—
t
)
= R+ Ã—R2âˆ’ Ã—R+ which is closed in R4. Using Proposi-
tion 5.1, we obtain
TC
(
gphC; (pÂ¯, xÂ¯)
)
=
{
(p, x) âˆˆ RÃ— R2 : tpâˆ’ tx1 âˆ’ (1âˆ’ t)x2 â‰¤ 0, âˆ€t âˆˆ T
}
.
Thus, for each p âˆˆ P,
{âˆ‡f(pÂ¯, xÂ¯)(p, x) : (p, x) âˆˆ TC(gphC; (pÂ¯, xÂ¯))}+R2+ = {(y1, y2) âˆˆ R2 : y1 â‰¥ 2p, y2 â‰¥ 0}.
Besides,
TC(epiF ; (pÂ¯, yÂ¯)) = {(p, y) âˆˆ RÃ— R2 : y1 â‰¥ 2p, y2 â‰¥ 0}, âˆ€p âˆˆ P.
So, (32) is valid. Applying Theorem 5.1, we get
DCF(pÂ¯, yÂ¯)(p) = {(2p, 0)}, âˆ€p âˆˆ R.
6 Project evaluation
In the third year of this three years project, we investigated existence and sensitivity
analysis of parametric vector equilibrium problems. Eight papers based on above
investigation have been published or accepted as the following list shows.
18
[4] Jahn, J., Rauh, R.: Contingent epiderivatives and set-valued optimization,
Mathematical Methods of Operations Research, 46, 193-211 (1997).
[5] Shi, D.S: Contingent derivative of the perturbation map in multiobjective opti-
mization, Journal of Optimization Theory and Applications, 70, 385â€“396 (1991).
[6] Shi, D.S: Sensitivity analysis in convex vector optimization, Journal of Optimiza-
tion Theory and Applications, 77, 145â€“159 (1993).
[7] Kuk, H., Tanino, T., Tanaka, M.: Sensitivity analysis in parametrized convex
vector optimization, Journal of Mathematical Analysis and Applications, 202,
511â€“522 (1996)
[8] Kuk, H., Tanino, T., Tanaka, M.: Sensitivity analysis in vector optimization,
Journal of Optimization Theory and Applications, 89, 713â€“730 (1996).
[9] Chen, G.Y., Jahn, J.: Optimality conditions for set-valued optimization prob-
lems, Mathematical Methods of Operations Research, 48, 187â€“200 (1998).
[10] Bednarczuk, E.M., Song, W.: Contingent epiderivate and its applications to
set-valued maps, Control Cybernet, 27, 375â€“386 (1998).
[11] Song, W., Wan, L.-J.: Contingent epidifferentiability of the value map in vector
optimization, Heilongjiang Daxue Ziran Kexue Xuebao 22, 198â€“203 (2005).
[12] Rockafellar, R.T: Proto-differentiability of set-valued mappings and its applica-
tions in optimization, Annales de lâ€™Institut Henri PoincareÂ´ - Analyse non lineÂ´aire,
6, 449â€“482 (1989).
[13] Lee, G.M., Huy, N.Q.: On sensitivity analysis in vector optimization, Taiwanese
Journal of Mathematics, 11, 945â€“958 (2007).
[14] Chen, L.: Generalized tangent epiderivative and applications to set-valued map
optimization, Journal of Nonlinear and Convex Analysis, 3, 303â€“313 (2002).
[15] Jahn, J.: Vector Optimization. Theory, Applications and Extensions, Springer-
Verlag, Berlin (2004).
[16] Sawaragi, Y., Nakayama, H., Tanino, T.: Theory of Multiobjective Optimization,
Mathematics in Science and Engineering, 176. Academic Press, Inc., Orlando
(1985).
[17] Rockafellar, R.T: Lipschitzian properties of multifunctions, Nonlinear Analysis,
9, 867â€“885 (1985).
[18] Goberna, M.A., LoÂ´pez, M.A.: Linear Semi-Infinite Optimization, John Wiley &
Sons, Chichester, UK (1998).
åœ‹ç§‘æœƒè£œåŠ©è¨ˆç•«è¡ç”Ÿç ”ç™¼æˆæœæ¨å»£è³‡æ–™è¡¨
æ—¥æœŸ:2010/12/20
åœ‹ç§‘æœƒè£œåŠ©è¨ˆç•«
è¨ˆç•«åç¨±: å¤šç›®æ¨™è¦åŠƒè§£æ³•åŠå­˜åœ¨æ€§ä¹‹ç ”ç©¶
è¨ˆç•«ä¸»æŒäºº: å§šä»»ä¹‹
è¨ˆç•«ç·¨è™Ÿ: 96-2628-E-110-014-MY3 å­¸é–€é ˜åŸŸ: ä½œæ¥­ç ”ç©¶
ç„¡ç ”ç™¼æˆæœæ¨å»£è³‡æ–™
å…¶ä»–æˆæœ 
(ç„¡æ³•ä»¥ï¥¾åŒ–è¡¨é”ä¹‹æˆ
æœå¦‚è¾¦ï§¤å­¸è¡“æ´»å‹•ã€ç²
å¾—çé …ã€é‡è¦åœ‹éš›åˆ
ä½œã€ç ”ç©¶æˆæœåœ‹éš›å½±éŸ¿
ï¦ŠåŠå…¶ä»–å”åŠ©ç”¢æ¥­æŠ€
è¡“ç™¼å±•ä¹‹å…·é«”æ•ˆï¨—äº‹
é …ç­‰ï¼Œè«‹ä»¥æ–‡å­—æ•˜è¿°å¡«
ï¦œã€‚) 
ç„¡ 
 æˆæœé …ç›® ï¥¾åŒ– åç¨±æˆ–å…§å®¹æ€§è³ªç°¡è¿° 
æ¸¬é©—å·¥å…·(å«è³ªæ€§èˆ‡ï¥¾æ€§) 0  
èª²ç¨‹/æ¨¡çµ„ 0  
é›»è…¦åŠç¶²ï¤·ç³»çµ±æˆ–å·¥å…· 0  
æ•™æ 0  
èˆ‰è¾¦ä¹‹æ´»å‹•/ç«¶è³½ 0  
ç ”è¨æœƒ/å·¥ä½œåŠ 0  
é›»å­å ±ã€ç¶²ç«™ 0  
ç§‘ 
æ•™ 
è™• 
è¨ˆ 
ç•« 
åŠ  
å¡« 
é … 
ç›® è¨ˆç•«æˆæœæ¨å»£ä¹‹ï¥«èˆ‡ï¼ˆé–±è½ï¼‰äººï¥© 0  
