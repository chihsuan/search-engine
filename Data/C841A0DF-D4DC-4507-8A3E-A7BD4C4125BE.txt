performance for arbitrary video downscaling. 
è‹±æ–‡é—œéµè©ï¼š Arbitrary video downscaling, Distance-trimmed filter, 
Kalman filter 
 
2 
åœ‹ç§‘æœƒè£œåŠ©å°ˆé¡Œç ”ç©¶è¨ˆç•«æˆæœå ±å‘Šè‡ªè©•è¡¨ 
è«‹å°±ç ”ç©¶å…§å®¹èˆ‡åŸè¨ˆç•«ç›¸ç¬¦ç¨‹åº¦ã€é”æˆé æœŸç›®æ¨™æƒ…æ³ã€ç ”ç©¶æˆæœä¹‹å­¸è¡“æˆ–æ‡‰ç”¨
åƒ¹å€¼ï¼ˆç°¡è¦æ•˜è¿°æˆæœæ‰€ä»£è¡¨ä¹‹æ„ç¾©ã€åƒ¹å€¼ã€å½±éŸ¿æˆ–é€²ä¸€æ­¥ç™¼å±•ä¹‹å¯èƒ½æ€§ï¼‰ã€æ˜¯
å¦é©åˆåœ¨å­¸è¡“æœŸåˆŠç™¼è¡¨æˆ–ç”³è«‹å°ˆåˆ©ã€ä¸»è¦ç™¼ç¾æˆ–å…¶ä»–æœ‰é—œåƒ¹å€¼ç­‰ï¼Œä½œä¸€ç¶œåˆè©•
ä¼°ã€‚ 
1. è«‹å°±ç ”ç©¶å…§å®¹èˆ‡åŸè¨ˆç•«ç›¸ç¬¦ç¨‹åº¦ã€é”æˆé æœŸç›®æ¨™æƒ…æ³ä½œä¸€ç¶œåˆè©•ä¼° 
â–“  é”æˆç›®æ¨™ 
â–¡  æœªé”æˆç›®æ¨™ï¼ˆè«‹èªªæ˜ï¼Œä»¥ 100å­—ç‚ºé™ï¼‰ 
â–¡ å¯¦é©—å¤±æ•— 
â–¡ å› æ•…å¯¦é©—ä¸­æ–· 
â–¡ å…¶ä»–åŸå›  
èªªæ˜ï¼š 
 
 
 
2. ç ”ç©¶æˆæœåœ¨å­¸è¡“æœŸåˆŠç™¼è¡¨æˆ–ç”³è«‹å°ˆåˆ©ç­‰æƒ…å½¢ï¼š 
è«–æ–‡ï¼šâ–“å·²ç™¼è¡¨ â–¡æœªç™¼è¡¨ä¹‹æ–‡ç¨¿ â–¡æ’°å¯«ä¸­ â–¡ç„¡ 
å°ˆåˆ©ï¼šâ–¡å·²ç²å¾— â–“ç”³è«‹ä¸­ â–¡ç„¡ 
æŠ€è½‰ï¼šâ–¡å·²æŠ€è½‰ â–¡æ´½è«‡ä¸­ â–¡ç„¡ 
å…¶ä»–ï¼šï¼ˆä»¥ 100å­—ç‚ºé™ï¼‰ 
 
 
 
4 
è¡Œæ”¿é™¢åœ‹å®¶ç§‘å­¸å§”å“¡æœƒå°ˆé¡Œç ”ç©¶è¨ˆç•«æˆæœå ±å‘Š 
å…ˆé€²çš„é‹å‹•ä¼°æ¸¬/è£œå„ŸæŠ€è¡“æ‡‰ç”¨æ–¼è¦–è¨Šè½‰ç§»ç·¨ç¢¼çš„ç ”ç©¶ 
The Research of Advance Motion Estimation/Compensation Techniques for Video Transcoding 
è¨ˆç•«ç·¨è™Ÿ: NSC-100-2221-E-214-068 
                 åŸ·è¡ŒæœŸé™: 101å¹´ 8æœˆ 1æ—¥è‡³ 100å¹´ 7æœˆ 31æ—¥ 
           ä¸»æŒäºº: å‘¨ç¾©æ˜Œæ•™æˆ   ç¾©å®ˆå¤§å­¸è³‡å·¥ç³» 
     å…±åŒä¸»æŒäºº: éƒ­å¿ æ°‘æ•™æˆ   ç¾©å®ˆå¤§å­¸è³‡å·¥ç³» 
E-Mail: {icjou, kuocm}@isu.edu.tw 
ABSTRACT 
How to convert the compressed information between delivery systems and the terminal devices becomes an important 
issue to be solved in order to be compatible with various resolutions of digital products. To solve this problem, video 
transcoding has become an important topic. When original motion vectors are available in the compressed domain, it 
becomes possible to save computational cost by utilizing the known information. Although many fast motion re-estimation 
approaches have been proposed, such as average approach (AA), area-weighted-average (AWA) and median approach (MA), 
they are not suitable to convert an existing video to various kinds of resolutions. On the other hand, these reuse schemes may 
introduce quality degradation due to the reconstruction errors. In this paper, we propose a method to address this problem. 
First, we introduce a distance-trimmed filter (DTF) that improves accuracy of estimated motion vectors (MVs). Then we 
embed Kalman filter, which considers the correlation of motion characteristics of neighbor blocks in temporal and spatial 
domain, to improve the accuracy of estimated MVs for fast downscaling algorithms. The experimental results indicate that 
the proposed method provides an effective improvement of performance for arbitrary video downscaling. 
 
Keywords: Arbitrary video downscaling, Distance-trimmed filter, Kalman filter 
 
æ‘˜è¦ 
ç‚ºäº†è€ƒæ…®åœ¨å‚³é€åŠæ¥æ”¶ç³»çµ±ä¹‹é–“è™•æ–¼ä¸åŒçš„ç¶²è·¯é »å¯¬çš„ç’°å¢ƒä¸‹ï¼Œå¦‚ä½•å°‡å£“ç¸®çš„è¨Šæ¯è½‰æ›ä½¿ç”¨å·²
ç¶“æ˜¯ä¸€å€‹é‡è¦çš„å•é¡Œã€‚ç‚ºäº†è§£æ±ºé€™å€‹å•é¡Œï¼Œè¦–é »è½‰ç¢¼å·²ç¶“æˆç‚ºä¸€å€‹é‡è¦çš„èª²é¡Œï¼Œå…¶ä¸­æœ€é‡è¦çš„é‚„
æ˜¯è¦–è¨Šå£“ç¸®ä¸­é‹å‹•ä¼°æ¸¬çš„å•é¡Œï¼Œå› ç‚ºéœ€è¦æ¥µå¤§çš„é‹ç®—é‡ã€‚ç•¶å£“ç¸®ä¸­é‹å‹•è¨Šæ¯å·²ç¶“å­˜åœ¨ï¼Œé‚£å°±å¯ä»¥
æœ‰æ•ˆçš„æ‡‰ç”¨ä»¥è§£æ±ºé‹ç®—è¤‡é›œåº¦çš„å•é¡Œã€‚é›–ç„¶å·²ç¶“æœ‰è¨±å¤šçš„å¿«é€Ÿé‹å‹•ä¼°æ¸¬ç®—æ³•ï¼Œå¦‚å¹³å‡æ³•
ï¼ˆAAï¼‰ï¼Œè¦†è“‹é¢ç©åŠ æ¬Šå¹³å‡æ³•ï¼ˆAWAï¼‰é›†ä¸­ä½æ³•ï¼ˆMAï¼‰å·²è¢«æå‡ºï¼Œä½†åœ¨ä»»æ„çš„å–æ¨£å°ºåº¦ä¸‹ï¼Œ
ä»ç„¶ç„¡æ³•é”åˆ°ä»¤äººæ»¿æ„çš„çµæœã€‚åœ¨æœ¬è¨ˆç•«ä¸­ï¼Œæå‡ºäº†ä¸€ç¨®æ–°çš„æ–¹æ³•ä¾†è§£æ±ºé€™å€‹å•é¡Œã€‚é¦–å…ˆï¼Œæˆ‘å€‘
å°å…¥ä¸€å€‹è·é›¢åˆªé™¤æ¿¾æ³¢å™¨ï¼ˆDTFï¼‰ï¼Œæé«˜äº†é‹å‹•ä¼°æ¸¬çš„ç²¾åº¦ã€‚ç„¶å¾Œï¼ŒåµŒå…¥å¡æ›¼æ¿¾æ³¢å™¨ï¼Œå®ƒåƒè€ƒåœ¨
æ™‚é–“åŸŸå’Œç©ºé–“åŸŸçš„ç›¸é„°å¡Šé‹å‹•ç‰¹æ€§çš„ç›¸é—œæ€§ï¼Œä»¥é€²ä¸€æ­¥æ”¹å–„çš„é‹å‹•ä¼°æ¸¬çš„ç²¾ç¢ºåº¦ã€‚å¯¦é©—çµæœè¡¨
æ˜ï¼Œæ–°æ–¹æ³•å°å‚³çµ±æ–¹æ³•æœ‰æ•ˆçš„æ”¹å–„ä¼°æ¸¬çš„å“è³ªã€‚ 
 
é—œéµå­—:ä»»æ„å°ºå¯¸ç¸®å°ï¼Œè·é›¢èª¿æ•´æ¿¾æ³¢å™¨ï¼Œå¡æ›¼æ¿¾æ³¢å™¨ 
I. MOTIVATION 
The rapid development of multimedia communication, such as the third-generation (3G) mobile 
communication, is leading to an increasing demand of mobile multimedia services. Nowadays, many 
service providers investigate various multimedia applications such as news, sports, entertainments and 
other media contents to serve the users of mobile communication networks. Therefore, an effective 
video compression technique that applies to various bandwidth networks is also necessary. For video 
compression, there are many video coding standards [1], such as MPEG-x or H.26x, have been 
developed. As the number of video formats increase, to convert the compressed information between 
delivery systems and the terminal devices in the heterogeneous networks becomes an important research 
area. 
6 
 
 
FIGURE 1. A polygon is formed by four candidate MVs 
Our extensive experiments indicate that 94.5% MVs obtained by full search algorithm are located 
inside the polygon. Theoretically, the fast algorithms are able to find MVs very close to their exact value. 
However, in our experiments we found that if we move the final position one pixel along the direction of 
FS result, then a better performance could be achieved. TABLE 1 lists the results of the preliminary 
experiments. From the above observations, we can conclude that the conventional fast schemes 
mentioned in Section 2 could be possibly loss some visual quality. In this work, we will propose a new 
scheme to effectively resolve the problems for improving the accuracy of motion re-estimation. To 
overcome the problems mentioned in observation (1) and (2), we will apply the Kalman filter to reduce 
the uncertainty. The solution to the observation (3) is that we will propose a distance-trimmed mean filter 
to eliminate the unreliable motion vectors. 
 
TABLE 1. Performance of MA, full search and MA with known direction from FS (dB) 
 Foreman News M&D Akiyo Paris Hall Silent Tempete Mobile 
MA 30.25 38.02 38.62 45.50 32.86 35.26 36.16 30.77 27.32 
MA*  32.02 38.74 40.54 45.84 33.67 36.37 36.91 30.94 27.59 
FS 33.07 38.93 42.36 45.84 33.80 36.85 37.42 31.84 27.76 
*moving one pixel based on FS result 
3.2  Distance-trimmed mean filters (DTF) 
The alpha-trimmed mean filters [11] have been developed to eliminate the extreme data and hence 
increase the reliability of the data average. Therefore, we can use such idea to eliminate the extreme 
motion vector, and then reduce the uncertainty of motion re-estimation. The candidate MVs are ordered 
by their amplitude, the output of the alpha-trimmed mean filter is 
1
1
 
( 2 )
M M
new i
i M
mv mv
M M
 ï€¨ï€±ï€©ï€ 
where 0 ï‚£ ï¡ ï‚£ 0.5; mvi is the ith MV; M is the total number of the candidate MVs, and ïƒ«ïƒ—ïƒ» denotes the 
lowest integer. However, we can adjust the ï¡ value to exceed 0.5 when the downscaling factor increases. 
The purpose of alpha-trimmed mean filter is to symmetrically trim the extreme, and then the reliability 
of data average can be increased. Intuitively, it can be directly applied to AA for performance 
improvement. However, the use of amplitude-based symmetrical trimming process is not reasonable in 
motion re-estimation. For example, let { 1,2,6,15}ï€­  be the set of candidate of x-component MVs. When ï¡ 
is set to 0.3, the elements -1 and 15 will be removed by the alpha-trimmed mean filter. It is clear that 
8 
( , )
( , , ) ( , , ) ( , , )y kp y y
k p S
v m n i a v m k n i p w m n i  ï€¨ï€¶ï€©ï€ 
where 1, 0 1, 1S k p k p , kpa  is model coefficient and w(m,n,i) represents the 
model error component. 
In order to reduce the computational complexity, we assume kpa  to be a constant. Consider the 
macroblock example as shown in FIGURE 2. For simplicity, we only select two nearest neighboring 
blocks from spatial and temporal as shown in FIGURE 2. Then  (5) and (6) are simplified as 
10 01( , , ) ( 1, , ) ( , , 1) ( , , )x x x xv m n i a v m n i a v m n i w m n i  ï€¨ï€·ï€©ï€ 
10 01( , , ) ( 1, , ) ( , , 1) ( , , )y y y yv m n i a v m n i a v m n i w m n i  ï€¨ï€¸ï€©ï€ 
 
Frame i-1
Frame i
m 
n 
 
 
 
 
 
v
â€™
(k)
v(k)
a10  
a01  
 
FIGURE 2. The prediction model support for Kalman filter 
 
The state-space representation of  (7) and (8) can be written as [6, 7] 
V( ) V( 1 ) u( ) w( )m,n,i m ,n,i m,n,i m,n,iÎ¦  ï€¨ï€¹ï€©ï€ 
And the measurement equation is 
( , , ) ( , , ) ( , , )m n i m n i m n iZ HV e  ï€¨ï€±ï€°ï€©ï€ 
where V(m,n,i) is state vector on position (m,n,i); u(m,n,i) is previous state updating; Î¦, Î›, Î“ and H 
are corresponding matrices respectively. The details are shown as follows. 
10 
TABLE 2 summarize the PSNR of the reconstructed images of the four test sequences, where the 
simulation results of AA, AWA, MA, DTF and distance-trimmed filter with Kalman filter are listed. It 
can be seen that the proposed method improves performance significantly. For the Foreman sequence 
(352Ã—288) downscaled to SIF(320Ã—240) size with integer precision , for example, the DTF coupled with 
Kalman filter outperforms AA, AWA and MA by 0.946, 0.906 and 1.104 dB, respectively. On an average 
there is 0.985 dB gain for this case.  
TABLE 2. Performance of the test sequences with integer precision   (dB) 
Method 
Frame 
Size FS AA AWA MA DTF 
DTF 
(KF) 
Foreman 
320Ã— 240 34.403 31.576 31.616 31.418 31.580 32.522 
224Ã— 176 32.413 29.991 30.003 30.013 30.028 30.669 
176Ã— 144 30.910 28.783 28.783 28.916 28.787 29.441 
144Ã— 112 30.017 28.060 28.075 28.071 28.042 28.361 
Paris 
320Ã— 240 34.189 32.909 32.932 33.303 33.051 33.404 
224Ã— 176 32.385 31.367 31.376 31.622 31.541 31.771 
176Ã— 144 30.807 30.159 30.159 30.202 30.254 30.496 
144Ã— 112 30.240 29.647 29.659 29.794 29.778 29.861 
 
Examples of some estimated frames are shown in FIGURES. 3-4. It can be observed that the proposed 
method provides smoother motion fields because Kalman filter algorithm can compensate the poor 
measurement and thereby raise the PSNR significantly. For example, the visual quality of the Foremanâ€™s 
right ear and left face are improved as shown in FIGURE 3. In FIGURE 4, the Paris has a relative complex 
background. Traditional algorithms can not perform satisfactory results. With accurate MV estimation, 
we can see that the noises on the faces could be removed by the proposed method. We can conclude that 
the object-based downscaling method achieves better motion compensation efficiency for integer 
downsizing factors. Note that the proposed method also provides floating point accuracy for motion 
compensation, which can be applied to carry out transmission in H.263. 
   
FS (28.415 dB) AA (25.432 dB) AWA (25.457 dB) 
   
MA (25.435 dB) DTF (25.413 dB) DTF with KF (25.667 dB) 
12 
[4] J. Youn, M.-T. Sun, and J. Xin, Video transcoder architectures for bit rate scaling of H.263 bit streams, Proc. of the 
37th ACM international Conf. on Multimedia (Part 1) Orlando, Florida, United States: ACM, 1999. 
[5] S. Guobin, Z. Bing, Z. Ya-Qin, and M. L. Liou, Transcoder with arbitrarily resizing capability, The 2001 IEEE 
International Symposium on Circuits and Systems, vol.5, pp.25-28, 2001. 
[6] N. Bjork, and C. Christopoulos, Transcoder architectures for video coding, IEEE Trans. on Consumer Electronics, 
vol.44, pp.88-98, 1998. 
[7] J. W. C. Wong, O. C. Au, P. H. W. Wong, and A. Tourapis, Predictive motion estimation for reduced-resolution video 
from high-resolution compressed video, Proc. of the 1998 International Conf. on Image Processing, vol.2, pp.461-464, 
1998. 
[8] Y. P. Tan and H. W. Sun, Fast motion re-estimation for arbitrary downsizing video transcoding using H.264/AVC 
standard, IEEE Trans. on Consumer Electronics, vol. 50, pp. 887-894, 2004. 
[9] J. Youn, M. T. Sun, and C. W. Lin, Motion vector refinement for high-performance transcoding, IEEE Trans. on 
Multimedia, vol.1, pp.30-40, 1999 
[10] C. M. Kuo, C, H. Hsieh, Y. D. Jou, H. C. Lin and P. C. Lu, Motion estimation for video compression using Kalman 
filtering, IEEE Trans. on Broadcasting, vol. 42, pp. 110-116, 1996. 
[11] R. Oten and R. J. P. de Figueiredo, Adaptive alpha-trimmed mean filters under deviations from assumed noise model, 
IEEE Trans. on Image Processing, vol.13, pp.627-639, 2004. 
 
 2
ä¸€ã€ ï¥«åŠ æœƒè­°ç¶“é 
æœ¬æ¬¡ï¥«åŠ çš„åœ‹éš›æœƒè­°åç¨±ç‚ºâ€œ2012 Consumer Electronics, Communications and  Networksâ€ï¼Œä»¥ä¸‹ç°¡
ç¨± â€œ(CECNet 2012)â€ã€‚æ­¤æ¬¡ CECNet 2012 çš„èˆ‰è¾¦åœ°é»æ˜¯ä½æ–¼ä¸­åœ‹æ¹–ï¥£ï¥­å®œæ˜Œè¯ç¾é”é…’åº—èˆ‰ï¨ˆï¼Œæ™‚é–“ç‚º 4
æœˆ 21 æ—¥è‡³ 4 æœˆ 23 æ—¥ç‚ºæœŸä¸‰å¤©çš„æœƒè­°ã€‚ 
æœƒè­°ç•¶å¤© 4 æœˆ 21 æ—¥åœ¨è¯ç¾é”é…’åº—å…ˆè¾¦ï§¤è¨»å†Šæ‰‹çºŒï¼Œæœ¬æœƒè­°è´ˆé€ï¦ºä¸€å€‹èƒŒåŒ…ï¼Œä¸¦å¯åœ¨æœƒå¾Œé€²ï¨ˆä¸­é¤
åŠæ™šé¤çš„é¤åˆ¸ã€‚æ­¤ç ”è¨æœƒçš„ï¥æ–‡å°‡å¯ä»¥åœ¨ EI åœ‹éš›é‡è¦çš„å·¥ç¨‹ï¥æ–‡è³‡ï¦¾åº«ç³»çµ±ä¸­ï¥ªå¼•åˆ°ã€‚ 
ç•¶å¤©æœƒè­°ä¸­é‚€è«‹åˆ°7å ´Keynote speechï¼Œåˆ†åˆ¥ç”±President of IVI, USA çš„Todd Weaveræ•™æˆä¸»è¬›çš„ 
â€œOver-the Top Television, A Technical Story of Pioneersâ€ï¼ŒChairman of CenturyLink, Intelius, and 
FlowMobile, USAçš„Admiral Bill Owensæ‰€å ±å‘Šçš„ â€œAdmiral Bill Owensâ€ï¼Œä»¥åŠâ€Rambus Inc., USAçš„Dr. T. 
Gary Yipæ•™æˆæ‰€ä¸»è¬›çš„ â€œFrom Mobile to Wearable Electronicsâ€ç­‰ã€‚å­¸ç”Ÿåœ¨ç›¸é—œç ”ç©¶ï¦´åŸŸå¹¾ä¹å…¨ç¨‹ï¥«èˆ‡ï¼Œ
æ­¤å¤–å°å½±åƒè™•ï§¤æœ‰èˆˆè¶£ï¼Œï¥«åŠ ï¦ºè¨±å¤šç›¸é—œçš„è­°ç¨‹ï¼Œå°å­¸ç”Ÿè€Œè¨€æ­¤ï¨ˆæ”¶ç©«é —è±ã€‚ 
æœƒè­°ï¨ˆç¨‹å¦‚ä¸‹ï¼š 
04 æœˆ 21 æ—¥ (ç¬¬ä¸€å¤©): 
æœƒè­°ç•¶å¤©ç‚ºå¤§æœƒçš„å ±åˆ°ç™¼æ”¾æœƒè­°è³‡ï¦¾çš„æ™‚é–“ï¼Œå„åœ‹èè‹±é å¾å„åœ°é½Šèšè€Œï¤­æœ‰å°ï¨ã€ä¸­æ±ã€éŸ“åœ‹ã€
æ–°åŠ å¡ã€é¦¬ï¤­è¥¿äºâ€¦ç­‰åœ‹å®¶çš„å­¸è€…ï¼Œï¨¦ï§“çºŒåœ¨é€™ä¸€å¤©å ±åˆ°ï¼Œä¹Ÿç‚ºé€™æ¬¡çš„ç ”è¨æœƒä¹‹ï¨ˆç¨‹æ·»åŠ ï¤æ·±çš„è¨˜æ†¶
èˆ‡å­¸è¡“ç„¡åœ‹ç•Œçš„å¯è²´ã€‚ 
04 æœˆ 22 æ—¥ (ç¬¬äºŒå¤©): 
ç¬¬äºŒå¤©åœ¨å¤§æœƒï¨å¿ƒå®‰æ’ä¸‰å ´Keynote speechã€‚é‚€è«‹åˆ°ï¦ºPresident of IVI, USA çš„Todd Weaveræ•™æˆä¸»
è¬›çš„ â€œOver-the Top Television, A Technical Story of Pioneersâ€ï¼Œï¥æ–‡ä¸­æä¾›æ–°ä¸€ä»£OTT (Over The Top)å®Œ
æˆTriple Play IPTV Terminal Middlewareè»Ÿé«”é–‹ç™¼ï¼Œå¯æä¾›TV Phoneã€TV Text Chattingã€TV Widgetsã€
Video Surveillanceã€Web Browsingã€Video-on-Demandã€åŠPicture & Video Sharingç­‰Triple PlayåŠ å€¼æ‡‰ç”¨
æœå‹™ï¼ŒChairman of CenturyLink, Intelius, and FlowMobile, USAçš„Admiral Bill Owensæ‰€å ±å‘Šçš„ â€œAdmiral 
Bill Owensâ€ï¼Œä»¥åŠâ€Rambus Inc., USAçš„Dr. T. Gary Yipæ•™æˆæ‰€ä¸»è¬›çš„â€œFrom Mobile to Wearable 
Electronicsâ€ï¼Œæå‡ºä¸€å€‹æ–°çš„ï¨ˆå‹•å»£å‘Šæ¶æ§‹ï¼Œè®“ï¨ˆå‹•å»£å‘Šè£ç½®å¯ä»¥ç©¿æˆ´åœ¨èº«ä¸Šï¼Œå…·æœ‰ä½ç½®æ„ŸçŸ¥åŠŸèƒ½ï¼Œå¯
ä»¥ä¸»å‹•é‡å°æ¶ˆè²»æ—ç¾¤çš„ç‰¹æ€§æ’­æ”¾å•†å“å»£å‘Š;ç³»çµ±ä¸¦æä¾›ä»‹é¢ï¼Œè®“è¨—æ’­çš„åº—å®¶å¯ä»¥éš¨æ™‚è§€å¯Ÿåˆ°ç§»å‹•å»£å‘Šè£
ç½®çš„ä½ç½®åŠï¤å‹•å»£å‘Šçš„è¨Šæ¯å…§å®¹;é–‹æ”¾çš„ç³»çµ±æ¶æ§‹ï¼Œä¹Ÿå°‡æä¾›ä¸€èˆ¬çš„ç§»å‹•å»£å‘Šè£ç½®ç§Ÿç”¨åŠç‰¹å®šå€åŸŸå»£å‘Š
ï¥¸ç¨®ç‡Ÿé‹æ¨¡å¼ä¾›æœ‰å»£å‘Šéœ€æ±‚çš„åº—å®¶æˆ–ä¼æ¥­é¸æ“‡ï¼Œè½å®Œä¸‰å ´ï¥§åŒï¦´åŸŸæ¼”è¬›ç›¸ä¿¡å°æœªï¤­çš„å¯¦é©—å’Œç ”ç©¶æ–¹å‘
æ˜¯å¯ä»¥å¸¶ï¤­ï¤å¤§å¤šæ–¹é¢çš„å¹«åŠ©ä¸”ï¤å…·æœ‰æ˜ç¢ºçš„ç›®æ¨™ã€‚ 
04 æœˆ 23 æ—¥ (ç¬¬ä¸‰å¤©): 
æˆ‘çš„ï¥æ–‡è¢«å®‰æ’åœ¨ä¸‹åˆ Poster Sessionï¼Œä¸Šåˆæ™‚é–“å°±å‰å¾€ Oral Session 2 ä¸­ï¦°è½æ‰€ç™¼è¡¨çš„ï¥æ–‡ï¼Œé€™ä¸€
å€‹ SESSION æ‰€ç™¼è¡¨çš„ï¥æ–‡ä¸­ï¼ŒåŒ…å«æœ‰è¦–è¨ŠæŠ€è¡“ã€å½±åƒæª¢ï¥ªã€å½±åƒç´‹ï§¤è™•ï§¤ã€å½±åƒè‰²å½©è™•ï§¤ ç­‰ç­‰ã€‚åœ¨
é€™äº›æ‰€ç™¼è¡¨çš„ï¥æ–‡ä¸­æˆ‘å€‹äººæ¯”è¼ƒåå‘å–œå¥½è½‰æ›åŸŸè¦–è¨Šè½‰ç§»ç·¨ç¢¼çš„è™•ï§¤ï¼Œé›–ç„¶ç ”ç©¶ï¦´åŸŸï¥§å®Œå…¨ç›¸åŒï¼Œå»
ä¹Ÿèƒ½ç‚ºæˆ‘çš„ç ”ç©¶æ–¹å‘å¢é€²ï¦³æ„Ÿï¼ŒåŒæ™‚åœ¨ï¦°è½ï¥§åŒåœ‹å®¶çš„å­¸è€…çš„å ±å‘Šæ™‚ï¼Œå¾ˆæ˜é¡¯èƒ½å¤ æ„Ÿå—åˆ°ï¥§åŒçš„å ±å‘Š
é¢¨æ ¼ï¼Œè—‰ç”±æœƒä¸Šï¥§åŒåœ‹éš›è§€è¨ï¥æ„ï¨Šç²ï¨—ï¥¼å¤šã€‚ 
ä¸‹åˆ Poster Sessionï¼Œæˆ‘å€‘çš„æ‰€ç™¼è¡¨çš„ï¥æ–‡ã€Partial Distortion Based Computation-Constraint Motion 
Estimationã€‘ï¼Œæœ¬ç¯‡ï¥æ–‡åœ¨ç ”ç©¶è¿‘ï¦ï¤­ç”±æ–¼ç„¡ç·šç¶²ï¤·çš„æ™®åŠèˆ‡å„ç¨®å¤šåª’é«”æ‡‰ç”¨æœå‹™çš„å¢åŠ ï¼Œæ‰‹æŒè£ç½®çš„
ï¥©ä½è¦–è¨Šä½¿ç”¨å¤§å¹…æå‡ã€‚è€Œåœ¨ä½¿ç”¨ï¥©ä½å½±åƒçš„å‚³è¼¸æˆ–å„²å­˜æ™‚å½±åƒå£“ç¸®æ˜¯æœ€é‡è¦çš„æŠ€è¡“ï¼Œè€Œé‹å‹•ä¼°æ¸¬å‰‡
è¦–å½±åƒå£“ç¸®ä¸­ç›¸ç•¶é‡è¦çš„ä¸€éƒ¨åˆ†ã€‚ç„¶è€Œå‚³çµ±é‹å‹•ä¼°æ¸¬æ¼”ç®—æ³•åœ¨è¨­è¨ˆä¸Šï¼Œåªè€ƒæ…®ã€Œç•«é¢å“è³ªã€è€Œæ²’æœ‰è€ƒ
æ…®åˆ°ã€Œè¨ˆç®—ï¥¾ã€ï¼Œå³ä½¿ç”¨å¿«é€Ÿæ¼”ç®—æ³•é€²ï¨ˆé‹å‹•ä¼°æ¸¬ï¼Œå…¶è¨ˆç®—ï¥¾ä¹Ÿæ˜¯è¨ˆç®—èƒ½ï¦Šï¥§è¶³çš„æ‰‹æŒè£ç½®ç„¡æ³•è² è·çš„ï¼Œ
ä»¥è‡³æ–¼å‚³çµ±çš„é‹å‹•ä¼°æ¸¬è¨­è¨ˆæ–¹æ³•åœ¨è¨ˆç®—ï¥¾ï¥§è¶³çš„æ‰‹æŒè£ç½®ä¸Šä¸¦ï¥§å¯¦ç”¨ã€‚æœ¬ç ”ç©¶æ‰€æå‡ºçš„æ–¹æ³•åŒæ™‚è€ƒæ…®
 
 
æœƒå¾Œæ–¼æœƒè­°å»³å¤–ï§å½± å°‡æµ·å ±å¼µè²¼æ–¼æœƒè­°å»³å…§ï§å½± 
 
 
å¼µç¹¼é«˜ï¥æ–‡ç™¼è¡¨å¯¦æ³ ï¥«è¨ªå…¶ä»–ä½œè€…ï¥æ–‡ 
  
èˆ‡æ­¦æ¼¢å¤§å­¸åšå£«ç”Ÿäº¤ï§Š èˆ‡æ­¦æ¼¢å¤§å­¸åšå£«ç”Ÿäº¤ï§Š 
 
ä¸€ã€èˆ‡æœƒå¿ƒå¾— 
å­¸ç”Ÿè¦ºå¾—ï¥«èˆ‡æ­¤ï§ç ”è¨æœƒæ˜¯å¿…é ˆçš„ï¼Œåœ¨æœƒè­°æœŸé–“ï¥§ä½†èƒ½ï¦°è½ï¥æ–‡ç™¼è¡¨è€…çš„å£é ­å ±å‘Šï¼Œï¤é‡è¦çš„æ˜¯
å¯ä»¥å’Œï¥æ–‡ç™¼è¡¨è€…ï¼Œæˆ–ç†Ÿæ‚‰ç›¸é—œï¦´åŸŸçš„å°ˆå®¶å­¸è€…å€‘äº’ç›¸è¨ï¥ï¼Œè€Œå¾—åˆ°ï¤å¤šçš„ç ”ç©¶å¿ƒå¾—èˆ‡å•Ÿç™¼ï¼Œï¥§åªæ˜¯
ç•¶å€‹åœ¨ï¦°è½è€…æœƒæœ‰æ”¶ç©«ï¼Œåœ¨å°ä¸Šæˆ–æ˜¯æµ·å ±ç™¼è¡¨ï¥æ–‡è€…ä¹Ÿæœƒå› ç‚ºå½¼æ­¤çš„äº’å‹•è€Œç²ï¨—ï¥¼å¤šï¼Œæ­¤ç¨®é›™å‘çš„æº
é€šèˆ‡è¨ï¥æ˜¯è®“å¤§å®¶èƒ½å¤ ï¤é€²æ­¥çš„åŸå‹•ï¦Šã€‚ 
 4
Partial Distortion Based Computation-Constraint 
Motion Estimation 
Chi-Kao Chang, Min-Yuan Fang, I-Chang Jou, Ming-Haw Jing, Chung-Ming Kuo* 
Department of Information Engineering 
I-Shou University 
No. 1, Sec. 1, Syuecheng Rd., Dashu Township, Kaohsiung 840, Taiwan 
*Corresponding author: kuocm@isu.edu.tw 
 
Abstractâ€” Recently, the rapid development of wireless networks 
and multimedia communication techniques provide solutions to 
achieve watching digital videos on hand-held devices. Motion 
estimation (ME), the most important part of video coding, has 
been used to increase the effectiveness of video compression. 
However, the computations of motion estimation could be failed 
in limited computing environments even using the fast algorithms. 
Therefore, the traditional ME algorithms cannot directly applied 
to the hand-held devices. In this paper, we propose a partial 
distortion scheme that sacrifice little visual quality for hand-held 
devices in a given computation constraint condition. We also 
analyze various computation-aware based block matching 
algorithms and present an efficient method to compute the 
motion vectors. The proposed method significantly reduces the 
requirement of computation power in computing motion vectors 
while the number of search points needed is only 25% of the 
conventional method. 
Keywords- Motion estimation; partial distortion; computation 
constraint 
I.  INTRODUCTION 
For video compression, the motion estimation is the most 
important and time consuming operation. While the block-
matching algorithms such as the three-step search (TSS) [1], 
the four-step search (FSS) [2], and the diamond search (DS) [3] 
have been proposed to reduce the computational complexity, it 
is still not enough to achieve the desired coding efficiency for 
the handheld consumer electronic devices. Typically, the 
motion estimation consumes over 60% of processor power [4] 
to encode a video, which decreases the operational lifetime of 
these devices. 
Recently, the issue has been focused on optimizing ME 
algorithms to achieve low-bit-rate and low-power coding. He et 
al. [5] proposed an analytic framework to model the power-
rate-distortion (P-R-D) behavior to manage power consumption, 
and pointed out that the video quality is a function of bit rate 
and power consumption. This leads to problems on the trade-
off between the reconstruction quality and the computational 
cost. In order to efficiently allocate computational resources, 
many solutions have been proposed such as computation-
constrained predictive ME algorithm [6], code-optimization 
technique [7], joint source coding and transmission power 
technique [8], and joint complexity-distortion optimization 
approach [9]. These algorithms achieve to limit the amount of 
distortion by using a relatively small number of bits. However, 
these improvements still cannot satisfy the requirements 
implemented in hand-held devices. Therefore, it is urgent to 
develop a more efficient ME algorithm for the low-power 
coding. 
In this work, we have two goals. The first is to use the 
algorithmic optimization to achieve efficient ME. The second 
is to understand what video quality can be achieved under 
extremely constrained complexity. Three strategies can be 
addressed to solve the problem of computation constraint 
coding. 
1) The selection of fast motion estimation algorithm 
For current video coding standard, a number of research 
interests have aimed at fast motion estimation (ME) to reduce 
the complexity of video compression [1-3]. However, for 
handheld devices, even the current fast algorithms are not 
satisfactory due to very narrow power constraints. Thus, the 
selection of motion estimation is very important. 
2) Computation-aware (CA) 
Usually, the current motion estimation terminates according 
to condition of convergence, and cannot be interrupted [10]. 
When the available computation power is not enough, the 
video quality could be unpredictable. The concept of CA is to 
allow the searching processes terminating after any specified 
amount of computation. The basic idea behind CA is to save 
checking points from previous blocks for extra checks. 
3) Sub-sampling algorithms 
Sub-sampling algorithms [1,12], which have been proposed 
to reduce the computational complexity of block matching, 
provides an alternative way to reduce the complexity. In 
general, this method achieves good ME results by using partial 
pixels in a block. 
All the techniques mentioned above focused on decreasing 
computation cost without losing significant visual quality. To 
achieve efficient motion estimation in limited computing 
environments, we need to consider an approach that takes into 
account the three specific techniques to generate a better ME. It 
is worth noting that ME algorithms consume over 60% of 
processor power, which implies that losing some reconstruction 
quality for saving checking points is the best way to solve the 
processor power problem in this stage. Motivated by this fact, 
we propose a partial distortion scheme that allows to loss some 
visual quality for power-constraints devices in a given 
computation constraint condition.  
1956
978-1-4577-1415-3/12/$26.00 Â©2012 IEEE
0 2 4 6 8 10
28
29
30
31
32
33
34 CA-TSS
CA-DS
CA-DASP
PSNR
!
Fig. 3. Average PSNR per frame produced by CA-TSS, CA-DS and CA-
DASP!
III. PARTIAL DISTORTION BASED MOTION ESTIMATION 
A. Directional asymmetric search with prediction (DASP) 
The DASP algorithm, proposed by Kuo et al. [13], has a 5-
point cross pattern as shown in Fig. 4. The algorithm attained 
successful results and is used in our evaluation for block 
matching.  
 
Fig. 4. Search pattern of DASP 
B. Pixel-Decimation 
When the sampling factor is given, there are many ways to 
achieve sub-sampling within a block. However, it is expected 
that the sampling pattern will extract the best samples to 
characterize the block MV. In this work, we propose two 
sampling patterns as mentioned in section 2. We simulate nine 
tested sequences by using the two patterns. Results are 
summarized in Table IV. As we can see, the largest value of 
the search points for the test sequences is 9.604 (Football). In 
order to efficiently carry out sampling, we use different 
sampling patterns adaptively. In the following, we denote P1 as 
the sampling pattern for all pixels, P1/2 and P1/4 are the 
sampling patterns by a factor of 2 and 4, respectively; DPMV is 
the difference of predicted MV; Davg is the average difference 
of the previous frame; spn  is the average number of search 
points. 
The conditions for the pattern selection used here are 
described as follows. 
z Case 1: If the number of search points nspÊ9, all pixels 
of a block are used for sampling. 
z Case 2: If 9Ênsp>4.5, both the sampling patterns P1 and 
P1/2 are used:  
P M V avg std 1
1 / 2
D D (6 .75 ) D ,   
o therw ise,                                     
spnÂ­ !   u mÂ°Â® mÂ°Â¯
P P
P P
 (1) 
where we use the symbol m to denote replacement. 
The difference of the predicted MV specifies importance of a 
block, and affects the efficiency. If the spn  is increased, 
meaning the number of search points available will increase, 
we can decrease the threshold accordingly. 
z Case 3: If the number of search point satisfies 4.5Ênsp 
>2.25, both the sampling patterns P1/2 and P1/4 are used. 
P M V avg std 1 / 2
1 / 4
D D (3 .75 ) D ,   
o therw ise,                                     
spnÂ­ !   u mÂ°Â® mÂ°Â¯
P P
P P
 (2) 
z Case 4: If the number of search point satisfies nsp<2.25, 
the sampling pattern P1/4 is used. 
C. Partial Distortion Based computation constraints ME 
Algorithm 
The flow chart for partial distortion based computation 
constraints ME algorithm is illustrated in Fig. 5. The system 
operates as follows: 
1) First, the total number of checking points available is 
assigned. 
2) Then the number of computation for each block can 
be determined. 
3) A proper sampling pattern will be chosen to allocate 
the limited computation number. 
4) Find the motion vector and the minimum SSD for 
each MB. 
5) Create PCDB list, and pick up the block with 
maximum MSE. 
6) The proper sampling pattern will be chosen and 
Perform the DASP. 
7) Checking stop condition. 
Determine the
maximum search points
Input image
Start
Compute the search
points for each block
Pattern selection
Compute difference
Create PCDB list
Pattern selection
DASP
End search?
End
No
Yes
 
Fig. 5. Flow chart for partial distortion based ME algorithm. 
1958
The International Conference on Consumer Electronics, Communications and Networks 
ï¼ˆCECNet 2012ï¼‰ 
 
www.cecnetconf.org/2012    Apr. 21st-23rd, 2012    Three Gorges, China 
 
Acceptance Notification 
Jan.31, 2012 
 
 
Dear Author, 
 
Congratulations! We are extremely glad to inform you that your paper: 
 
Paper ID: ET41049 
Author: Chi-Kao Chang, Min-Yuan Fang, I-Chang Jou, Ming-Haw Jing, Chung-Ming Kuo* 
Paper Title: Partial Distortion Based Computation-Constraint Motion Estimation 
 
has been accepted for presentation at the 2nd International Conference on Consumer 
Electronics, Communications and Networks (CECNet 2012) . 
 
Please finish all registration procedures before Feb. 15, 2012 by the Registration Instructions in 
attached.  
 
We are grateful for your contribution to CECNet2012. And we are looking forward to meeting 
you in Three Gorges, China. We also hope that you will contribute your excellent work to future 
CECNet conferences. 
  
For more information, please visit our website: www.cecnetconf.org/2012  
Thanks for your support again! 
Best regards! 
 
 
 
CECNet2012 Organizing Committee 
IEEE Catalog Numberï¼ˆPrint Versionï¼‰: CFP1253N-PRT  ISBN: 978-1-4577-1412-2-1 
100ï¦ï¨å°ˆé¡Œç ”ç©¶è¨ˆç•«ç ”ç©¶æˆæœå½™æ•´è¡¨ 
è¨ˆç•«ä¸»æŒäººï¼šå‘¨ç¾©æ˜Œ è¨ˆç•«ç·¨è™Ÿï¼š100-2221-E-214-068- 
è¨ˆç•«åç¨±ï¼šå…ˆé€²çš„é‹å‹•ä¼°æ¸¬/è£œå„ŸæŠ€è¡“æ‡‰ç”¨æ–¼è¦–è¨Šè½‰ç§»ç·¨ç¢¼çš„ç ”ç©¶ 
ï¥¾åŒ– 
æˆæœé …ç›® 
å¯¦éš›å·²é”
æˆï¥©ï¼ˆè¢«æ¥
å—æˆ–å·²ç™¼
è¡¨ï¼‰ 
é æœŸç¸½é”æˆ
ï¥©(å«å¯¦éš›
å·²é”æˆï¥©)
æœ¬è¨ˆç•«
å¯¦éš›è²¢
ç»ç™¾åˆ†
æ¯” 
å–®ä½ 
å‚™è¨»ï¼ˆè³ªåŒ–ï¥¯æ˜ï¼šå¦‚ï¥©
å€‹è¨ˆç•«å…±åŒæˆæœã€æˆ
æœï¦œç‚ºè©²æœŸåˆŠä¹‹å°é¢
æ•…äº‹...ç­‰ï¼‰ 
æœŸåˆŠï¥æ–‡ 0 0 100%  
ç ”ç©¶å ±å‘Š /æŠ€è¡“å ±
å‘Š 0 0 100%  
ç ”è¨æœƒï¥æ–‡ 0 0 100% 
ç¯‡ 
 
ï¥æ–‡è‘—ä½œ 
å°ˆæ›¸ 0 0 100%   
ç”³è«‹ä¸­ä»¶ï¥© 0 0 100%  å°ˆï§ å·²ç²å¾—ä»¶ï¥© 0 0 100% ä»¶  
ä»¶ï¥© 0 0 100% ä»¶  
æŠ€è¡“ç§»è½‰ 
æ¬Šï§ï¤Š 0 0 100% åƒå…ƒ  
ç¢©å£«ç”Ÿ 6 0 100%  
åšå£«ç”Ÿ 2 0 100%  
åšå£«å¾Œç ”ç©¶å“¡ 0 0 100%  
åœ‹å…§ 
ï¥«èˆ‡è¨ˆç•«äººï¦Š 
ï¼ˆæœ¬åœ‹ç±ï¼‰ 
å°ˆä»»åŠ©ï§¤ 0 0 100% 
äººæ¬¡ 
 
æœŸåˆŠï¥æ–‡ 0 0 100%  
ç ”ç©¶å ±å‘Š /æŠ€è¡“å ±
å‘Š 0 0 100%  
ç ”è¨æœƒï¥æ–‡ 2 0 100% 
ç¯‡ 
CECNet2012[Partial 
Distortion Based 
Computation-Constraint 
Motion 
Estimation][Event 
Detection for Broadcast 
Tennis Videos Based on 
Trajectory Analysis] 
ï¥æ–‡è‘—ä½œ 
å°ˆæ›¸ 0 0 100% ç« /æœ¬  
ç”³è«‹ä¸­ä»¶ï¥© 0 0 100%  å°ˆï§ å·²ç²å¾—ä»¶ï¥© 0 0 100% ä»¶  
ä»¶ï¥© 0 0 100% ä»¶  
æŠ€è¡“ç§»è½‰ 
æ¬Šï§ï¤Š 0 0 100% åƒå…ƒ  
ç¢©å£«ç”Ÿ 0 0 100%  
åšå£«ç”Ÿ 0 0 100%  
åšå£«å¾Œç ”ç©¶å“¡ 0 0 100%  
åœ‹å¤– 
ï¥«èˆ‡è¨ˆç•«äººï¦Š 
ï¼ˆå¤–åœ‹ç±ï¼‰ 
å°ˆä»»åŠ©ï§¤ 0 0 100% 
äººæ¬¡ 
 
åœ‹ç§‘æœƒè£œåŠ©å°ˆé¡Œç ”ç©¶è¨ˆç•«æˆæœå ±å‘Šè‡ªè©•è¡¨ 
è«‹å°±ç ”ç©¶å…§å®¹èˆ‡åŸè¨ˆç•«ç›¸ç¬¦ç¨‹ï¨ã€é”æˆé æœŸç›®æ¨™æƒ…æ³ã€ç ”ç©¶æˆæœä¹‹å­¸è¡“æˆ–æ‡‰ç”¨åƒ¹
å€¼ï¼ˆç°¡è¦æ•˜è¿°æˆæœæ‰€ä»£è¡¨ä¹‹æ„ç¾©ã€åƒ¹å€¼ã€å½±éŸ¿æˆ–é€²ä¸€æ­¥ç™¼å±•ä¹‹å¯èƒ½æ€§ï¼‰ã€æ˜¯å¦é©
åˆåœ¨å­¸è¡“æœŸåˆŠç™¼è¡¨æˆ–ç”³è«‹å°ˆï§ã€ä¸»è¦ç™¼ç¾æˆ–å…¶ä»–æœ‰é—œåƒ¹å€¼ç­‰ï¼Œä½œä¸€ç¶œåˆè©•ä¼°ã€‚
1. è«‹å°±ç ”ç©¶å…§å®¹èˆ‡åŸè¨ˆç•«ç›¸ç¬¦ç¨‹ï¨ã€é”æˆé æœŸç›®æ¨™æƒ…æ³ä½œä¸€ç¶œåˆè©•ä¼° 
â– é”æˆç›®æ¨™ 
â–¡æœªé”æˆç›®æ¨™ï¼ˆè«‹ï¥¯æ˜ï¼Œä»¥ 100å­—ç‚ºé™ï¼‰ 
â–¡å¯¦é©—å¤±æ•— 
â–¡å› æ•…å¯¦é©—ä¸­æ–· 
â–¡å…¶ä»–åŸå›  
ï¥¯æ˜ï¼š 
2. ç ”ç©¶æˆæœåœ¨å­¸è¡“æœŸåˆŠç™¼è¡¨æˆ–ç”³è«‹å°ˆï§ç­‰æƒ…å½¢ï¼š 
ï¥æ–‡ï¼šâ–¡å·²ç™¼è¡¨ â–¡æœªç™¼è¡¨ä¹‹æ–‡ç¨¿ â– æ’°å¯«ä¸­ â–¡ç„¡ 
å°ˆï§ï¼šâ–¡å·²ç²å¾— â–¡ç”³è«‹ä¸­ â– ç„¡ 
æŠ€è½‰ï¼šâ–¡å·²æŠ€è½‰ â–¡æ´½è«‡ä¸­ â– ç„¡ 
å…¶ä»–ï¼šï¼ˆä»¥ 100å­—ç‚ºé™ï¼‰ 
3. è«‹ä¾å­¸è¡“æˆå°±ã€æŠ€è¡“å‰µæ–°ã€ç¤¾æœƒå½±éŸ¿ç­‰æ–¹é¢ï¼Œè©•ä¼°ç ”ç©¶æˆæœä¹‹å­¸è¡“æˆ–æ‡‰ç”¨åƒ¹
å€¼ï¼ˆç°¡è¦æ•˜è¿°æˆæœæ‰€ä»£è¡¨ä¹‹æ„ç¾©ã€åƒ¹å€¼ã€å½±éŸ¿æˆ–é€²ä¸€æ­¥ç™¼å±•ä¹‹å¯èƒ½æ€§ï¼‰ï¼ˆä»¥
500å­—ç‚ºé™ï¼‰ 
é‹å‹•ä¼°æ¸¬ï¥§ä½†æ˜¯è¦–è¨Šå£“ç¸®çš„å…ˆæ±ºæ­¥é©Ÿï¼Œä¹Ÿæ˜¯æœ€é‡è¦çš„éƒ¨ä»½ï¼Œè¦–è¨Šå“è³ªåŠå£“ç¸®æ•ˆï¥¡å¾€å¾€ç”±é‹
å‹•ä¼°æ¸¬çš„æ¼”ç®—æ³•ï¤­æ±ºå®šã€‚å€å¡ŠåŒ¹é…æ¼”ç®—æ³• (Block Matching Algorithm)æ˜¯æœ€ç‚ºæ™®éä½¿ç”¨
çš„é‹å‹•ä¼°æ¸¬æ–¹æ³•ã€‚ä¸€èˆ¬è€Œè¨€ï¼Œæœå°‹æ˜¯ä»¥ç›®å‰å€å¡Šç‚ºä¸­å¿ƒï¼Œåœ¨ä¸€å®šå¤§å°çš„ç¯„åœå…§é€²ï¨ˆï¼Œæ­¤ç¯„
åœç¨±åšæœå°‹è¦–çª—(Search Window)ã€‚æœ€ç›´æ¥çš„å€å¡ŠåŒ¹é…æ¼”ç®—æ³•å°±æ˜¯å®Œå…¨æœå°‹(Full Search)
æ¼”ç®—æ³•ã€‚å®Œå…¨æœå°‹æ¼”ç®—æ³•å°æ•´å€‹æœå°‹è¦–çª—å…§çš„æ¯ä¸€å€‹é»é€²ï¨ˆå·®ï¥¢è¨ˆç®—ï¼Œæ‰¾å‡ºæœ€å°å·®ï¥¢çš„é»
åšç‚ºè©²å€å¡Šçš„é‹å‹•å‘ï¥¾(Motion Vector)ï¼Œå› æ­¤æ˜¯æœ€ä½³è§£(ä»¥è¦–è¨Šå“è³ªè€Œè¨€)ï¼Œä½†è¨ˆç®—ï¥¾å»
æ˜¯ååˆ†é©šäººã€‚å› æ­¤ï¼Œè¨±å¤šå¿«é€Ÿå€å¡ŠåŒ¹é…æ¼”ç®—æ³•(Fast Block Matching Algorithm)ç›¸ç¹¼ç”¢
ç”Ÿã€‚å¦‚ä½•åœ¨æœ€çŸ­çš„é‹ç®—æ™‚é–“å…§æ‰¾å‡ºæœ€ç›¸ä¼¼çš„å€å¡Šï¼Œä¸¦ä¸”ç¶­æŒèˆ‡å®Œå…¨æœå°‹æ¼”ç®—æ³•ç›¸è¿‘çš„è¦–è¨Š
å“è³ªï¼Œæ˜¯å„ç¨®å¿«é€Ÿæ¼”ç®—æ³•ä¸€è‡´çš„ç›®æ¨™ã€‚ 
è¨ˆåŠƒä¸­æˆ‘å€‘é‡å°è½‰æ›åŸŸ(DCT)è¦–è¨Šè½‰ç§»ç·¨ç¢¼æ¶æ§‹ï¼Œä¸»è¦æ¢è¨çš„è­°é¡Œæ˜¯é›†ä¸­åœ¨ï¨‰ä½ç•«æ¡†å°ºå¯¸
çš„è¦–è¨Šè½‰ç¢¼å™¨èˆ‡é‹å‹•å‘ï¥¾é‡ä¼°æ¸¬èˆ‡ä¿®æ­£ã€‚ï¨‰ä½ç•«æ¡†å°ºå¯¸çš„éƒ¨åˆ†æˆ‘å€‘æå‡ºå¥‡ï¥©å€ï¥¡èˆ‡éå°ç¨±
å€ï¥¡ä¹‹ï¨‰ä½ç•«æ¡†å°ºå¯¸æŠ€è¡“ï¤­è§£æ±ºå‚³çµ±æ¼”ç®—æ³•åªèƒ½è™•ï§¤å¶ï¥©å€ï¥¡çš„å•é¡Œï¼Œé€™ï¥¸ç¨®æŠ€è¡“ï¨¦æ˜¯åœ¨
è½‰æ›åŸŸä¸­å‘ä¸‹èª¿æ•´ç•«æ¡†å°ºå¯¸ï¤­ç¬¦åˆå„ç¨®æ¥æ”¶ç«¯æ‰€éœ€æ±‚ä¹‹è¦–è¨Šè¦æ ¼ã€‚é‹å‹•å‘ï¥¾é‡ä¼°æ¸¬èˆ‡ä¿®æ­£
çš„éƒ¨ä»½æˆ‘å€‘ï§ç”¨åœ¨è½‰æ›åŸŸçš„é‹å‹•è£œå„Ÿä¹‹æŠ€è¡“æ­é…é‹å‹•å‘ï¥¾é‡ä¼°æ¸¬ï¤­å¢åŠ é‹å‹•å‘ï¥¾ä¹‹æº–ç¢º
ï¨ï¼Œé€²ä¸€æ­¥æå‡ç•«é¢å“è³ªã€‚ 
æœ¬ç ”ç©¶å…·æœ‰æ¥µé«˜çš„å­¸è¡“æ€§åŠå¯¦ç”¨åƒ¹å€¼ï¼Œç›®å‰å·²æœ‰ç›¸ç•¶å¤šçš„ç ”ç©¶æˆæœï¼ŒåŒ…å«ç™¼è¡¨ï¦ºç ”è¨æœƒï¥
æ–‡(CECNet2012)ï¼ŒæœŸåˆŠï¥æ–‡(IEEE Trans. Circuits and systems for Video Technology)ï¼Œ
ä»¥åŠå°ˆæ›¸å°ˆç« (Search Algorithms, InTech - Open Access Publisher)ï¼ŒåŒæ™‚ä¹Ÿæå‡ºï¦º
