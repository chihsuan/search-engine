I 
 
 
 
ç›® éŒ„ 
 
 
ä¸€ã€ä¸­æ–‡æ‘˜è¦ ............................................................................................................................. II 
äºŒã€è‹±æ–‡æ‘˜è¦ ........................................................................................................................... III 
ä¸‰ã€å ±å‘Šå…§å®¹ ............................................................................................................................. 1 
ï¼ˆä¸€ï¼‰ã€å‰è¨€ ........................................................................................................................ 1 
ï¼ˆäºŒï¼‰ã€ç ”ç©¶ç›®çš„ ................................................................................................................ 3 
ï¼ˆä¸‰ï¼‰ã€æ–‡ç»æ¢è¨ ................................................................................................................ 5 
ï¼ˆå››ï¼‰ã€ç ”ç©¶æ–¹æ³• ................................................................................................................ 8 
ï¼ˆäº”ï¼‰ã€çµæœèˆ‡è¨è«– .......................................................................................................... 13 
å››ã€åƒè€ƒæ–‡ç» ........................................................................................................................... 22 
åœ‹ç§‘æœƒè£œåŠ©å°ˆé¡Œç ”ç©¶è¨ˆç•«æˆæœå ±å‘Šè‡ªè©•è¡¨ ........................................................................... 25 
 
 
 
 
 
 
 
 
III 
 
äºŒã€è‹±æ–‡æ‘˜è¦ 
 
 In this project, tasks on (1) perception with radio frequency identification (RFID) and (2) control with 
imitation learning are accomplished and verified. While collision-free navigation could be done using 
traditional rule-based approaches, it becomes more attractive to use learning from demonstration (LfD) 
approaches to ease the burden of tedious coding and parameter tuning procedures recently. Given the world 
model, the starting pose, and the goal pose, a path could be learned using trajectory-based LfD approaches. In 
this project, we argue that learning collision-free navigation in static environments could be accomplished 
using only instance-based examples without using global information such as the map and the goal location. 
Meanwhile, on the perception side, the RFID technology has been studied and used to solve the localization 
and mapping problems in which most of studies use long-range active or passive RFID systems with multiple 
readers and dense tags. In this project, we propose to use a short-range passive RFID reader to accomplish 
extended Kalman filter (EKF) based simultaneous localization and mapping (SLAM) with sparse tags in large 
indoor environments. We demonstrate that it is feasible to accomplish SLAM with sufficient accuracy using 
only odometry and short-range RFID data. The experimental results of control with imitation learning using a 
real robot with a laser scanner demonstrated that the low level control commands for collision-free navigation 
are learnable from demonstration using the proposed approach, while the simulation and experimental results 
of RFID SLAM demonstrate the feasibility of the proposed system. 
 
 
Keywords: learning from demonstration, robot navigation, SLAM, RFID 
 
 
 
2 
 
compared with indoor or outdoor environments thus the effect of the environment to the robot is not 
considered in this application. In most applications, the information from the environments is usually 
extracted to form the feature space. The transformation from a feature space to a cost space could later be 
learned for outdoor navigation using trajectory-based examples generated by a planner [12]. In [15] and [16], 
it is assumed that an optimal or near-optimal action agent could be queried during the learning process and an 
agent could be trained to navigate through the environments in the world of Super Tux Kart or Super Mario 
Bros. 
 Observing such successes, demonstration based learning techniques may be a great tool to learn the 
actions of the robot according to the userâ€™s demonstration. Thus, we aimed to use demonstration based 
learning techniques to deal with the motion control problems in this project. On the other hand, for a mobile 
robot, it is also important for the robot to have the ability to localize itself and generate the map thus the 
global path planning could be done accordingly. In this project, the radio frequency identification (RFID) 
technology has been applied to solve the localization and mapping problems. The radio frequency 
identification technology has been applied in many applications such as storage management, personal 
guarding and public transporting system. The RFID applications are flexible and feasible because of RFIDâ€™s 
fast detection capability and contactless identification with perfect data association. As data association is one 
of the most challenging problems in robot perception, the RFID technology has been used to solve a number 
of daunting robot perception problems such as mapping, localization and activity recognition. With a 
predefined or calibrated map of RFID tags, localization can be performed [17] [18] [19]. HÃ¤hnel et al. [20] 
and Joho et al. [21] proposed to learn the map of the RFID tags with perfect localization, and then use the 
built map to perform localization in which mapping and localization are solved separately in the two stages. 
RFID is also used and integrated with other sensors. In [22], data from a camera and RFID mounted on a 
pan-tilt unit of a robot are fused to accomplish person tracking where a RFID tagged person can be followed 
by the robot. As RFID tags also have a limited data storage capability, RFID can be used to deliver 
information in tasks such as activity recognition [23], search and rescue [24], and human robot interaction 
[25]. 
 
 
 
 
4 
 
information for a couple more seconds after the robot leave the tag. To diminish the delayed measurement 
effect, the delayed-state EKF [26] is implemented to deal with the issue of delayed measurements. 
 
 
(a) The NTU-PAL4 robot. 
 
(b) The short-range passive RFID reader and tag. 
Fig. 1. The RFID system is mounted on the right side of the NTU-PAL4 robot. The SICK laser scanners on 
the top of the robot were used to collect ground truth data. 
 
 
 
 
 
6 
 
project. Table I summaries a comparison of the proposed method and related works and demonstrates the 
significance of the proposed approach in terms of the cost, the accomplished tasks and the coverage area per 
tag. 
RFID measurement modeling strongly depends on the communication between the tag and the antenna 
(or reader) which is affected by a number of the environmental and location-dependent factors such as 
materials the tag and the reader are attached to, orientations between a tag and the antenna, objects disturbing 
the electromagnetic wave and interferences from the scene. There are two major measurement modeling 
approaches. One is the environment-based measurement model and the other is the sensor-centric 
measurement model. 
In the environment-based modeling approach, data are collected at each place in the environment as 
snapshots or fingerprints [27] [28]. These snapshots or fingerprints are later used for accomplished 
localization. In [29], the robot trajectory is estimated in a batch-processing fashion which could be unsuitable 
for real-time and online robotic applications. In this work, the proposed approach is online in a 
recursive-processing fashion. 
The sensor-centric measurement modeling approach was firstly proposed in [20]. Vorst et al. [30] 
proposed a semi-supervised learning approach to learn about the detection probability. With a high-end 
long-range RFID system, Ni et al. [17] adjusted the power levels of the antenna to change detection ranges for 
estimating distances between the reader and tags. In the RFID systems that the received signal strength 
indication (RSSI) is available, the signal strength can be used for estimating distances between the reader and 
tags [31]. Joho et al. [21] took both RSSI and the detection probability into account using a hybrid 
measurement model. In the applications that the high-end RFID systems are used, measurements from RFID 
could contain range information. Bearing information could be also available if multiple readers are used. In 
this work, the low-cost RFID system is applied in which both range and bearing information are unavailable. 
Delayed state estimation is well understood in the control literature. The Delayed-State EKF was 
proposed to estimate the states of nonlinear time-delay systems in [26]. In the robotics literature, Eustice et al. 
[32] used the exactly sparse delayed-state filter to initiate the new landmarks. With the augmented poses, 
landmarks can be estimated more accurately. In this work, we follow the same principle to deal with the 
delayed measurement problem of our short-range passive RFID system and accomplish SLAM. 
 
 
 
 
 
 
 
 
 
 
 
 
 
8 
 
ï¼ˆå››ï¼‰ã€ç ”ç©¶æ–¹æ³• 
 The methods and algorithms of both learning from demonstration and RFID-SLAM are described in this 
section. 
 
A. Learning from demonstration 
The learning from demonstration framework can be modeled as finding optimization criteria that make 
the expert look optimal in the sense that the learning procedure is used to identify a mapping from features of 
a state to costs such that the resulting minimum cost plans capture well the demonstrated behavior [12] [35]. 
This intuition is formalized by the maximum margin planning (MMP) framework [34] which could be solved 
by the Learning to Search (LEARCH) algorithm [35]. In this project, the learning algorithm is implemented 
based on the LEARCH algorithm with some minor changes based on the application. 
 
(a). The Learning to Search (LEARCH) Algorithm 
Recall that the goal is to identify a mapping function from features of any given state to costs such that 
the resulting minimum cost plans capture well the demonstrated behavior. To get a minimum cost path, it is 
essential to get the cost value on each state in the map as ğ‘ (ğ¹ğ‘–) which could be generated by querying the 
feature function F to get the features in a given state ğ‘– and applied it with the learned costmap s. The costmap 
is then further modified to the exponential form as ğ‘’ğ‘ (ğ¹ğ‘–) to create a hypothesis space of cost functions with 
substantially higher dynamic ranges for a given set of features and fulfill the requirement of many planning 
algorithms with strictly positive costs in order to ensure the existence of an admissible heuristic. 
The procedure of the LEARCH algorithm is presented in Algorithm 1. The log-costmap is initialized as 
zero. Then the loss function and feature function are used to compute the loss-augmented costmap. Here the 
loss function is used to perform margin-maximization like the similar interpretation in support vector machine 
[35] and could be easily defined by the users. The feature function is used to provide the observed features at 
a given state. A planner in the learner then plans a path using the loss-augmented costmap. According to the 
current planned and example paths, the learner generates positive and negative examples and then further 
trains a regressor or classifier based on those collected data set to get the log-hypothesis in order to update the 
costmap during the training process. The training process is terminated if the planned paths are close enough 
with the example paths. 
 
 
 
 
 
 
 
 
 
 
 
10 
 
initial position of the robot is given. Those information of the motion is decomposed motion to three 
components: a rotation, followed by a straight line translation, and another rotation which is formulated as [d 
r1 r2], where d is the translation, r1 is the initsial rotation, and r2 is the final rotation. The robot pose 
transformation is simplified from [37]: 
 
   (       ) = (
    +     (   1 +  1)
    +     (   1 +  1)
   1 +  1 +  2
)                   (1) 
 
where the xt-1 =[xt-1 yt-1  t-1]
T
 is the robot pose in the previous time step. The variance of the three components 
is estimated using the following equations: 
 
  
2 = {
   m n
2                        m n
(   )2                                
                   (  )
  
2 = {
   m n
2                  ( 1 +  2)      m n
(   )2                                               
    (  )
 
 
where   and   are the percentage of the distance and rotation difference.  d,min,  r,min are the minimum 
standard deviation of distance and rotation respectively. 
 
(b). Probabilistic Measurement Model for Short-Range RFID 
The probabilistic measurement model is established as P(ztâˆ£xt, li) â‰ˆ P(ztâˆ£â–³(xt, li) ) where â–³(xt, li) is 
the relative location between the i-th tag and the RFID antenna, zt is the measurement from the reader, xt = (x, 
y,  ) is the antenna pose, and li = (li,x, li,y) is the i-th tag location. Without RSSI and power levels data, our 
RFID system only receives strings of the tag ID code. Fig. 2 (a) shows the histogram of the tag detection 
events in a 2D space of the RFID system. The size of each grid is 2cm_2cm. The measurements of the tag 
detection events in each grid are collected from the center of the antenna to unobservable areas. It is clear that 
the reliable detection range of the system is less than 10cm. The relative orientation between the tag and the 
antenna may affect the speed of the system charging, but in our system the effect is negligible with the 
maximum 24-millisecond operating time. 
From Fig. 2 (a), the weighted mean and variance with respect to the antenna coordinate system are 
computed from the histogram by taking the detection probability in each grid as the weight. Fig. 2 (b) shows 
the proposed probabilistic measurement model of tag detection with the weighted mean and variance. Hence, 
the measurement model is formulated as 
 
P(z |  (     )) =  P(ID|  (     ))  â‰ˆ  P (z  l|  (     ))    (3) 
 
where ID is the unique ID code and zt,l is the relative tag location in the antenna coordinate system. 
 
(c). Delayed-State EKF-based SLAM 
12 
 
 
(a) RFID detection histogram. 20 
measurements were collected at 
each 2cm*2cm cell. 
 
(b) The proposed measurement 
model with the weighted mean 
and variance. 
Fig. 2. The proposed short-range passive RFID measurement model. 
 
 
 
14 
 
 
Fig. 4. The navigation environment: a corridor occupied with obstacles. 
 
 
 
Fig. 5. One of the demonstrations in the navigation environment as depicted in Fig. 4. The ambiguous 
regions within the green rectangles would cause the poor performance when testing. 
 
Fig. 5 shows one of the demonstrations in the environment. The local map and the robot pose are 
generated by the iterative closest point (ICP) [40] alignment with the initial guess from the information of the 
recorded odometer data. In this case, the learned policy results in hitting the obstacles or the walls. It is 
because the ambiguity of the environment to cause such results. To make an explanation, check out the 
rectangle regions depicted in Fig. 5 and the laser scans in those regions in Fig. 6 to understand the ambiguity 
issue. When testing, the learned policy may drive the robot to pass through the right passage at the bottom 
rectangle region or drive the robot to pass through the center passage at the top rectangle region. It is a 
reasonable control policy given the demonstrations and the laser scans. However, as the robot dimension is 
not included in the learned policy, the robot would be encouraged to pass through a narrow passage by the 
learned policy and results in hitting the obstacles or walls as illustrated by Fig. 7. 
In our second attempt, the environment is slightly modified to reduce some narrow passages thus also 
reduce the ambiguity when testing. Fig. 8 (b) shows one of the three demonstrations in the less ambiguous 
16 
 
  
(a) The laser scans in the bottom ambiguous region 
in Fig. 5. The left and right passages with respect 
to the robot may cause the ambiguity in control 
policy. The control command is turning left in the 
training data. 
(b) The laser scans in the top ambiguous region in 
Fig. 5. The center and right passages with respect 
to the robot may cause the ambiguity in control 
policy. The control command is turning right in the 
training data. 
Fig. 6. The blue dots are the corresponding laser scans in the ambiguous regions. The cross in red color 
indicates the robot position. 
 
 
 
  
(a) The overall generated path. The robot   
exchanged the control commands between trying 
to pass through the center passage and the right 
passage whereas resulted in hitting the obstacles. 
(b) A closer look at the end of the generated path. 
The direction of the robot is changed obviously 
at the final few steps before hitting the obstacle. 
Fig. 7. The result when testing with the ambiguous environment. 
 
18 
 
performance of the proposed approach should strongly depend on the odometry data quality. The motion error 
in terms of the velocity is 10 cm/sec and the angular error is 0.05 rad/sec. The simulated motion control 
command is the motion model uncertainty multiplied by the given noise level number. This simulation 
performs 10 loops for each run and applies Monte Carlo test with 10 runs for each noise level number. éŒ¯èª¤! 
æ‰¾ä¸åˆ°åƒç…§ä¾†æºã€‚ shows the root mean square errors from the 0.6 noise level to 1.6 noise level in which 13 
tags are deployed at fixed locations. The maximum and minimum curves show the mean values of the 
maximum and minimum range errors for each tag in the 10 runs, respectively. In éŒ¯èª¤! æ‰¾ä¸åˆ°åƒç…§ä¾†æºã€‚, 
the results of the 5th loop and the 10th loop are also illustrated. The result indicates that the mapping error 
increases as the odometry noise level increases. At the 0.8 noise level, the mapping error is 2m with the 
minimum error 1.05m and the maximum error 3.23m. It is also demonstrated that the mapping error becomes 
smaller with more loops as the relationship between the robot and tags could be more certain with more 
information. 
The second simulation evaluates the effect of the number of tags. In each run, the simulation selects a fix 
number of tags from 4 to 40. The tags are deployed randomly. The robot performs a 10-loop trajectory. For 
each number of tags, 10 Monte Carlo tests are performed. The odometry noise level is 0.6, and the velocity 
noise is 6 cm/sec and the angular velocity noise 0.03 rad/sec. éŒ¯èª¤! æ‰¾ä¸åˆ°åƒç…§ä¾†æºã€‚ shows the results in 
which the mapping error is decreasing and converged to 0.6m as the feature number increases. As the 
30mÃ—20m environment should be large in many indoor robotics applications, the SLAM performance is 
acceptable. The results also point out that more tags do not always improve the performance. 
In addition to performance evaluation in the previous figures, Fig. 12 shows the SLAM results of the 5th 
loop at the 0.6 noise level and at 1.4 noise level with 13 tags and 40 tags. It shows that the effect of the 
odometry noise level could be significant and the topology of the map could be more accurate with sufficient 
tags. 
 
(b). Experiments using NTU-PAL4 
The experiment using the NTU-PAL4 robot with the short-range passive RFID system was conducted in 
the 4th floor of our department building. The environment size is about 20mÃ—50m and the 66 passive RFID 
tags were randomly attached on the wall. The NTU-PAL4 robot was controlled manually to follow the wall 
for detecting the tags and followed the same loop 5 times. To evaluate the effect of the number of tags, the 
tags are randomly chosen with a fix number from 10 to 66. We perform 10 Monte Carlo tests for each number 
of tags. Fig. 13 shows the root mean square errors of the mapping errors. The errors decrease when the 
number of tags increases. According to the analysis, only 25 tags are needed to accomplish SLAM in the 4th 
floor of our department building and the mapping error is converged to 2.43m. 
Fig. 14 show the results of mapping and localization with 25 and 66 tags. The mean of the mapping error 
with 25 tags as shown in Fig. 14 (a) is 2.43m with the minimum error 0.28m and the maximum error 4.31m 
comparing to the ground truth obtained from the SICK laser scanner. The mean of the mapping error with 66 
tags as shown in Fig. 14 (b) is 1.44m with the minimum error 0.16m and the maximum error 4.25m. Note that 
there is a large gap between two tags at the bottom of the map and the tag location uncertainties are large in 
this area. However, the topological geometry of the built map is still close to the ground truth. Although the 
accuracy of mapping and localization of the proposed approach may not be superior to the systems using 
long-range active RFID readers with dense tags, the performance of the proposed approach should be 
20 
 
0.03rad/sec. 0.07rad/sec. 
 
(c) The 0.6 noise level with 40 tags: the velocity 
noise is 6cm/sec and the angular velocity noise is 
0.03rad/sec. 
 
(d) The 1.4 noise level with 40 tags: the velocity 
noise is 14cm/sec and the angular velocity noise is 
0.07rad/sec. 
Fig. 12. Simulation results at the 5th loop. The blue squares are the ground truth of tags and the black dots are 
the estimated tag positions. The green line is the desired robot path and the light red eclipses are the two 
sigma covariance bounds of the estimated tag positions. 
 
 
 
 
Fig. 13. Experiment using NTU-PAL4: the root mean square errors with the different numbers of tags. 
 
 
22 
 
å››ã€åƒè€ƒæ–‡ç» 
[1] O. Khatib, â€œReal-Time Obstacle Avoidance for Manipulators and Mobile Robots,â€ In International Journal of Robotics 
Research, 5(1), 1986. 
[2] J. Borenstein and Y. Koren, â€œThe Vector Histogram (VFH)-Fast Obstacle Avoidance for Mobile Robots,â€ IEEE Transactions 
on Robotics and Automation, 7(3), 1991. 
[3] D. Fox, W. Burgard, and S. Thrun, â€œThe Dynamic Window Approach to Collision Avoidance,â€ IEEE Transactions on Robotics 
and Automation, 4:1, 1997. 
[4] J. Minguez and L. Montano, â€œNearness Diagram Navigation (ND): A new Real Time Collision Avoidance Approach,â€ In 
Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Takamatsu, Japan, 2000. 
[5] J. Minguez and L. Montano, â€œNearness Diagram Navigation (ND): Collision Avoidance in Troublesome Scenarios,â€ IEEE 
Transactions on Robotics and Automation, vol. 20, 2004, pp 45-59. 
[6] J. Minguez, J. Osuna and L. Montano, â€œA â€œDivide and Conquerâ€ Strategy based on Situations to achieve Reactive Collision 
Avoidance in Troublesome Scenarios,â€ In Proceedings of the IEEE International Conference on Robotics and Automation 
(ICRA), New Orleans, USA, 2004. 
[7] Chung-Che Yu, Wei-Chi Chen, Chieh-Chih Wang and Jwu-Sheng Hu, â€œSelf-Tuning Nearness Diagram,â€ In Proceedings of the 
International Conference on Service and Interactive Robotics (SIRCon), Taipei, Taiwan, August 2009. 
[8] Brenna D. Argall, Sonia Chernova, Manuela Veloso, Brett Browning, â€œA survey of robot learning from demonstration,â€ 
Robotics and Autonomous Systems, Vol. 57, No. 5. (31 May 2009), pp. 469-483. 
[9] Pieter Abbeel, Adam Coates and Andrew Y. Ng, â€œAutonomous Helicopter Aerobatics through Apprenticeship Learning,â€ In 
International Journal of Robotics Research (IJRR), 2010. 
[10] Adam Coates, Pieter Abbeel and Andrew Y. Ng, â€œLearning for control from multiple demonstrations,â€ In Proceedings of the 
Twenty-fifth International Conference on Machine Learning, 2008. 
[11] Nathan Ratliff, J. Andrew (Drew) Bagnell, and Siddhartha Srinivasa, â€œImitation Learning for Locomotion and Manipulation,â€ 
IEEE-RAS International Conference on Humanoid Robots, November, 2007. 
[12] David Silver, J. Andrew (Drew) Bagnell, and Anthony (Tony) Stentz, â€œHigh Performance Outdoor Navigation from Overhead 
Data using Imitation Learning,â€ Robotics Science and Systems, June, 2008. 
[13] Brian D. Ziebart, Andrew Maas, J. Andrew (Drew) Bagnell, and Anind Dey, â€œMaximum Entropy Inverse Reinforcement 
Learning,â€ Proceeding of AAAI 2008, July, 2008. 
[14] Brian D. Ziebart, Nathan Ratliff, Garratt Gallaghey, Christoph Mertz, Kevin Peterson, J. Andrew  (Drew) Bagnell, Martial 
Hebert, Anind K. Dey, and Siddhartha Srinivasa, â€œPlanning-based Prediction for Pedestrians,â€ IEEE Conference on Intelligent 
Robots and Systems (IROS 2009). 
[15] Stephane Ross and J. Andrew (Drew) Bagnell, â€œEfficient Reductions for Imitation Learning,â€ Proceedings of the 13th 
International Conference on Artificial Intelligence and Statistics (AISTATS), May, 2010. 
[16] Stephane Ross, Geoffrey Gordon, and J. Andrew (Drew) Bagnell, â€œA Reduction of Imitation Learning and Structured 
Prediction to No-Regret Online Learning,â€ Proceedings of the 14th International Conference on Artificial Intelligence and 
Statistics (AISTATS), April, 2011. 
[17] L. M. Ni, Y. Liu, Y. C. Lau, and A. P. Patil. Landmarc: Indoor location sensing using active RFID. In Proc. of the IEEE Int. 
Conf. on Pervasive Computing and Communications (PerCom), pages 407â€“415, Los Alamitos, CA, USA, 2003. 
[18] X. Liu, M. Corner, and P. Shenoy. Ferret: RFID localization for pervasive multimedia. In Proc. of the IEEE Int. Conf. on 
Ubiquitous Computing (UbiComp), pages 422â€“440, Orange County, CA, USA, 2006. 
24 
 
[40] http://www-personal.acfr.usyd.edu.au/tbailey/software/scan_matching.zip 
[41] Peter Henry, Christian Vollmer, Brian Ferris and Dieter Fox, â€œLearning to Navigate Through Crowded Environments,â€ 
International Conference on Robotics and Automation, 2010. 
[42] P. Trautman, A. Krause, â€œUnfreezing the Robot: Navigation in Dense, Interacting Crowds,â€ IEEE/RSJ International 
Conference on Intelligent Robots and Systems (IROS) 2010. 
 
 
 
 
 
26 
 
3. è«‹ä¾å­¸è¡“æˆå°±ã€æŠ€è¡“å‰µæ–°ã€ç¤¾æœƒå½±éŸ¿ç­‰æ–¹é¢ï¼Œè©•ä¼°ç ”ç©¶æˆæœä¹‹å­¸è¡“æˆ–æ‡‰ç”¨åƒ¹
å€¼ï¼ˆç°¡è¦æ•˜è¿°æˆæœæ‰€ä»£è¡¨ä¹‹æ„ç¾©ã€åƒ¹å€¼ã€å½±éŸ¿æˆ–é€²ä¸€æ­¥ç™¼å±•ä¹‹å¯èƒ½æ€§ï¼‰ï¼ˆä»¥
500 å­—ç‚ºé™ï¼‰ 
 
The future works of this project are also addressed in two parts. The first part is the navigation 
learning based on the learning from demonstration framework. The second part is the environment 
learning. 
Recent years, safe navigation of a mobile robot through crowds of dynamic agents was studied 
[41] [42]. Using the simulation, they show that it could be possible to teach the robot to navigate 
through dynamic environments. It is our future work to do the navigation in dynamic environments 
with the real robot using the framework of learning from demonstration. How to extract the 
information from the dynamic environments is the key issue. The temporal information such as 
tracking results should be very important. A local map contains temporal information should be built 
from the demonstrations for the learning process. The failure cases could also be additional 
examples for the training process without repeatedly querying the user. Although the issue of feature 
extraction is not addressed in this work, the feature selection is still an important issue for the 
learning process. It is an important future work to find out a suitable data representation to ease the 
burden of feature selection. For the environment learning issue, thus far, the robot is manually 
controlled to detect tags. We would like to develop an automatic tag search engine in which 
different strategies will be defined to search new and existing tags based on the SLAM estimates. 
 
 äºŒã€ï¥«åŠ æœƒè­°ç¶“éèˆ‡èˆ‡æœƒå¿ƒå¾—: 
I arrived in Shanghai on May 9 and attended all session talks interesting to me.  
 
The plenary talk I was delivered by Prof. Alberto Broggi on May 10. His group 
recently accomplished autonomous driving from Parma, Italy to Shanghai, China 
during summer 2010. Instead of fully autonomous driving, they applied a 
leader-follower approach and collected a huge amount of valuable data.      
  
  
The other interesing plenart talk was delivered by Dr. Martin Buehler who was the 
  
ä¸‰ã€å¿ƒå¾—åŠå»ºè­° 
It is always great to chat and discuss ideas with the best robotics researchers at 
ICRA. Below is the list of the best papers at ICRA 2011. 
Best Manipulation Paper: Characterization of Oscillating Nano Knife for 
Single Cell Cutting by Nanorobotic Manipulation System Inside ESEM: Yajing Shen, 
Masahiro Nakajima, Seiji Kojima, Michio Homma, Yasuhito Ode, Toshio Fukuda 
Best Vision Paper: Sparse Distance Learning for Object Recognition 
Combining RGB and Depth Information: Kevin Lai, Liefeng Bo, Xiaofeng Ren, 
Dieter Fox 
Best Automation Paper: Automated Cell Manipulation: Robotic ICSI: Zhe Lu, 
Xuping Zhang, Clement Leung, Navid Esfandiari, Robert Casper, Yu Sun 
Best Medical Robotics Paper: An Articulated Universal Joint Based Flexible 
Access Robot for Minimally Invasive Surgery: Jianzhong Shang, David Noonan, 
Christopher Payne, James Clark, Mikael Hans Sodergren, Ara Darzi, Guang-Zhong 
Yang 
Best Conference Paper: Minimum Snap Trajectory Generation and Control for 
Quadrotors: Daniel Mellinger, Vijay Kumar 
KUKA Service Robotics Best Paper: Dynamic Shared Control for 
Human-Wheelchair Cooperation: Qinan Li, Weidong Chen, Jingchuan Wang 
Best Video: High Performance of Magnetically Driven Microtools with 
Ultrasonic Vibration for Biomedical Innovations: Masaya Hagiwara, Tomohiro 
Kawahara, Lin Feng, Yoko Yamanishi, Fumihito Arai 
Best Cognitive Robotics Paper: Donut As I Do: Learning from Failed 
Demonstrations: Daniel Grollman, Aude Billard 
 
  The first interesting session is about educational robotics. In this session, an 
educational robot which is used in elementary school and kindergarten in Korea is 
discussed. This robot project is leaded by the Korea Institute of Science and 
Technology and is cooperated with the government policy. 
 
The second interesting session is about the safety and security robots. This 
session is brought by Japan researchers and they share their experience in the 
application of the rescue robots. 
 
The third interesting session is about humanoid business. The session starts from 
HRP-4C, a Japan humanoid robot. The development progress is represented and 
discussed to view the industry opportunity. 
  
åœ‹ç§‘æœƒè£œåŠ©è¨ˆç•«è¡ç”Ÿç ”ç™¼æˆæœæ¨å»£è³‡æ–™è¡¨
æ—¥æœŸ:2011/10/13
åœ‹ç§‘æœƒè£œåŠ©è¨ˆç•«
è¨ˆç•«åç¨±: å­è¨ˆç•«ä¸‰ï¼šå­¸ç¿’å‹è¾¦å…¬å®¤ç¤¾äº¤æ‹›å¾…æ©Ÿå™¨äºº
è¨ˆç•«ä¸»æŒäºº: ç‹å‚‘æ™º
è¨ˆç•«ç·¨è™Ÿ: 99-2221-E-002-192- å­¸é–€é ˜åŸŸ: æ™ºæ…§å‹æ©Ÿå™¨äºº
ç„¡ç ”ç™¼æˆæœæ¨å»£è³‡æ–™
å…¶ä»–æˆæœ 
(ç„¡æ³•ä»¥é‡åŒ–è¡¨é”ä¹‹æˆ
æœå¦‚è¾¦ç†å­¸è¡“æ´»å‹•ã€ç²
å¾—çé …ã€é‡è¦åœ‹éš›åˆ
ä½œã€ç ”ç©¶æˆæœåœ‹éš›å½±éŸ¿
åŠ›åŠå…¶ä»–å”åŠ©ç”¢æ¥­æŠ€
è¡“ç™¼å±•ä¹‹å…·é«”æ•ˆç›Šäº‹
é …ç­‰ï¼Œè«‹ä»¥æ–‡å­—æ•˜è¿°å¡«
åˆ—ã€‚) 
ç„¡ 
 æˆæœé …ç›® é‡åŒ– åç¨±æˆ–å…§å®¹æ€§è³ªç°¡è¿° 
æ¸¬é©—å·¥å…·(å«è³ªæ€§èˆ‡é‡æ€§) 0  
èª²ç¨‹/æ¨¡çµ„ 0  
é›»è…¦åŠç¶²è·¯ç³»çµ±æˆ–å·¥å…· 0  
æ•™æ 0  
èˆ‰è¾¦ä¹‹æ´»å‹•/ç«¶è³½ 0  
ç ”è¨æœƒ/å·¥ä½œåŠ 0  
é›»å­å ±ã€ç¶²ç«™ 0  
ç§‘ 
æ•™ 
è™• 
è¨ˆ 
ç•« 
åŠ  
å¡« 
é … 
ç›® è¨ˆç•«æˆæœæ¨å»£ä¹‹åƒèˆ‡ï¼ˆé–±è½ï¼‰äººæ•¸ 0  
 
