where the users are allowed to have different numbers 
of transmit antennas and can transmit at different 
levels of multiplexing gain.  The exact optimal MAC-
DMT of such channel is explicitly characterized in 
this report. Interestingly, in the general MAC-DMT, 
some users might not be able to achieve their single-
user DMT performance as in the symmetric case, even 
when the multiplexing gains of the other users are 
close to 0. Detailed explanations of such unexpected 
result are provided in this report. By generalizing 
the code construction for the symmetric MIMO-MAC, 
explicit code constructions are provided for the 
general MIMO-MAC and are proved to be optimal in 
terms of the general MAC-DMT. 
 
We also answer several open questions related to 
diversity-multiplexing tradeoffs (DMTs) for point-to-
point and multiple-access (MAC) MIMO channels. By 
analyzing the DMT performance of a simple code, we 
show that the optimal MAC-DMT holds even when the 
channel remains fixed for less than Kn_t+n_r-1 
channel uses, where K is the number of users, n_t is 
the number of transmit antennas of each user, and n_r 
is the number of receive antennas at receiver. We 
also prove that the simple code is MAC-DMT optimal. A 
general code design criterion for constructing MAC-
DMT optimal codes that is much more relaxed than the 
previously known design criterion is provided. 
Finally, by changing some design parameters, the 
simple code is modified for  use  in point-to-point 
MIMO channels. We show the modified code achieves the 
same DMT performance as the Gaussian random code. 
è‹±æ–‡é—œéµè©ï¼š Diversity-multiplexing  gain tradeoff (DMT), multiple 
access channel (MAC), cyclic division algebras 
(CDAs), multiple-input multiple-output (MIMO) 
channel, space-time block codes (STBCs) 
 
Abstract
This report provides an overview of major results we have obtained in the research project â€œCon-
structions of Diversity-Multiplexing Tradeoff Optimal Codes for Multiuser MIMO Systems with
Applications to MIMO Mobile Communicationsâ€ supported by National Science Council under
contract number NSC98 - 2221 - E - 009 - 045 - MY3 during August 2009 - July 2012.
In this report, we are concentrating explicit code constructions for multiple-input multiple-
output (MIMO) multiple-access channels (MAC) with K users. The first construction is dedicated
to the case of symmetric MIMO-MAC where all the users have the same number of transmit anten-
nas nt and transmit at the same level of per-user multiplexing gain r. Furthermore, we assume that
the users transmit in an independent fashion and do not cooperate. The construction is systematic
for any values of K, nt and r. It is proved that this newly proposed construction achieves the opti-
mal MIMO-MAC diversity-multiplexing gain tradeoff (DMT) provided by Tse et al. at high-SNR
regime. We next take a further step to investigate the MAC-DMT of a general MIMO-MAC where
the users are allowed to have different numbers of transmit antennas and can transmit at different
levels of multiplexing gain. The exact optimal MAC-DMT of such channel is explicitly charac-
terized in this report. Interestingly, in the general MAC-DMT, some users might not be able to
achieve their single-user DMT performance as in the symmetric case, even when the multiplexing
gains of the other users are close to 0. Detailed explanations of such unexpected result are provided
in this report. Finally, by generalizing the code construction for the symmetric MIMO-MAC, ex-
plicit code constructions are provided for the general MIMO-MAC and are proved to be optimal
in terms of the general MAC-DMT.
We also answer several open questions related to diversity-multiplexing tradeoffs (DMTs) for
point-to-point and multiple-access (MAC) MIMO channels. By analyzing the DMT performance
of a simple code, we show that the optimal MAC-DMT holds even when the channel remains
fixed for less than Knt + nr âˆ’ 1 channel uses, where K is the number of users, nt is the number
of transmit antennas of each user, and nr is the number of receive antennas at receiver. We also
prove that the simple code is MAC-DMT optimal. A general code design criterion for constructing
MAC-DMT optimal codes that is much more relaxed than the previously known design criterion
is provided. Finally, by changing some design parameters, the simple code is modified for use in
point-to-point MIMO channels. We show the modified code achieves the same DMT performance
as the Gaussian random code.
Keywords: Diversity-multiplexing gain tradeoff (DMT), multiple access channel (MAC), cyclic
division algebras (CDAs), multiple-input multiple-output (MIMO) channel, space-time block codes
(STBCs).
1
13. R. Vehkalahti, C. Hollanti, J. Lahtonen, and H. F. Lu, â€Some Simple Observations on MISO
Codesâ€, Proc. 2010 ISITA, Taichung, Taiwan, Oct. 2010.
14. R. Vehkalahti and H. F. Lu, â€œAn algebraic look into MAC-DMT of lattice space-time codes,â€
Proc. 2011 IEEE Int. Symp. on Inform. Theory (ISIT), St. Petersburg, Russia.
15. T.W. Tang, M. K. Chen, and H. F. Lu, â€œImproving the DMT Performances of MIMO Linear
Receivers,â€ Proc. 2011 IEEE Int. Symp. on Inform. Theory (ISIT), St. Petersburg, Russia.
16. R. Vehkalahti and H. F. Lu, â€œDiversity-multiplexing gain tradeoff: a tool in algebra?â€ in
Proc. ITW 2011, pp. 135 - 139 , Paraty, Brazil, Oct. 2011.
17. S. M. Huang, H. F. Lu, and S. M. Moser, â€œMinimal-Rate Description for Multiple-Access
Channels,â€ in Proc. ISITA 2012, Hawaii, Oct. 2012.
3
m independent fading blocks. Therefore, the multi-block CDA-based ST code is optimal in terms
of the multi-block DMT at high-SNR regime. More important, (1.3) indicates that the code has
error probability decreasing to zero as m approaches infinity whenever dâˆ—nt,nr(r) > 0. Hence, the
multi-block ST code could potentially achieve the MIMO ergodic channel capacity at high-SNR
regime and simultaneously be optimal in terms of the multi-block DMT at every discrete value m.
Motivated by the promising outcome in the point-to-point scenario, the aim of this report is
to investigate the code construction for the multiple-access channel (MAC) scenario. We will
concentrate on the uplink transmission from multiple mobile users to a common base station (or
access point). Both the mobile users and the base station may be equipped with multiple antennas.
Consider a MIMO-MAC with K mobile users. For simplicity, we first focus on the case of
symmetric MIMO-MAC [11], where each user is equipped with nt transmit antennas and commu-
nicates independently to the base station that has nr receive antennas. Furthermore, we assume
that all the users transmit at the same level of multiplexing gain. With a slight abuse of notation,
hereafter we will denote by r the per-user multiplexing gain in the symmetric MIMO-MAC. Let
S0, Â· Â· Â· ,SKâˆ’1, be respectively the ST codes used by the kth user, k = 0, 1, Â· Â· Â· , K âˆ’ 1. Each code
Sk, k = 0, 1, Â· Â· Â· , Kâˆ’1, consists of (ntÃ—T ) matrices and satisfies the following power constraint:
E SâˆˆSk â€–Sâ€–2F â‰¤ T Â· SNR, (1.4)
where by â€–Sâ€–F we mean the Frobenius norm of matrix S. Furthermore, we require |Sk| = SNRrT
for all k such that every user transmits at the same multiplexing gain r. Let Hk be the (nr Ã— nt)
channel matrix of the kth user. We assume Hk is fixed for a block of T channel uses. Hk is known
completely to the receiver at base station but unknown to all the users. Entries of Hk are modeled
as i.i.d. CN (0, 1) complex Gaussian random variables to model the MIMO Rayleigh block fading
channel. Let Sk âˆˆ Sk be the signal matrix transmitted by the kth user; then the signal matrix
received at base station is given by
Y =
Kâˆ’1âˆ‘
k=0
HkSk +W, (1.5)
where W is the (nr Ã— T ) noise matrix with i.i.d. CN (0, 1) entries. When each userâ€™s information
is encoded independently, Tse et al. [11] proved that the tradeoff between the diversity gain d and
multiplexing gain r in a symmetric MIMO-MAC is governed by the following theorem.
Theorem 1 (Symmetric MAC-DMT [11]). In a symmetric MIMO-MAC withK users, each having
nt transmit antennas and transmitting independently at multiplexing gain r, the maximal possible
diversity gain is given by
dâˆ—nt,nr,K(r) := min1â‰¤kâ‰¤K
dâˆ—knt,nr(kr)
=
ï£±ï£´ï£´ï£´ï£´ï£´ï£´ï£²ï£´ï£´ï£´ï£´ï£´ï£´ï£³
dâˆ—nt,nr(r), if r âˆˆ
[
0,min
{
nt,
nr
K+1
}]
,
dâˆ—Knt,nr(Kr),
if r âˆˆ [min{nt, nrK+1} ,min{nt, nrK }] ,
(1.6)
where dâˆ—knt,nr(kr) is the point-to-point DMT for knt transmit antennas, nr receive antennas and
multiplexing gain kr defined as before (or see [9,11]). Equation (1.6) is termed optimal symmetric
MAC-DMT. The multiplexing gain r for nonnegative diversity gain is bounded between
0 â‰¤ r â‰¤ min
{
nt,
nr
K
}
= rmax. (1.7)

5
code1, i.e., a (2 Ã— 4) code for each user, based on independent Alamouti blocks [2] is also
introduced in [13]. Yet, we remark that such code does not achieve the optimal symmetric
MAC-DMT (1.6).
2. In [14] Badr and Belfiore proposed an explicit algebraic code for K = 2 and nt = 1. The
idea can be extended to bigger values of K. The determinant of the code matrix is non-
zero thanks to a â€twisting element.â€ However, the determinant is vanishing. The decay of
determinants of this two-user MIMO-MAC code was carefully studied in [15]. It was shown
that the code is MAC-DMT optimal, when r â‰¤ 1
5
. Whether this code achieves the optimal
MAC-DMT also when r > 1/5 remains an open question. In [15] it was shown, however,
that the code fails to satisfy the criteria for achieving optimal MAC-DMT set forth in [16],
when r > 1/5. This alone does not mean that their code could not be optimal, as the criteria
in [16] is sufficient, but not necessary (see [17] for justification of this claim).
3. Some explicit, algebraic code constructions for nt > 1 and K = 2 were introduced by
Hong and Viterbo in [18]. A design criterion based on an approximation of truncated union
bound was proposed. With such criterion they constructed a code that outperforms in error
performance the aforementioned (4Ã— 4) two-user code [13].
4. Badr and Belfiore [19] proposed another (4 Ã— 4) two-user MIMO-MAC code which is ob-
tained by adding a twist matrix Î“ to the (2 Ã— 2) Golden ST code [20, 21] such that the
overall code matrix is nonsingular whenever all the submatrices associated with each user
are nonzero. However, because of this additional Î“ matrix, the overall code matrix, though
nonsingular, could be ill-conditioned at high-SNR regime, thereby resulting in a vanishing
determinant, similarly as did their earlier one-antenna code [14] already discussed above.
5. [22] addressed the problem of whether there exists a two-user MIMO-MAC code satisfying
the non-vanishing determinant (NVD) property. This problem concerns whether the twisted
Golden MIMO-MAC code [19] can be further improved to avoid the disadvantage of having
a vanishing determinant. The answer is negative. [22] shows that if all the overall code
matrices are nonsingular whenever the submatrices from each user are nonzero, then some
of them must have determinant arbitrarily close to zero, i.e., have vanishing determinants.
6. By removing the Î“ matrix, [22] reported another code construction and proved its MAC-
DMT optimality for K = 2 and for any values of nt and nr. Computer simulations showed
that this code outperforms the (4 Ã— 4) code of [19] at all SNR values. Another important
contribution reported in [22] was that, for the two-user MAC case, one does not need the
whole code matrix to be nonsingular, and hence introducing the additional Î“ rotation matrix
is not necessary from the MAC-DMT point of view.
7. In [16], Coronel et al. studied the optimal DMT performance of a selective fading MIMO-
MAC and provided a sufficient criterion for designing MAC-DMT optimal codes for any
K and nt. Noting that the Rayleigh block fading channel is a flat fading channel, a simpli-
fication of their criterion requires the product concatenation of codes from any subsets of
K users to satisfy the NVD property such that the error probabilities associated with these
subcodes do not exceed the corresponding outage probability. However, as already pointed
out in [22], such codes do not exist for the case of K = 2 . A further investigation of their
criterion can be found in [17].
1In this report, by an (mÃ— n) code we mean a code consisting of (mÃ— n) code matrices, where m is the number
of transmit antennas required for transmission, and n is the number of channel uses. The number m can be either nt
or Knt, depending on the discussion. When m = nt, the code is for each userâ€™s use. When m = Knt, we mean
the vertical concatenation of all usersâ€™ codes as an overall code. Notation nt Ã— nr without parenthesis is used for the
channel dimensions.
7
same DMT dâˆ—(r) holds whenever the channel is static for at least T â‰¥ nt channel uses. However,
such result cannot be further improved, and the exact DMT for T < nt is still uncertain.
In both DMT results, Theorems 1 and 2, the proofs proceed by first establishing an upper bound
on DMT based on an outage formulation, and then by using a Gaussian random coding scheme to
show the converse based on a union bound argument. It should be noted that in both point-to-point
and MAC cases the requirement on the channel coherence time T for the optimal DMT to hold
actually comes from the union bound, not the outage. When T â‰¥ Knt+ntâˆ’1, Coronel et al. [16]
presented a criterion for constructing MAC-DMT optimal codes. For any coding schemes, let Ek
denote the error event that only the messages from k users are erroneously decoded. Coronel et al.
showed that for any k-subsets of users, 1 â‰¤ k â‰¤ K, if Pr {Ek} is upper bounded by the probability
of the corresponding outage event formulated by these k users, i.e. if one can show
Pr {Ek} â‰¤Ë™Pr
{
log det
(
Inr + SNRHkH
â€ 
k
)
â‰¤ kr log SNR
}
, (1.8)
where H = [Hi1 Â· Â· Â·Hik ] is the overall channel matrix and Hij is the (nr Ã— nt) channel matrix of
the jth user, then the code is MAC-DMT optimal. Notions of exponential inequalities â‰¥Ë™, â‰¤Ë™, >Ë™, <Ë™,
and equality .= are defined in [9]. Specifically, in terms of code design, the above criterion (1.8)
means that the (knt Ã— T ) matrix obtained by vertically concatenating the signal matrices from k
users must be of full row rank and should perhaps satisfy the nonvanishing determinant (NVD)
criterion [4, 26]. This full NVD design criterion was explicitly given in [16].
The aim of this report is to answer the following questions.
1. Is it possible to achieve the optimal MAC-DMT dâˆ—nt,nr,K(r) when T < Knt + nr âˆ’ 1?
2. Is design criterion (1.8) necessary? or is it only sufficient?
3. In order to be MAC-DMT optimal, is it necessary for a code to satisfy the NVD criterion for
any (knt Ã— T ) submatrix formed by any k-subsets of users?
4. In point-to-point MIMO channel, can one design a non-random DMT optimal code for T <
nt? Also, will the resulting DMT be the same as dâˆ—nt,nr(r)? In other words, when T < nt, it
relates to the question of whether the outage event will dominate the error performance.
The major contribution of this report is not to provide constructions of codes having per-
formance better than the previously known DMT optimal codes, for example, the CDA based
codes [4], the Golden perfect codes [20], the max-order codes [7], or the multi-block codes [6].
Instead, we aim to address the above four questions that none of these codes can answer.
By analyzing the DMT performance of a very simple code, we will provide answers to all the
above questions. We will consider a MIMO-MAC channel with K = 2 users, each having only
nt = 1 transmit antenna, and we will assume there are nr = 2 receive antennas at receiving end.
While Theorem 1 holds for codes with T â‰¥ Knt + nr âˆ’ 1 = 3 channel uses, we will prove this
simple code achieves the same optimal MAC-DMT dâˆ—1,2,2(r) with only T = 1 or 2 channel uses.
Furthermore, from the DMT analysis of this code we will see that criterion (1.8) is only sufficient,
not necessary, and one does not need full NVD in order to achieve the optimal MAC-DMT. By
slightly modifying the parameters of this code, we will show in the point-to-point MIMO scenario
this simple code achieves the same DMT performance as the Gaussian random code over the fast
Rayleigh fading channel, i.e. the case when T = 1, which relates to the fourth question in the
above list.
In Chapter 8 we will present the simple code as well as the corresponding DMT performance
analysis. Inferences from the DMT analysis will be given in Chapter 9 and will answer all the
above questions of interest.
9
Ck âˆˆ Ck. Thus, the constant Îº is chosen such that the code Sk = Îº Ck satisfies the power constraint
(1.4).
From [4], it is easy to prove the following theorem which in turn gives a sufficient criterion for
designing MAC-DMT optimal codes. We remark that this theorem is an alternative statement of
the result given in [16] under certain restrictions, and we refer the interested readers to [17] for the
connections.
Theorem 3 ( [16]). Let C0, Â· Â· Â· , CKâˆ’1 be given as above. For any Im = {i0, i1, Â· Â· Â· , imâˆ’1} âŠ†
{0, 1, Â· Â· Â· , K âˆ’ 1}, let CIm be the product concatenation of Ci0 , Â· Â· Â· , Cimâˆ’1 , defined by
CIm =
ï£±ï£´ï£²ï£´ï£³CIm =
ï£®ï£¯ï£° Ci0...
Cimâˆ’1
ï£¹ï£ºï£» : Cij âˆˆ Cij , ij âˆˆ Im
ï£¼ï£´ï£½ï£´ï£¾ .
If for all pairs of distinct code matrices Cij 6= C â€²ij âˆˆ Cij , j = 0, 1, Â· Â· Â· ,mâˆ’1, the difference matrix
âˆ†CIm =
ï£®ï£¯ï£° Ci0 âˆ’ C
â€²
i0
...
Cimâˆ’1 âˆ’ C â€²imâˆ’1
ï£¹ï£ºï£» , (2.3)
satisfies det(âˆ†CImâˆ†C
â€ 
Im) â‰¥Ë™ 1, where by Câ€  we mean the Hermitian transpose of matrix C, then
the codes C0, Â· Â· Â· , CKâˆ’1 are jointly MAC-DMT optimal.
Proof. Note that the imposed condition implies that the code CIm satisfies the NVD property for
any Im. Along similar lines as in [4], it can be shown that the error event E(Im) associated with
code CIm , i.e., the error event of users in Im in error, has probability upper bounded by
Pr {E(Im)} â‰¤Ë™ Pr {O(Im)} .= SNRâˆ’dâˆ—mnt,nr (mr),
where O(Im) is the event of users in Im in outage. Now taking union bound over all possible Im
as in (2.2) completes the proof. 
Remark 1. The condition of det(âˆ†CImâˆ†C
â€ 
Im) â‰¥Ë™ 1 for all Im is called the full NVD criterion
and is actually equivalent to the criterion given by Coronel et al. in [16] with certain restrictions,
see [17] for details. It should be noted that this full NVD condition is only sufficient, not necessary.
However, the following result suggests that this condition might be too strong and precludes the
existence of codes meeting the criterion. We call the stronger condition det(âˆ†CImâˆ†C
â€ 
Im) â‰¥ 1
the exactly full NVD criterion.
Theorem 4. For any K > 1 and for any nt â‰¥ 1, there do not exist any linear MIMO-MAC codes1
that satisfy the exactly full NVD criterion.
Proof. For ease of reading, the proof is relegated to Chapter 5. 
1Here by linear codes we mean codes having linear dispersion forms [8] or having a lattice structure. Almost all
existing ST codes are linear, for example, the Alamouti codes [2], the CDA-based ST codes [3â€“7, 13, 18â€“21, 27], etc.
11
1. We do not require the difference matrix âˆ†CIm to be nonsingular and to satisfy the NVD
property when all the component matrices Cij âˆ’ C â€²ij are nonzero, which has been shown to
be impossible by Theorem 4.
2. Should the difference matrix âˆ†CIm happen to be singular, (2.4) requires the resulting error
performance must be no worse than SNRâˆ’d
âˆ—
nnt,nr
(nr) for some n, 1 â‰¤ n â‰¤ m, in order to
maintain the MAC-DMT optimality.
3. In Theorem 3, events En(Im) with n < m were required to have probability absolutely zero.
This is too strict and would preclude the existence of MAC-DMT optimal codes.
13
E o = F(Î¸, Î·o)
Ko
ntKo
nt
L = F(Î¸)
nt
Ko = F(Î·o)
Ko
F = Q( Ä± )
Figure 3.1: Field extensions required by the proposed code constructions.
Remark 2. While in the above we have set Î¶ to be of form Î¶ = Î³
Î³âˆ— such that Î¶ is unimodular, it
might be possible that in some CDAs, the nonnorm element Î³ is actually an nth root of unity for
some integer n and is already unimodular. See [31] for such example construction. Should it be
the case, we could set Î¶ = Î³, and the discussion below can be easily modified to show that the
MAC-DMT optimality of the proposed constructions remains to hold. Therefore, for simplicity,
here we will focus only on the case of Î¶ = Î³
Î³âˆ— . 
Remark 3. We note that by construction the Galois groups of the numbers fields are
Gal(E o/Ko) = ã€ˆÏƒã€‰ ,
Gal(E o/L) = ã€ˆÏ„oã€‰ ,
Gal(E o/F) = ã€ˆÏ„o, Ïƒã€‰ = ã€ˆÏ„oã€‰ Ã— ã€ˆÏƒã€‰ ,
where in the last line ã€ˆÏ„oã€‰ Ã— ã€ˆÏƒã€‰ denotes the direct product of the groups generated by Ï„o and Ïƒ,
respectively. It should also be noted that the automorphisms Ï„o and Ïƒ commute, i.e.,
Ï„oÏƒ = ÏƒÏ„o
due to the direct product of two groups. 
Given multiplexing gain r, let A(SNR) be the base alphabet defined as
A(SNR) =
{
a+ b Ä± :
âˆ’SNR r2nt â‰¤ a, b â‰¤ SNR r2nt ,
a, b âˆˆ Z, a, b odd
}
;
then the corresponding information set is
Ao(SNR) =
{
ntâˆ’1âˆ‘
i=0
zi
Kontâˆ’1âˆ‘
k=0
xi,kek : xi,k âˆˆ A(SNR)
}
, (3.5)
where {e0, Â· Â· Â· , eKontâˆ’1} is an integral basis of E o/F. It should be noted that
âˆ‘Kontâˆ’1
k=0 xi,kek âˆˆ E o
for xi,k âˆˆ A(SNR) âŠ‚ OF and that Ao(SNR) âŠ‚ Do. Let
Ïˆo : Do â†’Mnt(E o)
be the left-regular map that maps elements inDo into (ntÃ—nt) square matrices with entries in E o.
Specifically, given u âˆˆ Do with
u =
ntâˆ’1âˆ‘
i=0
ziui, ui âˆˆ E o,
15
Example 1. We consider the case of K = 2 and nt = 2. By construction Ko = 3 is the smallest
odd integer such that Ko â‰¥ K. Then it can be shown that with Î¸ = e Ä± pi8 and Î·o = 2 cos
(
2pi
7
)
the
number fields L = F(Î¸) and Ko = F(Î·o) meet the required conditions of [L : F] = 2, [Ko : F] = 3
and L âˆ© Ko = F. Furthermore, we have Î·3o + Î·2o âˆ’ 2Î·o âˆ’ 1 = 0. The generators Ïƒ and Ï„o for the
Galois groups Gal(L/F) and Gal(Ko/F) are given respectively by
Ïƒ : Î¸ 7â†’ âˆ’Î¸ and Ï„o : Î·o 7â†’
(
Î·2o âˆ’ 2
)
= 2 cos
(
4pi
7
)
The set {1, Î¸, Î·o, Î¸Î·o, Î·2o , Î¸Î·2o} is an integral basis for E o/F.
As the prime ideal (2 + Ä± ) of Z[ Ä± ] remains inert in OKo and OL, following from [4] this gives
an appropriate nonnorm element Î³ = 2 + Ä± . Hence we have Î¶ = 2+ Ä±
2âˆ’ Ä± . With E o = F(Î¸, Î·o),
Do = (E o/Ko, Ïƒ, Î¶) is a CDA of index 2 which is also a central simple Ko-algebra [25]. Next let
ui = xi,0 + Î¸xi,1 + Î·oxi,2 + Î¸Î·oxi,3 + Î·
2
oxi,4 + Î¸Î·
2
oxi,5
for i = 0, 1 with xi,j âˆˆ A(SNR). The Galois conjugates of ui are for example given by
Ïƒ(ui) = xi,0 âˆ’ Î¸xi,1 + Î·oxi,2 âˆ’ Î¸Î·oxi,3 + Î·2oxi,4 âˆ’ Î¸Î·2oxi,5,
Ï„o(ui) = xi,0 + Î¸xi,1 + Î·
â€²
oxi,2 + Î¸Î·
â€²
oxi,3 + Î·
â€²2
o xi,4 + Î¸Î·
â€²2
o xi,5
where Î·â€²o = Î·
2
o âˆ’ 2 = 2 cos
(
4pi
7
)
and Ï„o(Î·â€²o) = 1âˆ’ Î·oâˆ’ Î·2o = 2 cos
(
8pi
7
)
. With the above, the signal
matrix of the first user is given by S0 = Îº
[
X0 Ï„o(X0) Ï„
2
o (X0)
]
, where Îº2 = SNR1âˆ’
r
2 and
X0 =
[
u0 Î¶Ïƒ(u1)
u1 Ïƒ(u0)
]
.

By vertically concatenating the signal matrices from all users, the overall MIMO-MAC code
of the K users is
S =
ï£±ï£´ï£´ï£´ï£´ï£´ï£²ï£´ï£´ï£´ï£´ï£´ï£³
S = Îº
ï£®ï£¯ï£° X0 Â· Â· Â· Ï„
Koâˆ’1
o (X0)
... . . .
...
XKâˆ’1 Â· Â· Â· Ï„Koâˆ’1o (XKâˆ’1)
ï£¹ï£ºï£» :
Xi = Ïˆo(xi), xi âˆˆ Ao(SNR)
ï£¼ï£´ï£´ï£´ï£´ï£´ï£½ï£´ï£´ï£´ï£´ï£´ï£¾
. (3.9)
For ease of code performance analysis that comes later we set C = 1
Îº
S, i.e.,
C =
ï£±ï£´ï£´ï£´ï£´ï£´ï£²ï£´ï£´ï£´ï£´ï£´ï£³
C =
ï£®ï£¯ï£° X0 Â· Â· Â· Ï„
Koâˆ’1
o (X0)
... . . .
...
XKâˆ’1 Â· Â· Â· Ï„Koâˆ’1o (XKâˆ’1)
ï£¹ï£ºï£» :
Xi = Ïˆo(xi), xi âˆˆ Ao(SNR)
ï£¼ï£´ï£´ï£´ï£´ï£´ï£½ï£´ï£´ï£´ï£´ï£´ï£¾
. (3.10)
Remark 5. Below we briefly compare the proposed construction of S with another MAC-DMT
optimal code constructed forK = 2 users in [22]. The latter MIMO-MAC code takes the following
form
S2 =
ï£±ï£´ï£´ï£²ï£´ï£´ï£³
S2 = Îº
[
X0 Ï„(X0)
X1 âˆ’Ï„(X1)
]
:
Xi = Ïˆ(xi), xi âˆˆ A(SNR)
ï£¼ï£´ï£´ï£½ï£´ï£´ï£¾ . (3.11)
17
Property 1. For any Co âˆˆ Co, we have[
(Î³âˆ—)Ko(ntâˆ’1) det(Co)
]
âˆˆ Z[ Ä± ]. (3.16)
Proof. We first claim
Ï„o(det(Co)) = det(Co). (3.17)
To see this, notice that
Ï„o(det(Co)) = det
ï£«ï£¬ï£­ Ï„o(X0) Â· Â· Â· Ï„
Ko
o (X0)
... . . .
...
Ï„o(XKoâˆ’1) Â· Â· Â· Ï„Koo (XKoâˆ’1)
ï£¶ï£·ï£¸
= det
ï£«ï£¬ï£­ Ï„o(X0) Â· Â· Â· X0... . . . ...
Ï„o(XKoâˆ’1) Â· Â· Â· XKoâˆ’1
ï£¶ï£·ï£¸
= (âˆ’1)nt(Koâˆ’1) det(Co) = det(Co),
where the last equality follows from the fact that Ko âˆ’ 1 is even, hence the claim (3.17) is proved.
Next, we show
Ïƒ(det(Co)) = det(Co). (3.18)
To this end, define
Z = Ïˆo(z), (3.19)
where z is the indeterminate defined as in (3.2). Since from (3.4) xz = zÏƒ(x) for all x âˆˆ E o, it is
clear that Ïƒ(X) = Zâˆ’1XZ, where X = Ïˆo(x). Now we have
Ïƒ(det(Co))
=
âˆ£âˆ£âˆ£âˆ£âˆ£âˆ£âˆ£
Zâˆ’1X0Z Â· Â· Â· Ï„Koâˆ’1o (Zâˆ’1X0Z)
... . . .
...
Zâˆ’1XKoâˆ’1Z Â· Â· Â· Ï„Koâˆ’1o (Zâˆ’1XKoâˆ’1Z)
âˆ£âˆ£âˆ£âˆ£âˆ£âˆ£âˆ£
=
âˆ£âˆ£âˆ£âˆ£âˆ£âˆ£âˆ£
Zâˆ’1X0Z Â· Â· Â· Zâˆ’1Ï„Koâˆ’1o (X0)Z
... . . .
...
Zâˆ’1XKoâˆ’1Z Â· Â· Â· Zâˆ’1Ï„Koâˆ’1o (XKoâˆ’1)Z
âˆ£âˆ£âˆ£âˆ£âˆ£âˆ£âˆ£
=
âˆ£âˆ£âˆ£âˆ£âˆ£âˆ£âˆ£
Zâˆ’1
. . .
Zâˆ’1
âˆ£âˆ£âˆ£âˆ£âˆ£âˆ£âˆ£Ã—âˆ£âˆ£âˆ£âˆ£âˆ£âˆ£âˆ£
X0 Â· Â· Â· Ï„Koâˆ’1o (X0)
... . . .
...
XKoâˆ’1 Â· Â· Â· Ï„Koâˆ’1o (XKoâˆ’1)
âˆ£âˆ£âˆ£âˆ£âˆ£âˆ£âˆ£
âˆ£âˆ£âˆ£âˆ£âˆ£âˆ£âˆ£
Z
. . .
Z
âˆ£âˆ£âˆ£âˆ£âˆ£âˆ£âˆ£
= det(Co),
where we have used the fact that Ï„o(Z) = Z since 0 6= Î¶ âˆˆ F by construction. Thus, as det(Co) is
fixed by both Ï„o and Ïƒ, we see that det(Co) âˆˆ F = Q( Ä± ).
Finally, from the definition of Ïˆo (3.6), the matrix
Ï„ jo (Xi)
ï£®ï£¯ï£¯ï£¯ï£°
1
Î³âˆ—
. . .
Î³âˆ—
ï£¹ï£ºï£ºï£ºï£»
19
Property 2 shows that the overall code matrix Co âˆˆ Co might not always have full rank Kont,
and the rank of Co is always a multiple of nt. This is not too much of a surprise as it is straight-
forward to see that in (3.13) if some Xiâ€™s are identical, then the overall code matrix Co cannot be
nonsingular.
Compared with the constructions proposed in [18,19], the matrixCo of the present construction
could be singular even when the component matrices Xi are all distinct and nonzero as shown
by Property 2. Nevertheless, we will prove in Chapter 6 that in order to achieve the optimal
MAC-DMT performance at high-SNR regime, it is unnecessary to construct codes such that Co is
nonsingular whenever all the component matrices Xi are distinct and nonzero.
Before rigorously proving the above statement, a heuristic way to see this is the following.
Since the users communicate independently to the base station, for any overall MIMO-MAC code
C it is impossible for all the code matrices C âˆˆ C to be nonsingular as some component matrices
Ck of the kth user could be zero. Also, from the pairwise error probability point of view, for any
C 6= C â€² âˆˆ C, C âˆ’ C â€² can be singular at least when the information symbols transmitted by some
users are the same. The rank of overall code matrices Co is at best a multiple of nt. Therefore,
intuitively speaking, perhaps it would not hurt to make things a bit worse in the sense that the
difference matrix C âˆ’ C â€² can be singular in other cases. By this we mean that if there are m
distinct information symbols in the difference matrix Câˆ’C â€², the maximal possible rank of Câˆ’C â€²
is mnt. We claim that it would not hurt in the DMT sense if the construction can provide only
rank nnt for some n with 1 < n < m. The reason for this actually follows from Theorem 5 that
the error events En (Im) of m users in error but getting only rank distance nnt do not dominate
the error performance in the final DMT performance. Therefore, we strongly speculate that such
difference matrices Câˆ’C â€² do not have to achieve the same rank mnt as the Gaussian random code
does. The rank can be less, as long as the resulting error performance is not worse than those of
m = 1 and m = Ko.
Although we do not need the whole code Co to satisfy the full NVD property as in the point-to-
point scenario, an alternative NVD-like property is preferred and is given as below.
Property 3. Let C be defined as in (3.20) and assume that {x>i0 , Â· Â· Â· , x>imâˆ’1} is a subset of rows of
C that are linearly independent as a left Do-module. Define
Cs :=
ï£®ï£¯ï£° x
>
i0
...
x>imâˆ’1
ï£¹ï£ºï£» and Cs := Î¨o (Cs) , (3.23)
i.e., Cs is the submatrix of Co consisting of the corresponding linearly independent mnt rows,
where Î¨o is the natural extension of Ïˆo. Then
1 â‰¤
[
|Î³|2mnt Â· det (CsCâ€ s)] âˆˆ Z, (3.24)
where by Aâ€  we mean the hermitian transpose of matrix A.
Proof. First, it follows from Property 2 that[
|Î³|2mnt Â· det (CsCâ€ s)] > 0
since Cs has full row rank mnt and Î³ 6= 0 by assumption. To show |Î³|2mnt Â· det
(
CsC
â€ 
s
) âˆˆ Z,
we shall first verify that det
(
CsC
â€ 
s
)
is fixed under automorphisms Ï„o and Ïƒ. For Ï„o, it can be seen
from the proof of Property 1 that
Ï„o
(
det
(
CsC
â€ 
s
))
= det
(
Ï„o (Cs) [Ï„0 (Cs)]
â€ 
)
21
Property 4. LetCo andCs be defined as above with rank(Co) = rank(Cs) = mnt. Let Î²1, Â· Â· Â· , Î²mnt
be the nonzero eigenvalues of CoCâ€ o . Then
mntâˆ
i=1
Î²i â‰¥ det (CsCs) â‰¥Ë™ 1. (3.26)
Proof. Here we take an information theoretic approach to prove the first inequality. To this end,
let N = [N1, Â· Â· Â· , NKont ]> be a complex Gaussian random vector of length Kont with zero mean
and covariance matrix
EN N â€  = CoCâ€ o .
Without loss of generality we can assume that m linearly independent users are the first m users
and ij corresponds to the jth user, j = 0, 1, Â· Â· Â· ,m âˆ’ 1. Hence the covariance matrix of the
sub-vector N s = [N1, Â· Â· Â· , Nmnt ]> equals
EN sN â€ s = CsCâ€ s .
We have the following inequality for the differential entropies of N and N s
h (N1, Â· Â· Â· , NKont) â‰¥ h (N1, Â· Â· Â· , Nmnt)
= log det
(
CsC
â€ 
s
)
+mnt log(2pie)
(3.27)
Notice that the covariance matrix of N can be decomposed as
CoC
â€ 
o = UÎ£U
â€ 
for some (Kont Ã—Kont) unitary matrix U . Î£ is a diagonal matrix whose nonzero entries are the
Î²iâ€™s. Thus setting N â€² = UN we have
h(N) = h(U â€ N â€²) =
mntâˆ‘
i=1
log Î²i +mnt log(2pie).
Now combining the above results proves the first inequality in (3.26). The second inequality in
(3.26) follows directly from Property 3 and from |Î³| .= 1. 
Remark 6. The above property shows that despite Co can be singular, the product of the nonzero
eigenvalues ofCoCâ€ o is always bounded from below by 1. This can be regarded as a relaxation of the
conventional NVD property. In the design of ST codes, satisfying the NVD criterion is a sufficient
condition to achieve the optimal point-to-point DMT performance. To guarantee NVD in the point-
to-point MIMO, we require all the users to cooperate fully as already seen in Theorem 4. However,
it is not allowed in MIMO-MAC where users transmit independently their own information to the
common receiver. Thus, in MIMO-MAC we do not demand full NVD, and only partial NVD is
required as shown in (3.26). 
3.3 MAC-DMT Optimality of the Proposed Construction
Armed with the properties discussed in the previous section, below we are able to show the pro-
posed code is MAC-DMT optimal.
23
Chapter 4
MAC-DMT Optimal Codes for General
MIMO-MAC Systems
In [11], Tse et al. focused on analyzing the DMT in a symmetric MIMO-MAC system. By sym-
metric we mean that every mobile user in the system has the same number of transmit antennas
and transmits at the same level of multiplexing gain. However, the symmetric MIMO-MAC might
not be practical enough. In the near future, the mobile communication is likely to be at a transi-
tion stage, migrating from conventional SISO (single-input single-output) to MIMO. In fact, such
transition already takes place in wireless local area networks where some old laptops have single
transmit antenna while the latest ones could have more than two transmit antennas. In the mixture
of SISO and MIMO communication environment, one would expect the mobile users having dif-
ferent numbers of transmit antennas. Furthermore, in practice it is often possible that mobile users
transmit at different rates because of the different plans they purchase from the service provider.
The different rate implies a different level of multiplexing gain in the DMT sense. It is then of
fundamental importance that we must have a general code construction that works for any MIMO-
MAC systems where the mobile users are allowed to have different numbers of transmit antennas
and can transmit at different levels of multiplexing gains. In the previous sections we have pro-
vided a systematic construction for the symmetric MIMO-MAC and have proved that it achieves
the optimal MAC-DMT. Below we will extend these results to the general channel.
4.1 Decoding in General MIMO-MAC
There can be at least two decoding methods in the general MIMO-MAC, depending on how much
computational complexity one can afford. The first decoder is the joint ML decoder, by which
we mean the following. Assuming there are K users, each transmitting using a codebook Si that
consists of (ni Ã— T ) ST code matrices, for i = 0, 1, Â· Â· Â· , K âˆ’ 1. Let Si âˆˆ Si be the signal matrix
transmitted by the ith user, and let
Y =
Kâˆ’1âˆ‘
i=0
HiSi +W
be the received signal matrix; then the joint ML decoder seeks the optimal joint ML estimate(
SË†0, Â· Â· Â· , SË†Kâˆ’1
)
by(
SË†0, Â· Â· Â· , SË†Kâˆ’1
)
= arg max
SâˆˆS
Pr {S = (S0, Â· Â· Â· , SKâˆ’1) |Y }
= arg min
SâˆˆS
âˆ¥âˆ¥âˆ¥âˆ¥âˆ¥Y âˆ’
Kâˆ’1âˆ‘
i=0
HiSi
âˆ¥âˆ¥âˆ¥âˆ¥âˆ¥
F
, (4.1)
25
Example 2. For simplicity, here we consider a general MIMO-MAC system with two users. The
first user has n0 = 1 transmit antenna and transmits at multiplexing gain r0; the second user has
n1 = 2 transmit antennas and transmits at multiplexing gain r1. Assume there are nr = 2 receive
antennas at receiver end. Using (4.3) the resulting MAC-DMT is shown in Fig. 4.1. First, it is
interesting to note that unlike the symmetric MIMO-MAC where all users have same number of
transmit antennas and transmit at same level of multiplexing gain, here the second user cannot
achieve his single-user DMT performance even when r0 = 0. This effect is shown in Fig. 4.2.
While this is quite unexpected, such phenomenon can be easily explained. Recall that the DMT is
an asymptotic result. Strictly speaking, the multiplexing gain ri is defined as
ri = lim
SNRâ†’âˆ
Ri
log2 SNR
,
and Ri is the actual transmission rate. Therefore, when we say r0 = 0 it does not necessarily mean
R0 = 0. It simply means that the rate of the first user grows much slower than log2 SNR. For
example, an ST code that is fixed and does not vary with SNR has multiplexing gain 0 since the
rate Ri is a constant. But the rate Ri is bounded away from 0.
Having learned the above, in our example given the multiplexing gain r0 =  for some positive 
very close to 0, the DMT performance of joint decoder would be dominated by erroneous decoding
of the first userâ€™s signals when r1 is small. It is also easy to confirm this observation from pairwise
error probability (PEP) analysis. Assume r0 = r1 = 0, butR0, R1 > 0, i.e., the codes are fixed and
do not vary with SNR. Since the two users do not cooperate, for any distinct pairs of overall code
matrices, the maximal possible rank is the minimum of n0 and n1. Hence the resulting maximal
possible diversity gain equals
dmax = nr Â·min{n0, n1},
which equals 2 in this example. Therefore, the PEP analysis confirms that the single-user DMT
performance dâˆ—2,2(r1) cannot be achieved for small values of r0 as shown in Fig. 4.2.
Before concluding this example we remark that the loss in DMT for the second user can in fact
be recovered if an individual ML decoder is used. We will come back to this in Chapter 4.3. 
0
1
2
0
0.5
1
0
1
2
Multiplexing Gain r1
Multiplexing Gain r0
D
iv
er
si
ty
 g
ai
n 
d
Figure 4.1: Joint MAC-DMT dâˆ—{1,2},2(r0, r1) of general MIMO-MAC with two users.
The proof of Theorem 8 follows along similar lines of that of symmetric MAC-DMT provided
by Tse et al. in [11]. Specifically, let
Ri := ri log2 SNR (bits/channel use)
27
Following similar arguments as in [11] it is straightforward to see that the error probability of joint
decoding Pe(r0, Â· Â· Â· , rKâˆ’1) is lower bounded by
Pe(r0, Â· Â· Â· , rKâˆ’1) â‰¥ Pr {O} â‰¥ maxI Pr {O(I)}
.
= SNRâˆ’minI d
âˆ—
Nt(I),nr(
âˆ‘
iâˆˆI ri).
(4.6)
To establish the converse, we take the random codebook approach similar to that used by Tse
et al. in [11]. Let Si be the codebook of the ith mobile user, consisting of (ni Ã— T ) code matrices
that are randomly generated by some complex Gaussian random generator. Further, Si satisfies the
desired multiplexing gain,
1
T
log2 |Si| = Ri = ri log2 SNR.
Let E (I) denote the event that the signal matrices of users in I are erroneously decoded by the
joint decoder. Then arguing similarly as in [11], it can be shown that
Pr {E (I)} â‰¤Ë™ SNRâˆ’dâˆ—Nt(I),nr(
âˆ‘
iâˆˆI ri)
whenever
T â‰¥ Nt(I) + nr âˆ’ 1.
Thus, using union bound we have
Pe (r0, Â· Â· Â· , rKâˆ’1) â‰¤
âˆ‘
I
Pr {E (I)}
.
= SNRâˆ’minI d
âˆ—
Nt(I),nr(
âˆ‘
iâˆˆI ri),
provided that
T â‰¥ max
I
Nt(I) + nr âˆ’ 1 = N + nr âˆ’ 1.
This proves Theorem 8.
4.3 MAC-DMT for General MIMO-MAC with Individual ML
Decoding
In the previous section we investigated the MAC-DMT for a general MIMO-MAC with joint de-
coding at the receiver end. We also observed in Example 2 that certain DMT performance loss
could result from the use of joint decoder. However, such loss can be safely avoided by the use of
individual ML decoder.
Recall that for the ith user, the truly optimal decoder, though having extremely high computa-
tional complexity, is the individual ML decoder that seeks optimal ML estimate SË†i by
SË†i = arg max
SiâˆˆSi
Pr {Si|Y }
= arg max
SiâˆˆSi
âˆ‘
S(i)âˆˆS(i)
exp
ï£«ï£­âˆ’âˆ¥âˆ¥âˆ¥âˆ¥âˆ¥Y âˆ’
Kâˆ’1âˆ‘
i=0
HiSi
âˆ¥âˆ¥âˆ¥âˆ¥âˆ¥
2
F
ï£¶ï£¸ , (4.7)
where S(i) = (S0, S1, Â· Â· Â· , Siâˆ’1, Si+1, Â· Â· Â· , SKâˆ’1) and S(i) = S0 Ã— S1 Ã— Â· Â· Â· Ã— Siâˆ’1 Ã— Si+1 Ã—
Â· Â· Â· Ã— SKâˆ’1. Clearly (4.7) outperforms (4.1) in error performance, but at a cost of much higher
computational complexity.
29
0 0.5 1 1.5 20
0.5
1
1.5
2
2.5
3
3.5
4
Multiplexing Gain r
Di
ve
rs
ity
 g
ain
 d
d{1,2},2
* (r/4,r)
d{1,2},2
(1)* (r/4,r)
Figure 4.3: Comparison between the joint MAC-DMT and the individual MAC-DMT of the second
user when r1 = 4r0 = r.
0 0.5 1 1.5 20
0.5
1
1.5
2
2.5
3
3.5
4
Multiplexing gain r
Di
ve
rs
ity
 g
ain
 d
d{1,2},2
* (r,r)
d{1,2},2
(0)* (r,r)
d{1,2},2
(1)* (r,r)
d2,2
* (r)
d1,2
* (r)
Figure 4.4: Comparison between the joint MAC-DMT and the individual MAC-DMT when r1 =
r0 = r.
With the above result, we now come back to Example 2 to investigate the individual MAC-
DMT of the second user.
Example 3 (Continued from Example 2). In Example 2 we have considered the specific case of
K = 2, n0 = 1, n1 = 2, nr = 2 and r0 = 0. Assuming the second user transmits at multiplexing
gain r1, from Theorem 9 the individual MAC-DMT of the second user is
d
(1)âˆ—
{1,2},2(0, r1) = min{dâˆ—2,2(r1), dâˆ—3,2(r1)} = dâˆ—2,2(r1).
Hence we see that the single-user performance of the second user is recovered by the use of an
individual ML decoder. To illustrate further the difference in MAC-DMT between (4.1) and (4.7),
in Fig. 4.3 we compare the MAC-DMT performances of joint and individual decoders at r1 =
4r0 = r. It can be clearly seen that the individual ML decoder outperforms significantly the joint
ML decoder at low-multiplexing-gain regime.
31
userâ€™s code matrices, similar to that described in Chapter 3. Henceforth we will drop the subscript
â€œoâ€ in Ko, Ko, Ï„o, Co, So, etc. for simplicity.
Given ni and K, we first define
nmax := max
0â‰¤iâ‰¤Kâˆ’1
ni (4.9)
as the maximal number of transmit antennas among all users. In general, the number nmax can
be either pre-known to all the users, or explicitly specified among any groups of users. Next, let
L = F(Ï‘) be the number field that is cyclic Galois over F = Q( Ä± ) with degree nmax, and let
K = F(Î·) be another cyclic Galois extension of F with degree K. Let Ïƒ be the generator of the
Galois group Gal(L/F), and similarly let Ï„ be the generator of Gal(K/F). The fields L and K are
required to satisfy Lâˆ©K = F or are required such that Ï„ and Ïƒ commute. Finally, we set E = LK
to be the compositum of fields L and K. Similar to Chapter 3, with some suitable unimodular
Î¶ âˆˆ Fâˆ—, we have
D = E âŠ• zE âŠ• Â· Â· Â· âŠ• znmaxâˆ’1E (4.10)
as an appropriate central simple division K-algebra with xz = zÏƒ(x) for x âˆˆ E , where z is an
indeterminate satisfying znmax = Î¶ .
Given the multiplexing gain ri of the ith user, we set the corresponding base alphabet and
information set as follows:
Ai(SNR) =
{
a+ b Ä± :
âˆ’SNR ri2nmax â‰¤ a, b â‰¤ SNR ri2nmax ,
a, b âˆˆ Z, a, b odd
}
(4.11)
and
Ai(SNR) =
{
nmaxâˆ’1âˆ‘
j=0
zj
Knmaxâˆ’1âˆ‘
k=0
xj,kek : xj,k âˆˆ Ai(SNR)
}
, (4.12)
where {e0, Â· Â· Â· , eKnmaxâˆ’1} is an integral basis of E /F. Unlike the construction for symmetrical
MIMO-MAC, here the information set can be different among users as each user has different
level of multiplexing gain.
Let Ïˆ denote the left-regular map of elements in D into matrices of size (nmax Ã— nmax) whose
entries are in E (similar to Ïˆo of (3.6)); then the ST code Si of the ith user is given by
Si =
ï£±ï£²ï£³ Si = Îºi
[
Xi Ï„ (Xi) Â· Â· Â· Ï„Kâˆ’1 (Xi)
]
:
Xi = Ïˆ(xi), xi âˆˆ Ai(SNR)
ï£¼ï£½ï£¾ , (4.13)
where
Îº2i
.
= SNR1âˆ’
ri
nmax (4.14)
such that the power constraint (1.4) is satisfied.
Given Si, i = 0, 1, Â· Â· Â· , Kâˆ’1, the overall code is obtained by vertically concatenating the code
matrices from each user,
S := S0 Ã— S1 Ã— Â· Â· Â· Ã— SKâˆ’1
=
ï£±ï£´ï£²ï£´ï£³S =
ï£®ï£¯ï£° S0...
SKâˆ’1
ï£¹ï£ºï£» : Si âˆˆ Si
ï£¼ï£´ï£½ï£´ï£¾ . (4.15)
The overall code matrix S is a square matrix of size (Knmax Ã— Knmax). Below we will present
some nice properties of S which are essential to proving its MAC-DMT optimality.
The first property extends Property 2 of the symmetric MAC code So in Chapter 3.2.
33
Proof. Arguing similarly to the proof of Property 5, set
Cs =
ï£®ï£¯ï£° Xi0 Â· Â· Â· Ï„
Kâˆ’1 (Xi0)
... . . .
...
Ximâˆ’1 Â· Â· Â· Ï„Kâˆ’1
(
Ximâˆ’1
)
ï£¹ï£ºï£» . (4.21)
Then we have
Ss =
ï£®ï£¯ï£° Îºi0Inmax . . .
Îºimâˆ’1Inmax
ï£¹ï£ºï£»Cs
and [
â€–Î³â€–2mnmax Â· det (CsCâ€ s)] â‰¥ 1
by Property 3 since Cs is a submatrix of the code matrix C (cf. (4.18)) of the code Co (cf. (3.14))
for the symmetric MIMO-MAC when setting nt = nmax and r = maxi ri. The result now follows
from
det
(
SsS
â€ 
s
)
= det
(
CsC
â€ 
s
)mâˆ’1âˆ
j=0
det
(
ÎºijInmax
)
â‰¥Ë™
mâˆ’1âˆ
j=0
det
(
ÎºijInmax
)
and from the definition of Îºij in (4.14). 
The two properties above are exactly what we need to prove the MAC-DMT optimality of the
proposed general MIMO-MAC code S in (4.15). Hence, with these properties we can prove the
following theorem.
Theorem 11. Given ni and ri, i = 0, 1, Â· Â· Â· , K âˆ’ 1 with K odd, the proposed code S defined in
(4.15) achieves the general joint MAC-DMT
d(r0, Â· Â· Â· , r1) = minIm d
âˆ—
Nt(I),nr
(âˆ‘
iâˆˆI
ri
)
(4.22)
over a Rayleigh block fading channel that remains static for at least T â‰¥ Knmax channel uses. S
is MAC-DMT optimal.
Proof. The proof is similar to that of Theorem 7 and is relegated to Chapter 7 for ease of reading.

The proof to Theorem 11 can in fact be further extended to show that the proposed code S
(4.15) achieves the optimal individual MAC-DMT (4.8), provided that an individual ML decoder
for each user is used at the receiver end. This result along with the proof will be presented in
Corollary 15 of Chapter 7.
35
though invertible, the absolute of determinant |det(âˆ†C)| can be arbitrarily small and be close to
0, hence the third requirement of NVD cannot be met.
To see this, set
âˆ†Ck = Ck âˆ’ C â€²k,
with âˆ†Ck 6= 0 from the second requirement, and let W be the complex vector space of (ntÃ—Knt)
matrices. Let V = L(âˆ†C1,âˆ†C2, Â· Â· Â· ,âˆ†CKâˆ’1) be the complex vector space spanned by these
K âˆ’ 1 matrices. From the second requirement we immediately see that dimC V â€² = K âˆ’ 1. We
shall work with the quotient space Q = W/V . It has a natural structure of a finite dimensional
complex vector space. We also need its topology which is that of a Euclidean (or a Hermitian)
space that is well known to also be equal to the quotient topology.
The following simple observation is the key to prove Theorem 4.
Lemma 12. The mapping f : Qâ†’ C, given by
X + L(âˆ†C1, Â· Â· Â· ,âˆ†CKâˆ’1) 7â†’ det(M(X,âˆ†C1, Â· Â· Â· ,âˆ†CKâˆ’1) (5.1)
is well-defined and continuous.
Proof. Any two (nt Ã—Knt) matrices X and X â€² determine the same coset modulo V , if and only
if the difference matrix X âˆ’ X â€² is a complex linear combination of the matrices âˆ†C1,âˆ†C2, Â· Â· Â· ,
âˆ†CKâˆ’1. It is immediately clear that in that case
det(M(X,âˆ†C1, Â· Â· Â· ,âˆ†CKâˆ’1)
= det(M(X â€²,âˆ†C1, Â· Â· Â· ,âˆ†CKâˆ’1).
Therefore f is a well-defined function. Continuity of f follows from the continuity of the polyno-
mial function X 7â†’ det(M(X,âˆ†C1, Â· Â· Â· ,âˆ†CKâˆ’1) and the basic properties of the quotient topol-
ogy. 
Lemma 13. A subgroup in Cn is a lattice if and only if it is discrete. 
Having obtained Lemmas 12 and 13, we are now in position to prove Theorem 4.
Proof. As above, let us fix non-zero difference matrices âˆ†Ck âˆˆ Lk, k = 1, 2, Â· Â· Â· , K âˆ’ 1 for all
the other users. Let âˆ†C0 âˆˆ L0 be non-zero. Let pi : W â†’ Q denote the natural projection.
By the second requirement we have
det(M(âˆ†C0, Â· Â· Â· ,âˆ†CKâˆ’1)) 6= 0,
so âˆ†C0 does not belong to the subspace V . Therefore âˆ†C0 + V 6= 0Q, and we see that kerpi
intersects trivially with the lattice of the first user L0. So restricted to the free abelian group L0, pi
is an injection. Hence G = pi(L0) is a free abelian group of rank 2Kn2t âŠ‚ Q.
Because dimCQ < Kn2t , the quotient spaceQ is not big enough to contain a free abelian group
of rank 2Kn2t as a discrete subset. Therefore the set G must have an accumulation point in Q by
Lemma 13. In other words, there are matrices in G that are arbitrarily close to each other. As G
is closed under addition and negation, it follows that we can find a sequence of non-zero matrices
(Si)i=1,2,Â·Â·Â· from the lattice L0 such that the sequence of their images in the space Q converges
towards zero, or
lim
iâ†’âˆ
pi(Si) = 0Q.
The continuity of the function f of Lemma 12 then implies that
lim
iâ†’âˆ
det(M(Si,âˆ†C1, Â· Â· Â· ,âˆ†CKâˆ’1) = f(0) = 0.
As all these matrices are of the form prescribed in condition 3), we see that this last condition
cannot be met. 
37
Note that the difference matrix Co âˆ’ C â€²o has exactly mnt nonzero rows, and by Property 2 we see
the rank distance nt â‰¤ rank(Co âˆ’ C â€²o) â‰¤ mnt. Hence it makes sense for the second requirement
of error event En (Im) that rank(Co âˆ’ C â€²o) = nnt for some 1 â‰¤ n â‰¤ m.
Thus, it can be seen from the union bound argument that the codeword error probability is
upper bounded by
Pcwe(r) = Pr
{ â‹ƒ
Im,nâ‰¤m
En (Im)
}
â‰¤
âˆ‘
m
âˆ‘
Im
âˆ‘
nâ‰¤m
Pr {En (Im)} . (6.3)
The event En (Im) is a further partition of the event considered by Tse et al. in [11]. We discuss
this in more detail in the following remark.
Remark 7. With regard to the Gaussian random codebook considered by Tse et al. [11], it is
straightforward to see En (Im) is empty with probability one if n < m, since the component ma-
trices associated with each user are complex Gaussian random matrices of size (nt Ã— T ) for some
T â‰¥ Kont. In other words, if xi 6= xË†â€²i for all i âˆˆ Im and xi = xË†â€²i otherwise, then the error matrix
Co âˆ’ C â€²o would have rank mnt with probability one. Therefore, one can rewrite (6.3) as
Pcwe(r) â‰¤
âˆ‘
m
âˆ‘
Im
Pr {Em (Im)} (6.4)
and recover the same union bound used in [11]. 
Unlike [11] where the authors analyzed each summand Pr {Em (Im)} of (6.4) by a union bound
argument with a Gaussian random codebook, here we will focus on the error probability of a
deterministic codebook So (cf. (3.14)), and attempt to upper bound the probability Pr {En (Im)}
by using a joint ML decoder. To this end, in Chapter 6.2 we will examine the minimum Euclidean
distance among the noise-free received code matrices contained in En (Im). It should be noted that
here by minimum Euclidean distance, we mean the minimum Euclidean distance among only the
pairs of code matrices in En(Im), not the whole code Co. Thus, the minimum Euclidean distance
will be a function of n, Im, and Co.
Once we obtain the minimum Euclidean distance, we will analyze the error performance of a
bounded distance decoder, which will be used as an upper bound on that of the ML decoder. The
bounded distance decoder results in an error only when the noise matrix has norm larger than half
of the minimum Euclidean distance. More precisely, let H be the overall channel matrix defined
in (6.1) and be known to the decoder; let So = S0Ã— Â· Â· Â·Ã—SKoâˆ’1 be the overall MIMO-MAC code,
where Si is the codebook of the ith user. The minimum Euclidean distance dmin among all code
matrices in So is defined as
dmin(H) = min
So 6=Sâ€²oâˆˆSo
â€–H (So âˆ’ S â€²o)â€– ,
which is dependent upon H . Given the received signal matrix Y = HSo + W , the bounded dis-
tance decoder outputs SË†o âˆˆ So if
âˆ¥âˆ¥âˆ¥Y âˆ’HSË†oâˆ¥âˆ¥âˆ¥ < dmin(H)2 , and declares a decoding failure otherwise.
Thus, only the received signal matrices that are within distance dmin(H)
2
from the original transmit-
ted overall code matrix can be correctly decoded in the bounded distance decoder. Other received
signal matrices would result in either a decoding error (i.e., decoding into an erroneous code ma-
trix) or a decoding failure (i.e., cannot find a code matrix within distance dmin(H)
2
). Though this
decoder is suboptimal compared to the ML decoder, its error performance can be mathematically
analyzed.
The error performance analysis following this outline will be given in Chapter 6.3. Finally, in
Chapter 6.6 we briefly discuss the proof for the case of even K.
39
By repeatedly using the arithmetic mean-geometric mean inequality and (6.7) as in [4,6] for
k = 1, 2, Â· Â· Â· , Qm, we have
d2E(So, S
â€²
o) (6.8)
â‰¥ Îº2
Qmâˆ‘
i=Qmâˆ’k+1
Î»
(m)
1,i `1,mntâˆ’Qm+i
â‰¥Ë™ Îº2
[
Qmâˆ
i=Qmâˆ’k+1
Î»
(m)
1,i
] 1
k
Ã—
[
Qmâˆ
i=Qmâˆ’k+1
`1,mntâˆ’Qm+i
] 1
k
â‰¥Ë™ Îº2
[
Qmâˆ
i=Qmâˆ’k+1
Î»
(m)
1,i
] 1
k
[
mntâˆ’kâˆ
i=1
`1,i
]âˆ’ 1
k
(6.9)
â‰¥Ë™ Îº2
[
Qmâˆ
i=Qmâˆ’k+1
Î»
(m)
1,i
] 1
k
[
mntâˆ’kâˆ‘
i=1
`1,i
]âˆ’mntâˆ’k
k
â‰¥Ë™ Îº2
[
Qmâˆ
i=Qmâˆ’k+1
Î»
(m)
1,i
] 1
k
â€–Cs âˆ’ C â€²sâ€–âˆ’
mntâˆ’k
k
F
â‰¥Ë™ SNR1âˆ’ rnt
[
Qmâˆ
i=Qmâˆ’k+1
Î»
(m)
1,i
] 1
k
SNRâˆ’
r
nt
mntâˆ’k
k
:= d
(m)
1,k (Î±
(m)
1 ) = SNR
Î´
(m)
1,k (Î±
(m)
1 ), (6.10)
where (6.9) follows from (6.7) and where in (6.10) we have set
Î»
(m)
1,i = SNR
âˆ’Î±(m)1,i ,
Î±
(m)
1 =
[
Î±
(m)
1,1 Â· Â· Â·Î±(m)1,Qm
]>
.
Hence the SNR exponent of d2E(So, S
â€²
o) is lower bounded by
Î´
(m)
1,k (Î±
(m)
1 ) :=
1
k
[
Qmâˆ‘
i=Qmâˆ’k+1
(
1âˆ’ Î±(m)1,i
)]
âˆ’ rm
k
. (6.11)
2. The second case corresponds to event En (Im) which means x` 6= xâ€²` for ` âˆˆ Im = {i0, Â· Â· Â· , imâˆ’1},
xi = x
â€²
i otherwise, and rank (Co âˆ’ C â€²o) = nnt < mnt. In other words, the m nonzero rows{[
(x` âˆ’ xâ€²`) Â· Â· Â· Ï„Koâˆ’1o (x` âˆ’ xâ€²`)
]
: ` âˆˆ Im
}
are not linearly independent over Do. From Property 2 we can assume without loss of gen-
erality that {[
(x` âˆ’ xâ€²`) Â· Â· Â· Ï„Koâˆ’1o (x` âˆ’ xâ€²`)
]
: ` = i0, Â· Â· Â· , inâˆ’1
}
are linearly independent for some n < m.
Let dx` := x` âˆ’ xâ€²` and let Cs and C â€²s be defined as in (3.23) with respect to the set
{i0, Â· Â· Â· , imâˆ’1}. Set âˆ†Cs = Cs âˆ’ C â€²s and âˆ†X` = Ïˆo(dx`). Property 2 in turn implies
41
Remark 8. We remark that (6.20) shows the last term is âˆ’ rn
k
, instead of being âˆ’ rm
k
as in (6.11).
For readers who may wonder why these two terms are different given both events concern the case
of m users in error, the major reason is due to the distance bounding techniques, i.e., the repeated
arithmetic mean-geometric mean inequalities, we have used in the above.
In general, when the equivalent channel matrix Heq of (6.15), and similarly when the channel
matrix Hs with n = m, has rank Qn, the rank of the product matrix Heqâˆ†X would be Qn since
âˆ†X is of full rank nnt. Thus our lower bound on the norm â€–Heqâˆ†Xâ€– would only capture the Qn
smaller eigenvalues of âˆ†Xâˆ†Xâ€ , which are all nonzero. Furthermore, one reason for introducing
the equivalent channel matrix Heq, rather than working withHs is that, algebraically speaking, the
norm â€–Hsâˆ†Csâ€– could be zero as âˆ†Cs is singular and all the rows of Hs could lie in the left-null
space of Cs. However, since Hs is random, this occurs with probability zero. In other words, if we
apply the series of arithmetic mean-geometric mean inequalities to the matrix product Hsâˆ†Cs, we
could end up with the trivial algebraic inequality
dE(So, S
â€²
o) â‰¥ min
Hs
â€–Hsâˆ†Csâ€– = 0,
even the right-hand-side has probability 0. Whether the above could happen depends on the rela-
tions among n, m, nt, and nr. While there is nothing wrong with the algebraic inequality itself,
this bound can actually be further tightened by introducing the equivalent channel Heq so that we
can focus on error events that have probability larger than zero. 
Remark 9. Another heuristic way to see why the last term of Î´(m,n)2,k equals âˆ’ rnk follows from the
base-alphabet A(SNR) defined in Chapter 3.1. Recall that in the construction of (nnt Ã— T ) CDA-
based ST code for point-to-point channel [4, 6], to achieve the DMT optimality therein we would
set the base-alphabet as
Aâ€²(SNR) =
{
a+ b Ä± :
âˆ’SNR r2nnt â‰¤ a, b â‰¤ SNR r2nnt ,
a, b âˆˆ Z, a, b odd
}
such that the resulting exponent equals
Î´
â€²(m,n)
2,k (Î±
(m,n)
2 ) :=
1
k
[
Qnâˆ‘
i=Qnâˆ’k+1
(
1âˆ’ Î±(m,n)2,i
)]
âˆ’ r
k
;
then along the same lines as in [4, 6] one can prove such code is approximately universal and
achieves diversity gain dâˆ—nnt,nr(r). However, it is because we set the base-alphabet as A(SNR),
which has size
|A(SNR)| = |Aâ€²(SNR)|n ,
meaning an n-fold increase in the multiplexing gain, we expect the error probability associated
with event En(Im) has diversity gain dâˆ—nnt,nr(nr). 
6.3 Upper Bounds on Codeword Error Probability
Having obtained the squared minimum Euclidean distances d(m)1,k (Î±
(m)
1 ) among the signal matrices
associated with error event Em(Im), and d(m,n)2,k (Î±(m,n)2 ) among the signal matrices associated with
error event En(Im), below we proceed to analyze the error performance of the proposed construc-
tion. The analysis resembles the sphere bounding technique used in [4, 6] which is essentially
a bounded-distance decoding technique. That is, the bounded-distance decoder declares an error
only when the noise has norm larger than half of the minimum Euclidean distance. Clearly, the
43
Remark 10. One can regard the probability(
Ko
m
)
Pr
{
H : Î´
(m)
1,k (Î±
(m)
1 ) â‰¤ 0, 1 â‰¤ k â‰¤ Qm
}
as a further upper bound on the union bound
âˆ‘
Im Pr {Em (Im)} in (6.3), and the second type of
probability (
Ko
m
)mâˆ’1âˆ‘
n=1
(
m
n
)
Pr
{
H : Î´
(m,n)
2,k (Î±
(m,n)
2 ), 1 â‰¤ k â‰¤ Qn
}
(6.23)
as an upper bound on
âˆ‘
Im
âˆ‘
n<m Pr {En (Im)}. Furthermore, the event Em of m users in error
has probability upper bounded by
Pr {Em} â‰¤
âˆ‘
Im
âˆ‘
nâ‰¤m
Pr {En (Im)}
â‰¤
(
Ko
m
)[
Pr
{
H : Î´
(m)
1,k (Î±
(m)
1 ) â‰¤ 0, 1 â‰¤ k â‰¤ Qm
}
+
mâˆ’1âˆ‘
n=1
(
m
n
)
Pr
{
H : Î´
(m,n)
2,k (Î±
(m,n)
2 ), 1 â‰¤ k â‰¤ Qn
}]
. (6.24)
It should be noted that in (6.23) we have over-estimated the number of choices of n Do-linearly
independent rows out of m nonzero rows in the difference matrix [Ï„ jo (xi âˆ’ xâ€²i)]Koâˆ’1i=0 Koâˆ’1j=0 that can
happen in the event En (Im). 
Even with this over-estimate, noting(
Ko
m
)
,
(
m
n
)
.
= 1
for all m,n within the range of interest, we can rewrite (6.22) as
Pcwe(r) â‰¤Ë™ max
m
Pr
{
H : max
k
Î´
(m)
1,k (Î±
(m)
1 ) â‰¤ 0
}
+
max
n<m
Pr
{
H : max
k
Î´
(m,n)
2,k (Î±
(m,n)
2 ) â‰¤ 0
}
.
(6.25)
Below we investigate the diversity orders of each term in (6.25).
6.4 Diversity Gain of the First Case
For each m, 1 â‰¤ m â‰¤ K0, we have
Pr
{
H : max
k
Î´
(m)
1,k (Î±
(m)
1 ) â‰¤ 0
}
= Pr
{
H :
1
k
[âˆ‘Qm
i=Qmâˆ’k+1
(
1âˆ’ Î±(m)1,i
)]
âˆ’ rm
k
â‰¤ 0,
all k, and Î±(m)1,1 â‰¥ Î±(m)1,2 Â· Â· Â· â‰¥ Î±(m)1,Qm
}
= Pr
{
H :
Qmâˆ‘
i=1
(
1âˆ’ Î±(m)1,i
)+
â‰¤ rm
}
(6.26)
= Pr
{
H : log det
(
Inr + SNRHsH
â€ 
s
) â‰¤ rm log SNR}
.
= SNRâˆ’d
âˆ—
mnt,nr
(rm), (6.27)
45
for error events Em(Im), m = 1, 2, Â· Â· Â· , K, and
Pr {En(Im)} â‰¤ Pr
{
H : max
k
Î´
(m,n)
2,k (Î±
(m,n)
2 ) â‰¤ 0
}
.
= SNRâˆ’d
âˆ—
nnt,nr
(nr)
for 1 â‰¤ n < m. This is exactly what is shown in Theorem 3. Furthermore, in the event Em of m
users in error, the proposed code So has error probability
Pr {Em} â‰¤
mâˆ‘
n=1
Pr {En(Im)}
â‰¤Ë™ max
{
SNRâˆ’d
âˆ—
nt,nr
(r),SNRâˆ’d
âˆ—
mnt,nr
(mr)
}
.

6.6 Proof Outline for K Even
The proof of Theorem 7 can be adapted to cater to the case when the number of users K is even.
Here we discuss only briefly what the changes are. Firstly, with
H =
[
H0 Â· Â· Â· HKâˆ’1 0
]
in mind, i.e., HKoâˆ’1 = 0, the result (6.5) of the squared Euclidean distance between So and S â€²o
remains to hold. Similarly, the further lower bounds on d2E(So, S
â€²
o) in (6.11) and (6.20) stay without
changes except that one should keep the following in mind.
1. The parameter m of the first case, where rank(Co âˆ’ C â€²o) = mnt, and m out of Ko xiâ€™s are
distinct, has value from 1 up to Koâˆ’1 = K. This is because HKoâˆ’1 = 0, and we can always
assume xKoâˆ’1 = xâ€²Koâˆ’1 without affecting the value of d
2
E(So, S
â€²
o). Thus the diversity gain
resulting from the first case is
min
1â‰¤mâ‰¤K
dâˆ—mnt,nr (mr) .
Compared with the case of odd K, (6.27) has m up to Ko.
2. The parameters m and n in the second case can be argued similarly as the above, and we
have 1 â‰¤ n < m â‰¤ Ko âˆ’ 1 = K. Hence the diversity gain of this case is
min
1â‰¤nâ‰¤Kâˆ’1
dâˆ—nnt,nr (nr) .
Overall, it shows the MAC-DMT optimality of the proposed construction remains to hold.
47
Then the minimum squared Euclidean distance between Ss and S â€²s is bounded by
d2E(Ss, S
â€²
s) â‰¥
Q
(m)
Imâˆ‘
i=Q
(m)
Im âˆ’k+1
Î»
(m)
1,i `1,mnmaxâˆ’Q(m)Im +i
â‰¥Ë™
ï£®ï£¯ï£° Q
(m)
Imâˆ
i=Q
(m)
Im âˆ’k+1
Î»
(m)
1,i
ï£¹ï£ºï£»
1
k
Ã—
SNR
mnmaxâˆ’
âˆ‘m
j=1 rij
k â€–Ss âˆ’ S â€²sâ€–âˆ’
mnmaxâˆ’k
k
F
(7.1)
â‰¥Ë™ SNRÎ´(m)1,k (Î±(m)1 ), (7.2)
where
Î´
(m)
1,k (Î±
(m)
1 ) =
1
k
ï£®ï£¯ï£° Q
(m)
Imâˆ‘
j=Q
(m)
Im âˆ’k+1
(
1âˆ’ Î±(m)1,j
)
âˆ’
mâˆ‘
j=1
rij
ï£¹ï£ºï£» (7.3)
for k = 1, Â· Â· Â· , Q(m)Im , and where
Î±
(m)
1,j = âˆ’
log Î»
(m)
1,i
log SNR
. (7.4)
(7.1) follows from Property 6 that
mnmaxâˆ
j=1
`1,1 â‰¥Ë™ SNRmnmaxâˆ’
âˆ‘m
j=1 rij
and (7.2) from Property 5 that
mnmaxâˆ‘
j=1
`1,1 â‰¤Ë™ SNR.
Now we see that
Pr {Em(Im)}
â‰¤Ë™ Pr
{
HËœs : Î´
(m)
1,k (Î±
(m)
1 ) < 0, all k
}
.
= Pr
{
log det
(
Inr + SNRHËœsHËœ
â€ 
s
)
â‰¤
mâˆ’1âˆ‘
j=0
rij log SNR
}
.
= SNRâˆ’d
âˆ—
Nt(Im),nr(
âˆ‘
iâˆˆIm ri). (7.5)
Similarly, techniques used in Chapters 6.2 and 6.5 can be modified accordingly to show
Pr {En(Im)} â‰¤Ë™ SNR
âˆ’dâˆ—âˆ‘nâˆ’1
i=0
ni,nr
(
âˆ‘nâˆ’1
i=0 ri)
. (7.6)
Combining the above results completes the proof of MAC-DMT optimality of the proposed con-
struction.
Corollary 15. Given ni and ri, i = 0, 1, Â· Â· Â· , K âˆ’ 1 with K odd, the proposed code S defined in
(4.15) achieves the general individual MAC-DMT of the ith user
d
(i)âˆ—
{n0,Â·Â·Â· ,nKâˆ’1},nr(r0, Â· Â· Â· , rKâˆ’1) = minI:iâˆˆI d
âˆ—
Nt(I),nr
(âˆ‘
iâˆˆI
ri
)
,
49
Chapter 8
DMT Performance of A Simple Code
For simplicity, we will first present the code for use in a MIMO-MAC channel. For point-to-point
MIMO channels, the same code can be easily modified and will be discussed later in the next
section.
Consider a MIMO-MAC channel with K = 2 users, each having nt = 1 transmit antenna and
transmitting at multiplexing gain r. Assume there are nr = 2 receive antennas at receiving end.
The code to be analyzed is the following:
S =
{
S = Îº
[
s11 s12
s21 s22
]
: sij âˆˆ A(SNR)
}
(8.1)
where
A(SNR) = {a+ b Ä± : |a|, |b| â‰¤ SNR r2 , a, b odd} , (8.2)
Ä± =
âˆšâˆ’1, and where
Îº2
.
= SNR1âˆ’r. (8.3)
Entries sij are independently drawn from the QAM set A(SNR). During transmission, the first
user transmits the first row of S while the second user sends the second row. Clearly, the two users
do not cooperate. Given S âˆˆ S, the received signal matrix is
Y = HS +W, (8.4)
whereH = [h1h2] is the overall (2Ã—2) channel matrix whose entries are modeled as i.i.d. complex
Gaussian random variables CN (0, 1) and where W is the (2 Ã— 2) noise matrix. hi is the channel
vector associated with the ith user. We assume H is known to the receiver but is unknown to either
of the users.
Obviously, the code S of (8.1) is uncoded since the entries are just plain QAM symbols with
some scaling factor Îº that is chosen to satisfy the power constraint E |Îºsij|2 â‰¤Ë™ SNR. Nevertheless,
below we will show that this uncoded scheme S achieves the optimal MAC-DMT (cf. (1.6))
dâˆ—1,2,2(r) = min
{
dâˆ—1,2(r), d
âˆ—
2,2(2r)
}
over the two-user MIMO-MAC channel.
To prove the claim, we will partition the error event E into several subevents E1, Â· Â· Â· , En for
some n, and analyze the probability of each. Then we will apply the union bound
Pr
{
E =
nâ‹ƒ
i=1
Ei
}
â‰¤
nâˆ‘
i=1
Pr {Ei}
to establish the claim. Although during the analysis some subevents can be combined, in order
to be extra cautious we will analyze separately the error probabilities of these events. Below we
distinguish five different kinds of error events.
51
8.3 Type-III Error Event
The third-type error event is the case when both users are in error but only the one of the two
transmissions is erroneously decoded. Again, without loss of generality, we focus on the case
when the first transmission is erroneously decoded, i.e. it is of the following form:
E3,1 :=
{
S âˆ’ S â€² = Îº
[
d11 0
d21 0
]
: 0 6= di1 = si1 âˆ’ sâ€²i1
}
. (8.8)
and we have Pr {E3} â‰¤ 2 Pr {E3,1}.
We remark that in this case the difference matrix âˆ†S = Sâˆ’S â€² is of rank 1 and does not satisfy
the full NVD criterion given in [16] (cf. (1.8)). Furthermore, if one applies the conventional
mismatched bound on product of eigenvalues [38], which is subsequently used as a key ingredient
for proving the DMT optimality of CDA-based codes [4], the resulting bound on the DMT of
present event E3,1 would be too loose to become any useful. Thus, below we will use a novel
technique to analyze the DMT performance of this case.
Let s1 = [s11 s21]
>, sâ€²1 = [s
â€²
11 s
â€²
21]
>, si1 6= sâ€²i1 âˆˆ A(SNR), where by a> we mean the usual
transpose of vector a. Set d1 = s1 âˆ’ sâ€²1. Then from the pairwise error probability analysis [1, 24],
the probability of erroneously decoding s1 as s
â€²
1 is given by
Pr {s1 â†’ sâ€²1} .=
[
1 + Îº2 â€–d1â€–2
]âˆ’2
. (8.9)
Fixing s1, we see that the number of s
â€²
1 such that â€–d1â€–2 â‰¤Ë™SNRz for some 0 â‰¤ z â‰¤ r can be upper
bounded by âˆ£âˆ£âˆ£{sâ€²1 : â€–s1 âˆ’ sâ€²1â€–2 â‰¤Ë™ SNRz}âˆ£âˆ£âˆ£ â‰¤ SNR2z (8.10)
due to the choice of A(SNR). The exponent 2z comes from the independent choices of sâ€²11 and
sâ€²21. Now from the union bound we see
Pr {E3,1} â‰¤
âˆ‘
sâ€²1:E3
Pr {s1 â†’ sâ€²1}
.
= sup
0â‰¤zâ‰¤r
[
1 + Îº2SNRz
]âˆ’2 SNR2z
.
= Îºâˆ’4 = SNRâˆ’(2âˆ’2r)
+
= SNRâˆ’d
âˆ—
1,2(r).
Thus we conclude that the diversity gain achieved by S in E3 equals dâˆ—1,2(r).
8.4 Type-IV Error Event
The fourth error event concerns the case when the messages from both users are erroneously de-
coded in both transmissions, but the difference matrix has only rank 1. That is, E4 can be formulated
as
E4 :=
{
S âˆ’ S â€² = Îº
[
d11 d12
d21 d22
]
:
0 6= dij = sij âˆ’ sâ€²ij,
rank(S âˆ’ S â€²) = 1
}
. (8.11)
The conditions of dij 6= 0 for all i, j = 1, 2 and rank(S âˆ’ S â€²) = 1 distinguish this case from the
remaining one, the type-V error event, the case when rank(S âˆ’ S â€²) = 2. Specifically, if dij = 0
for only one pair of i and j, then the difference matrix would have rank equal to 2. The same also
applies to the cases of d12 = d21 = 0 or d11 = d22 = 0. On the other hand, if d11 = d21 = 0 then it
is equivalent to E3. Similarly, the case of d11 = d12 = 0 reduces to type-II.
Analyzing the probability of E4 might be the most troublesome as neither the weighted pairwise
error probability technique used in analyzing type-II nor the conventional techniques [4] used for
53
8.6 Further Extension
In this chapter, we have answered all the four open questions posed in Chapter 1.3. We showed
it is possible to achieve the optimal MAC-DMT with T < Knt + nr âˆ’ 1, and previously known
full NVD design criterion for MAC-DMT optimal codes [16] is only sufficient. A simple code
not satisfying this full NVD criterion is provided, and we proved it is still MAC-DMT optimal. In
view of this, we have provided an alternative, yet much more relaxed, criterion for constructing
MAC-DMT optimal codes. This simple code is also modified for use in point-to-point MIMO
channels. We showed the modified code is optimal in DMT in the sense that it achieves the same
DMT performance as the Gaussian random coding schemes.
Below we state without proof a generalization of the results in this report.
Theorem 17. Consider a MIMO-MAC channel with n users, each having nt = 1 transmit antenna
and transmitting at multiplexing gain r. Assume there are n receive antennas at receiver. Then the
following overall code
Sn =
ï£±ï£´ï£²ï£´ï£³Îº
ï£®ï£¯ï£° s11 Â· Â· Â· s1n... . . . ...
sn1 Â· Â· Â· snn
ï£¹ï£ºï£» : sij âˆˆ A(SNR)
ï£¼ï£´ï£½ï£´ï£¾
achieves the optimal MAC-DMT dâˆ—1,n,n(r) with T = n channel uses, where Îº and A(SNR) are
defined as before (cf. Chapter 8). Furthermore, the same result holds for the vector code Sn,vec
obtained by taking the first column of code matrices in Sn. Hence dâˆ—1,n,n(r) holds for T = nt = 1
as well. Finally, by setting the multiplexing gain at r
n
in Sn,vec the resulting code achieves DMT
d(r) = n âˆ’ r in the point-to-point MIMO channel with nt = nr = n and T = 1. It is the same
DMT performance achieved by Gaussian random coding schemes. 
55
channel uses. The requirement on T was improved by the simple code S analyzed in Chapter 8. We
proved that S achieves the same MAC-DMT optimality with only T = 2 channel uses, and hence
improves the result on minimal channel coherence time required by Theorem 1. In particular, we
note that in this specific channel we actually have
dâˆ—1,2(r) â‰¤ dâˆ—2,2(2r), for all 0 â‰¤ r â‰¤ 1.
In other words, the single-user performance dominates the entire region of r âˆˆ [0, 1], and there is
no region of antenna-pooling [11] in this case.
From the analyses presented in the previous section, we can further strengthen the MAC-DMT
result to the following. The vector code
Svec =
{
Îº
[
s1
s2
]
: si âˆˆ A(SNR)
}
(9.2)
that is a subcode of S given in Chapter 8 and is obtained by taking only the first column of code
matrices in S, is in fact MAC-DMT optimal. To see this, from the error events E1 and E3, the error
probability of Svec is
Pr {E (Svec)} â‰¤ Pr {E1}+ Pr {E3} â‰¤Ë™SNRâˆ’(2âˆ’2r)+ . (9.3)
It then implies that the MAC-DMT dâˆ—1,2,2(r) holds even for fast fading channel, i.e. the case when
T = 1. This answers the first question posed in Chapter 1.3.
9.3 Point-to-Point MIMO Channel
The vector code Svec of (9.2) can be easily modified for use in a point-to-point MIMO channel. To
this end, let
ASU(SNR) =
{
a+ b Ä± : |a|, |b| â‰¤ SNR r4 , a, b odd} (9.4)
and set
SSU =
{
ÎºSU
[
s1
s2
]
: si âˆˆ ASU(SNR)
}
(9.5)
where Îº2SU = SNR
1âˆ’ r
2 . In other words, SSU can be obtained from Svec when both users transmit at
multiplexing gain r
2
such that the overall multiplexing gain achieved by SSU equals r. Because of
this, the error probability of SSU is upper bounded by
Pr {E (SSU)} â‰¤ SNRâˆ’(2âˆ’r)+ , (9.6)
and the diversity gain equals d(r) = 2 âˆ’ r for r âˆˆ [0, 2]. The maximal multiplexing gain rmax =
2, same as that indicated by the ergodic channel capacity [9, 23] of this channel. However, the
resulting DMT is only d(r) = 2âˆ’r, much worse than the optimal DMT dâˆ—2,2(r). It is understandable
since the latter requires the channel to be fixed for at least two channel uses, while the former
changes from one channel use to another, and there is no coding across independent channel uses.
The maximal diversity gain dmax achieves by SSU is given by d(0) = 2, which is the same
for any such vector codes. This can be easily seen from the pairwise error probability argument.
Taking any fixed vector coding schemes that do not vary with SNR, the resulting multiplexing gain
equals 0 and the maximal possible rank distance between any pairs of distinct code vectors equals
1. Hence the resulting diversity order is 2 since there are two receive antennas. Therefore, we
conclude that for T < nt the maximal diversity order is nrT , and the resulting DMT can never be
the same as the optimal one dâˆ—nt,nr(r), where the maximal diversity order equals ntnr. Furthermore,
it means that the outage event does not dominate the error performance when T < nt. These
answer the fourth question posed in Chapter 1.3.
While the code SSU is not optimal in terms of dâˆ—2,2(r), in [9] Zheng and Tse proved the following
result.
57
Bibliography
[1] V. Tarokh, N. Seshadri, and A. R. Calderbank, â€œSpace-time codes for high data rate wire-
less communication: performance criterion and code construction,â€ IEEE Trans. Inf. Theory,
vol. 44, pp. 744â€“765, Mar. 1998.
[2] S. M. Alamouti, â€œA simple transmitter diversity scheme for wireless communications,â€ pp.
1451â€“1458, Oct. 1998.
[3] F. Oggier, G. Rekaya, J.-C. Belfiore, and E. Viterbo, â€œPerfect space time block codes,â€ IEEE
Trans. Inf. Theory, vol. 52, no. 9, pp. 3885â€“ 3902, Sep. 2006.
[4] P. Elia, K. R. Kumar, S. A. Pawar, P. V. Kumar, and H.-F. Lu, â€œExplicit construction of
space-time block codes achieving the diversity-multiplexing gain tradeoff,â€ IEEE Trans. Inf.
Theory, vol. 52, no. 9, pp. 3869â€“3884, Sep. 2006.
[5] P. Elia, B. A. Sethuraman, and P. V. Kumar, â€œPerfect space-time codes for any number of
antennas,â€ IEEE Trans. Inf. Theory, vol. 52, no. 11, pp. 3853 â€“ 3868, Nov. 2007.
[6] H. F. Lu, â€œExplicit constructions of multi-block space-time codes that achieve the diversity-
multiplexing tradeoff,â€ IEEE Trans. Inf. Theory, vol. 54, no. 8, pp. 3790â€“3796, Aug. 2008.
[7] R. Vehkalahti, C. Hollanti, J. Lahtonen, and K. Ranto, â€œOn the densest MIMO lattices from
cyclic division algebras,â€ IEEE Trans. Inf. Theory, vol. 55, no. 8, pp. 3751â€“3780, Aug. 2009.
[8] B. Hassibi and M. Hochwald, â€œHigh-rate codes that are linear in space and time,â€ IEEE Trans.
Inf. Theory, vol. 48, no. 7, pp. 1804â€“1824, Jul. 2002.
[9] L. Zheng and D. Tse, â€œDiversity and multiplexing: a fundamental tradeoff in multiple antenna
channels,â€ IEEE Trans. Inf. Theory, vol. 49, no. 5, pp. 1073â€“1096, May 2003.
[10] S. Tavildar and P. Viswanath, â€œApproximately universal codes over slow fading channels,â€
IEEE Trans. Inf. Theory, vol. 52, no. 7, pp. 3233â€“ 3258, Jul. 2006.
[11] D. N. C. Tse, P. Viswanath, and L. Zheng, â€œDiversity-multiplexing tradeoff in multiple-access
channels,â€ IEEE Trans. Inf. Theory, vol. 50, no. 9, pp. 1859â€“1874, Sep. 2004.
[12] Y. Nam and H. El Gamal, â€œOn the optimality of lattice coding and decoding in multiple access
channels,â€ in Proc. 2007 IEEE Int. Symp. Inform. Theory, Nice, France, Jun. 2007.
[13] M. GaÂ¨rtner and H. BoÂ¨lcskei, â€œMultiuser space-time/frequency code design,â€ in Proc. 2006
IEEE Int. Symp. Inform. Theory, Seattle, WA, Jul. 2006, pp. 2819 â€“ 2823.
[14] M. Badr and J. C. Belfiore, â€œDistributed space-time block codes for the non cooperative
multiple access channel,â€ in Proc. IEEE Int. Zurich Seminar on Commun., Zurich, Mar. 12-
14 2008, pp. 132 â€“ 135.
59
[32] S. Lin and D. J. Costello, Jr., Error Control Coding, 2nd ed. Englewood Cliffs, NJ: Prentice
Hall, 2004.
[33] P. Elia and P. V. Kumar, â€œApproximately-universal space-time codes for the parallel, multi-
block and cooperative-dynamic-decode-and-forward channels,â€ in Proc. 2009 IEEE Int.
Symp. on Information Theory, Seoul, Korea, Jul. 2009, pp. 2813â€“2817.
[34] H. F. Lu, â€œConstructions of multi-block space-time coding schemes that achieve the diversity
mulplexing tradeoff,â€ in Proc. 2006 IEEE Int. Symp. Inform. Theory, Seattle, WA, Jun. 2006,
pp. 1149â€“1153.
[35] S. Yang and J.-C. Belfiore, â€œOptimal space-time codes for the amplify-and-forward coopera-
tive channel,â€ in Proc. 43nd Allerton Conference on Communication, Control and Computing,
Monticello, Illinois, Sep. 2005.
[36] L. Zhao, W. Mo, Y. Ma, and Z. Wang, â€œDiversity and multiplexing tradeoff in general fading
channels,â€ IEEE Trans. Inf. Theory, vol. 53, no. 4, pp. 1549â€“1557, Apr. 2007.
[37] K. R. Kumar and G. Caire, â€œOutage analysis and code design for correlated MIMO fading
channels,â€ in Proc. 2007 IEEE Int. Symp. on Information Theory, Nice, France, Jun. 24 - Jun.
29 2007, pp. 2276â€“2280.
[38] C. KoÂ¨se and R. D. Wesel, â€œUniversal space-time trellis codes,â€ IEEE Trans. Inf. Theory,
vol. 49, no. 10, pp. 2717â€“2727, Oct. 2003.
61
me that I would get it back two days later.  
After taking a short rest and cleaning myself, I headed directly to the welcome reception. Several 
of my colleagues, Prof Yu-Ted Su, Prof. Po-ning Chen, Prof Chun-Chin Lu, and of course, Prof. 
Stefan Moser, all at some point showed up in the reception room. Many of my friends were there 
too, including my former advisor Prof. Vijay Kumar and his wife, Prof. Raymond Yeung, Prof. 
Petros Elia, my long-time collaborator Dr. Roope Vehkalahti, etc. Most importantly, I had a good 
chance to have a long discussion with Prof. Li-zhong Zheng from MIT. We had exchanged many 
opinions regarding recent developments in the field of MIMO communications and coding. He 
also shared with me the current situation of the US job market. It was extremely difficult for a 
fresh Ph.D. to find a teaching position in the US, he said. He also mentioned that he had a very 
good Ph.D. student who was originally from Taiwan and might consider going back to his home 
country after his graduation. I concurred with him in this. 
I have two papers published in this conference, one titled â€œImproving the DMT Performances of 
MIMO Linear Receivers,â€ which is scheduled for presentation on Tuesday afternoon. The 
second paper, titled â€œAn algebraic look into MAC-DMT of lattice space-time codes,â€ which is 
a joint work with Dr. Roope Vehkalahti, and is scheduled on Friday for presentation. The 
former paper is a joint work with my two students, Mr. Ti-Wen Tang and Mr. Min-Kun Chen. 
Mr. Tang is my Ph.D. student, and I thought this would be a good chance for him to present his 
work in front of all the renowned scholars at an international conference. So I had asked him to 
come to the ISIT conference and present the paper. The work by itself is fantastic and impacts 
significantly on many areas in MIMO communications; it pointed out a serious mistake in the 
performance analysis of MIMO linear receivers, and unfortunately this mistaken result has 
been applied to hundreds of research works. But it is never too late to correct. We showed that 
the performance of MIMO linear receiver was greatly underestimated in the previous work and 
a much better performance can indeed be achieved without any complexity increase. Several 
renowned, leading researchers already heard of our work after submission and greatly 
appreciated it. Others, who did not know it, were astounded.  
The second paper, though was not a complete work at the time, addressed a subject of great 
importance in both coding theory and advanced mathematics. It is related to a long-open problem 
that extends the famous Dirichlet unit theorem to Lie algebra. With great success, we were able to 
answer many details in this problem. However, as the problem itself is too deep in mathematics, 
only very few audiences could understand our work.  
During the conference time, I attended many interesting talks, including recent works on polar 
codes, MIMO coding, and one of my favorite subject, combinatorics. One of the talk in particular, 
is about counting the number of 0/1 orthogonal matrices and the results were fascinating.  
The conference organization committee was very kind to provide several tours so that we could 
have a good look at St. Petersburg. I took several of these tours. Together with Prof. Raymond 
Yeung, Prof. Ying Li, and Prof Po-ning Chen, we joined the city tour and visited the St. Petersburg 
harbor. Later, with Prof. Shu Lin and his wife and also Dr. Tom Richardson, who is the vice 
president of engineering at Qualcomm, we went to the winter palace museum. There we saw many 
breathtaking paintings and collections exhibited at the winter palace.  
here. They simply came to socialize and establish their connection. Perhaps we could do the 
same.  
r!\> a= 
A complete conference proceeding and CD-ROM. 
 
+ 
IMPORTANT INFORMATION FOR AUTHORS:
* Authors' registration:
In order to be included in the final program and the
proceedings, at least one author must register to ISIT2011 for
each  accepted paper (with a maximum of three papers
registered  by  the  same  author).  The  deadline  for  such
registration is also  May 31, 2011.  At this moment the
registration website (to appear at www.isit2011.org) is not
open; we will send a follow up email when it is open. 
**Accepted papers with  no registered authors will  not be
included  in the final program and the proceedings**. In order
to link  your registration form to a paper, please use the 
following five-digit  PAPER IDENTIFIER NUMBER for this
paper:  {paper5}.  You have to report this number in the
registration form.
* IEEE Copyright form:
An IEEE copyright  form  must be  provided  for each 
accepted paper. Papers without  copyright form **will not be 
included** in the final program and the proceedings.   Those 
forms may be filled out electronically via the IEEE e-copyright
system when the final version of the paper is submitted.
See details in the instructions for final manuscripts.
*****************************************************************
The reviews are attached below or can be found at
http://edas.info/showPaper.php?m=1569410743.
We look forward to seeing you in St. Petersburg
Our Best Regards,
* Authors' registration:
In order to be included in the final program and the
proceedings, at least one author must register to ISIT2011 for
each  accepted paper (with a maximum of three papers
registered  by  the  same  author).  The  deadline  for  such
registration is also  May 31, 2011.  At this moment the
registration website (to appear at www.isit2011.org) is not
open; we will send a follow up email when it is open. 
**Accepted papers with  no registered authors will  not be
included  in the final program and the proceedings**. In order
to link  your registration form to a paper, please use the 
following five-digit  PAPER IDENTIFIER NUMBER for this
paper:  {paper5}.  You have to report this number in the
registration form.
* IEEE Copyright form:
An IEEE copyright  form  must be  provided  for each 
accepted paper. Papers without  copyright form **will not be 
included** in the final program and the proceedings.   Those 
forms may be filled out electronically via the IEEE e-copyright
system when the final version of the paper is submitted.
See details in the instructions for final manuscripts.
*****************************************************************
The reviews are attached below or can be found at
http://edas.info/showPaper.php?m=1569420213.
We look forward to seeing you in St. Petersburg
Our Best Regards,
ISIT2011 TPC Chairs
the rank of the covariance matrix of the colored Gaussian input
and allowing temporal coding, the linear receiver can achieve
the maximal possible diversity gain ntnr as r approaches 0.
This is much larger than all previously known results. Similar
improvements of DMT performance are also obtained for
r > 0 through our approach.
Notation. Underlined lowercase letters x represent vectors
and uppercase letters A denote matrices. The (i, j) the entry
of matrix A is denoted by Ai,j . Aâ€  (resp. Aï¿¿) denotes the
Hermitian transpose (resp. transpose) of matrix A, and ï¿¿Aï¿¿
denotes the denotes the Frobenius norm of matrix A. In
is the (n Ã— n) identity matrix and 0n denotes the all-zero
(n Ã— n) matrix. Inequalities, denoted by ï¿¿, ï¿¿, ï¿¿ and â‰º,
represent partial orderings of positive semi-definite matrices.
x âˆ¼ CN (m,Kx) stands for a circularly symmetric complex
Gaussian random vector x with meanm and covariance matrix
Kx. f(x) and g(x) are said to be exponentially equal, denoted
by f(x) .= g(x), if limxâ†’âˆ
log f(x)
log x = limxâ†’âˆ
log g(x)
log x .
Eponential inequalities, indicated by â‰¤Ë™, â‰¥Ë™, <Ë™ and >Ë™, are
defined similarly.
II. IMPROVED DMT FOR LINEAR RECEIVERS
In this section we investigate the DMT performance of lin-
ear receivers with general colored Gaussian input. For brevity,
we will restrict ourselves to the MMSE receiver while our
techniques can be directly applied to ZF receivers and all the
results will hold the same. For simplicity, in Section II-A we
will first focus on the DMT analysis of linear receiver under
single channel use. It will be shown that even in this case,
by varying the rank of the covariance matrix, the resulting
maximal diversity gain can already be increased to the value
of nr, compared to the original value of (nr âˆ’ nt + 1) given
in [4], [5]. In Section II-B we will extend the results to the
case of multiple channel uses with temporal coding allowed.
A. DMT of Linear Receiver under Single Channel Use
Consider an (nt Ã— nr) MIMO channel with the following
channel input-output relation
y =
âˆš
SNRHx+ w (1)
where x âˆ¼ CN (0,Kx) is the transmitted code vector with
Tr(Kx) â‰¤ 1. H is the (nr Ã— nt) channel matrix with i.i.d.
CN (0, 1) entries and is assumed to be known to the receiver,
but not the transmitter. w âˆ¼ CN (0, Inr ) is the additive
complex Gaussian noise. We assume nt â‰¤ nr throughout.
LetKx = UxÎ›xU â€ x be the eigen-decomposition ofKx. Note
that H and HUx share the same statistical distribution. We can
without loss of generality reformulate (1) as
y =
âˆš
SNRHUxUâ€ xx+ w =
âˆš
SNRHËœxËœ+ w
where xËœ = Uâ€ xx and HËœ = HUx. It should be noted that
xËœ âˆ¼ CN (0,Î›x). Assume that Î›x has rank m â‰¤ nt and
that the first m diagonal entries of Î›x are nonzero. Then the
transmitted code vector xËœ is statistically equivalent to
xËœ =
ï¿¿
s
0(ntâˆ’m)Ã—1
ï¿¿
where s âˆ¼ CN (0,Î›) and Î› = diag(Î»1, Â· Â· Â· ,Î»m) is the
(mÃ—m) diagonal matrix whose main diagonal consists of the
nonzero eigenvalues of Kx. Therefore, it suffices to reduce the
channel to the following
y =
âˆš
SNRHs s+ w, (2)
where Hs is the equivalent channel matrix of size (nr Ã—m)
and consists of the left-most m columns of HËœ . Knowing that
HËœ = HUx and H share the same statistical distribution, and
that Hs is an (nr Ã—m) channel matrix with i.i.d. CN (0, 1)
entries, (2) can be regarded as an (mÃ—nr)MIMO channel with
channel matrix Hs and channel input s âˆ¼ CN (0,Î›) subject
to the constraints of Î› ï¿¿ 0m and Tr(Î›) â‰¤ 1. For Î› = 1mIm,
the following result is immediate from [5, Theorem 1].
Theorem 1: Given Î› = 1mIm, the DMT of (ntÃ—nr) i.i.d.
Rayleigh MIMO channel with m â‰¤ nt â‰¤ nr and multiplexing
gain r, using either linear MMSE or ZF receivers in single
channel use, is given by
dout,MMSE(r)
ï¿¿ï¿¿
Î›= 1m Im
= (nr âˆ’m+ 1)
ï¿¿
1âˆ’ r
m
ï¿¿+
. (3)
From the above theorem, it is clear that even in the case
of single channel use, the maximal diversity gain of either
MMSE or ZF linear receivers can be significantly improved
to nr by setting m = 1 and r = 0. The value is much larger
compared to the previously known (nr âˆ’ nt + 1) in [4], [5].
While Theorem 1 concerns only the case of Î› = 1mIm,
below we show a much stronger result that the same DMT (3)
holds for all Kx ï¿¿ 0nt , Tr(Kx) â‰¤ 1 and rank(Kx) = m.
Theorem 2: The DMT of the (nt Ã— nr) i.i.d. Rayleigh
MIMO channel with rank(Kx) = m â‰¤ nt â‰¤ nr and
multiplexing gain r, using either linear MMSE or ZF receivers
in single channel use, is given by
dout,MMSE(r)
ï¿¿ï¿¿
rank m = sup
Tr(Kx)â‰¤1,rank(Kx)=m
dout,MMSE(r)
ï¿¿ï¿¿
Kx
= (nr âˆ’m+ 1)
ï¿¿
1âˆ’ r
m
ï¿¿+
. (4)
By varying values of m, in Fig. 1, we show the best DMT
performance offered by Theorem 2. That is, for each r, we
find
max
1â‰¤mâ‰¤nt
(nr âˆ’m+ 1)
ï¿¿
1âˆ’ r
m
ï¿¿+
.
It can be clearly seen that the colored degenerate Gaussian
input can achieve a much larger DMT than that in [5] which
uses i.i.d. input.
To prove Theorem 2, recall that the filter response of linear
MMSE equalizer for (2) is
WMMSE =
âˆš
SNRÎ›Hâ€ s
ï¿¿
SNR Â·HsÎ›Hâ€ s + Inr
ï¿¿âˆ’1
=
âˆš
SNR
ï¿¿
SNR Â· Î›Hâ€ sHs + Im
ï¿¿âˆ’1
Î›Hâ€ s
and the output of MMSE equalizer is given by
yË† = WMMSE y = Gs+ n (5)
where the last exponential equality can be obtained from
arguments similar to [5, Theorem 1], and details are omitted
for brevity. Finally, combining (11) and (12) proves Theorem
2.
B. DMT of Linear Receiver with Temporal Coding Allowed
Having seen the significant improvement on the DMT
performance of linear receivers in single channel use in the
previous subsection, we now consider the case when the
(nt Ã— nr) MIMO channel is fixed for n channel uses so that
temporal coding can be applied across the multiple n channel
uses. Specifically, by temporal coding we mean the space-time
codes that have linear dispersion forms [3] so that the linear
receivers can be used to recover the transmitted message. In
this case, the channel input-output relation is given by
y
i
=
âˆš
SNRHxi + wi, i = 1, Â· Â· Â· , n
where xi satisfies E ï¿¿xiï¿¿2 â‰¤ 1.
By stacking the received signal vectors vertically, the above
channel can be reformulated as
y =
ï£®ï£¯ï£° y1...
y
n
ï£¹ï£ºï£» = âˆšSNR
ï£®ï£¯ï£° H . . .
H
ï£¹ï£ºï£»
ï¿¿ ï¿¿ï¿¿ ï¿¿
:=HËœ
x+ w (13)
where x =
ï¿¿
xï¿¿1 Â· Â· Â· xï¿¿n
ï¿¿ï¿¿ and w = ï¿¿wï¿¿1 Â· Â· Â· wï¿¿n ï¿¿ï¿¿. Let x
be a complex Gaussian random vector with x âˆ¼ CN (0,Kx)
with rank(Kx) = m and Tr(Kx) â‰¤ n. Since Kx is Hermitian
symmetric and non-negative definite, Kx can be decomposed
as Kx = UxÎ›U â€ x where Î› is a diagonal (m Ã— m) matrix
whose main diagonal consists of the nonzero eigenvalues of
Kx. Ux is an (nnt Ã—m) matrix satisfying Uâ€ xUx = Im. Then
the stacking channel (13) is statistically equivalent to
y =
âˆš
SNRHss+ w, (14)
where Hs = HËœUx and s âˆ¼ CN (0,Î›). It should be noted that
unlike the previous section, here Hs does not share the same
statistical distribution as H .
Following similar arguments as in the previous section,
it can be shown that with Î› = nmIm, the optimal outage
probability is upper bounded by
Pout,MMSE(r| rank m, n channel uses)
â‰¤ inf
UxâˆˆK
Pr
ï¿¿
Tr
ï¿¿ï¿¿ n
m
SNRHâ€ sHs + Im
ï¿¿âˆ’1ï¿¿
â‰¥ SNRâˆ’nrm
ï¿¿
,
(15)
where K = ï¿¿Ux âˆˆ CnntÃ—m : Uâ€ xUx = Imï¿¿. Furthermore,
from (15) we see that the outage upper bound does depend
upon the choice of â€œpre-codingâ€ matrix Ux. To analyze the
above, we consider the following specific type of Ux
Ux :=
ï£±ï£´ï£²ï£´ï£³Ux =
ï£®ï£¯ï£° U1...
Un
ï£¹ï£ºï£» : Ui âˆˆ CntÃ—m, Uâ€ i Uj = Î´i,jn Im
ï£¼ï£´ï£½ï£´ï£¾ ,
(16)
where Î´i,j = 1 if i = j and Î´i,j = 0 if i ï¿¿= j. It is not hard
to see Ux is nonempty if and only if nm â‰¤ nt. Moreover,
there is a one-one correspondence between the set Ux and the
submatrices of the elements in the unitary group U(nt). Thus,
given any Ux âˆˆ Ux, it can be shown that the entries of Hs,
Hs = HËœUx =
ï£®ï£¯ï£° HU1...
HUn
ï£¹ï£ºï£» ,
are i.i.d. CN ï¿¿0, 1nï¿¿ random variables. It means that the
equivalent channel (14) is an (mÃ—nnr) i.i.d. Rayleigh MIMO
channel. Following similar arguments as in the previous sec-
tion we have
Pout,MMSE(r| rank m, n channel uses)
â‰¤ inf
UxâˆˆUx
Pr
ï¿¿
Tr
ï¿¿ï¿¿
SNRHâ€ sHs + Im
ï¿¿âˆ’1ï¿¿ â‰¥ SNRâˆ’nrm ï¿¿
.
= SNRâˆ’(nnrâˆ’m+1)(1âˆ’
nr
m )
+
.
We arrive at the following main result of this paper.
Theorem 3: For an (nt Ã— nr), nt â‰¤ nr, i.i.d. quasi-static
Rayleigh MIMO channel in which the MIMO channel remains
fixed for at least nt channel uses, given multiplexing gain r,
the DMT under linear MMSE or ZF receivers is lower bounded
by
dâˆ—out,MMSE(r) â‰¥ max
1â‰¤nmâ‰¤nt
(nnr âˆ’m+ 1)
ï¿¿
1âˆ’ nr
m
ï¿¿+
. (17)
We remark that with n = nt channel uses and m = 1, the
optimal DMT is lower bounded by
dâˆ—out,MMSE(r) â‰¥ ntnr (1âˆ’ ntr)+ .
It shows at r = 0 the maximal diversity order ntnr is indeed
achievable by the use of linear receivers, without help from
any further processing such as the LLL lattice reduction.
Before concluding this subsection, we would like to say
more about the design of pre-coding matrix Ux. We offer the
following theorem for the case of mn â‰¤ nt.
Theorem 4: For an (nt Ã— nr), nt â‰¤ nr, i.i.d. quasi-static
Rayleigh MIMO channel that is fixed for at least n channel
uses, let
Ux =
ï£®ï£¯ï£° u11 Â· Â· Â· u1m... . . . ...
un1 Â· Â· Â· unm
ï£¹ï£ºï£»
be the (nntÃ—m) pre-coding matrix defined as before, i.e., we
have Kx = UxÎ›U â€ x, rank(Kx) = m and Tr(Kx) â‰¤ n . If the
set of vectors {u11, Â· Â· Â· , unm} is linearly independent over C,
then given multiplexing gain r, the DMT resulting from the
use of linear MMSE or ZF receivers is exactly
d(r) = (nnr âˆ’m+ 1)
ï¿¿
1âˆ’ nr
m
ï¿¿+
.
We remark that the condition of Theorem 4 is much weaker
than that in (16) and, therefore, gives more insight to the
An algebraic look into MAC-DMT of lattice
space-time codes
Roope Vehkalahti, Member, IEEE
Department of Mathematics
University of Turku
Finland
Email: roiive@utu.fi
Hsiao-feng (Francis) Lu, Member, IEEE
Department of Electronical Engineering
National Chiao Tung University
Hsinchu, Taiwan
Email:francis@cc.nctu.edu.tw
Abstractâ€”In this paper we are concentrating on the diversity-
multiplexing gain trade-off (DMT) of some space-time lattice
codes. First we give a DMT bound for lattice codes having
restricted dimension. We then recover the well known results
of the DMT of algebraic number field codes and the Alamouti
code by using the union bound and see that these codes do
achieve the previously mentioned bound. During our analysis
interesting connections to the number theoretic concepts are
revealed. Finally we prove that both the number field codes and
Alamouti code are in some sense optimal codes in the multiple
access channel (MAC).
I. INTRODUCTION
In [1] the authors gave diversity multiplexing trade-off for
MIMO (multiple-input multiple-output) MAC. In their paper
Tse, Viswanath and Zheng pointed out that the MAC-DMT is
obviously always upper bounded by the DMT of the single-
user. In this paper we are concentrating on the scenario where
the single-user codes are not DMT optimal. In such a scenario
it is obvious that we cannot achieve the optimal MAC DMT
given in [1]. However we can ask another question: in which
cases the single-users can maintain their single-user DMT-
performance despite the interference of the other users.
The importance of this problem lies in the fact that in
some scenarios codes achieving the optimal DMT can have
high decoding complexity. As an example, let us consider the
situation where we have two users, both using Alamouti [2]
code, and where the receiver has two antennas. The decoding
complexity of this coding scheme is still relatively light to
decode even when for example sphere decoding is used.
In this case the DMT of a single-user can never be better
than the performance of the Alamouti code in the 2 Ã— 2
MIMO channel. Therefore we are immediately bounded away
from the optimal achievable MAC DMT. However, we can
ask whether both transmitters can achieve their single-user
performance despite the interference of the other user.
II. BASIC DEFINITIONS
Let us now consider a slow fading channel where we have
nt transmit and nr receiving antennas and where the decoding
delay is T time units. The channel equation can be now written
as
Y =
ï¿¿
SNR
nt
HX +N
where H âˆˆ MnrÃ—nt(C) is the channel matrix whose entries
are independent identically distributed (i.i.d.) zero-mean com-
plex circular Gaussian random variables with the variance 1,
and N âˆˆ MnrÃ—T (C) is the noise matrix whose entries are
i.i.d. zero-mean complex circular Gaussian random variables
with the variance 1. Here X âˆˆ MntÃ—T (C) is the transmitted
codeword and SNR presents the signal to noise ratio.
In order to shorten the notation we denote SNR with Ï. Let
us suppose we have coding scheme where for each value of
Ï we have a code C(Ï) having |C(Ï)| matrices in MnÃ—T (C).
The rate R(Ï) is then log (|C(Ï))|/T . Let us suppose that the
scheme fulfills the power constraint
1
|C(Ï)|
ï¿¿
XâˆˆC(Ï)
||X||2F â‰¤ Tnt.
We then have the following definition from [7].
Definition 2.1: The scheme is said to achieve spatial mul-
tiplexing gain r and diversity gain d if the data rate
lim
Ïâ†’âˆ
R(Ï)
log(Ï)
= r
and the average error probability
lim
Ïâ†’âˆ
log(Pe(Ï))
log(Ï)
= âˆ’d.
Let us now consider a coding scheme based on a k-
dimensional lattice L inside MnÃ—T (C) where for a given
positive real number R the finite code is
L(R) = {a|a âˆˆ L, ||a||F â‰¤ R}.
The following lemma is a well known result from basic lattice
theory.
Lemma 2.1: Let L be a k-dimensional lattice in MnÃ—T (C)
and
L(R) = {a | a âˆˆ L, ||a||F â‰¤ R },
then
|L(R)| = cRk + f(R),
where c is some real constant and |f(R)| âˆˆ o(R(kâˆ’1/2)).
In particular it follows that we can choose real numbers K1
and K2 so that
K1R
k â‰¥ |L(R)| â‰¥ K2Rk.
A. Alamouti code
Let us warm up by calculating the DMT of the Alamouti
code in the case where we have nr receiving antennas. Let us
use the following notation
A(x1, x2, x3, x4) =
ï¿¿
x1 + x2i âˆ’(x3 + x4i)âˆ—
x3 + x4i (x1 + x2i)âˆ—
ï¿¿
.
We then have the following
A(x1, x2, x3, x4)A(x1, x2, x3, x4)
â€  =ï¿¿
x21 + x
2
2 + x
2
3 + x
2
4 0
0 x21 + x
2
2 + x
2
3 + x
2
4
ï¿¿
.
Here the lattice L is
ZA(1, 0, 0, 0)+ZA(0, 1, 0, 0)+ZA(0, 0, 1, 0)+ZA(0, 0, 0, 1),
which is a 4-dimensional lattice in M2(C). For simplicity
we do not use the spherical shaping scheme, but instead we
consider the following scheme
C1(Ï
r/2) = {Ï1/2âˆ’r/2A(x1, x2, x3, x4)|âˆ’Ïr/2 â‰¤ xi â‰¤ Ïr/2},
where xi âˆˆ Z.
Proposition 4.1: When received with nr antennas the
Alamouti code achieves the DMT curve
(r, 2nr(1âˆ’ r)).
Proof: The usual union bound argument now gives us the
following bound for the error probability of making a mistake
in reception when transmitting arbitrary codeword
Pe â‰¤
ï¿¿
âˆ’2Ïr/2â‰¤xiâ‰¤2Ïr/2,xiâˆˆZ
Ïâˆ’2nr(râˆ’1)
(det(A(x1, x2, x3, x4))2nr
=
ï¿¿
|xi|â‰¤2Ïr/2,xiâˆˆZ
Ïâˆ’2nr(râˆ’1)
(x21 + x
2
2 + x
2
3 + x
2
4)
2nr
,
where we suppose that not all xi can be 0 at the same time.
If we then apply AM-GM inequality, we get the following
Pe â‰¤
ï¿¿
|xi|â‰¤2Ïr/2,xiâˆˆZ
Ïâˆ’2nr(râˆ’1)
| .x1 .x2 .x3 .x4 |nr ,
where the dot sign means that if xi = 0 we have that
.
xi= 1.
By considering the right side of the previous equation we have
that
Pe â‰¤ Ïâˆ’2nr(râˆ’1)
ï£«ï£­ ï¿¿
|x1|â‰¤2Ïr/2,xiâˆˆZ
1
| .x1 |nr
ï£¶ï£¸ Â·
Â· Â· Â·
ï£«ï£­ ï¿¿
|x4|â‰¤2Ïr/2,xiâˆˆZ
1
| .x4 |nr
ï£¶ï£¸
â‰¤ Ïâˆ’2nr(râˆ’1)K(2log(2Ïr/2))4nr ,
where K is some constant independent of Ï.
B. Diagonal Number field codes
For simplicity let us consider a degree n cyclic number field
extension K/Q(i), where the Galois group is < Ïƒ >. Then we
can define a relative canonical embedding of K into Mn(C)
by
Ïˆ(x) = diag(Ïƒ1(x), . . . ,Ïƒn(x)),
where x is an element in K. The ring of algebraic integers
OK has a Z-basis W = {w1, . . . , w2n} and therefore
Ïˆ(OK) = Ïˆ(w1)Z+ Â· Â· Â·+ Ïˆ(w2n)Z,
is a 2n-dimensional lattice of matrices in Mn(C). The main
reason to use such a code construction is that for each element
nonzero a âˆˆ OK , we have that |det(Ïˆ(a))| â‰¥ 1. Let us now
suppose that we have a 2n-dimensional number field lattice
code L âŠ† Mn(C) and that we are considering the coding
scheme, where the finite codes are chosen by the method of
Lemma 2.1.
We will now measure the DMT of these type of codes.
Before that we will need some concepts and lemmas.
The unit group UK of the ring OK consists of such elements
u âˆˆ OK , that |det(Ïˆ(u))| = 1.
Do the restriction on the length of the paper we skip the
proof of the following lemma.
Lemma 4.2: Let us suppose that we have a cyclic extension
K/Q(i), where [K : Q(i)] = n. Let us now consider the set
UK(R) = {Ïˆ(u)|u âˆˆ UK , ||Ïˆ(u)||F â‰¤ R },
we then have that
|UK(R)| â‰¤Mlog(R)nâˆ’1,
where M is a constant independent of R.
Corollary 4.3: Let us suppose that we have a cyclic exten-
sion K/Q(i), where [K : Q(i)] = n. Let us suppose we have
a non-zero element x âˆˆ OK , where ||Ïˆ(x)||F â‰¤ R. We then
have that
|Ïˆ(UKx) âˆ©B(R)| = |{u | ||Ïˆ(xu)||F â‰¤ R, u âˆˆ UK}|
â‰¤Mlog(R)nâˆ’1,
where M is a constant independent of R and of the element
x.
Proof: We can write Ïˆ(x) = diag(x1, . . . , xn). The
condition ||Ïˆ(x)||F â‰¤ R then gives us that |xi| â‰¤ R âˆ€i. We
also have that |x1| Â· Â· Â· |xn| â‰¥ 1. It now follows that
|xi| â‰¥ 1
Rnâˆ’1
âˆ€i. (2)
Let us now suppose that u is such a unit that ||Ïˆ(ux)||F =
||Ïˆ(u)Ïˆ(x)||F = ||diag(x1u1, . . . , xnun)||F â‰¤ R. Equation
(2) now gives us that that |ui| â‰¤ Rn âˆ€i. Therefore we have that
||Ïˆ(u)||F â‰¤ âˆšnRn. Lemma 4.2 now gives us that |UKx(R)âˆ©
B(R)| â‰¤Mlog(âˆšnRn)nâˆ’1 â‰¤M1log(R)nâˆ’1, where M1 is a
constant independent of R.
In the following we will use the term IK for the set of
integral ideals of the ring OK .
V. MISO CODES IN MAC SCENARIO
Let us now consider a scenario where we have K inde-
pendent users each using 2n-dimensional MISO-lattice codes
L1, . . . , LK âŠ† Mn(C) and that the receiver has nr â‰¥ K
antennas. In this section we prove that if each user uses a
MISO code from the previous sections (Alamouti or number
field code) they can reach the single-user DMT despite the
interference of the other users. According to Proposition 3.2
the achieved DMT:s are the best it is possible to get when the
users are applying 2n-dimensional lattice codes.
Lemma 5.1: The product of singular values (non-zero) of
the matrix AAâ€  are the same as those of Aâ€ A.
The following result is well known from matrix theory.
Lemma 5.2: Let us consider a Kn Ã— n matrix X =
[X1, . . . , XK ]T . We then have that
det((X)(X)â€ ) â‰¥
Kï¿¿
i=1
det(XiX
â€ 
i ).
Let us suppose that the receiver uses joint decoding. As
noted in [1] this choice of receiving strategy does not change
the DMT performance of each user. We can now consider
the whole system as a single-user code where the single-user
has Kn transmit antennas and the receiver has nr receiving
antennas. The single-user code can then be defined as
L = {[X1, X2, . . . , XK ]T |Xi âˆˆ Li } âŠ†MKnÃ—n(C).
As each of the lattices Li are 2n-dimensional the lattice L is
2Kn-dimensional.
Following the previously defined coding scheme (1) we
define the finite codes needed in DMT analysis by
CL(Ï
r/2K) = Ï1/2âˆ’r/2KL(Ïr/2K).
Let us now suppose that each Li is either number field code
as defined previously or in the case n = 2 Alamouti code.
The crucial properties of the codes Li are the following.
â€¢ We have |det(Xi)| â‰¥ 1, when Xi ï¿¿= 0 and Xi âˆˆ Li.
â€¢ We also have the inequalityï¿¿
XâˆˆLi| ||X||Fâ‰¤R
1
|det(X)|2 â‰¤ Slog(R)
M , (3)
where S and M are some constants.
Proposition 5.3: Let us suppose that we have the previously
described coding scheme and that the receiver has nr â‰¥ K
antennas. Then the code L achieves the DMT curve
(r, nnr(r/K âˆ’ 1))
and each single-user achieves DMT curve
(r, nnr(r âˆ’ 1)).
Proof: The usual union bound argument gives us
Pe â‰¤ Ïâˆ’nnr(r/Kâˆ’1)
ï¿¿
XâˆˆL(2Ïr/2K)
1
|det(XXâ€ )|nr
â‰¤ Ïâˆ’nnr(r/Kâˆ’1)
ï¿¿
XiâˆˆL(2Ïr/2K)
1
(det(X1)2 + Â· Â· Â· + det(XK)2)nr
â‰¤ Ïâˆ’nnr(r/Kâˆ’1)
ï¿¿
XiâˆˆLi(2Ïr/2K)
1
(
.
det(X1) Â· Â· Â·
.
det(XK))2nr/K
â‰¤ Ïâˆ’nnR(r/Kâˆ’1)
ï£«ï£­ ï¿¿
X1âˆˆL1(2Ïr/2K)
1
det(X1)2
ï£¶ï£¸ Â· Â· Â·
Â· Â· Â·
ï£«ï£­ ï¿¿
XKLK(2Ïr/2K)
1
det(XK)2
ï£¶ï£¸
â‰¤ Ïâˆ’nnr(r/Kâˆ’1)log(2Ïr/2K)V K ,
where the last inequality comes from condition (4.5) and
where the dotted notation
.
det(Xi)=1, if Xi = 0. This finally
gives us
Pe â‰¤MÏâˆ’nnr(r/Kâˆ’1)log(Ï)T ,
where M and T are some constants independent of Ï. This
gives us the first claim.
In order to get the single-user perspective we have to
multiply the multiplexing gain r with number of user K. This
gives us the second claim.
Remark 5.1: We point out that in the previous result we
could combine any kind of codes as long as they fulfilled the
conditions given before Proposition 5.3. The DMT of stacked
Alamouti codes was earlier proved in [6].
ACKNOWLEDGEMENT
The research of R. Vehkalahti is supported by the Emil
Aaltonen Foundation and by the Academy of Finland (grant
131745).
REFERENCES
[1] D. Tse, P. Viswanath, and L. Zheng, â€œDiversity and multiplexing tradeoff
in multiple-access channelsâ€, IEEE Trans. Inf. Theory, vol. 50, pp. 1859â€“
1874, September 2004.
[2] S. M. Alamouti, â€œA Simple Transmit Diversity Technique for Wireless
Communicationâ€, IEEE J. on Select. Areas in Commun., vol. 16, pp.
1451â€“1458, October 1998.
[3] X. Giraud, E. Boutillon, and J. C. Belfiore, â€œAlgebraic tools to build
modulation schemes for fading channelsâ€, IEEE Trans. Inf. Theory,
vol.43, pp. 938â€“952, May 1997.
[4] W. Narkiewicz, Elementary and Analytic Theory of Algebraic Numbers,
Springer, Berlin, 1980.
[5] V. Tarokh, N. Seshadri, and A.R. Calderbank, â€œSpace-Time Codes for
High Data Rate Wireless Communications: Performance Criterion and
Code Constructionâ€, IEEE Transactions on Information Theory, vol. 44,
pp. 744â€“765, March 1998.
[6] Narayan Prasad, Luca Venturinot, Xiaodong Wang and Mohammad
Madihian, â€œAnalysis of Multiuser Stacked Space-time Orthogonal and
Quasi-orthogonal Designsâ€, Proc. 2007 IEEE Int. Symp. Inform. Theory
(ISIT), ISIT2007, Nice, France, June 2007.
[7] L. Zheng and D. Tse, â€œDiversity and Multiplexing: A Fundamental
Tradeoff in Multiple-Antenna Channelsâ€, IEEE Trans. Inf. Theory vol.
49, pp. 1073â€“1096, May 2003.
[8] Hsiao-feng Lu, Yuankai Wang, P. Vijay Kumar and Keith M. Chugg
â€œRemarks on Space-Time Codes Including a New Lower Bound and
an Improved Codeâ€, IEEE Trans. Inf. Theory vol. 49, pp. 2752â€“2757,
October 2003.
am greatly beneficial from her talk. I then attended to many sessions that are interested to me, 
including Communication System 1 and 2, Multiuser Coding 1, Quantum Information Processing 
1, and MIMO Diversity Techniques.  
For the second day of the conference, it began with the plenary talk given by Prof Te-sun Han, 
whose presentation titled â€œPolymatroidal Structures in Multiuser Coding,â€ a research area that I am 
not quite familiar with. It appears that Prof Han has applied the study of co-polymatroid as well as 
the Hoffman theorem from classical graph theory to the analysis the capacity region of some 
simple, yet remaining open, communication networks. Though I do not understand the material 
completely, I am keen to the approach of Prof. Han for that unlike other research efforts in this line 
of research targeting at only the approximate capacity region that can be a few bits away from the 
true region, Prof Han focuses on the characterization of the true region.  
My own presentation, titled â€œMinimal-Rate Description for Multiple-Access Channelsâ€, was 
scheduled in the session of Multiuser Coding 2 and was immediately after the plenary speech. 
There were about 20 people attending my talk, and one attendant, named Krishnamoorthy Iyer 
from IISC of India, was highly interested in my paper. Together, we had discussed some possible 
future works. After my presentation, I then attended the sessions of Algebraic codes, Mobile 
Communications, Network Coding, and Application of Information Theory. 
 
`UD 
While the size of ISITA is much smaller compared to that of ISIT, I found small-size 
conferences are actually very beneficial in the sense that it is relatively easier to find 
researchers with a common research interest and formulate possible collaborations. The ISIT, 
though has the highest reputation in the field of information and coding theory, generally has 
more than 1000 attendees and contains almost 150 sessions in 5 days. The time schedule of 
ISIT is too tight so that it is almost impossible to find friends or researchers to discuss research 
matters. The ISITA, on the other hand, is not as reputable as the ISIT, but seems to be a much 
better place for possible discussion and collaboration. In this conference, I had a chance to 
discuss with Prof Frederique Oggier on her work of generalized rank weight of rank-metric 
codes, that parallels the notion of generalized Hamming weight for conventional linear error 
correcting codes.  
The conference plenary speech given by Prof Michelle Effros on the computation of capacity 
region for large communication networks was extremely nice. Her statements were very clear 
and easy to understand. Most importantly, I found my own research work is closely related to 
her presentation, in the sense that my work is a strong embodiment of her claims. She stated 
that without the need of figuring out all transmitted message at the intermediate nodes, the 
resulting capacity region could actually be larger. Yet, she does not have any explicit coding 
schemes to support such claim. My work, on the other hand, provides several algebraic codes 
that are shown to achieve a larger capacity region for a simple communication network.  
I also attended several presentations on algebraic codes, a topic that I am always interested in. 
The talks were very nice, but I did find one of them not very convincing. The author attempted 
to apply the Fourier theory to several classes of algebraic geometry codes. However, it was 
From: ISITA2012 <isita2012tpc-
secretary@it.ss.titech.ac.jp>
Subject: [ISITA2012] Your paper #1569614621 ('Minimal-
Rate Description for Multiple-Access 
Channels')  has been accepted
Date: July 23, 2012 11:32:19 AM GMT+08:00
To: Sue-May Huang <mamia3698@gmail.com>
Cc: Hsiao-feng Francis Lu 
<francis@mail.nctu.edu.tw>, "Stefan M. Moser" 
<stefan.moser@ieee.org>
Dear Ms. Sue-May Huang:
We are happy to inform you that your paper #1569614621
('Minimal-Rate Description for Multiple-Access Channels'),
has been accepted by the ISITA2012 for presentation at the
symposium, and publication in the proceedings. We received
a high number of paper submissions which were subjected to
a rigorous review process. Your paper was selected for
inclusion based on its high quality and contribution. 
We encourage you to incorporate comments of the reviewers
in modifying your paper before its final submission.
Your presentation is tentatively scheduled at the session
`Multi-user Coding 2'
starting from October 30, 2012 10:00.
The tentative technical program is available at
http://edas.info/p11533
Please make sure that one of the authors can present the
result.
The deadline of final manuscripts is August 10, 2012 at 23:59
UTC.
Final manuscripts must be uploaded via EDAS
(http://edas.info/showPaper.php?m=1569614621).
Final manuscripts must be prepared in compliance with the
IEEE format.  If not, the manuscript will not be included in the
Minimal-Rate Description for Multiple-Access
Channels
Sue-May Huang
Institute of Communications Engineering
National Chiao Tung University
Hsinchu, 30010
Taiwan
Email: mamia3698@gmail.com
Hsiao-feng (Francis) Lu
Department of Electrical Engineering
National Chiao Tung University
Hsinchu, 30010
Taiwan
Email: francis@mail.nctu.edu.tw
Stefan M. Moser
Department of Electrical Engineering
National Chiao Tung University
Hsinchu, 30010
Taiwan
Email: stefan.moser@ieee.org
Abstractâ€”In this paper we consider the problem of a two-
user multiple-access channel that is different from the conven-
tional one. We require the receiver to provide only a reliable
information-mixture of the incoming messages from the two users,
not the exact contents. The minimum rate of such mixture
is termed the minimal description rate of the channel output.
Answers to this problem have many potential applications to the
latest network-coding-based wireless communication networks.
Exact capacity regions of a class of fading multiple-access chan-
nels are determined, along with the corresponding deterministic
capacity-achieving coding schemes.
I. INTRODUCTION
Consider a multiple-access channel with two users who send
independent information to a common receiver at rates R1
and R2, respectively. Let X1 âˆˆ X1 (resp. X2 âˆˆ X2) be the
transmitted signal of the first (resp. the second) user, and let
Y âˆˆ Y be the received signal at the receiver. The sets X1 and
X2 are the channel input alphabets of the first and the second
user, respectively, and Y is the channel output alphabet.
The conventional information theoretic problem [1] for the
multiple-access channel addresses the region of achievable
rates at which the receiver can recover reliably the information
sent by each user. Let p(y|x1x2) be the channel transition
probability. The resulting capacity region is [1]
RMAC =
ï£±ï£²ï£³(R1, R2) âˆˆ ï¿¿R+ï¿¿2 : R1 â‰¤ I(X1;Y |X2),R2 â‰¤ I(X2;Y |X1),
R1 +R2 â‰¤ I(X1X2;Y )
ï£¼ï£½ï£¾
(1)
for some product distribution p1(x1)p2(x2) on X1 Ã— X2. It
is well-known [1] that the region RMAC takes a shape of a
pentagon, rather than a rectangle. This is due to the third sum-
rate constraint in (1).
The sum-rate constraint could also be seen as being caused
by the requirement of recovering both transmitted signals
X1 and X2 at the receiver. However, in a large wireless
communication network, especially when network coding is
applicable, such requirement might be no longer necessary. For
example, consider the noisy butterfly network [2] in Fig. 1. The
communication links are assumed to be wireless. S1 and S2 are
the transmitting nodes representing the two independent users,
sending independent signals X1 and X2 to destination nodes
S1
ï¿¿ï¿¿
ï¿¿ï¿¿
S2
ï¿¿ï¿¿
ï¿¿ï¿¿
T
ï¿¿ï¿¿ ï¿¿ï¿¿
D1 D2
Fig. 1. A noisy butterfly network with two transmitting nodes S1 and S2,
an intermediate relay node T , and two receiving nodes D1 and D2.
D1 and D2, respectively. The intermediate node T , which can
be seen as a relay, broadcasts to nodes D1 and D2 based on
what it receives from S1 and S2. Notice that at node T , the
two incoming links form a multiple-access channel.
In order to increase the overall channel capacity, the conven-
tional network coding approach [2] requires the relay node T
to broadcast an â€œinformation-mixtureâ€ to the destination nodes.
The mixture must be some linear (or nonlinear) combination
of the information W1 and W2 associated with X1 and X2,
respectively. Specifically, in the language of network coding,
what is needed at node T is a local encoding kernel [2]
f : W1Ã—W2 â†’W with f(W1,W2) = W such that the maps
f(W1, Â·) and f(Â·,W2) are injective for any fixed W1 âˆˆ W1
and W2 âˆˆW2.
What interests us is the following. In order to produce the
information-mixture W , one possible way is for the relay to
first recover reliably W1 and W2 from the received signal Y ,
and then apply the local encoding kernel f . This corresponds
to a conventional multiple-access channel, whose capacity
region is given by RMAC in (1). An alternative approach is
for the relay to generate directly the information mixture W
based on Y , without knowing W1 and W2. Such a strategy
is exactly what is needed by relay T , as node D1 can learn
W1 from its other communication link from S1, and similarly
W2 for node D2. In other words, knowing W1 and W2 should
not be a primary goal for node T . It only needs to provide
a reliable mixture W to nodes D1 and D2. Furthermore, the
information rate carried by W must be as small as possible
We say the rate (R1, R2, R) is achievable if there exists a
series of coding schemes Cn such that error probability
P (n)e :=
1
2n(R1+R2)
ï¿¿
(w1,w2)âˆˆW1Ã—W2
Pr
ï¿¿
g (Y n) ï¿¿= f(w1, w2)
ï¿¿ï¿¿ï¿¿ï¿¿
(w1, w2) sent
ï¿¿
âˆ’â†’ 0 (3)
as nâ†’âˆ.
We claim that the former formulation, Definition 1, is a
more relaxed and more general formulation of the problem.
Proposition 1: If the rate (R1, R2, R) is achievable for (3),
then so is it for (2).
Proof: Omitted for lack of space.
It then follows that Definition 1 not only provides a more
relaxed formulation of the problem, but also results in a larger
capacity region. That is, we have the following corollary.
Corollary 2: {(R1, R2, R) is achievable for (3)} âŠ† {(R1,
R2, R) is achievable for (2)} = R.
With the above, we will hereafter stick to the relaxed
definition, Definition 1.
C. What if the Description Rate R is Unbounded?
In our definition of the capacity region, there are three rates
to be considered, namely, the rates R1 and R2 of the two users,
and the description rate R for the information-mixture. On the
other hand, when only the region of achievable transmission
rates (R1, R2) is of interest, we show such region can be trivial
for R unbounded.
Proposition 3: For the multiple-access channel with addi-
tive noise
Y = h1X1 + h2X2 +W,
where h1 and h2 are some fixed channel gains and W is an
additive random noise, we have
{(R1, R2) : (R1, R2, R) âˆˆ R for some R â‰¥ 0}
=
ï¿¿
(R1, R2) :
0 â‰¤ R1 â‰¤ I (X1;Y |X2) ,
0 â‰¤ R2 â‰¤ I (X2;Y |X1)
ï¿¿
Proof: Due to lack of space, we will omit all the details.
But the main idea is that since R can grow without bound,
we may simply let g(yn) = yn, even if it might call for a
description rate R â†’ âˆ for a continuous-alphabet channel.
The above proposition shows that in order to make the
present problem interesting one has to limit the description
rate R. Also, as already said in Section I, the rate R is limited
directly by the outgoing links of relay node T .
D. Minimal Description Rate
With R, we define the function for minimal description rate
as
R (R1, R2) = inf {R : (R1, R2, R) âˆˆ R) . (4)
We have the following lower bound for the minimal descrip-
tion rate.
Proposition 4: R (R1, R2) â‰¥ max{R1, R2}.
Proof: Omitted due to space limitations.
From Proposition 4 we are then interested in the following
region of achievable rates for R1 and R2 with minimal
description rate
R12,inf = {(R1, R2) : (R1, R2,max{R1, R2}) âˆˆ R} . (5)
III. SOME INTERESTING CHANNELS WITH MINIMAL
DESCRIPTION
A. Noise-free Multiple-Access Fading Channel
Consider the following noise-free channel
Y = h1X1 + h2X2 (6)
where h1, h2 are some deterministic real numbers.
Since the channel is noise-free, it is clear that
{(R1, R2) : (R1, R2, R) âˆˆ R for some R > 0} =
ï¿¿
R+
ï¿¿2
However, it is not clear what the minimal description rate
R(R1, R2) is. In fact, it is not hard to see that for any
codebooks C1,n for user 1 and C2,n for user 2, there exist h1
and h2 such that the channel output Y n can take |C1,n| Â· |C2,n|
possible values, suggesting R = R1+R2. But, below we show
it is not the minimal description rate for the present problem.
Proposition 5: For the noise-free channel given in (6), the
minimal description rate is
R(R1, R2) = max{R1, R2}.
Proof: Without loss of generality we assume R1 â‰¥ R2.
For any fixed n, let the codebook for user 1 be C1,n =
{0, 1, . . . , 2nR1 âˆ’ 1} and let the codebook for user 2 be
C2,n = {0, 1, . . . , 2nR2 âˆ’ 1}. Let p be a prime such that
2nR1 < p < 2nR1+1. Such prime p exists for a sufficiently
large n as guaranteed by the Bertrand-Chebyshev theorem.
Also, for any h1, h2 âˆˆ R, let s ï¿¿ p2 be an integer and there
exist a1, a2 âˆˆ Z such that
max{|a1 âˆ’ sh1| , |a2 âˆ’ sh2|} â‰¤ 1âˆš
s
by simultaneous Dirichlet approximation. [3] Thus, with suit-
able choices of (p, s) we have
sY = a1X1 + a2X2 + ï¿¿ and |ï¿¿|ï¿¿ 1
2
and (a1, p) = (a2, p) = 1. Set the description function as
g(Y ) = [sY ]Z (mod p) = a1X1 + a2X2 (mod p)
where by [x]Z we mean the rounding of x to the nearest
integer. Now given x2
x1 = a
âˆ’1
1 (g(Y )âˆ’ a2x2) (mod p)
and similarly for x2. Finally note that the range of g(Y ) is
at most 2nR1+1, hence R â‰¤ R1 + 1n and the claimed result
follows.
We remark that the coding scheme used in the above proof is
independent of h1 and h2.
Corollary 6: For the noise-free channel given in (6),
R12,inf =
ï¿¿
R+
ï¿¿2
Given (R1, R2) with
0 â‰¤ R2 â‰¤ max
ï¿¿
R1 âˆ’ 1
2
log2
ï¿¿ï¿¿ï¿¿ï¿¿h1h2
ï¿¿ï¿¿ï¿¿ï¿¿2 , 0
ï¿¿
â‰¤ R1
the codebook for user 1 is C1,n = 1h1 (Î›f âˆ© Vc). Clearly,
|C1,n| = |Î›f/Î›c| = 2nR1 and E C1,n ï¿¿x1ï¿¿2 = 1h21Ïƒ
2(Vc) =
PX . The codebook for user 2 is C2,n = 1h2 [Î›f âˆ© (k2Vc)],
where k2 = 2R2âˆ’R1 < 1. The size of C2,n is
|C2,n| = |Î›f âˆ© (k2Vc)| = |k2|n |Î›f/Î›c| = 2nR2 ,
and the average power for C2,n is
E C2,n ï¿¿x2ï¿¿2 =
k22
h22
Ïƒ2(Vc) = h
2
1k
2
2
h22
PX â‰¤ h
2
1
h22
h22
h21
PX = PX
since k2 â‰¤
ï¿¿ï¿¿ï¿¿h2h1 ï¿¿ï¿¿ï¿¿ by construction.
The encoding functions are any bijections Ï†1 : W1 â†’ C1,n
and Ï†2 : W2 â†’ C2,n. Given message indices w1 and w2, the
corresponding transmitted vectors are
x1 = Ï†1(w1)âˆ’ U
ï¿¿
mod 1
h1
Vc
1
h1
Î›c
ï¿¿
and x2 = Ï†2(w2),
where U is some random vector uniformly distributed over
1
h1
Vc, known to both transmitter and receiver.
Given x1 and x2 as defined above, we note first that
Ï†1(w1) âˆˆ 1h1Î›f and Ï†2(w2) âˆˆ 1h2Î›f . With this in mind,
the channel output is
y = h1x1 + h2x2 + w
Let c1 = Ï†1(w1); then
h1x1 = h1
ï¿¿
c1 âˆ’ U
ï¿¿
mod 1
h1
Vc
1
h1
Î›c
ï¿¿ï¿¿
= h1c1 âˆ’ h1U (modVc Î›c)
with h1c1 âˆˆ Î›f and h1c1 âˆˆ Vc by construction. Similarly, for
the user 2â€™s signal, h2x2 âˆˆ Î›f and h2x2 âˆˆ k2Vc âŠ† Vc. Most
important, we have h1c1 + h2x2 âˆˆ Î›f and
h1c1 + h2x2 (modVc Î›c) â‰¡ x âˆˆ Î›f/Î›c (8)
and |Î›f/Î›c| = 2nR1 . In other words, despite the fact that
two vectors c1 and x2 were sent through the channel with
different fading gains, after taking the modulo-Î›c reduction
with respect to Vc, it is equivalent to sending vector x through
the channel.
Following [7] and with MMSE coefficient Î± := h
2
1PX
h21PX+PN
,
the decoding output is
cË† = QVf
ï¿¿
Î±y + h1U
ï¿¿
(modVc Î›c)
= QVf
ï¿¿
Î± (h1c1 âˆ’ h1U + h2x2 + w) + h1U
ï¿¿
modVf Î›c
ï¿¿ï¿¿
(modVc Î›c)
= QVf
ï¿¿
x+ Î±w âˆ’ (1âˆ’ Î±) (xâˆ’ h1U)
ï¿¿
modVf Î›c
ï¿¿ï¿¿
(modVc Î›c)
where Vf is the Voronoi region of Î›f .
Noting that U ï¿¿ = (xâˆ’ h1U) (modVc Î›c) is uniformly
distributed over Vc, we can rewrite the noise vector as
N ï¿¿ = Î±w âˆ’ (1âˆ’ Î±)U ï¿¿ (modVc Î›c) ,
which has the same distribution as Î±w âˆ’ (1 âˆ’
Î±) (xâˆ’ h1U) (modVc Î›c). That is,
cË† = QVf
ï¿¿
x+N ï¿¿
ï¿¿
(modVc Î›c)
Now [7, Theorem 5] guarantees that
Pr {x ï¿¿= cË†} = Prï¿¿N ï¿¿ ï¿¿âˆˆ Vfï¿¿ â‰¤ eâˆ’n(Ep(e2(Câˆ’R))âˆ’o(1))
where
C :=
1
2
log2
ï¿¿
1 +
h21PX
PN
ï¿¿
= C1,
and where the function Ep(Âµ) is the Poltyrev exponent, defined
explicitly in [7].
To summarize, the above Voronoi-region decoder can re-
cover reliably x (defined in (8)) whenever R â‰¤ C1 as nâ†’âˆ.
Following from the above, the minimal description of y is
g
ï¿¿
y
ï¿¿
= QVf [Î±Y + h1U ] (modVc Î›c)
and g
ï¿¿
y
ï¿¿ âˆˆ Î›f/Î›c with |Î›f/Î›c| = 2nR1 = 2nR.
Since g(y) = h1c1 + h2x2 (modVc Î›c) with probability
approaching 1 as nâ†’âˆ, given c1, we have g(y)âˆ’h1c1 âˆˆ Î›f .
It follows that
xË†2 =
1
h2
ï¿¿
g(y)âˆ’ h1c1 (modVc Î›c)
ï¿¿
(9)
and w2 = Ï†âˆ’12 (xË†2) with high probability. Similarly, it can be
shown that given x2, with high probability
Ï†1(w1) =
1
h1
ï¿¿
g(y)âˆ’ h2x2 (modVc Î›c)
ï¿¿
.
This proves the achievability of (R1, R2, R = R1) in RL.
Achievability in RU . The proof for the achievability of
(R1, R2, R = R1) in RU follows along similar lines and is
therefore omitted.
REFERENCES
[1] T. M. Cover and J. A. Thomas, Elements of Information Theory, 2nd ed.
New Jersey: John Wiley & Sons, 2006.
[2] S.-Y. R. Li, R. W. Yeung, and N. Cai, â€œLinear network coding,â€ IEEE
Trans. Inf. Theory, vol. 49, no. 2, pp. 371â€“381, Feb 2003.
[3] W. M. Schmidt, Diophantine approximation. Springer: Lecture Notes
in Mathematics 785, 1980.
[4] J. H. Conway and N. J. A. Sloane, Sphere Packings, Lattices, and Groups,
3rd ed. New York: Springer, 1998.
[5] G. Poltyrev, â€œOn coding without restrictions for the AWGN channel,â€
IEEE Trans. Inf. Theory, vol. 40, no. 2, pp. 409â€“417, Mar. 1994.
[6] C. A. Rogers, Packing and Covering. Cambridge, U.K.: Cambridge
University Press, 1964.
[7] U. Erez and R. Zamir, â€œAchieving 12 log(1+SNR) on the AWGN channel
with lattice encoding and decoding,â€ IEEE Trans. Inf. Theory, vol. 50,
no. 10, pp. 2293â€“2314, Oct. 2004.
[8] H.A.Loeliger, â€œAveraging bounds for lattices and linear codes,â€ IEEE
Trans. Inf. Theory, vol. 43, no. 6, pp. 1767â€“1773, Nov. 1997.
[9] U. Erez, S. Litsyn, and R. Zamir, â€œLattices which are good for (almost)
everything,â€ IEEE Trans. Inf. Theory, vol. 51, no. 10, pp. 3401â€“3416,
Oct. 2005.
98 å¹´åº¦å°ˆé¡Œç ”ç©¶è¨ˆç•«ç ”ç©¶æˆæœå½™æ•´è¡¨ 
è¨ˆç•«ä¸»æŒäººï¼šé™¸æ›‰î¹ è¨ˆç•«ç·¨è™Ÿï¼š98-2221-E-009-045-MY3 
è¨ˆç•«åç¨±ï¼šå¤šç”¨æˆ¶å¤šè¼¸å…¥è¼¸å‡ºè¡Œå‹•é€šè¨Šç³»çµ±ä¸­é”åˆ°æœ€ä½³ Diversity èˆ‡ Multiplexing æ¬Šè¡¡çš„ä»£æ•¸ç·¨ç¢¼è¨­
è¨ˆ 
é‡åŒ– 
æˆæœé …ç›® å¯¦éš›å·²é”æˆ
æ•¸ï¼ˆè¢«æ¥å—
æˆ–å·²ç™¼è¡¨ï¼‰
é æœŸç¸½é”æˆ
æ•¸(å«å¯¦éš›å·²
é”æˆæ•¸) 
æœ¬è¨ˆç•«å¯¦
éš›è²¢ç»ç™¾
åˆ†æ¯” 
å–®ä½ 
å‚™ è¨» ï¼ˆ è³ª åŒ– èªª
æ˜ï¼šå¦‚æ•¸å€‹è¨ˆç•«
å…±åŒæˆæœã€æˆæœ
åˆ— ç‚º è©² æœŸ åˆŠ ä¹‹
å° é¢ æ•… äº‹ ...
ç­‰ï¼‰ 
æœŸåˆŠè«–æ–‡ 0 0 100%  
ç ”ç©¶å ±å‘Š/æŠ€è¡“å ±å‘Š 0 0 100%  
ç ”è¨æœƒè«–æ–‡ 0 0 100% 
ç¯‡ 
 
è«–æ–‡è‘—ä½œ 
å°ˆæ›¸ 0 0 100%   
ç”³è«‹ä¸­ä»¶æ•¸ 0 0 100%  å°ˆåˆ© å·²ç²å¾—ä»¶æ•¸ 0 0 100% ä»¶  
ä»¶æ•¸ 0 0 100% ä»¶  
æŠ€è¡“ç§»è½‰ 
æ¬Šåˆ©é‡‘ 0 0 100% åƒå…ƒ  
ç¢©å£«ç”Ÿ 0 0 100%  
åšå£«ç”Ÿ 0 0 100%  
åšå£«å¾Œç ”ç©¶å“¡ 0 0 100%  
åœ‹å…§ 
åƒèˆ‡è¨ˆç•«äººåŠ› 
ï¼ˆæœ¬åœ‹ç±ï¼‰ 
å°ˆä»»åŠ©ç† 0 0 100% 
äººæ¬¡ 
 
æœŸåˆŠè«–æ–‡ 1 1 100%  
ç ”ç©¶å ±å‘Š/æŠ€è¡“å ±å‘Š 0 0 100%  
ç ”è¨æœƒè«–æ–‡ 2 2 100% 
ç¯‡ 
 
è«–æ–‡è‘—ä½œ 
å°ˆæ›¸ 0 0 100% ç« /æœ¬  
ç”³è«‹ä¸­ä»¶æ•¸ 0 0 100%  å°ˆåˆ© å·²ç²å¾—ä»¶æ•¸ 0 0 100% ä»¶  
ä»¶æ•¸ 0 0 100% ä»¶  
æŠ€è¡“ç§»è½‰ 
æ¬Šåˆ©é‡‘ 0 0 100% åƒå…ƒ  
ç¢©å£«ç”Ÿ 5 5 100%  
åšå£«ç”Ÿ 2 20 100%  
åšå£«å¾Œç ”ç©¶å“¡ 0 0 100%  
åœ‹å¤– 
åƒèˆ‡è¨ˆç•«äººåŠ› 
ï¼ˆå¤–åœ‹ç±ï¼‰ 
å°ˆä»»åŠ©ç† 0 0 100% 
äººæ¬¡ 
 
