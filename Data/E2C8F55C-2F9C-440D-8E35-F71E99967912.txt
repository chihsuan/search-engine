nodes in a cloud cluster. Therefore, in this project, 
the adaptive task assignment approach is proposed to 
assign appropriate mapper tasks no nodes according to 
the job types and nodesï¼‡ capability and available 
resources. The objective is to achieving the load 
balancing among nodes which incurs high performance 
and resource utilization. Moreover, in order to 
realize such system, a prototype, which is able to 
distribute tasks to nearby mobile nodes for parallel 
processing, has been designed and implemented in this 
project. For ensuring the data security, the data 
transmission in this system is encrypted. According 
to usersï¼‡ security and performance requirements, 
this system can select the appropriate nodes and 
encryption algorithms for maximizing the data 
security and job performance. 
è‹±æ–‡é—œéµè©ï¼š Cloud computing, MapReduce, Load balancing, Task 
assignment, Data encryption 
 
 2
é»æ•¸ä¾†é€²è¡Œå·¥ä½œçš„åˆ†æ•£å¼è™•ç†æ‰èƒ½å¤ ç¸®çŸ­åŸ·è¡Œæ™‚é–“ï¼Œè€Œé€™æ˜¯å› ç‚ºå·¥ä½œé‹ç®—å®Œæˆå¾Œé‚„éœ€è¦æ™‚é–“ä¾†é€²è¡Œå„
ç¯€é»é‹ç®—çµæœçš„æ•´åˆã€‚èˆ‰ä¾‹ä¾†èªªï¼Œå¦‚åœ–äºŒæ‰€ç¤ºï¼Œå‡è¨­ä¸€å€‹ç¯€é»è™•ç† 200 MBçš„è³‡æ–™é‡éœ€è¦èŠ± 20ç§’è€Œä¸”
ç¶²è·¯å‚³è¼¸é€Ÿåº¦æ˜¯ 5 MBpsï¼Œç•¶ 1GBçš„è³‡æ–™ç”± 5å€‹ç¯€é»ä¾†è™•ç†æ™‚éœ€èŠ±è²» 20ç§’çš„é‹ç®—æ™‚é–“èˆ‡å‚³è¼¸æ™‚é–“ 160
ç§’(å‡è¨­æ•´åˆç¯€é»åŒæ™‚åªèƒ½æ¥æ”¶ä¸€å€‹ç¯€é»çš„é‹ç®—çµæœ)ï¼Œæ‰€ä»¥åŸ·è¡Œæ™‚é–“ç¸½å…±éœ€è¦ 180ç§’ï¼›ç•¶ 1 GBçš„è³‡æ–™
ç”± 2å€‹ç¯€é»ä¾†è™•ç†æ™‚éœ€èŠ±è²» 50ç§’çš„é‹ç®—æ™‚é–“èˆ‡å‚³è¼¸æ™‚é–“ 100ç§’ï¼Œæ‰€ä»¥åŸ·è¡Œæ™‚é–“ç¸½å…±éœ€è€—è²» 150ç§’ã€‚æ‰€
ä»¥ï¼Œå¦‚ä½•æ ¹æ“šç¶²è·¯ç’°å¢ƒç‹€æ…‹é¸æ“‡ç¯€é»çš„æ•¸é‡ä¾†åšé€²è¡Œé‹ç®—ï¼Œæœƒå½±éŸ¿é›²ç«¯é‹ç®—çš„é‹ç®—æ•ˆèƒ½ã€‚ 
 
åœ–äºŒ åŸ·è¡Œç¯€é»æ•¸é‡èˆ‡åŸ·è¡Œæ•ˆèƒ½çš„é—œä¿‚ 
 
ç¬¬äºŒï¼Œè©²å¦‚ä½•æ ¹æ“šç¯€é»çš„èƒ½åŠ›èˆ‡å¯ç”¨è³‡æºåˆ†é…é©ç•¶çš„ mapperä»»å‹™æ•¸é‡çµ¦åŸ·è¡Œå·¥ä½œçš„ç¯€é»ä¹Ÿæœƒå½±éŸ¿
é›²ç«¯æœå‹™æ•ˆèƒ½ã€‚ä¾‹å¦‚ï¼Œç•¶ mapperä»»å‹™æ•¸é‡å·²ç¶“è¶…å‡ºç¯€é»æœ¬èº«èƒ½è² è¼‰çš„å·¥ä½œé‡æ™‚ï¼Œç¯€é»é‹ç®—æ•ˆèƒ½å°±æœƒé™
ä½ï¼Œé€²è€Œå½±éŸ¿åˆ°æ•´å€‹å·¥ä½œçš„é‹ç®—æ•ˆèƒ½ã€‚èˆ‰ä¾‹ä¾†èªªï¼Œå¦‚åœ–ä¸‰æ‰€ç¤ºï¼Œå·¦åœ–æ˜¯æ¡ç”¨å¹³å‡åˆ†é… mapperä»»å‹™æ•¸é‡
çš„æ–¹å¼ï¼Œå› ç‚ºç¯€é»å¯ç”¨è³‡æºæ‰€ä»¥æœƒå°è‡´ç¯€é»çš„è² è¼‰ä¸å¹³å‡è€Œå½±éŸ¿åˆ°å·¥ä½œåŸ·è¡Œçš„æ™‚é–“ï¼›å³åœ–å‰‡æ˜¯è€ƒé‡ç¯€
é»å¯ç”¨è³‡æºä¾†åˆ†é…ä¸åŒçš„ mapperä»»å‹™æ•¸é‡ï¼Œå› æ­¤å¯ä»¥å¹³è¡¡ç¯€é»çš„è² è¼‰ã€‚æ‰€ä»¥å¦‚ä½•æ ¹æ“šç¯€é»èƒ½åŠ›èˆ‡å¯ç”¨
è³‡æºä¾†é…ç½® mapperä»»å‹™æ•¸é‡ä½¿å¾—ç¯€é»é–“å·¥ä½œè² è¼‰å¹³è¡¡ï¼Œäº¦æ˜¯å½±éŸ¿MapReduceæ•ˆèƒ½çš„è­°é¡Œä¹‹ä¸€ã€‚ 
 
åœ–ä¸‰ å·¥ä½œé‡å°ç¯€é»çš„è² è¼‰æ¯”ä¾‹åœ– 
 
ç¬¬ä¸‰ï¼Œå·¥ä½œå‹æ…‹ä¹Ÿæœƒå½±éŸ¿é›²ç«¯æœå‹™æ•ˆèƒ½ï¼Œä¾‹å¦‚é‹ç®—å¯†é›†(computation intensive)çš„å·¥ä½œæŒ‡çš„æ˜¯åœ¨åŸ·è¡Œ
å·¥ä½œæ™‚ CPU è² è¼‰å¤§å¤šæ˜¯ 100%ï¼Œè€Œè³‡æ–™çš„å‚³è¼¸å¯ä»¥åœ¨å¾ˆçŸ­çš„æ™‚é–“å…§å®Œæˆï¼Œæ‰€ä»¥éœ€è¦è¼ƒå¤šçš„é‹ç®—è³‡æºï¼›
è€Œé€šè¨Šå¯†é›†(communication intensive)çš„å·¥ä½œæŒ‡çš„æ˜¯åœ¨åŸ·è¡Œå·¥ä½œæ™‚å¤§éƒ¨åˆ†çš„ç‹€æ³æ˜¯åœ¨é€²è¡Œè³‡æ–™çš„å‚³éï¼Œ
 4
3.1. ä¸»è¦æ–¹æ³• 
æœ¬è¨ˆç•«æå‡ºçš„ ATAæ–¹æ³•å…±æœ‰äº”å€‹æ­¥é©Ÿä¸¦ä¸”åˆ†æˆå…©å€‹éšæ®µé€²è¡Œæ”¹å–„ï¼Œæµç¨‹å¦‚åœ–äº”æ‰€ç¤ºã€‚ç¬¬ä¸€å€‹éšæ®µ
(ä»¥ä¸‹ç°¡ç¨± ATA-1)æœ‰å››å€‹æ­¥é©Ÿï¼Œ(1)åˆ†æå·¥ä½œç‰¹å¾µã€(2)æ±ºå®šåŸ·è¡Œå·¥ä½œçš„ç¯€é»æ•¸é‡ã€(3)æ±ºå®šåŸ·è¡Œå·¥ä½œçš„ç¯€
é»ã€èˆ‡(4)æ±ºå®šå¹³å‡åˆ†é… mapperä»»å‹™çš„æ•¸é‡ï¼›ç¬¬äºŒå€‹éšæ®µ(ä»¥ä¸‹ç°¡ç¨± ATA)æœ‰ä¸€å€‹æ­¥é©Ÿï¼Œ(5)æ ¹æ“šç¯€é»èƒ½åŠ›
èˆ‡å¯ç”¨è³‡æºé‡æ–°é…ç½® mapperä»»å‹™ã€‚ 
 
 
åœ–äº” ATAå„ªåŒ–æµç¨‹åœ– 
 
åœ¨ç¬¬ä¸€å€‹éšæ®µ(ATA-1)ä¸‹ï¼Œæˆ‘å€‘çš„å¯¦é©—çµæœæ¯” Hadoopé è¨­æ–¹æ³•æ›´æœ‰æ•ˆç‡ï¼Œé€™æ˜¯å› ç‚º Hadoopé è¨­æ–¹
æ³•ä¸æœƒæ ¹æ“šæª”æ¡ˆå¤§å°èˆ‡å·¥ä½œçš„ç‰¹å¾µä¾†æ±ºå®šé¸å–å“ªå¹¾å€‹ç¯€é»ä¾†é€²è¡Œé‹ç®—ï¼Œè€Œæ˜¯å¹³å‡åˆ†é…çµ¦å…¨éƒ¨çš„ç¯€é»ä¾†
é‹ç®—ã€‚ç›¸ååœ°ï¼Œæ‰€æå‡ºçš„ ATA-1æ–¹æ³•æœƒæ ¹æ“šæª”æ¡ˆå¤§å°èˆ‡å·¥ä½œç‰¹å¾µä¾†æ±ºå®šé¸å–å¹¾å€‹ç¯€é»ä¾†é‹ç®—ä»¥åŠæ¯å€‹
ç¯€é»æ‡‰è©²å¹³å‡åŸ·è¡Œå¹¾å€‹ mapperä»»å‹™ä»¥æ”¹å–„ MapReduceæ•ˆèƒ½ã€‚ç„¶è€Œï¼Œå¦‚æœå¹³å‡åˆ†é… mapperä»»å‹™æ•¸é‡ï¼Œ
å‰‡åœ¨ä¸€å€‹ç•°è³ªé›²ä¸­è³‡æºè¼ƒä½çš„ç¯€é»èˆ‡è³‡æºè¼ƒé«˜çš„ç¯€é»å› ç‚ºåˆ†é…çš„å·¥ä½œé‡ç›¸åŒè€Œæœƒå°è‡´å·¥ä½œé‡ä¸å¹³è¡¡çš„
ç‹€æ³(è³‡æºè¼ƒä½çš„ç¯€é»å·¥ä½œè² è¼‰éé«˜)ï¼Œè€Œé€ æˆé‹ç®—æ•ˆèƒ½ä¸‹é™ã€‚å› æ­¤ï¼Œæœ¬è¨ˆç•«æ‰€æå‡ºçš„ ATA æ–¹æ³•å°±æ˜¯ç‚º
äº†æ”¹å–„ä¸Šè¿°å•é¡Œã€‚ATAæœƒé€²ä¸€æ­¥æ ¹æ“šå¯¦éš›ç¯€é»çš„èƒ½åŠ›èˆ‡å¯ç”¨è³‡æºï¼Œå°åœ¨å¹³å‡åˆ†é…ä¸‹çš„ mapperä»»å‹™æ•¸é‡
ä½œå¾®èª¿ï¼Œä½¿å¾—é‹ç®—èƒ½åŠ›èˆ‡å¯ç”¨è³‡æºè¼ƒé«˜çš„ç¯€é»åŸ·è¡Œè¼ƒå¤šçš„ mapperä»»å‹™ï¼›åä¹‹ï¼Œé‹ç®—èƒ½åŠ›èˆ‡å¯ç”¨è³‡æºè¼ƒ
ä½çš„ç¯€é»åŸ·è¡Œè¼ƒå°‘çš„ mapperä»»å‹™ä¾†å¾—åˆ°ä¸€å€‹èƒ½è®“å·¥ä½œè² è¼‰å¹³è¡¡çš„ä»»å‹™é…ç½®ã€‚ 
 
3.1.1. ç¬¬ä¸€éšæ®µ(ATA-1)æ–¹æ³•èªªæ˜ 
A. æ­¥é©Ÿä¸€ï¼šåˆ†æå·¥ä½œç‰¹å¾µ 
å¦‚ä¸Šè¿°ï¼Œå› ç‚ºä¸åŒå‹æ…‹çš„å·¥ä½œæ‡‰è©²ä»¥ä¸åŒçš„ç¯€é»æ•¸ä¾†é€²è¡Œåˆ†æ•£å¼é‹ç®—ä»¥æé«˜é›²ç«¯æœå‹™æ•ˆèƒ½ï¼Œæ‰€ä»¥
æˆ‘å€‘æ‰€æå‡ºçš„æ–¹æ³•æœƒå…ˆåˆ†æå·¥ä½œç‰¹å¾µã€‚ä¾‹å¦‚ï¼Œç”±æ–¼ CPU-boundçš„å·¥ä½œéœ€è¦è¼ƒé«˜çš„ CPUè³‡æºä¾†é‹ç®—ï¼Œä¸¦
ä¸”ä¸éœ€è¦å¸¸å¸¸å­˜å–è³‡æ–™ï¼Œæ‰€ä»¥ CPU-boundçš„å·¥ä½œå¯ä»¥åœ¨è¼ƒå¤šçš„ç¯€é»æ•¸é‡ä¾†é‹ç®—ä»¥å¾—åˆ°è¼ƒé«˜çš„å·¥ä½œæ•ˆèƒ½ï¼›
åä¹‹ï¼Œè‹¥æ˜¯ I/O-boundçš„å·¥ä½œï¼Œç”±æ–¼éœ€è¦å¸¸å¸¸é€²è¡Œè³‡æ–™çš„å­˜å–èˆ‡å‚³è¼¸ï¼Œä¸¦ä¸”ä¸éœ€è¦è¼ƒé«˜çš„ CPUè³‡æºä¾†
é‹ç®—ï¼Œæ‰€ä»¥å¦‚æœåœ¨è¼ƒå°‘çš„ç¯€é»ä¸Šé€²è¡Œåˆ†æ•£å¼é‹ç®—å¯ä»¥æœ‰æ•ˆé™ä½ç¯€é»ä¹‹é–“çš„è³‡æ–™å‚³è¼¸æ™‚é–“ã€‚å› æ­¤ï¼Œåˆ†æ
å·¥ä½œç‰¹å¾µä¾†æ±ºå®šé‹ç®—ç¯€é»çš„æ•¸é‡æ˜¯å¿…è¦çš„ã€‚ 
æœ¬è¨ˆç•«æ‡‰ç”¨éå»çš„æ–‡ç»[2][7]æ‰€æå‡ºçš„æ–¹æ³•ä¾†å®Œæˆå·¥ä½œç‰¹å¾µçš„åˆ¤å®šã€‚ç”±æ–¼ä¸€å€‹MapReduceå·¥ä½œæ‰€éœ€
 6
æ–¼ CPU-bound ä½† mapper ä»»å‹™è¼¸å‡ºè³‡æ–™é‡å»å¾ˆå¤§çš„å·¥ä½œåœ¨ç¶²è·¯å‚³è¼¸é€Ÿåº¦å¾ˆæ…¢çš„é›²ç«¯å¢é›†ä¸­åŸ·è¡Œæ™‚ï¼Œå¦‚
æœåœ¨æ­¥é©ŸäºŒè€ƒæ…®å·¥ä½œç‰¹å¾µæ¬Šé‡ï¼Œå³æ¡ç”¨æ–¹ç¨‹å¼(3)ï¼Œç”±æ–¼ CPU-boundå·¥ä½œéœ€è¦è¼ƒå¤šçš„ç¯€é»ä¾†é‹ç®—ï¼Œä½†æ˜¯
å› ç‚º mapperä»»å‹™è¼¸å‡ºè³‡æ–™é‡å¾ˆå¤§è€Œç¶²è·¯å‚³è¼¸çš„é€Ÿåº¦è¼ƒæ…¢ï¼Œæ‰€ä»¥å¯èƒ½å°è‡´éœ€è¦æ›´å¤šçš„è³‡æ–™å‚³è¼¸æ™‚é–“ï¼Œä½¿
å¾—æ•´é«”é‹ç®—æ™‚é–“çš„æ‹‰é•·ã€‚å› æ­¤ï¼Œåœ¨æ­¤æƒ…æ³ä¸‹å¦‚æœä¸è€ƒæ…®å·¥ä½œç‰¹å¾µæ¬Šé‡ï¼Œå³æ¡ç”¨æ–¹ç¨‹å¼(4)ï¼Œåè€Œå¯ä»¥é”
åˆ°æ›´å¥½çš„æ•ˆèƒ½ã€‚ 
 
C. æ­¥é©Ÿä¸‰ï¼šæ±ºå®šé¸æ“‡é‚£äº›ç¯€é»å·¥ä½œ 
åœ¨æ­¥é©ŸäºŒæ±ºå®šå‡ºæœ€ä½³çš„å·¥ä½œç¯€é»æ•¸â€²ä¹‹å¾Œï¼ŒATA-1 æœƒæ ¹æ“šå·¥ä½œç‰¹å¾µèˆ‡ç¯€é»å¯ç”¨è³‡æºåœ¨é›²ç«¯å¢é›†ä¸­
æ‰€æœ‰ Nå€‹ç¯€é»ä¸­é¸å–â€²å€‹ç¯€é»ä¾†åŸ·è¡Œå·¥ä½œã€‚é€™æ˜¯å› ç‚ºå¦‚æœç¯€é»é¸æ“‡ä¸å¥½ä¹Ÿæœƒå°è‡´é‹ç®—æ•ˆèƒ½ä¸‹é™ï¼Œä¾‹å¦‚
å°‡ CPU è³‡æºè¼ƒä½çš„ç¯€é»åˆ†é…å»åŸ·è¡Œé‹ç®—å¯†é›†çš„å·¥ä½œï¼Œé€™æ¨£å°è‡´é‹ç®—æ™‚é–“æ‹–é•·ï¼Œè‹¥åˆ†é… CPU è³‡æºè¼ƒé«˜
çš„ç¯€é»å»é‹ç®—é€šè¨Šå¯†é›†çš„å·¥ä½œï¼Œå‰‡æœƒå°è‡´è³‡æºçš„æµªè²»ã€‚é¦–å…ˆï¼Œç³»çµ±å¿…é ˆå…ˆæ”¶é›†é›²ç«¯å¢é›†ä¸­æ‰€æœ‰ç¯€é»çš„
å¯ç”¨è³‡æº(é€éç¸½è¨ˆç•«ä¸­å…¶ä»–å­è¨ˆç•«)ï¼Œå†æ ¹æ“šé€™äº›è³‡è¨Šä»¥åŠå·¥ä½œçš„å‹æ…‹ä¾†æ±ºå®šä¾†é¸æ“‡é©ç•¶çš„ç¯€é»åŸ·è¡Œå·¥
ä½œã€‚ç°¡å–®ä¾†èªªï¼Œé‹ç®—å¯†é›†çš„å·¥ä½œï¼ŒATA-1æœƒé¸å– CPUå¯ç”¨è³‡æºæ¯”ä¾‹è¼ƒé«˜çš„ç¯€é»ï¼›åä¹‹ï¼Œé€šè¨Šå¯†é›†çš„å·¥
ä½œæœƒé¸æ“‡ç¶²è·¯é »å¯¬è³‡æºæ¯”ä¾‹è¼ƒé«˜çš„ç¯€é»ï¼Œé€™æ¨£å°±å¯ä»¥é¸æ“‡èƒ½å¤ ç¬¦åˆå·¥ä½œç‰¹å¾µä¸”æœ‰æ•ˆåˆ©ç”¨è³‡æºçš„ç¯€é»ä¾†
åŸ·è¡Œå·¥ä½œã€‚ 
è©³ç´°ä½œæ³•èªªæ˜å¦‚ä¸‹ã€‚é¦–å…ˆï¼Œå¿…é ˆæ ¹æ“šæ–¹ç¨‹å¼(6)è¨ˆç®—åœ¨ç¬¬	å€‹ç¯€é»ä¸­ç¬¬ç¨®è³‡æºå æ‰€æœ‰è³‡æºçš„æ¯”ä¾‹ï¼Œ
ä»¥,è¡¨ç¤ºï¼Œ 
, =

âˆ—,
,

âˆ‘ 
âˆ—	,
,


, âˆ€                  (6) 
å…¶ä¸­,ã€,èˆ‡åˆ†åˆ¥ç‚ºç¬¬ nå€‹ç¯€é»ä¸­ç¬¬ kç¨®è³‡æºå¯ç”¨é‡ã€ç¬¬ nå€‹ç¯€é»ä¸­ç¬¬ kç¨®è³‡æºæœ€å¤§ä¾›æ‡‰é‡ã€èˆ‡
è©²å·¥ä½œå°æ–¼ç¬¬ç¨®è³‡æºçš„éœ€æ±‚ç¨‹åº¦è€Œ 
âˆ‘  = 1                     (7) 
åœ¨æ–¹ç¨‹å¼(6)ä¸­ï¼Œå› ç‚ºæ¯ä¸€ç¨®è³‡æºçš„å–®ä½éƒ½ä¸ç›¸åŒè€Œç„¡æ³•ç›´æ¥åŠ åœ¨ä¸€èµ·ï¼Œæ‰€ä»¥æˆ‘å€‘æœƒå…ˆå°‡æ¯ç¨®è³‡æº
é€²è¡Œæ­£è¦åŒ–(normalization)ï¼Œäº¦å³å°‡ç¬¬ nç¯€é»ç¬¬ kç¨®è³‡æºçš„å¯ç”¨é‡é™¤ä»¥ç¬¬ kç¨®è³‡æºçš„æœ€å¤§ä¾›æ‡‰é‡ã€‚å¦å¤–ï¼Œ
ç”±æ–¼é‹ç®—å¯†é›†èˆ‡é€šè¨Šå¯†é›†çš„å·¥ä½œå°æ–¼ä¸åŒç¨®é¡è³‡æºçš„éœ€æ±‚ç¨‹åº¦ä¸åŒï¼Œæ‰€ä»¥å¯ä»¥é€éä¾†æ±ºå®šè©²å·¥ä½œå°
æ–¼æ¯ç¨®è³‡æºçš„éœ€æ±‚ç¨‹åº¦ï¼Œå¦‚åœ–å…­æ‰€ç¤ºï¼Œé‹ç®—å¯†é›†ã€é€šè¨Šå¯†é›†æˆ–æ˜¯å¹³å‡çš„å·¥ä½œå¯ä»¥æ¡ç”¨ä¸åŒçš„æ¬Šé‡å€¼çµ„
åˆã€‚ 
é‹ç®—å¯†é›†å‹å·¥ä½œ CPU HD RAM OTHER 
æ¬Šé‡ 0.5 0.2 0.2 0.1 
é€šè¨Šå¯†é›†å‹å·¥ä½œ CPU HD RAM OTHER 
æ¬Šé‡ 0.2 0.5 0.2 0.1 
å¹³å‡å‹å·¥ä½œ CPU HD RAM OTHER 
æ¬Šé‡ 0.3 0.3 0.2 0.2 
 
å¯ç”¨è³‡æº ç¯€é» A ç¯€é» B ç¯€é» C ç¯€é» D 
CPU 30% 10% 20% 40% 
HD 20% 30% 40% 10% 
RAM 20% 30% 10% 30% 
OTHER 10% 10% 10% 10% 
 
 ç¯€é» A ç¯€é» B ç¯€é» C ç¯€é» D 
é‹ç®—å¯†é›†å‹å·¥ä½œ 62.5% 27.7% 47.6% 68.9% 
é€šè¨Šå¯†é›†å‹å·¥ä½œ 47.6% 62.5% 74% 20% 
åœ–å…­ ç¯€é»è³‡æºæ¯”ä¾‹èˆ‡å·¥ä½œè² è¼‰çš„é—œä¿‚ 
 
D. æ­¥é©Ÿå››ï¼šæ±ºå®šå¹³å‡åˆ†é… mapperä»»å‹™çš„æ•¸é‡ 
ç•¶é¸å–å¥½é©ç•¶çš„åŸ·è¡Œç¯€é»ä¹‹å¾Œï¼ŒATA-1æ¥ä¸‹ä¾†æœƒæ±ºå®šå¦‚ä½•åˆ†é…mapperä»»å‹™çµ¦æ‰€é¸å‡ºä¾†çš„ç¯€é»åŸ·è¡Œã€‚
 8
ç¤ºï¼š 
	 =
âˆ‘ 
âˆ—	,
,


âˆ‘ âˆ‘ 
âˆ—	,
,






âˆ— âˆ‘ 	                 (9) 
å…¶ä¸­	èˆ‡		åˆ†åˆ¥ç‚ºç¬¬
å€‹è¢«é¸å‡ºä¾†åŸ·è¡Œå·¥ä½œçš„ç¯€é»ä¸­ç¬¬ kç¨®è³‡æºçš„å¯ç”¨é‡èˆ‡æœ€å¤§ä¾›æ‡‰é‡ï¼›è€Œ	èˆ‡	åˆ†
åˆ¥æ˜¯ç¬¬
å€‹è¢«é¸å‡ºä¾†åŸ·è¡Œå·¥ä½œçš„ç¯€é»èª¿æ•´å¾Œèˆ‡èª¿æ•´å‰çš„è™•ç† mapperä»»å‹™æ•¸é‡ã€‚æ ¹æ“šæ–¹ç¨‹å¼(9)ï¼Œè³‡æºè¼ƒ
å°‘çš„ç¯€é»æœƒè¢«åˆ†é…åˆ°è¼ƒå°‘çš„ mapperä»»å‹™æ•¸é‡ï¼›åä¹‹ï¼Œè³‡æºè¼ƒé«˜çš„ç¯€é»å‰‡æœƒè¢«åˆ†é…åˆ°è¼ƒå¤šçš„ mapperä»»
å‹™æ•¸é‡ä»¥é”åˆ°å·¥ä½œè² è¼‰å¹³è¡¡ã€‚ 
 
4. çµæœèˆ‡è¨è«– 
æœ¬è¨ˆç•«é€éå¯¦é©—ä¾†é€²è¡Œç†è«–çš„é©—è­‰ï¼Œå¯¦é©—ç’°å¢ƒèˆ‡å¯¦é©—çµæœèªªæ˜å¦‚ä¸‹ã€‚ 
 
4.1. å¯¦é©—ç’°å¢ƒ 
æœ¬è¨ˆç•«æ–½è¡Œä¹‹å¯¦é©—ç’°å¢ƒä¸»è¦å»ºæ§‹æ–¼å…©å°ä»¥ Gigabitä¹™å¤ªç¶²è·¯é€£çµçš„å¯¦é«”æ©Ÿå™¨ä¸Šï¼Œå¯¦é«”æ©Ÿå™¨çš„ç¡¬é«”è¦
æ ¼ 4æ ¸å¿ƒä¸”è™•ç†é€Ÿåº¦ç‚º 2.66GHzçš„è™•ç†å™¨(CPU)ã€ä¸»è¨˜æ†¶é«”(MEM)ç‚º 8 GBã€ä»¥åŠè£è¼‰ 1 TBçš„ç¡¬ç¢Ÿ(HD)ã€‚
åœ¨å…©å°å¯¦é«”æ©Ÿå™¨ä¸Šæˆ‘å€‘å®‰è£äº† XENé–‹æ”¾åŸå§‹ç¢¼çš„è™›æ“¬åŒ–ç³»çµ±ç”¨ä¾†å»ºæ§‹è™›æ“¬ç¯€é»ï¼Œä¸¦åœ¨è™›æ“¬ç¯€é»ä¸Šå®‰è£
Hadoop ä¾†åŸ·è¡Œ MapReduce å·¥ä½œã€‚ç”±æ–¼å¯¦é«”æ©Ÿå™¨çš„ç¡¬é«”é™åˆ¶ï¼Œæ‰€ä»¥æ¯å°å¯¦é«”æ©Ÿå™¨æœ€å¤šå¯ä»¥æ¨¡æ“¬ 4 å€‹è™›
æ“¬ç¯€é»ã€‚å¯¦é©—ä¸»è¦åœ¨å¦‚è¡¨ä¸€ã€è¡¨äºŒã€èˆ‡è¡¨ä¸‰ç­‰ä¸‰å€‹ä¸åŒçš„å¯¦é©—ç’°å¢ƒä¸‹é€²è¡Œã€‚ 
 
è¡¨ä¸€ é…ç½® 2å€‹è™›æ“¬ç¯€é»çš„ç•°è³ªé›²ç«¯å¢é›† 
 Slave 1 Slave 2 
CPU 4 core 1 core 
MEM 1.5 GB 1.5 GB 
HD 200 GB 200 GB 
 
è¡¨äºŒ é…ç½® 4å€‹è™›æ“¬ç¯€é»çš„ç•°è³ªé›²ç«¯å¢é›† 
 Slave1 Slave2 Slave3 Slave4 
CPU 3 core 1 core 2 core 2 core 
MEM 3 GB 3 GB 3 GB 3 GB 
HD 200 GB 200 GB 200 GB 200 GB 
 
è¡¨ä¸‰ é…ç½® 8å€‹è™›æ“¬ç¯€é»çš„åŒè³ªé›²ç«¯å¢é›† 
 Slave1 Slave2 Slave3 Slave4 Slave5 Slave6 Slave7 Slave8 
CPU 1 core 1 core 1 core 1 core 1 core 1 core 1 core 1 core 
MEM 1.5 GB 1.5 GB 1.5 GB 1.5 GB 1.5 GB 1.5 GB 1.5 GB 1.5 GB 
HD 200 GB 200 GB 200 GB 200 GB 200 GB 200 GB 200 GB 200 GB 
 
4.2. å¯¦é©—çµæœ 
åœ¨ä¸‹é¢çš„å¯¦é©—ä¸­å°‡æ¯”è¼ƒ ATAã€ATA-2ã€èˆ‡ Hadoopé è¨­æ–¹æ³•çš„æ•ˆèƒ½ã€‚æˆ‘å€‘ä½¿ç”¨ Grepèˆ‡ Sortç¨‹å¼åˆ†
åˆ¥ä»£è¡¨é‹ç®—å¯†é›†èˆ‡é€šè¨Šå¯†é›†çš„å·¥ä½œä¸¦ä»¥ 10 GBã€20 GBã€40 GBã€èˆ‡ 80 GBç­‰ä¸åŒçš„æª”æ¡ˆå¤§å°ä¾†è§€å¯Ÿä¸
åŒæ–¹æ³•çš„æ•ˆèƒ½ã€‚ 
 
4.2.1. æ¯”è¼ƒ ATA-1 èˆ‡Hadoop é è¨­æ–¹æ³•åŸ·è¡Œé‹ç®—å¯†é›†å·¥ä½œçš„æ•ˆèƒ½ 
 10
 
åœ–å ä»¥ 8å€‹ç¯€é»åŸ·è¡Œ Grepç¨‹å¼è™•ç†ä¸åŒå¤§å°çš„æª”æ¡ˆæ™‚æ¯å€‹ç¯€é»æ•¸åŸ·è¡Œä¹‹ mapperä»»å‹™æ•¸é‡èˆ‡å·¥ä½œåŸ·è¡Œæ™‚é–“çš„é—œä¿‚ 
 
4.2.2. æ¯”è¼ƒ ATA-1 èˆ‡Hadoop é è¨­æ–¹æ³•åŸ·è¡Œé€šè¨Šå¯†é›†å·¥ä½œçš„æ•ˆèƒ½ 
æ¥ä¸‹ä¾†ï¼Œæˆ‘å€‘æ¯”è¼ƒåŸ·è¡Œ Sortç¨‹å¼æ™‚ï¼ŒATA-1èˆ‡ Hadoopé è¨­æ–¹æ³•çš„æ•ˆèƒ½ã€‚åŒæ¨£åœ°ï¼Œæ ¹æ“š ATA-1çš„
ç¬¬ä¸€æ­¥é©Ÿï¼Œæœƒå…ˆæ‰¾å‡º Sort ç¨‹å¼çš„å·¥ä½œç‰¹å¾µï¼Œç”±æ–¼ Sort çš„è¼¸å‡ºç­‰æ–¼è¼¸å…¥ï¼Œæ‰€ä»¥å…¶å·¥ä½œç‰¹å¾µå€¼Ï‰å³ç‚º 1ã€‚
æ¥ä¸‹ä¾†ï¼Œæ ¹æ“š ATA-1ç¬¬äºŒè‡³ç¬¬å››æ­¥é©Ÿå¾—åˆ°ç”± 4å€‹ç¯€é»ä¸”æ¯å€‹ç¯€é»åŸ·è¡Œ 2å€‹ mapperä»»å‹™ä¾†åŸ·è¡Œ Srepç¨‹
å¼æ™‚ç‚ºæœ€ä½³ã€‚åœ–åä¸€èˆ‡åœ–åäºŒåˆ†åˆ¥ç‚ºè¼¸å…¥è³‡æ–™é‡ç‚º 10 GBèˆ‡ 80 GBçš„å¯¦é©—çµæœï¼Œå¾åœ–ä¸­å¯ä»¥ç™¼ç¾ç•¶é‹
ç®—çš„æª”æ¡ˆè¶Šå°æ™‚ï¼Œæ•ˆèƒ½çš„å·®ç•°è¼ƒä¸æ˜é¡¯ï¼Œä½†æ˜¯ç•¶é‹ç®—çš„æª”æ¡ˆè¶Šå¤§æ™‚ï¼Œä¸åŒçš„ç¯€é»æ•¸é‡èˆ‡ mapperä»»å‹™æ•¸
é‡å°å·¥ä½œåŸ·è¡Œæ™‚çš„å½±éŸ¿è¶Šå¤§ã€‚ 
 
 
åœ–åä¸€ åŸ·è¡Œ Sortç¨‹å¼è™•ç† 10 GBæª”æ¡ˆæ™‚åŸ·è¡Œç¯€é»æ•¸é‡èˆ‡å·¥ä½œåŸ·è¡Œæ™‚é–“çš„é—œä¿‚ 
 
 
åœ–åäºŒ åŸ·è¡Œ Sortç¨‹å¼è™•ç† 80 GBæª”æ¡ˆæ™‚åŸ·è¡Œç¯€é»æ•¸é‡èˆ‡å·¥ä½œåŸ·è¡Œæ™‚é–“çš„é—œä¿‚ 
 
0
1000
2000
3000
4000
5000
10GB 20GB 40GB 80GB
s
e
c
o
n
d
s
Data size
Grep
hadoop-
map*4
hadoop-
map*6
hadoop-
map*8
ATA-1
0
5000
10000
15000
20000
Map*2 Map*4 Map*6 Map*8
s
e
c
o
n
d
s
Sort-10G
Node*2
ATA-1
Node*8
0
10000
20000
30000
40000
50000
60000
70000
Map*2 Map*4 Map*6 Map*8
s
e
c
o
n
d
s
Sort-80G
Node*2
ATA-1
Node*8
 12
 
åœ–åäº” åœ¨ 4å€‹ç¯€é»çš„ç•°è³ªé›²ç«¯å¢é›†ä¸‹åŸ·è¡Œ Sortç¨‹å¼æ™‚ ATAã€ATA-1èˆ‡ Hadoopé è¨­æ–¹æ³•çš„æ•ˆèƒ½æ¯”è¼ƒ 
 
5. ç³»çµ±å¯¦ä½œ 
æœ¬è¨ˆç•«ç¬¬ä¸€å¹´ä¸»è¦å®Œæˆäº†è¡Œå‹•ç¶²è·¯é›²ç«¯é‹ç®—åŸºç¤æ¶æ§‹çš„å»ºåˆ¶ä»¥åŠåŸºæœ¬çš„ç’°å¢ƒæ„ŸçŸ¥è³‡æ–™å­˜å–æœå‹™ã€‚
ç‚ºäº†ç¢ºä¿è³‡æ–™çš„å®‰å…¨æ€§ï¼Œé€éè³‡æ–™åŠ å¯†æŠ€è¡“ï¼Œå‚³è¼¸éç¨‹çš„è³‡æ–™éƒ½æ˜¯åŠ å¯†éå¾Œçš„å¯†æ–‡ã€‚ç•¶åŠ å¯†éå¾Œçš„è³‡
æ–™åˆ†æ•£åˆ°ä¸åŒçš„ç¯€é»ä¸Šå¾Œï¼Œå¦‚æœæœ‰ç¶“éæˆæ¬Šçš„ç¯€é»å³å¯å°‡è³‡æ–™è§£å¯†ä»¥é€²è¡Œé‹ç®—ã€‚åœ–åå…­ç‚ºç›®å‰æ‰€å®Œæˆ
ç³»çµ±ä¹‹ç³»çµ±æ¶æ§‹èˆ‡è³‡æ–™/æ§åˆ¶æµç¨‹åœ–ï¼Œèªªæ˜å¦‚ä¸‹ï¼š 
 
 Step 1. Service Request 
ä½¿ç”¨è€…é€éè¡Œå‹•è£ç½®é€å‡ºèº«åˆ†é©—è­‰è¨Šæ¯èˆ‡æœå‹™å“è³ªè¦æ±‚ã€‚ 
 Step 2. Service Profiling  
ä»²ä»‹å™¨åœ¨é©—è­‰èº«åˆ†é©—è­‰è¨Šæ¯å¾Œï¼Œæ ¹æ“šæœå‹™å“è³ªè¦æ±‚ï¼ŒåŒ…å«ç¶²è·¯ã€é›²ç«¯é‹ç®—ä¸­å¿ƒã€å‘¨é­è¡Œå‹•è£ç½®é‹
ç®—è³‡æºèˆ‡èƒ½åŠ›ã€èˆ‡è³‡æ–™åˆ†å¸ƒç­‰ç‹€æ…‹æ±ºå®šå“ªäº›è³‡æ–™ç”±é‚£äº›ç¯€é»ä¾†åŸ·è¡Œé‹ç®—ã€‚(ç’°å¢ƒæ„ŸçŸ¥å­˜å–) 
 Step 3. Job Submitting 
ä»²ä»‹å™¨å°‡é‹ç®—å·¥ä½œèˆ‡ Step 2æ‰€æ±ºå®šä¹‹é‹ç®—è£ç½®æ¸…å–®éäº¤çµ¦ jobTrackerã€‚ 
 Step 4. Job Initialization 
jobTrackeré€²è¡Œåˆå§‹åŒ–ã€‚(ä¾‹å¦‚ï¼Œå°‡è³‡æ–™åŠ å¯†å¾Œå‚³çµ¦å…¶ä»–è£ç½®é‹ç®—)ã€‚ 
 Step 5. Mapper Assignment 
jobTrackerå°‡ä»»å‹™(èˆ‡åŠ å¯†çš„è³‡æ–™)ç™¼é€çµ¦æ‰€æ±ºå®šä¹‹é‹ç®—è£ç½®ä¸Šçš„ taskTrackeré€²è¡Œé‹ç®—ã€‚ 
 Step 6. Mapper Executing (åœ¨å…¨éƒ¨æ‰€æ±ºå®šä¹‹é‹ç®—è£ç½®ä¸Š) 
å¤šå€‹è¡Œå‹•è£ç½®ä¸Šçš„ taskTackeråŸ·è¡ŒMapperä»»å‹™ç”¢ç”Ÿä¸­é–“çµæœã€‚ 
 Step 7. Intermediate result submitting 
taskTrackerå°‡ä¸­é–“çµæœå›å‚³çµ¦ jobTrackerã€‚ 
 Step 8. Reducer Executing 
jobTackeråŸ·è¡Œ Reducerä»»å‹™æ•´åˆä¸­é–“çµæœä¸¦å¾—åˆ°æœ€å¾Œçµæœã€‚ 
 Step 9. Return final result 
jobTackerå°‡æœ€å¾Œçµæœå›å‚³çµ¦ä½¿ç”¨è€…ã€‚ 
 
0
5000
10000
15000
20000
25000
30000
35000
40000
10GB 20GB 40GB 80GB
s
e
c
o
n
d
s
Data size
Sort-node*4
ATA
ATA-1
hadoop
map*2
hadoop
map*6
hadoop
map*8
 14
 
   
(a)æœå‹™è¦æ±‚      (b)ç¶²è·¯ä¸Šè£ç½®ç‹€æ…‹æ¸…å–® 
åœ–åä¹ æ ¹æ“šæœå‹™è¦æ±‚åœ¨ç¶²è·¯ä¸Šæ‰¾å°‹é©åˆçš„é‹ç®—ç¯€é» 
 
 
 Step 3è‡³ Step 9åŸ·è¡Œçµæœç•«é¢ 
 
åœ–äºŒå Brokerç«¯åŸ·è¡Œçµæœç•«é¢ 
 
 16
åƒè€ƒæ–‡ç» 
[1] Hadoop. (2011). Welcome to Apacheâ„¢ Hadoopâ„¢! [Online]. Available: http://hadoop.apache.org 
[2] Wikipedia. 2011. CPU-bound [Online] Available: http://en.wikipedia.org/wiki/CPU-bound 
[3] è‘£ çš„ åš å®¢ . 2011. Hadoop å…¬ å¹³ èª¿ åº¦ å™¨ ç®— æ³• è§£ æ [Online] Available: 
http://dongxicheng.org/mapreduce/hadoop-fair-scheduler/ 
[4] Wikipedia. 2011. Apache Hadoop [Online]. Available: http://zh.wikipedia.org/wiki/Hadoop 
[5] J. Dean and S. Ghemawat, â€œMapReduce: Simplied data processing on large clusters,â€ in Proc. of 4th 
USENIX Symposium on Operating Systems Design and Implementation, 2004, pp. 137-150. 
[6] K. Kambatla, A. Pathak, and H. Pucha, â€œTowards Optimizing Hadoop Provisioning in the Cloud,â€ in Proc. 
of the First Workshop on Hot Topics in Cloud Computing, San Diego, 2009. 
[7] C. Tian, H. Zhou, Y. He, and L. Zha, â€œA Dynamic MapReduce Scheduler for Heterogeneous Workloads,â€ 
in Proc. of Grid and Cooperative Computing International Conference, China, 2009, pp. 218-224. 
[8] R. Maggiani, â€œCloud Computing is Changing How We Communicate,â€ in Proc. of 2009 IEEE 
International Professional Communication Conference, Hawaiian, 2009, pp.1-4. 
[9] M. Zaharia, A. Konwinski, A.D. Joseph, R. Katz, and I. Stoica.,â€œImproving MapReduce performance in 
heterogeneous environments,â€ in Proc. of 8th USENIX Symposium on Operating Systems Design and 
Implementation, San Diego for, 2008, pp. 29-42. 
[10] R. Chen, H. Chen, and B. Zang, â€œTiled-MapReduce: optimizing resource usages of data-parallel 
applications on multicore with tiling,â€ in Proc. of the 19th international conference on Parallel 
architectures and compilation techniques, Vienna, Austria, 2010, pp. 523-534. 
[11] J. Wei, V. T. Ravi, and G. Agrawal, â€œComparing MapReduce and Freeride For Data-Intensive 
Applications,â€ in Proc. of IEEE International Conference on Cluster Computing and Workshops, New 
Orleans, 2009, pp. 1-10. 
[12] W. Hu, C. Tain, X. Liu, H. Qi, L. Zha, U. Liao, Y. Zhang, and J. Zhang, â€œMultiple-Job Optimization in 
MapReduce for Heterogeneous Workloads,â€ in Proc. of the Sixth International Conference on Semantics 
Knowledge and Grid, Beijing, China, 2010, pp. 135-140. 
[13] M. Zhou, R. Zhang, D. Zeng, W. Qian, and A. Zhou, â€œJoin Optimization in the MapReduce Environment 
for Column-wise Data Storeâ€ in Proc. of the Sixth International Conference on Semantics Knowledge and 
Grid, Beijing, China, 2010, pp.97-104. 
[14] D. Jiang, B. C. Ooi, L. Shi, and S. Wu, â€œThe performance of MapReduce: an in-depth study,â€ The Proc. 
of the VLDB Endowment VLDB Endowment, vol. 3, no. 1-2, pp. 472-483, September 2010. 
[15] M. M. Rafique, B. Rose, A. R. Butt, and D. S. Nikolopoulos, â€œSupporting MapReduce on large-scale 
asymmetric multi-core clusters,â€ ACM SIGOPS Operating Systems Review, vol. 43, no. 2, pp.25-34, 
April 2009. 
[16] L. A. Barroso , J. Dean , and U. HÃ¶lzle, â€Web Search for a Planet: The Google Cluster Architectureâ€ 
IEEE Micro, vol. 23, no. 2, pp. 22-28, March-April, 2003. 
[17] C.-L. Chen, J.-W. Lee, W.-T. Su, M.-F. Horng, and Y.-H. Kuo, â€œNoise Referred Packet Length 
Adaptation and Energy-Proportional Routing for Clustered Sensor Network,â€œInternational Journal of Ad 
Hoc and Ubiquitous Computing, vol. 3, no. 4, pp. 224-235, June 2008. 
[18] W. Tom, Hadoop: The Definitive Guide. O'Reilly Media, Inc., 2009 
 1
åœ‹ç§‘æœƒè£œåŠ©å°ˆé¡Œç ”ç©¶è¨ˆç•«é …ä¸‹å‡ºå¸­åœ‹éš›å­¸è¡“æœƒè­°å¿ƒå¾—å ±å‘Š 
                                     æ—¥æœŸï¼š101 å¹´ 9 æœˆ 1 æ—¥ 
ä¸€ã€åƒåŠ æœƒè­°ç¶“é 
æœ¬æ¬¡åƒåŠ çš„æ˜¯ç¬¬ 1å±† IEEEä¸­åœ‹é€šè¨Šåœ‹éš›æœƒè­°(ä»¥ä¸‹ç°¡ç¨± IEEE ICCC)ï¼Œå…¶è¦æ¨¡èˆ‡ç¶²è·¯é€šè¨Šé ˜åŸŸé‡
è¦æœƒè­° IEEE ICCç›¸ç•¶ï¼Œå·®åˆ¥æ–¼èˆ‰è¾¦åœ°é»åœ¨ä¸­åœ‹ï¼Œè€Œç¬¬ 1å±†ç•¶ç„¶å°±é¸åœ¨ä¸­åœ‹é¦–éƒ½åŒ—äº¬å¸‚ä¸­åŒ—äº¬å¤§å­¸åš
é›…é£¯åº—ä¾†èˆ‰è¾¦ã€‚IEEE ICCCæ˜¯ä¸€å€‹ç›¸ç•¶å¤§å‹çš„æœƒè­°ï¼Œé–‹å¹•å¼é™¤äº†é‚€è«‹åˆ° IEEE Communication Society
ä¸»å¸­ Vijay Bhargava åšå£«å¤–ï¼Œé‚„åŒ…å«ä¸­åœ‹å·¥æ¥­èˆ‡è³‡è¨Šç§‘æŠ€éƒ¨å‰¯éƒ¨é•·ã€ä¸­åœ‹é›»ä¿¡å‰¯ä¸»å¸­ã€ä¸­åœ‹ç§»å‹•é€š
ä¿¡å‰¯ä¸»å¸­ã€èˆ‡ä¸­åœ‹è¯é€šå‰¯ä¸»å¸­ç­‰é‡è¦äººç‰©ï¼Œå…¶è­°ç¨‹åŒ…å«äº† 3 å ´å°ˆé¡Œæ¼”è¬›ã€2 å€‹çŸ­æœŸèª²ç¨‹ã€èˆ‡ç™¾é¤˜ç¯‡
ç ”ç©¶è«–æ–‡çš„ç™¼è¡¨ï¼Œå…¶è­°é¡Œæ¶µè“‹ç„¡ç·šé€šè¨Šã€ç„¡ç·šç¶²è·¯ã€ç¶ èƒ½é€šè¨Šã€è¨Šè™Ÿè™•ç†ã€é€šè¨Šç†è«–ã€ç¶²è·¯å®‰å…¨ã€
å“è³ªä¿è­‰ã€æ–°å‹ç¶²è·¯æœå‹™ã€å…‰çº–ç¶²è·¯ç­‰é€šè¨Šç›¸é—œé ˜åŸŸã€‚ç”±æ–¼ IEEE ICCCåŒæ™‚é€²è¡Œçš„å ´æ¬¡ç´„æœ‰ 8å€‹ï¼Œ
æ‰€ä»¥ç„¡æ³•åƒèˆ‡æ‰€æœ‰å ´æ¬¡ï¼Œåªèƒ½æŒ‘é¸å¹¾å€‹èˆ‡è¨ˆç•«ç›¸é—œä¸»é¡Œï¼Œå¦‚é›²ç«¯é‹ç®—èˆ‡åˆ†æ•£å¼é‹ç®—ï¼Œç­‰è­°é¡Œç›¸é—œä¹‹
è«–æ–‡ç™¼è¡¨çš„å ´æ¬¡ä¾†åƒåŠ ã€‚ 
é€™æ¬¡çš„å°ˆé¡Œæ¼”è¬›é‚€è«‹åˆ° NYU-Polyçš„ T. R. Rappaportæ•™æˆé€²è¡Œé—œæ–¼ç„¡ç·šç¶²è·¯ä¸Šæ–°å‹çš„æ‡‰ç”¨ï¼›ä¸­
åœ‹å·¥æ¥­èˆ‡è³‡è¨Šç§‘æŠ€éƒ¨é€šè¨Šç ”ç©¶é™¢ä¸»å¸­ S. Caoåšå£«é€²è¡Œé—œæ–¼ ICTåœ¨ä¸­åœ‹çš„ç™¼å±•ï¼›ä»¥åŠè¯ç‚ºé€šè¨Šç§‘æŠ€å¯¦
é©—å®¤ä¸»ä»»W. Tongåšå£«é€²è¡Œé—œæ–¼è¡Œå‹•å¯¬é »ç¶²è·¯çš„æœªä¾†ç™¼å±•ç­‰è­°é¡Œã€‚å¾ 3å ´å°ˆé¡Œæ¼”è¬›ä¸­å¯ä»¥ç™¼ç¾æœªä¾†
è¡Œå‹•é€šè¨Šç¶²è·¯èˆ‡é›²ç«¯é‹ç®—çµåˆå·²ç¶“å‹¢ä¸å¯æ“‹ã€‚æœ¬äººæ‰€ç™¼è¡¨çš„è«–æ–‡è¢«å®‰æ’åœ¨æœƒè­°ç¬¬ 2å¤©ä¸‹åˆçš„ã€Œé›²ç«¯
æœå‹™èˆ‡è³‡æºç®¡ç†ã€å ´æ¬¡ä¸­é€²è¡Œå ±å‘Šï¼Œå…±æœ‰ 4ç¯‡è«–æ–‡åœ¨æ­¤å ´æ¬¡ä¸­é€²è¡Œå ±å‘Šã€‚æœ¬äººè¢«å®‰æ’åœ¨ç¬¬ 1é †ä½ï¼Œ
å ±å‘ŠçµæŸå¾Œéš¨å³æœ‰å­¸è€…æå‡ºå¦‚ä½•å–å¾—é›²ç«¯å¢é›†ä¸‹æ‰€æœ‰ç¯€é»çš„è³‡è¨Šï¼Œè€Œåœ¨æ‰€æå‡ºçš„æ–¹æ³•ä¸­å¿…é ˆè¦æœ‰ä¸€
å€‹Masterç¯€é»ä¾†é€²è¡Œè’é›†ç¯€é»è³‡è¨Šæ‰èƒ½æ“šä»¥é€²è¡Œå·¥ä½œåˆ†é…ã€‚ 
 
äºŒã€èˆ‡æœƒå¿ƒå¾— 
åœ¨æ­¤æ¬¡æœƒè­°ä¸­ï¼Œé™¤äº†å°ˆé¡Œæ¼”è¬›é‚€è«‹åˆ°çš„éƒ½æ˜¯åœ¨é€šè¨Šé ˜åŸŸå…§ç›¸ç•¶é‡è¦çš„äººç‰©å¤–ï¼Œæ‰€ç™¼è¡¨çš„ç ”ç©¶è«–
æ–‡éƒ½ç›¸ç•¶å…·æœ‰æ°´æº–ï¼Œå…¶ä¸­ä¸ä¹ç›¸ç•¶çŸ¥åå¤§å­¸ï¼Œä¾‹å¦‚å¤šå€«å¤šå¤§å­¸ã€åŒ—äº¬å¤§å­¸ã€å—åŠ å¤§ã€é›ªæ¢¨å¤§å­¸ã€
é¦™æ¸¯ç§‘æŠ€å¤§å­¸ã€å°ç£äº¤é€šå¤§å­¸ã€å°ç£æ¸…è¯å¤§å­¸ã€ä¼Šåˆ©è«¾å¤§å­¸é¦™æª³åˆ†æ ¡ã€é¦™æ¸¯ä¸­æ–‡å¤§å­¸ã€å¾©æ—¦å¤§å­¸ã€
è¨ˆç•«ç·¨è™Ÿ NSC100-2218-E-156-001 
è¨ˆç•«åç¨± å­è¨ˆç•«å››ï¼šé–‹ç™¼é›²ç«¯ä»²ä»‹å™¨é–˜é“ä¹‹ç’°å¢ƒæ„ŸçŸ¥è³‡æ–™åŠ å¯†èˆ‡åˆ†æ•£æœå‹™(I) 
å‡ºåœ‹äººå“¡
å§“å 
è˜‡ç¶­å®— 
æœå‹™æ©Ÿæ§‹
åŠè·ç¨± 
çœŸç†å¤§å­¸è³‡è¨Šå·¥ç¨‹å­¸ç³»/åŠ©ç†æ•™æˆ 
æœƒè­°æ™‚é–“ 
101å¹´ 8æœˆ 15æ—¥è‡³ 
101å¹´ 8æœˆ 18æ—¥ æœƒè­°åœ°é» ä¸­åœ‹åŒ—äº¬ 
æœƒè­°åç¨± 
(ä¸­æ–‡)ç¬¬ 1å±† IEEEä¸­åœ‹é€šè¨Šåœ‹éš›æœƒè­° 
(è‹±æ–‡) First IEEE International Conference on Communication in China 
ç™¼è¡¨è«–æ–‡
é¡Œç›® 
(ä¸­æ–‡) åœ¨ç•°è³ªé›²ä¸­è€ƒé‡ç¯€é»èƒ½åŠ›ä¹‹è³‡æºé…ç½®æ–¹æ³• 
(è‹±æ–‡) Node Capability Aware Resource Provisioning in a Heterogeneous 
Cloud 
Node Capability Aware Resource Provisioning in a 
Heterogeneous Cloud 
 
Wei-Tsung Su and Sun-Ming Wu 
Dept. of Computer Science and Information Engineering 
Aletheia University 
New Taipei City, Taiwan (R.O.C.) 
 
au4451@au.edu.tw and small-teeth@hotmail.com 
 
 
Abstractâ€”Although MapReduce, the core technology of cloud 
computing, lowers the barriers to enter the parallel computing, it 
introduces the other challenging research issue of improving its 
performance via properly resource provisioning. This issue is 
more complex in a heterogeneous cloud with multiple jobs since 
the nodes have various capability and workloads. In addition, the 
limited resources must be shared among all jobs. In this paper, 
this optimization problem, called Node Capability-aware 
Provisioning Problem (NCPP), is first formulated as a 
mathematical model. The purpose of NCPP is to minimize the job 
execution time which is influenced by node capability. However, 
NCPP is subject to the resource constraints on the nodes in a 
cloud. Moreover, the node Capability-Aware Resource 
Provisioner (CARP) is proposed based on Apache Hadoop to 
show its feasibility to solve NCPP in a systematic way. 
Keywordsï¼ Cloud computing; MapReduce; Hadoop; Resource 
provisioning 
 
I.  INTRODUCTION 
In recent years, there are many companies, such as Google, 
Facebook, Amazon, and Dropbox, rise suddenly according to 
their innovation Internet services. Typically, after users issue 
requests, these services are expected to response in time by 
processing massive data. Therefore, the cloud computing 
technology is received significant attention due to its capability 
of parallel and distributed computing. Cloud computing is the 
technology of achieving similar computation power of super 
computers by coordinating a number of commodity computers. 
In 2004, the core technology of cloud computing, MapReduce, 
is first announced by Google [1]. In this computation model, 
the massive data is divided into several splits and is then stored 
in the multiple data nodes via underlying distributed file 
systems, such as GFS [2] or HDFS [3]. When a job is 
submitted, the master node will dispatch the map tasks to these 
nodes for processing partial data and returning the intermediate 
results. After that, these intermediate results will be aggregated 
by the reduce tasks as needed [4]. 
One of the most challenging research issues in cloud 
computing is efficiently allocating computation resources with 
maximizing resulting utility (e.g. minimizing job execution 
time) [5], since there are various utility factors. Because a 
cloud cluster is typically composed of a number of 
heterogeneous computer nodes with various workloads, these 
nodes have different computation capability and dynamic 
available resources [6]. Thus, it is important to dispatch the 
right jobs to the right nodes in a heterogeneous cloud. For 
example, a job with feature of CPU-bound requires more 
computation resources than communication resources. On the 
contrary, a job with feature of IO-bound requires more 
communication resources than computation resources. In 
addition, the resource allocation must consider the capability 
and available resources of nodes. For executing a job, if the 
same number of tasks is allocated to heterogeneous nodes, the 
execution time may be prolonged since the bottleneck is the 
nodes with lower capability and available resources. 
Although several approaches have been proposed to solve 
the resource allocation problem in a heterogeneous cloud [7], 
most of them focus on allocating resources to single job or 
overlook the resource constraints [8]. However, in practical, the 
problem is more complex since there must be multiple jobs 
simultaneously requested [9] by users. In this paper, we first 
formulate the optimization problem of allocating the limited 
resources to multiple jobs according to the job feature and node 
capability. The objective is to maximizing the aggregate 
resulting utility. Moreover, the node Capability-Aware 
Resource Provisioner (CARP) is proposed based on Apache 
Hadoop [10] to show its feasibility to solve above optimization 
problem. 
The rest of the paper is organized as follows. In Section 2, 
related work is surveyed. Then, the problem formulation is 
modeled in Section 3. In Section 4, the detail of CARP is 
described. Finally, the paper is concluded in Section 5. 
II. RELATED WORK 
Due to the emerging of cloud computing, more and more 
government, industry and academic organizations launch 
various kinds of related research projects, including the 
performance of MapReduce which is one of the core 
technologies in cloud computing. Although MapReduce 
technically lowers the barriers to enter the parallel computing, 
it introduces another challenging research issue of improving 
MapReduce performance via properly resource provisioning. 
In this section, we will introduce the basics of MapReduce and 
First IEEE International Conference on Communications in China: Advanced Internet and Cloud (AIC)978-1-4673-2815-9/12/$31.00 Â©2012 IEEE 46
time is decreasing. Thus, the utility of job j is further 
formulated as 
j
j
e
u
1
= ,                (2) 
jCjPj TTe ,, +=                 (3) 
where jPT ,  and jCT ,  are the processing time and 
communication time, respectively. 
In addition, because the available resources of all nodes 
in a cloud must be shared among all jobs, the total allocated 
resources cannot exceed the available resources for each node 
in a cloud. Thus, NCPP is subject to the resource constraint as 
rn
J
j
njrnj Rxr ,
||
1
,,,
â‰¤â‹…âˆ‘
=
, ||,...,1 Nn =âˆ€ , ||,...,1 Rr = .      (4) 
Moreover, since the tasks of job j will be dispatched to a node 
set Nj for executing, NCPP is also subject to the node 
constraint as 
||
||
1
, j
N
n
nj Nx =âˆ‘
=
, ||,...,2,1 Jj =âˆ€              (5) 
By summarize Eq. (1) to Eq. (5), the NCPP is finally 
formulated as the following equations. 
Maximize                (6) 
âˆ‘
=
||
1
1J
j je
, 
Subject to 
rn
J
j
njrnj Rxr ,
||
1
,,,
â‰¤â‹…âˆ‘
=
, ||,...,1 Nn =âˆ€ , ||,...,1 Rr = , 
||
||
1
, j
N
n
nj Nx =âˆ‘
=
, ||,...,2,1 Jj =âˆ€  
where njx ,  is 1 if the node n is selected to run the tasks of job 
j and 0 otherwise. 
 
Table 1 Notation list 
Notation Description 
N The node set in a cloud 
J The job set in a cloud 
R The resource set in a node 
uj The utility of job j 
ej The execution time of job j 
Rn,r The available value of resource r in node n 
Nj The node set selected from N to run job j 
rj,n,r 
The allocated value of resource r in node n 
for running job j 
Sj The input data size of job j 
MSj The output data size from map tasks of job j 
SSj 
The split-size of job j. By default, the split-
size is 64MB in Hadoop. 
SIj 
The number of instructions per byte required 
to running job j. 
bwn The network bandwidth of node n 
cpn The instructions per second of node n 
 
IV. NODE CAPABILIRT AWARE RESOURCE PROVISIONER 
In order to solve NCPP systematically, the node 
capability-aware resource provisioner (CARP) is proposed in 
this section. In CARP, the resource provisioning will consider 
the job feature, the node capability and available resources. 
Moreover, CARP can be integrated into Hadoop. As shown in 
Fig. 3, the modification is that CARP will assist jobtracker in 
sharing resources among all jobs in an efficient way. 
 
Master Node
Jobtracker
1. Submit job
2. Store job 
data
Client JVM
3. Initialize 
job
4. Retrieve 
metadata
6. Retrieve 
data splitsHDFS
Namenode
TasktrackerDatanode
Slave Nodes
CARP
5. Dispatch 
tasks
 
Fig. 3. Proposed Hadoop MapReduce workflow 
 
The flow chart of CARP is shown in Fig. 4. There are 
four steps in CARP. In step 1, the job feature is first extracted. 
The job feature extraction is important since the resource 
requirements are different between a CPU-bound job and an 
IO-bound job. Then, the parallel degree of each job is 
determined according to the job feature and average node 
capability in a cloud in step 2. Finally, a two-stage procedure 
is employed for the purpose of solving NCPP. In coarse-
grained resource provisioning, NCPP is solved under the 
assumption of that tasks are uniformly allocated to nodes. 
Thus, in fine-grained resource provisioning, the task allocation 
will be further adjusted according to the node capability. The 
detailed description of CARP is described as follows. 
A. Job Feature Extraction 
The first step of CARP is job feature extraction. In this 
paper, we just consider the job feature which identifies a job is 
CPU-bound or IO-bound. The method of determining a job is 
a CPU-bound or an IO-bound job is beyond the scope of this 
paper. Based on the existing determination approaches 48
D. Fine-grained Resouce Provisioning 
In the coarse-grained resource-provisioning described as 
above, the job execution time is estimated based on the 
assumption of that all data splits are equally processed by the 
nodes selected to run this job. The reason is to decrease the 
complexity of NCPP. However, it is not practical in a 
heterogeneous cloud. For example, if there are node A and 
node B where cpA and cpB are 100MHz and 1GHz, 
respectively. If the same data splits are equally processed by 
node A and node B, then the processing time of node A will 
be 10 times of the processing time of node B. This will 
prolong the job execution time.  
Thus, the fine-grained resource provisioning is still 
required. In this step, the data-splits will be re-arranged to 
nodes according to node capability and workload. The re-
arrangement will be an iterative process which follows two 
heuristics. Firstly, the aggregate utility in NCPP must be 
higher than the previous arrangement. Secondly, the resource 
constraints in NCPP must still be met. 
 
V. CONCLUSION AND FUTURE WORK 
In this paper, the optimization problem for resource 
provisioning in a heterogeneous cloud with multiple jobs is 
first formulated as the Node Capability-aware Provisioning 
Problem (NCPP). In NCPP, the capability of nodes in a cloud 
will be considered in resource provisioning to minimize the 
job execution time. Moreover, the node capability-aware 
resource provisioner (CARP), which can be integrated into 
Hadoop, is designed to show its feasibility for solving NCPP 
in a systematic way. 
We focus on the problem formulation and system design 
in this paper. In the future, the algorithms in coarse-grained 
and fine-grained resource provisioning steps will be developed 
and integrated into Hadoop for further evaluation.  
 
Acknowledgement 
This paper is based on the work partially supported by 
National Science Council (NSC), Taiwan, R.O.C., under grant 
NSC100-2218-E-156-001 and NSC99-2632-H-156-001-MY3. 
 
REFERENCES 
[1] J. Dean. â€œExperiences with MapReduce, an abstraction 
for large-scale computation,â€œ in Proc. 15th International 
Conference on Parallel Architectures and Compilation 
Techniques, 2006, pp. 1. 
[2] S. Ghemawat, H. Gobioff and S.-T. Leung. â€œThe Google 
File System,â€ in Proc. ACM Symposium on Operating 
Systems Principles, 2003, pp. 29-43. 
[3] K. Shvachko, â€œThe Hadoop Distributed File System,â€ in 
Proc. IEEE 26th Symposium on Mass Storage Systems 
and Technologies, 2010, pp. 1-10. 
[4] T. White. Hadoop: The Definitive Guide, 2nd Edition. 
Sebastopol, CA: Oâ€™Reilly Media, Inc., 2010. 
[5] S. Khatua. â€œOptimizing the utilization of virtual 
resources in Cloud environment,â€œ in Proc. IEEE 
International Conference on Virtual Environments 
Human-Computer Interfaces and Measurement Systems, 
2010, pp. 82-87 
[6] T. Sandholm and K. Lai. â€œDynamic Proportional Share 
Scheduling in Hadoop,â€ in Proc. 15th International 
Workshop on Job Scheduling Strategies for Parallel 
Processing, 2010, pp. 110-131. 
[7] J. U. Duselis. â€œResource selection and allocation for 
dynamic adaptive computing in heterogeneous 
clusters,â€œ in Proc. IEEE International Conference, 
Cluster Computing and Workshops, 2009, pp. 1-9.  
[8] L. F. Bittencourt. â€œScheduling Service Workflows for 
Cost Optimization in Hybrid Clouds,â€ in Proc. 
International Conference, Network and Service 
Management, 2010, pp. 394-397. 
[9] Y. O. YazÄ±r, C. Matthews, R. Farahbod, S. Neville, A. 
Guitouni, S. Ganti, and Y. Coady. â€œDynamic Resource 
Allocation in Computing Clouds using Distributed 
Multiple Criteria Decision Analysis,â€ in Proc. IEEE 3rd 
International Conference on Cloud Computing, 2010, pp. 
91-98. 
[10] Wikipedia. â€œApache Hadoop.â€ Internet: 
http://zh.wikipedia.org/wiki/Hadoop [Dec. 30, 2011] 
[11] J. Dean and S. Ghemawat. â€œMapReduce: Simplied data 
processing on large clusters.â€ Communications of the 
ACM, vol. 51, pp. 107-113, Jan. 2008.  
[12] M. Tim. â€œScheduling in Hadoop.â€ Internet: 
http://www.ibm.com/developerworks/linux/library/os-
hadoop-scheduling/index.html?ca=drs- [Dec. 6, 2011] 
[13] C. Tian, H. Zhou, Y. He, and L. Zha. â€œA Dynamic 
MapReduce Scheduler for Heterogeneous Workloads,â€ 
in Proc. 8th International Conference on Grid and 
Cooperative Computing, 2009, pp. 218-224. 
[14] E. Rosti, G. Serazzi, E. Smirni, and M.S. Squillante. 
â€œModels of Parallel Applications with Large 
Computation and I/O Requirements.â€ IEEE Transaction 
on Software Engineering, vol. 28, pp. 286-307, Mar. 
2002. 
[15] E. Rosti, G. Serazzi, E. Smirni, and M.S. Squillante. 
â€œThe Impact of I/O on Program Behavior and Parallel 
Scheduling,â€ in Proc. SIGMETRICS Joint Conference 
on Measurement and Modeling of Computing Systems, 
1998, pp. 56-65 
[16] W. Lee, M. Frank, V. Lee, K. Mackenzie and L. 
Rudolph, â€œImplications of I/O for Gang Scheduled 
Workloads.â€ Lecture Notes in Computer Science, vol. 
1291, pp. 215-237, 1997. 
[17] Y. Wiseman. â€œPaired Gang Scheduling.â€ IEEE 
Transactions on Parallel and Distributed System, vol. 
14, pp. 581-592, Jun. 2003. 
[18] W. Su and W. Pan. â€œAn Adaptive Task Allocation 
Approach for MapReduce in a Heterogeneous Cloud,â€ 
in Proc. 3rd International Conference on Computational 
Intelligence, Communication Systems and Networks, 
2011, pp. 287-291. 
[19] J. Wu. â€œReal-time scheduling of CPU-bound and I/O-
bound processes,â€ in Proc. Real-Time Computing 
Systems and Applications, 1999, pp. 303-310. 50
 2
ä¸‰ã€ å»ºè­° 
æ­¤è¡Œåœ¨æ¾³æ´²çš„è¡Œç¨‹ï¼Œå› ç‚ºæ˜¯ä»Šå¹´åº¦ç¬¬ 2ç¯‡ç™¼è¡¨çš„è«–æ–‡ï¼Œæ‰€ä»¥é›–ç„¶åœ‹ç§‘æœƒè¨ˆç•«ä»æœ‰è£œåŠ©éƒ¨åˆ†å·®æ—…
è²»ï¼Œä½†æ˜¯ä¸¦ä¸è¶³ä»¥æ¶µè“‹æœ¬æ¬¡æœƒè­°çš„èŠ±è²»ã€‚ç”±æ–¼ç™¼è¡¨æœƒè­°è«–æ–‡ä¸€å®šè¦å‡ºåœ‹å ±å‘Šè€Œä¸”èƒ½å¤ å°±æœ‰æ©Ÿæœƒèˆ‡
åœ‹å¤–å­¸è€…äº¤æµï¼Œå› æ­¤åœ‹ç§‘æœƒæ˜¯å¦å¯è€ƒé‡åœ¨ç‰¹å®šé ˜åŸŸä¹‹æŒ‡æ¨™æ€§æœƒè­°å¯ä»¥å†å‘åœ‹åˆè™•ç”³è«‹ç›¸é—œç¶“è²»ä»¥
é¼“å‹µè€å¸«å‡ºåœ‹ç™¼è¡¨è«–æ–‡ã€‚ 
 
å››ã€ æ”œå›è³‡æ–™åç¨±åŠå…§å®¹ 
1. IEEE PIMRC 2012 æœƒè­°è­°ç¨‹ä¸€æœ¬    (Program) 
2. IEEE PIMRC 2012 è«–æ–‡é›†å…‰ç¢Ÿä¸€ç‰‡ (Proceeding) 
 
äº”ã€ å…¶ä»– 
 
derive a secure routing path while considering system 
performance. 
The rest of the paper is organized as follows. In Section 2, 
some related works about network security are mentioned. 
Then, the proposed system, Cross-Layer Network Security 
Evaluation is described in Section 3 and a Secure Dynamic 
Routing Protocol based on Cross-Layer Network Security 
Evaluation is proposed in Section 4. Next, some simulation 
results are presented in Section 5. Finally, the paper is 
concluded in Section 6. 
II. RELATED WORKS 
A. Network Security Evaluation 
To evaluate network security, there are four security 
elements to be discussed: threats, vulnerabilities, 
countermeasures and security requirements. Vulnerabilities are 
threatened by threats. Countermeasures are applied to resist 
attacks from threats while security requirements represent the 
actual demands of security protection.  
A probabilistic-based system security evaluation approach is 
proposed in [7]. In this approach, vulnerabilities are assessed 
according to their probability. However, the countermeasures 
and security requirements are not considered. Another system 
security evaluation which adopts a decision-tree based 
approach to quantify system risk is proposed in [8]. In this 
approach, authors describe a general-purpose evaluation model 
which simultaneously consider about vulnerabilities, threats 
and countermeasures. However, the lack of security 
requirement consideration makes it impractical to real network 
environments. 
More vulnerability evaluation or threat analysis systems [9] 
for system security are enumerated in [10]. Most of these 
network security evaluations talk about the system security 
rather than communication security. Besides, none of them 
consider all the four security elements simultaneously. 
B. CVSS 
CVSS [1] is proposed by the US National Infrastructure 
Assurance Council (NIAC) to evaluate system vulnerabilities. 
In CVSS, score are derived from three metrics based metric, 
temporal metric and environmental metric, which are described 
as follows. 
1) Base Metric: for a vulnerability, the metric represents the 
attributes that will not change over time or in different 
environments. For example, how the vulnerability is 
exploited, the complexity of the attack required to exploit 
the vulnerability, the number of times an attacker must 
authenticate to exploit a vulnerability, and the impact of on 
confidentiality, integrity and availability, are included in 
the base metrics. 
2) Temporal Metric: for a vulnerability, the metric measures 
the attributes that might change over time, such as the 
current state of exploit techniques, the remediation level of 
a vulnerability, and the degree of confidence in the 
existence of the vulnerability, are temporal metrics. 
3) Environmental Metric: for a vulnerability, the metric 
measures the attributes that might change in different 
environments. For example, operation system type, data 
asset values, and security requirements, are environmental 
metrics. 
By combining the above metrics, the severity level of system 
vulnerability is evaluated. However, as CVSS is designed only 
for system vulnerability, it does not consider about threats and 
communication security. Some other research applies CVSS to 
evaluate security [5] or tries to improve CVSS [6]. However, all 
of them are applied to evaluate system security. 
C. Routing Security 
Distributed Dynamic Routing Algorithm (DDRA) [3] is an 
approach proposed for communication security. By using the 
multi-path routing technique, DDRA decreases the probability 
of that the communication between source and destination is 
eavesdropped by routers. The approach assumes that attacks 
can be triggered only by the compromised routers. In fact, most 
attacks are launched by outsider attackers, nevertheless. The 
approach proposed in [4] adopts similar concept. 
Several cross-layer design security evaluation approaches 
[11], [12] are proposed to assess network security level. By 
adopting the cross-layer concept, the security countermeasures 
applied over different layers are well considered in network 
security evaluation. Thus, the cross-layer evaluation 
approaches provide more accurate result of security level. Thus, 
we adopt cross-layer design concept to evaluate network 
security in the paper. 
 Fig 2 Cross-Layer Threat Danger Intensity Evaluation Flow 
III. CROSS-LAYER NETWORK SECURITY EVALUATION 
In this section, the proposed Cross-Layer Network Security 
Evaluation (CNSE) is introduced. There are two major steps in 
CNSE. Firstly Cross-Layer Threat Danger Intensity Evaluation 
(CTDIE) is applied to access the danger intensity of individual 
threat in a link. Then, Threat-based Link Risk Evaluation 
(TLRE) is applied to derive a Link Risk Score which indicates 
the security level of a link by considering the danger intensity 
of all threats on the link.  
304
influenced vulnerability (IV) in ITP and application-based 
security requirement (SR) in UTP, is described as follows. 
z Influenced Vulnerability: We define the network 
vulnerability as short of the protection for a specific 
security objective in the network. For example, short of 
confidentiality protection is one kind of vulnerability. 
There are several definitions made for security objectives. 
In X.800 [13], the main security objectives are 
authentication, access control, confidentiality, integrity, 
non-repudiation. In TIPHON [14], the security objectives 
include confidentiality, integrity, accountability, 
availability, and non-repudiation. In the paper, the network 
vulnerabilities are defined as short of protection for the 
security objectives including authentication, 
confidentiality, integrity, non-repudiation, and availability. 
A complete influenced vulnerability would be assigned a 
higher score which indicates it is more insecure. 
z Application-based Security Requirement: In the paper, 
the security requirement is defined as the demand of a 
specific security objective. Various applications might 
have different security requirements. For example, to 
provide confidentiality protection of personal credit card 
information is the most important requirement in 
E-Commerce. We have to analyze the property of an 
application to find its actual requirements. And then, we 
can pay more attention to protecting the critical security 
objective. The more attention we pay to a security 
objective, the higher score it should be assigned. 
Obtaining the subjective metrics is typically done by security 
professionals and is time-consuming. Thus, the advantage of 
representing a threat property as an objective metric is that it is 
easily derived in an automatic way. For examples, attack record 
(AR) and countermeasure (CM) in ETP can be derived as 
follows. 
z Attack Record: Attacked records represent the 
trustworthy level of a relay router. If a relay router is 
attacked before, it might be attacked again. We use the 
following formula to assess the trustworthy level of relay 
router at time t 
atttARtAR uu )1()1()( OO                                    (1) 
where O  is the weighted value to adjust the historical 
influence, and att represents the numbers of attack in the 
time period. Relay router will update the AR value 
periodically. 
z Cross-Layer Counter-Measure: Countermeasures are 
applied to protect security objectives from threats. In 
X.800, countermeasures are classified into several 
categories, which are key management, encipherment, 
digital signature, access control, data integrity, 
authentication, traffic padding, routing control, and 
notarization. For cryptographic-based mechanisms, the 
concept of cracking year proposed in [12] is adopted to 
evaluate the strength of a countermeasure. By employing 
the Infeasible Key Size function proposed in [15], we can 
derive the time when a key will be cracked and further use 
it to represent the strength of the countermeasure.  
3) Threat Danger Intensity Evaluation:  
After User Device obtains the threat profiles, Threat Danger 
Intensity Evaluator is launched to derive the threat exploit 
possibility (EP) in relay router R at time t by: 
Rthreat NStARDDADAOAPtREP xx )()(),( GJED   (2) 
1 w GJE                    
(3) 
where GJED ,,,  are the weighted values of exploit possibility 
parameters in OTP. )(tAR  is the attacked record at time t 
derived as (1). RNS  is the network status of relay router R. 
Furthermore, the threat impact in router R at time t for user U 
can be derived as follows: 
 Â¦ Â˜Â˜Â˜Â˜
 
V
UUVRVV
threat
IRAssetSRtCMIV
UtRimpact
,, )(
),,(
                              (4) 
Â¦  
V
UVSR 1,                        (5) 
where V represents the security objectives in the network since 
Influenced Vulnerability, Countermeasure, and Security 
Requirements are all related to security objectives. For a threat, 
VIV  indicates the level how security objective V is influenced 
by the threat;  tCM RV ,  represents the strength of 
countermeasure to defend the threat for security object V in 
router R at time t, and UVSR ,  can be denoted as the required 
protection of security objective V for the user U. 
Finally, the Threat Danger Intensity Evaluation Metric is 
defined as follows: 
 ),,(),(),,( UtRimpacttREPUtRDI threatthreatthreat Â˜          (6) 
where ),,( UtRDIthreat  is the danger intensity of the threat in 
relay router R, at time t, for the user U. As the danger intensity 
will be applied to derive the link risk, the higher score indicates 
higher danger.  
B. Threat-based Link Risk Evaluation 
After obtaining the danger intensity (DI) of all threats, TLRE 
is employed to evaluate the risk of transmitting data on a link. 
Since it is obvious that the link risk is significantly decided by 
the most dangerous threat on this link, TLRE derives the Link 
Risk Score (LR) by 
}:{ DBinlistthreatinthreatsDIMAXLR threatlink              (7) 
IV. SECURE DYNAMIC ROUTING PROTOCOL 
As in Fig 3, we assume that there is a Layer-based Threat 
Profile DB provided by the trusted third party. Every Router 
will query the latest Original Threat Profile from the DB. 
According to the environment status of routers, they will 
provide their Environment Threat Profile to every user. Users 
will then derive the link risk scores of all links and decide a 
secure path by employing the Secure Dynamic Routing 
Protocol. 
306
indicates there is no danger link in the path.  
 
Table IV. Results of SDRP with Security Consideration 
 RPS RRS MLR connect 
OSPF 0.4 1.2 0.8 100% 
B-SDRP 0.9 0.8 0.6 100% 
S-SDRP 0.8 0.9 0.5 90% 
E-SDRP 0.9 1 0.3 100% 
 
S D
R1
R2
R3
R4
R5
R6
R7
R8
R9
R10
0.2 / 0.3
0.2 / 0.2
0.3 / 0.2
0.3 / 0.2
0.5 / 0.3
0.3 / 0.2
0.2 / 0.3
0.9 / 0.2
0.1 / 0.3 0.1 / 0.3
0.6 / 0.3
0.7 / 0.3 0.6 / 0.3
0.3 / 0.1
0.3 / 0.2 0.3 / 0.2
0.2 / 0.2
OSPF
B-SDRP
S-SDRP
E-SDRP
Fig 5. The Derived Paths of SDRP with Security Consideration 
C. Simulation Results with Security and Performance 
Consideration  
The simulation results are represented in Table V and Fig6. 
As shown in Table V, the RPS and RRS in both B-SDRP and 
S-SDRP is 0.7 and 1.1, respectively. It means they select a path 
more efficient than they originally do. Although, the RRS is 
lower with considering performance, it is still better than OSPF. 
  
Table V. Results of SDRP with Security and Performance Consideration 
 RPS RRS MLR connect 
B-SDRP 0.7 1.1 0.3 100% 
S-SDRP 0.7 1.1 0.3 90% 
E-SDRP 0.9 1 0.3 100% 
 
S D
R1
R2
R3
R4
R5
R6
R7
R8
R9
R10
0.2 / 0.3
0.2 / 0.2
0.3 / 0.2
0.3 / 0.2
0.5 / 0.3
0.3 / 0.2
0.2 / 0.3
0.9 / 0.2
0.1 / 0.3 0.1 / 0.3
0.6 / 0.3
0.7 / 0.3
0.6 / 0.3
0.3 / 0.1
0.3 / 0.2 0.3 / 0.2
0.2 / 0.2
B-SDRP
S-SDRP
E-SDRP
 Fig 6. The Derived Paths of SDRP with Security and Performance 
Consideration 
VI. CONCLUSIONS 
In the paper, the Secure Dynamic Routing Protocols based 
on Cross-Layer Network Security Evaluation are proposed. By 
analyzing the properties of various threats, threat danger 
intensity is evaluated and quantified through our Cross-Layer 
Threat Danger Intensity Evaluation (CTDIE). Then, the 
transmission risk on a link can be derived by our Threat-based 
Link Risk Evaluation (TLRE) according to the danger intensity 
of threats. Base on this comprehensive network security 
evaluation, we propose several Secure Dynamic Routing 
Protocols due to various requirements. By providing a secure 
routing path, the communication security can be retained.  The 
simulation results show that we can obtain a secure routing path 
by the proposed SDRP even with the performance 
consideration. In the future, we will try to improve the 
evaluation framework by integrating system security evaluation. 
By the evolved evaluation, a routing path with complete 
security consideration can be obtained.  
ACKNOWLEDGMENTS 
This paper is based partially on work supported by the 
National Science Council (NSC) of Taiwan, R.O.C., under 
grant No. NSC98-2221-E-006-222-MY3 and NSC100-221
8-E-156-001. 
REFERENCES 
[1] M. Peter, S. Karen, and R. Sasha, â€œCommon Vulnerability Scoring 
System,â€ IEEE Security and Privacy Magazine 2006 
[2] P. Dan, Z. Lixia, D. Massey, â€œA Framework for Resilient Internet 
Routing Protocols,â€ IEEE Network Magazine, 2004 
[3] K. Chin-Fu, P. Ai-Chun, C. Sheng-Kun, â€œDynamic Routing with Security 
Considerations,â€ IEEE Transactions on Parallel and Distributed Systems, 
2009  
[4] P. Tague, D. Slater, J. Rogers, and R. Poovendran, â€œEvaluating the 
Vulnerability of Network Traffic Using Joint Security and Routing 
Analysis,â€ IEEE Transactions on Dependable and Secure Computing, 
2009 
[5] S. Petajasoja, H. Kortti, A. Takanen, and J. Tirila, â€œIMS Threat and 
Attack Surface Analysis Using Common Vulnerability Scoring System,â€ 
IEEE 35th Annual Computer Software and Applications Conference 
Workshops (COMPSACW), 2011 
[6] M. Peter, S. Karen, â€œImproving the Common Vulnerability Scoring 
System,â€ IET Information Security, 2007 
[7] M.S. Ahmed, E. Al-Shaer, L. Khan, â€œA Novel Quantitative Approach For 
Measuring Network Security,â€ IEEE INFOCOM 2008 
[8] M. Sahinoglu, â€œSecurity meter: a practical decision-tree model to quantify 
Risk,â€ IEEE Security and Privacy Magazine, 2005 
[9] C. Alberts, A. Dorofee, J.Stevens, C. Woody, "OCTAVE Method 
Implementation Guide", CERT Coordination Centre, Software 
Engineering Institute, Carnegie Mellon Institute, 
2001-2003, http://www.cert.org/octave/ 
[10] N.R. Prasad, â€œThreat Model Framework and Methodology for Personal 
Networks (PNs),â€ International Conference on Communication Systems 
Software and Middleware, 2007. COMSWARE 2007. 
[11] Avesh K. Agarwal, Wenye Wang and Janise Y. McNair, "An 
Experimental Study of Cross-Layer Security Protocols in Public Access 
Wireless Networks," IEEE GLOBECOM 2005 
[12] I-Hsun Chuang,  Chou-Ting Hsieh, and  Yau-Hwang Kuo, â€œAn Adaptive 
Cross-Layer Design Approach for Network Security Management,â€ 
International Conference on Advanced Communication Technology 
(ICACT), 2011  
[13] The International Telegraph and Telephone Consultative Committee, 
â€œSecurity Architecture for Open Systems Interconnection for CCITT 
Applications Recommendation X.800,â€  
[14] ETSI. "Telecommunications and internet protocol harmonization over 
networks (TIPHON) release 4; protocol framework definition; methods 
and protocols for security; part 1: Threat analysis", Technical 
Specification ETSI TS 102 165-1 V4.61.v1, 2003, 
[15] Arjen K, Lenstra, and Eric R. Verheul, â€œSelecting Cryptographic Key 
Sizes,â€ Journal of Cryptology, vol. 14, pp. 255-293, 1999 
308
100ï¦ï¨å°ˆé¡Œç ”ç©¶è¨ˆç•«ç ”ç©¶æˆæœå½™æ•´è¡¨ 
è¨ˆç•«ä¸»æŒäººï¼šè˜‡ç¶­å®— è¨ˆç•«ç·¨è™Ÿï¼š100-2218-E-156-001- 
è¨ˆç•«åç¨±ï¼šå…·å‚™å¤šå±¤æ¬¡ç”¨æˆ¶æƒ…å¢ƒæ„ŸçŸ¥ã€å®‰å…¨åŠæœå‹™å“è³ªå”èª¿èƒ½ï¦Šä¹‹æ™ºæ…§å‹é›²ç«¯æœå‹™ä»²ä»‹å™¨é–˜é“é–‹ç™¼,--
å­è¨ˆç•«å››ï¼šé–‹ç™¼é›²ç«¯ä»²ä»‹å™¨é–˜é“ä¹‹ç’°å¢ƒæ„ŸçŸ¥è³‡ï¦¾åŠ å¯†èˆ‡åˆ†æ•£æœå‹™(I) 
ï¥¾åŒ– 
æˆæœé …ç›® å¯¦éš›å·²é”æˆ
ï¥©ï¼ˆè¢«æ¥å—
æˆ–å·²ç™¼è¡¨ï¼‰
é æœŸç¸½é”æˆ
ï¥©(å«å¯¦éš›å·²
é”æˆï¥©) 
æœ¬è¨ˆç•«å¯¦
éš›è²¢ç»ç™¾
åˆ†æ¯” 
å–®ä½ 
å‚™ è¨» ï¼ˆ è³ª åŒ– ï¥¯
æ˜ï¼šå¦‚ï¥©å€‹è¨ˆç•«
å…±åŒæˆæœã€æˆæœ
ï¦œ ç‚º è©² æœŸ åˆŠ ä¹‹
å° é¢ æ•… äº‹ ...
ç­‰ï¼‰ 
æœŸåˆŠï¥æ–‡ 0 0 100%  
ç ”ç©¶å ±å‘Š/æŠ€è¡“å ±å‘Š 3 3 100% 
éœ€æ±‚è¦æ ¼èˆ‡å°ˆæ¡ˆ
è¨ˆç•«ã€æ¸¬è©¦è¨ˆç•«èˆ‡
æ¸¬è©¦å ±å‘Šã€çµæ¡ˆå ±
å‘Š 
ç ”è¨æœƒï¥æ–‡ 0 0 100% 
ç¯‡ 
 
ï¥æ–‡è‘—ä½œ 
å°ˆæ›¸ 0 0 100%   
ç”³è«‹ä¸­ä»¶ï¥© 0 0 100%  å°ˆï§ å·²ç²å¾—ä»¶ï¥© 0 0 100% ä»¶  
ä»¶ï¥© 0 0 100% ä»¶  
æŠ€è¡“ç§»è½‰ 
æ¬Šï§ï¤Š 0 0 100% åƒå…ƒ  
ç¢©å£«ç”Ÿ 1 1 100% å³å­«éŠ˜(ç›®å‰æœå½¹ä¸­) 
åšå£«ç”Ÿ 0 0 100%  
åšå£«å¾Œç ”ç©¶å“¡ 0 0 100%  
åœ‹å…§ 
ï¥«èˆ‡è¨ˆç•«äººï¦Š 
ï¼ˆæœ¬åœ‹ç±ï¼‰ 
å°ˆä»»åŠ©ï§¤ 0 0 100% 
äººæ¬¡ 
 
æœŸåˆŠï¥æ–‡ 0 0 100%  
ç ”ç©¶å ±å‘Š/æŠ€è¡“å ±å‘Š 0 0 100%  
ç ”è¨æœƒï¥æ–‡ 2 2 100% 
ç¯‡ 
è©³ï¨Šå‡ºå¸­åœ‹éš›æœƒ
è­°å ±å‘Š 
ï¥æ–‡è‘—ä½œ 
å°ˆæ›¸ 0 0 100% ç« /æœ¬  
ç”³è«‹ä¸­ä»¶ï¥© 0 0 100%  å°ˆï§ å·²ç²å¾—ä»¶ï¥© 0 0 100% ä»¶  
ä»¶ï¥© 0 0 100% ä»¶  
æŠ€è¡“ç§»è½‰ 
æ¬Šï§ï¤Š 0 0 100% åƒå…ƒ  
ç¢©å£«ç”Ÿ 1 1 100% é»ƒå‚‘ç¿”(ç›®å‰ç‚ºç¢©å£«ç­äºŒï¦ç´š) 
åšå£«ç”Ÿ 0 0 100%  
åšå£«å¾Œç ”ç©¶å“¡ 0 0 100%  
åœ‹å¤– 
ï¥«èˆ‡è¨ˆç•«äººï¦Š 
ï¼ˆå¤–åœ‹ç±ï¼‰ 
å°ˆä»»åŠ©ï§¤ 0 0 100% 
äººæ¬¡ 
 
