è¡Œæ”¿é™¢åœ‹å®¶ç§‘å­¸å§”å“¡æœƒè£œåŠ©å°ˆé¡Œç ”ç©¶è¨ˆç•«â–“æˆæœå ±å‘Š  
â–¡æœŸä¸­é€²åº¦å ±å‘Š 
 
å¤šé‚Šå½¢ç¶²æ ¼åˆ†å‰²è½‰æ› 
 
è¨ˆç•«é¡åˆ¥ï¼šâ–“å€‹åˆ¥å‹è¨ˆç•«   â–¡æ•´åˆå‹è¨ˆç•« 
è¨ˆç•«ç·¨è™Ÿï¼šNSC 99-2221-E-009-118 
åŸ·è¡ŒæœŸé–“ï¼š99 å¹´ 8 æœˆ 1 æ—¥è‡³ 101 å¹´ 3 æœˆ 31 æ—¥ 
 
åŸ·è¡Œæ©Ÿæ§‹åŠç³»æ‰€ï¼š 
 
è¨ˆç•«ä¸»æŒäººï¼šèŠæ¦®å®  åœ‹ç«‹äº¤é€šå¤§å­¸è³‡è¨Šå·¥ç¨‹ç³»æ•™æˆ 
å…±åŒä¸»æŒäººï¼š 
è¨ˆç•«åƒèˆ‡äººå“¡ï¼šæå®œäº­ã€åŠ‰æ–‡é”ã€å¾å­Ÿæšã€è¶™ä¿®ç¯„ã€æ—è‚²å³ã€æ¥Š
ç­±ç­‘ã€ä½•ä¸¹æœŸã€å»–ä»å‚‘ã€å»–ä»è±ªã€é»ƒç¨‹åœ‹ã€æç´¹è¤† 
 
æˆæœå ±å‘Šé¡å‹(ä¾ç¶“è²»æ ¸å®šæ¸…å–®è¦å®šç¹³äº¤)ï¼šâ–“ç²¾ç°¡å ±å‘Š â–¡å®Œæ•´
å ±å‘Š 
 
æœ¬è¨ˆç•«é™¤ç¹³äº¤æˆæœå ±å‘Šå¤–ï¼Œå¦é ˆç¹³äº¤ä»¥ä¸‹å‡ºåœ‹å¿ƒå¾—å ±å‘Šï¼š 
â– èµ´åœ‹å¤–å‡ºå·®æˆ–ç ”ç¿’å¿ƒå¾—å ±å‘Š 
â–¡èµ´å¤§é™¸åœ°å€å‡ºå·®æˆ–ç ”ç¿’å¿ƒå¾—å ±å‘Š 
â–¡å‡ºå¸­åœ‹éš›å­¸è¡“æœƒè­°å¿ƒå¾—å ±å‘Š 
â–¡åœ‹éš›åˆä½œç ”ç©¶è¨ˆç•«åœ‹å¤–ç ”ç©¶å ±å‘Š 
 
 
è™•ç†æ–¹å¼ï¼šé™¤åˆ—ç®¡è¨ˆç•«åŠä¸‹åˆ—æƒ…å½¢è€…å¤–ï¼Œå¾—ç«‹å³å…¬é–‹æŸ¥è©¢ 
    â–¡æ¶‰åŠå°ˆåˆ©æˆ–å…¶ä»–æ™ºæ…§è²¡ç”¢æ¬Šï¼Œâ–¡ä¸€å¹´â–¡äºŒå¹´å¾Œå¯å…¬é–‹æŸ¥è©¢ 
 
ä¸­   è¯   æ°‘   åœ‹ 101 å¹´ 6 æœˆ  4  æ—¥ 
1. å‰è¨€ 
ç‰¹å¾µæˆ–å¹¾ä½•é‹ç®—ä¹‹è½‰æ›åœ¨å¹¾ä½•è™•ç†æ˜¯ä¸€å€‹é‡è¦çš„ç ”ç©¶èª²é¡Œã€‚æ­¤ç ”ç©¶ä¹‹å‹•æ©Ÿæ˜¯
ç¾ä»Šç¶²æ ¼åˆ†å‰²çš„è«¸å¤šæ–¹æ³•å„æœ‰å…¶å„ªç¼ºé»ï¼Œå„æœ‰å…¶é©åˆçš„ç¶²æ ¼å‹æ…‹ï¼Œé€šå¸¸ä¸€å€‹
æ–¹æ³•ç„¡æ³•å°æ‰€æœ‰ç‰©é«”ç”¢å‡ºå¥½çš„åˆ†å‰²çµæœï¼Œè€Œä¸”åˆ†å‰²çš„çµæœå¸¸èˆ‡äººç‚ºåˆ†å‰²çµæœ
æœ‰æ‰€å·®è·ã€‚æˆ‘å€‘çš„æ–¹æ³•å¯ä»¥å°‡ä¸€å€‹å¥½çš„ç¶²æ ¼åˆ†å‰²çµæœè½‰æ›åˆ°ä¸€å€‹é¡ä¼¼çš„ç‰©é«”ã€‚
ç›®å‰æˆ‘å€‘çš„ä½œæ³•æ¯”è¼ƒæ˜¯ä»¥å¹¾ä½•å‡ºç™¼ï¼Œè—‰ç”±éª¨æ¶å°æ‡‰çš„æ–¹æ³•å…ˆå°‡ä¾†æºç¶²æ ¼åˆ†å‰²
çš„é‚Šç•Œå„˜é‡å°æ‡‰åˆ°ç›®æ¨™ç¶²æ ¼ä¸Šï¼Œå†æ ¹æ“šå¹¾ä½•çš„ç´°ç¯€å»èª¿æ•´ç›®æ¨™ç¶²æ ¼çš„åˆ†å‰²é‚Š
ç•Œï¼Œä½¿ç›®æ¨™ç¶²æ ¼çš„å¹¾ä½•ç´°ç¯€èƒ½å¤ å’Œå°æ‡‰åˆ°çš„ä¾†æºåˆ†å‰²é‚Šç•Œç›¸ä¼¼ã€‚æ­¤æ–¹æ³•å°è‚¢
é«”å‹•ç‰©ä¹‹æ¸¬è©¦æˆæœä¸éŒ¯ï¼Œä½†å°å½¢é«”æ‹“æ¨¸å·®ç•°è¼ƒå¤§è€…ä¹‹æ•ˆæœè¡¨ç¾ä¸å¤ªç©©å®šï¼Œé€™
æ¬¡èˆ‡é¦¬æ•™æˆè¨è«–çš„æ–¹å‘æ˜¯å¸Œæœ›å¯ä»¥æ‡‰ç”¨æ©Ÿå™¨å­¸ç¿’çš„è§€å¿µåˆ°ç¶²æ ¼åˆ†å‰²è½‰æ›ã€‚ 
 
2. æ–‡ç»æ¢è¨ 
å½¢é«”å°æ‡‰ï¼ˆshape correspondenceï¼‰ 
å½¢é«”å°æ‡‰åœ¨å¹¾ä½•è™•ç†æ˜¯ä¸€å€‹å¾ˆé‡è¦çš„ç ”ç©¶èª²é¡Œã€‚å½¢é«”å°æ‡‰é€šå¸¸æ˜¯ä½¿ç”¨ Reeb 
graphæˆ–ç‰©é«”çš„éª¨æ¶ä¾†åšå°æ‡‰[HSKK01, TS04, SSGD03, BMSF06]ã€‚åœ¨ 
Graph matching çš„æ–¹æ³•ä¸­ï¼Œé€šå¸¸å­åœ–ï¼ˆsubgraphï¼‰æœƒè¢«æ ¹æ“šå¹¾ä½•æ€§è³ªçš„æœ€å°
èª¤å·®ä¾†é€²è¡Œä¸€å°ä¸€çš„å°æ‡‰ã€‚è€Œé€™é¡æ–¹æ³•é€šå¸¸æœƒæœ‰å…©å€‹å•é¡Œã€‚ä¸€å€‹æ˜¯å°ç¶²æ ¼çš„
æ‹“æ’²éæ–¼æ•æ„Ÿï¼Œå› ç‚ºä¸€èˆ¬çš„å­åœ–å»ºç«‹æ˜¯ä¾é åœ–å½¢çš„é€£çµæ€§ã€‚å¦ä¸€å€‹å‰‡æ˜¯å°ç¨±
æ€§äº¤æ›[ZSCO*08]ã€‚ä¾‹å¦‚å·¦å³æ‰‹å¸¸æœƒè¢«å°æ‡‰éŒ¯èª¤ï¼Œå› ç‚ºé€™æ¨£çš„éª¨æ¶æœƒæœ‰ç›¸åŒçš„
èªç¾©ä»¥åŠç›¸ä¼¼çš„å¹¾ä½•è³‡è¨Šã€‚è€Œæˆ‘å€‘çš„æ–¹æ³•åˆ©ç”¨éª¨æ¶ç¯€é»å’Œç¶²æ ¼é ‚é»ä¹‹é–“çš„é—œ
è¯ã€éª¨æ¶çš„ç©ºé–“è³‡è¨Šä¾†è§£æ±ºç¬¬ä¸€å€‹å•é¡Œã€‚ç¬¬äºŒçš„å•é¡Œå‰‡ä½¿ç”¨äº¤å‰ç¯€é»é€£çµçš„
éª¨æ¶é€²è¡Œå±€éƒ¨çš„å°æ‡‰ä¾†é¿å…ã€‚æˆ‘å€‘çš„æ–¹æ³•æœƒé©ç•¶çš„åˆä½µéª¨æ¶ç¯€é»æˆ–æ˜¯éª¨æ¶åˆ†
æ”¯ï¼Œé€™æœƒç”¢ç”Ÿå¤šå°å¤šçš„å°æ‡‰çµæœï¼Œä¸¦æé«˜æ­£ç¢ºå°æ‡‰çš„å¯èƒ½æ€§ã€‚è€Œ[ATCO*10]
å‰‡æ˜¯åˆ©ç”¨æŠ•ç¥¨(voting)çš„æ–¹å¼å»è¨ˆç®—ä¸€å°ä¸€å€‹å°æ‡‰ï¼Œæ ¹æ“šç¥¨æ•¸é«˜ä½ä¾†é¸å‡ºæœ€
å¥½çš„çµæœã€‚é€™å€‹æ–¹æ³•ä¸¦ä¸èƒ½åˆä½µä»»ä½•çš„éª¨æ¶ç¯€é»ï¼Œå› ç‚ºæŠ•ç¥¨æ–¹æ³•å°æ–¼ä¸åŒçš„
åˆä½µè¨­è¨ˆæœ‰ä¸åŒçš„æ„ç¾©ï¼Œè€Œç›®å‰ä¸¦ä¸æ¸…æ¥šå¦‚ä½•æ ¹æ“šæŠ•ç¥¨ä¾†èª¿æ•´æœ€å¥½çš„å°æ‡‰çµ
æœã€‚è€Œæˆ‘å€‘çš„æ–¹æ³•å‰‡æ˜¯æ¡ç”¨è¨ˆç®—æœ€å°æˆæœ¬çš„æ–¹å¼ï¼Œå› æ­¤å¯ä»¥å¾—åˆ°æœ€å¥½çš„çµæœã€‚ 
 
ç¶²æ ¼åˆ†å‰²(mesh segmentation) 
å¤§å¤šæ•¸ç¶²æ ¼åˆ†å‰²çš„æ¼”ç®—æ³•å¤§è‡´åˆ†ç‚ºå…©ç¨®ï¼šä¸€ç¨®æ˜¯å°‡ç¶²æ ¼åˆ†æˆä¸€å¡Šå¡Šè£œä¸
(patch)ï¼Œä¸”æ¯å¡Šè£œä¸éƒ½æ»¿è¶³ä¸€äº›å±¬æ€§ï¼›å¦ä¸€ç¨®å‰‡æ˜¯å°‡ç¶²æ ¼åˆ†å‰²æˆå°äººé¡ä¾†èªª
å…·æœ‰èªç¾©çš„çµ„æˆ(å¦‚ part)ã€‚ä¸åŒçš„åˆ†å‰²æ¼”ç®—æ³•å°æ–¼åŒä¸€å€‹ç¶²æ ¼é€šå¸¸æœƒç”¢ç”Ÿä¸
åŒçš„åˆ†å‰²çµæœï¼Œè€Œä¸€è‡´çš„ç¶²æ ¼åˆ†å‰²ç›®çš„å°±åœ¨æ–¼èƒ½å¤ åŒæ™‚å°ä¸€çµ„ç¶²æ ¼ä½œä¸€è‡´çš„
åˆ†å‰²ã€‚[GF09]è€ƒæ…®äº†å€‹åˆ¥ç¶²æ ¼çš„å¹¾ä½•ç‰¹å¾µä»¥åŠç¶²æ ¼ä¹‹é–“çš„å°æ‡‰è³‡è¨Šï¼Œåˆ©ç”¨å°
 åœ–1 éª¨æ¶å°æ‡‰çš„æ¨¹ç‹€çµæ§‹ç¤ºæ„åœ–ã€‚ 
 
 
åœ–2 ä¸åŒé¡è‰²ä»£è¡¨ä¸åŒçš„å­éª¨æ¶ã€‚ 
 
 
åœ–3 äº¤å‰ç¯€é»çš„åˆä½µã€‚ 
3.2 æ¸¬è©¦çµæœ 
æˆ‘å€‘ç”¨å¥½å¹¾ç¨®æ¨¡å‹è­‰å¯¦æˆ‘å€‘çš„æ–¹æ³•å¯ä»¥æœ‰æ•ˆåœ°æ‰¾å‡ºæ­£ç¢ºçš„å°æ‡‰çµæœï¼Œå¦‚åœ–6
æ‰€ç¤ºã€‚å°æ‡‰çš„ç¯€é»æœƒé¡¯ç¤ºå‡ºç›¸åŒçš„é¡è‰²ï¼Œæ²’æœ‰å°æ‡‰åˆ°çš„ç¯€é»å‰‡ä¸æœƒé¡¯ç¤ºåœ¨åœ–
ä¸Šï¼Œèªç¾©ç›¸ä¼¼çš„éƒ¨ä½éƒ½å¯ä»¥æœ‰æ­£ç¢ºçš„å°æ‡‰ã€‚å’Œ[ATCO*10]åšæ¯”è¼ƒ(è¦‹åœ–7)ï¼Œå¯
ä»¥å¾ˆæ˜é¡¯åœ°çœ‹åˆ°æˆ‘å€‘çš„çµæœæ¯”è¼ƒå¥½ã€‚[ATCO*10]åœ¨é¦¬çš„è€³æœµå’Œç‹—çš„å˜´å·´éƒ¨åˆ†æœƒ
å°æ‡‰éŒ¯èª¤ï¼Œåœ¨è±¬çš„è€³æœµå’Œé¾çš„ä¸Šé¡ä¹Ÿå°æ‡‰éŒ¯èª¤ã€‚ 
ä½†æ˜¯æˆ‘å€‘çš„æ–¹æ³•åœ¨æœ‰äº›èªç¾©çš„å°æ‡‰ä»æœ‰å¯èƒ½æœƒå‡ºç¾éŒ¯èª¤ï¼Œä¾‹å¦‚é¦¬çš„è€³æœµå’Œ
ç‰›çš„ç‰›è§’ã€‚é‚„æœ‰åœ¨æ¥åˆç¯€é»é™„è¿‘è‹¥æ˜¯å…¶å½¢ç‹€è¼ƒç‚ºå¹³ç·©ï¼Œæˆ‘å€‘æœƒç„¡æ³•ç”¨éª¨æ¶æ¨
æ–·å‡ºå‰å¾Œï¼Œå› æ­¤æœ‰å¯èƒ½æœƒå‡ºç¾éŒ¯èª¤çš„å°æ‡‰ã€‚æ­¤å¤–ï¼Œè‹¥æ˜¯äººé€ æ¨¡å‹æˆ‘å€‘ç„¡æ³•å–
å¾—è¼ƒå¥½çš„éª¨æ¶æˆ–æ˜¯éª¨æ¶ç„¡æ³•å¿ å¯¦åœ°æ•æ‰æ¨¡å‹çš„å½¢ç‹€ï¼Œé‚£æˆ‘å€‘çš„çµæœå°±æœƒå—åˆ°
å¾ˆå¤§çš„å½±éŸ¿ã€‚ 
 
 
åœ–6 å°ä¸åŒæ¨¡å‹çš„å°æ‡‰çµæœã€‚ 
 
 
åœ–7 èˆ‡[ATCO*10]æ¯”è¼ƒçµæœã€‚ 
4.2 æ¸¬è©¦çµæœ 
åœ–9å¯ä»¥çœ‹åˆ°æˆ‘å€‘çš„å¯¦é©—çµæœï¼Œå°æ‡‰çš„éƒ¨ä½æœƒæœ‰ç›¸åŒçš„é¡è‰²ã€‚æˆ‘å€‘å¯ä»¥å°‡ä¾†æº
ç¶²æ ¼çš„åˆ†å‰²çµæœæ­£ç¢ºçš„è½‰æ›åˆ°ç›®æ¨™ç¶²æ ¼ä¸Šã€‚åœ¨åœ–9ï¼Œç‹—çš„è€³æœµå’Œäººçš„æ¨¡å‹ä¸¦æ²’
æœ‰å°æ‡‰ï¼Œå› æ­¤åˆ†å‰²çš„çµæœå°±ä¸æœƒè½‰æ›åˆ°äººçš„æ¨¡å‹ä¸Šï¼Œä½†å…¶ä»–åŒé¡å‹çš„æ¨¡å‹éƒ½
å¯ä»¥æœ‰æ­£ç¢ºçš„åˆ†å‰²è½‰æ›ã€‚æˆ‘å€‘å°‡æ–¹æ³•å’Œä¸€äº›è¿‘æœŸçš„æ–¹æ³•åšæ¯”è¼ƒ(è¦‹åœ–10ã€åœ–11ã€
åœ–12)ã€‚åœ¨åœ–10ï¼Œå¯ä»¥å¾ˆæ˜é¡¯çš„çœ‹åˆ°[GF09]åœ¨æ¨¡å‹æœ‰è¼ƒå¤§ä¸åŒå½¢ç‹€çš„æ™‚å€™ï¼Œä¸¦
ä¸èƒ½å¾ˆå¥½çš„è½‰æ›ï¼Œä½†æˆ‘å€‘çš„æ–¹æ³•å› ç‚ºæœ‰åšéª¨æ¶çš„å°æ‡‰ï¼Œå› æ­¤å¯ä»¥æœ‰ä¸éŒ¯çš„çµ
æœã€‚åœ–11å’Œåœ–12æ˜¯å’Œ[KHS10]åšæ¯”è¼ƒçš„çµæœï¼Œæˆ‘å€‘çš„é‚Šç•Œåˆ‡å‰²çµæœæ›´å¥½ã€‚ä½†æ˜¯
æˆ‘å€‘çš„çµæœå¥½å£å–æ±ºæ–¼éª¨æ¶å°æ‡‰çš„çµæœï¼Œå¦‚æœéª¨æ¶ç„¡æ³•å¾ˆå¥½çš„æ•æ‰åˆ°ç¶²æ ¼çš„
å½¢ç‹€ï¼Œæˆ‘å€‘çš„åˆ†å‰²çµæœæœƒå—åˆ°å½±éŸ¿ï¼Œé€™ç®—æ˜¯ä¸€å€‹é™åˆ¶ã€‚ 
 
 
 
åœ–9 ç¶²æ ¼åˆ†å‰²è½‰æ›çµæœã€‚ 
 
 
 
åœ–10 èˆ‡[GF09]æ¯”è¼ƒçµæœã€‚ 
æ ¼çš„åˆ†å‰²çµæœå°æ‡‰åˆ°ç›®æ¨™ç¶²æ ¼ä¸Šã€‚ä¾†æºå’Œç›®æ¨™ç¶²æ ¼èªç¾©ä¸Šéœ€è¦ç›¸ä¼¼ï¼Œä½†å¹¾ä½•
ä¸Šå¯ä»¥æœ‰æ‰€ä¸åŒã€‚æˆ‘å€‘å…ˆç™¼å±•å‡ºä¸€å€‹å…©å€‹ç¶²æ ¼é–“çš„æ–°çš„éª¨æ¶å°æ‡‰æ–¹æ³•ï¼Œåˆ©ç”¨
éª¨æ¶ç¯€é»å’Œå…¶å‘¨åœç¶²æ ¼é ‚é»çš„å¹¾ä½•è³‡è¨Šä»¥åŠæ‹“æ’²çµæ§‹ä¾†åšéª¨æ¶å°æ‡‰ã€‚ä½†æ˜¯å°
æ–¼ä¸åŒçš„éƒ¨ä½ï¼Œéª¨æ¶ä¹Ÿè¨±ä¹Ÿæœƒæœ‰ä¸åŒçš„é€£çµæ–¹å¼ï¼Œç‚ºäº†é™ä½é€™ç¨®ä¸ç¢ºå®šæ€§ï¼Œ
æˆ‘å€‘å»ºç«‹äº†æ¨¹ç‹€çµæ§‹ï¼Œç”¢ç”Ÿå¥½å¹¾ç¨®ä¸åŒçš„çµæœï¼Œç„¶å¾Œå¾ä¸­é¸æ“‡æœ€å¥½çš„ä¸€å€‹ã€‚
è€Œç¶²æ ¼åˆ†å‰²è½‰æ›å°±è—‰ç”±éª¨æ¶å°æ‡‰å…ˆå°‡ä¾†æºç¶²æ ¼åˆ†å‰²çš„é‚Šç•Œå„˜é‡å°æ‡‰åˆ°ç›®æ¨™ç¶²
æ ¼ä¸Šï¼Œå†æ ¹æ“šå¹¾ä½•çš„ç´°ç¯€å»èª¿æ•´ç›®æ¨™ç¶²æ ¼çš„åˆ†å‰²é‚Šç•Œï¼Œä½¿ç›®æ¨™ç¶²æ ¼çš„å¹¾ä½•ç´°
ç¯€èƒ½å¤ å’Œå°æ‡‰åˆ°çš„ä¾†æºåˆ†å‰²é‚Šç•Œç›¸ä¼¼ã€‚é€™å…©å€‹ç¶²æ ¼è™•ç†çš„æ¼”ç®—æ³•éƒ½å…· 
ç›¸ç•¶çš„å‰µæ–°åŠç”¢æ¥­æ‡‰ç”¨åƒ¹å€¼ã€‚é€™å…©é …æˆæœéƒ½å·²æ’°å¯«æˆè«–æ–‡ï¼Œæ­£æŠ•ç¨¿åœ‹éš›æœŸåˆŠ
ä¸­ã€‚ 
 
7. åƒè€ƒè³‡æ–™ 
[ATCO_10] AU O.-C., TAI C., COHEN-OR D., ZHENG Y., FU. H.: Electors voting for 
fast automatic shape correspondence. Comp. Graph. Forum 29, 2 (2010), 645â€“
654. 
[BL08] BAI X., LATECKI L.: Path similarity skeleton graph matching. IEEE Trans. on 
PAMI 30 (2008), 1282â€“1292. 
[BMSF06] BIASOTTI S., MARINI S., SPAGNUOLO M., FALCIDIENO B.: Sub-part 
correspondence by structural descriptors of 3D shapes. Comp. Aided Design 38, 9 
(2006), 1002â€“1019. 
[GF09] GOLOVINSKIY A., FUNKHOUSER T.: Consistent segmentation of 3D models. 
Comp. Graph. Forum 33, 3 (2009), 262-269 
[HSKK01] HILAGA M., SHINAGAWA Y., KOHMURA T., KUNII T. L.: Topology 
matching for fully automatic similarity 
[KHS10] KALOGERAKIS E., HERTZMANN A., Singh K.: Learning 3D mesh 
segmentation and labeling. ACM TOG Forum 29, 4 (2010) 1-12 
[SSGD03] SUNDAR H., SILVER D., GAGVANI N., DICKINSON S.: Skeleton based 
shape matching and retrieval. In Shape Modeling Intâ€™l (2003), p. 130. 
[TS04] TUNG T., SCHMITT F.: Augmented reeb graphs for content-based retrieval 
of 3D mesh models. In Shape Modeling Intâ€™l (2004), pp. 157â€“166. 
[ZSCO*08] ZHANG H., SHEFFER A., COHEN-OR D., ZHOU Q., VAN KAICK O., 
TAGLIASACCHI A.: Deformation-driven shape correspondence. Symposium on 
Geometry Processing (2008), 1431â€“1439. 
 
Online submission ID:1077 / A Skeleton-Based Approach for Shape Correspondence
counts are adjusted for computing the best shape correspon-
dence. This is because the vote counts for different merging
schemes may have different meanings. In our method, we
may merge skeletal nodes and obtain different shape corre-
spondences for different merging schemes. But we can still
compute the best shape correspondence which has the min-
imum cost. Our method may compute not only 1-1 corre-
spondences but also many-many correspondences between
skeletal nodes of two objects.
A method based on path similarity is considered for com-
puting correspondence between the skeleton graphs of two
2D images [BL08]. A skeleton is treated as a set of geodesic
paths formed by the terminal skeletal nodes. The paths of
the two skeletons are matched by using sequence matching.
Their method can match the terminal skeletal nodes but it
cannot match the internal skeletal nodes. Our method relies
on the spatial information of skeletal branches and the asso-
ciation between the skeletons and vertices of objects. Our
method can match both the external and internal skeletal
nodes of the two skeletons.
An approximate skeleton which is a planar graph having
at most degree three, is obtained by tracing the medial seg-
ments of the inner triangles in a constrained Delaunay tri-
angulation of the polygon. Mortara and Spagnuolo [MS01]
proposed a method for matching the approximate skeletons
of 2D polygonal objects according to the similarity of the
skeletal junction nodes and arcs. Our approach adopts the
similar approach for matching skeletons based on the simi-
larity of junction nodes and branches. However, our compu-
tation is involved with the association between the skeletal
nodes and vertices of 3D objects. Furthermore, we cluster
similar branches so as to reduce the searching space.
2. Related Work
Shape correspondence is one of the important research top-
ics in geometry processing. A comprehensive survey can be
found in [vKZHCO10]. We review the approaches for shape
correspondence that are mostly related to our work.
Graph-matching has been adopted for matching the Reeb
graphs or skeletons of objects [HSKK01, TS04, SSGD03,
BMSF06]. Common subgraphs are computed so that the
nodes of the common subgraphs form an one-to-one map-
ping with the minimum deviation of geometric properties.
These approaches have two common problems: (1) sensitive
to mesh topology and (2) symmetry switching [ZSCOâˆ—08].
The first problem is due to that the construction of the com-
mon subgraphs depends on the graph connectivity. These ap-
proaches may be affected by small unwanted branches and
topological difference. The second problem is due to that
some skeletal nodes representing the same semantic parts
have similar geometric information, such as left/right hands
in a human model. The left hand may be mapped to the right
hand. We attempt to handle these two problems. The first
problem is handled by using the association between skeletal
nodes and vertices, and the spatial information of the skele-
tons. We may merge close-by junction nodes and group sim-
ilar skeletal branches as clusters. Most of the bad correspon-
dences can be eliminated. The second problem is tackled by
using shape matching locally for the skeletal branches at-
tached at the skeletal junction nodes. We observe that the ori-
entation of the skeletal branches does not change much for
most objects with different poses. We can match the skeletal
branches attached at the junction nodes based on the local
orientation of the skeletal branches.
A combinatorial search is adopted to compute electors and
they are applied in the cascading pruning tests [ATCOâˆ—10].
Each elector votes on individual feature-to-feature matching
for computing the final correspondence. The approach may
mismatch the close-by nodes. This is because inconsistent
results may be obtained by using MDS (multi-dimensional
scaling) transformation [EK03]. In our approach, we may
merge the adjacent skeletal junction nodes and the adjacent
branches so as to avoid the mismatched problem. In the elec-
tor voting approach, the vote count is not easy to be justified
for skeletons with various merged skeletal nodes and merged
skeletal branches. Furthermore, the final correspondence of
their approach is determined based on the vote count. The
connectivity between the matched skeletal nodes may be
messed up. On the other hand, we consider the spatial in-
formation of skeletal branches for matching and hence we
do not have this problem.
Path similarity is considered for computing correspon-
dence between two skeleton graphs of two images [BL08].
The method can match only the terminal nodes as they con-
sider only the geodesic paths which connect terminal nodes.
Mortara and Spagnuolo [MS01] proposed a method for eval-
uating the similarity between skeletal junctions and arcs so
as to match the 2D skeletons. Our method shares the similar
approach of these two techniques, but we also consider the
association between the skeletal nodes and vertices that is
important for analysing the geometric properties around the
skeletal nodes.
3. Overview
We present the definitions, notations and a brief overview of
our approach in this section.
3.1. Definitions and Notations
A skeletal node is associated with a set of vertices after the
skeleton is built, such as the method in [ATCâˆ—08]. The set of
vertices associated with a skeletal node often lay around it. A
skeletal node having one adjacent skeletal node is a terminal
node. A skeletal junction node is a skeletal node having three
or more adjacent skeletal nodes. A feature skeletal node is
either a terminal node or a junction node. A skeletal branch
cÂ© 2011 The Author(s)
cÂ© 2011 The Eurographics Association and Blackwell Publishing Ltd.
Online submission ID:1077 / A Skeleton-Based Approach for Shape Correspondence
Algorithm 3 matchOneCoreJunctionNodePair(P,Ks,Kt )
1: Input: the node P of correspondence tree; augmented skeletons Ks and Kt
2: for each node ns âˆˆ Ks do
3: for each node nt âˆˆ Kt do
4: if ns can be matched with nt then
5: add a child C to P
6: C.MatchingIn f oâ† P.MatchingIn f oâˆª (ns ,nt ) //set matching info. of C.
7: matchRemaining(C,ns,nt ,Ks,Kt )
8: end if
9: end for
10: end for
Algorithm 4 matchingRemaining(P,ns,nt ,Ks ,Kt )
1: Input: the node P of correspondence tree;matched junction node pairs (ns,nt ); aug-
mented skeletons Ks and Kt
2: (B, Ë†K1 , Ë†K2)â† matchBranches(ns,nt ,Ks,Kt )
3: if B != nil then
4: add a child C to P
5: C.MatchingIn f oâ† P.MatchingIn f oâˆª B
6: for each (bs ,bt ) âˆˆ B do
7: (nâ€²s ,nâ€²t ,Kâ€²s ,Kâ€²t ) <- matchJunctionNodePair(C,bs/ns,bt/nt ,Kâ€²s ,Kâ€²t )
8: if (nâ€²s ,nâ€²t ) != nil then
9: add a child C1 to C
10: C1 .MatchingIn f oâ† C.MatchingIn f oâˆª (nâ€²s ,nâ€²t )
11: matchRemaining(C1,nâ€²s ,nâ€²t ,Kâ€²s ,Kâ€²t )
12: end if
13: end for
14: end if
Table 1. The computation is fully automatic once the param-
eters are given. In practice, a user can usually obtain accept-
able results after tuning the parameters two to three times.
Parameters Purpose Value
K Number of pieces for constructing 8
the branch descriptor (Sec. 4.2.2)
Î»B Clustering of skeletal branches with similar 0.1
branch descriptors (Sec. 4.2.2)
CJ Cost for matching skeletal junction nodes 0.012 - 0.025
(Sec. 4.2.3)
dJ Distance for merging skeletal junction nodes 5 - 10
(% of the bounding box diagonal of the mesh, Sec. 4.2.3)
Table 1: The four parameters of our method.
4. Augmented Skeleton-Based Shape Correspondence
In this section, we present our method for establishing the
shape correspondence between two objects by matching
their augmented skeletons Ks (source) and Kt (target). We
use the subscript s and t to differentiate the elements of
the two skeletons. A correspondence tree is built for match-
ing the skeletal feature nodes and skeletal branches in a
breadth-first-search manner. Each node of the correspon-
dence tree stores the matched skeletal feature nodes and
skeletal branches while the correspondence tree is built. A
schematic diagram of constructing the correspondence tree
is shown in Fig. 3.
Initially the correspondence tree has one node, i.e. root,
which does not contain any matched pairs. Alg. 1 lists the
initialization procedure. We match a skeletal junction node
Figure 3: A correspondence tree for matching two aug-
mented skeletons. Core junction nodes are first matched. The
remaining skeletal branches and skeletal junction nodes are
matched in an interleaving manner.
pair with the minimum cost and create a node of the corre-
spondence tree. The newly created node of the correspon-
dence tree becomes the child node of the current inspected
node, i.e. the root node. The matching information is stored
in the child node. We proceed to match the remaining skele-
tal branches and skeletal nodes in an interleaving manner.
This process is invoked recursively until we cannot match
any more. Each leaf node of the final correspondence tree
represents a correspondence candidate. The leaf node with
the minimum cost is the best skeleton correspondence.
4.1. Core Junction Node Correspondence
The centricity cost Ccenter(ns,nt) is defined by:
Ccenter(ns,nt) = |AGD(ns)âˆ’AGD(nt)|, (1)
where AGD(Â·) is the normalized averaged geodesic
distance (âˆˆ [0,1]) of the junction node, which is
computed by averaging the AGD values of the ver-
tices associated with the junction node. In other
words, AGD(ns) = 1|Ï†(ns)| âˆ‘vâˆˆÏ†(ns) AGD(v) and
AGD(nt) = 1|Ï†(nt)| âˆ‘vâˆˆÏ†(nt) AGD(v). The centricity cost
measures how far a skeletal node is away from the center
of the object. The definition of the centricity cost is similar
to [ATCOâˆ—10]. However, we consider the AGD of the
vertices associated with the skeletal node instead of the
skeletal node itself. In this way, the geometric properties
of the vertices around the skeletal node can be taken into
consideration.
cÂ© 2011 The Author(s)
cÂ© 2011 The Eurographics Association and Blackwell Publishing Ltd.
Online submission ID:1077 / A Skeleton-Based Approach for Shape Correspondence
coordinate system at nt such that ns locates at nt (see
Fig. 5(b)). Assume that there are Nâ€² and Mâ€² unmatched
skeletal branches at ns and nt , respectively, Nâ€² â‰¥Mâ€². Hence,
there are Mâ€² branch pairs to match. In total, there are Mâ€²!CN
â€²
Mâ€²
combinations for matching the Mâ€² branch pairs.
We adopt a greedy approach to match Mâ€² branch pairs.
Assume that P = (p1, p2, ..., pMâ€²) and Q = (q1,q2, ...,qMâ€²),
where pi and qi are the unit branch vectors at the
matched junction pair (ns,nt). We employ shape matching
[MHTG05] to compute a rotation matrix R by minimizing
the sum of the distances between the branch vector pairs.
The angle difference between a branch vector pair (pi,qi) is:
ang(pi,qi) = acos(dot(pi,Rqi))/pi, (4)
where dot(Â·, Â·) is the dot product of two vectors. The spatial
cost for (P,Q) is given by
Cspatial(P,Q) =
Mâ€²
âˆ‘
i=1
(ang(pi,qi))2. (5)
Now, the cost for matching P and Q is computed as
Cbranch(P,Q)= (Cstruct(Bs(ns),Bt(nt))+Îµ)âˆ—(Cspatial (P,Q)+Îµ).
(6)
The cost Cbranch not only depends on the spatial orienta-
tion of the skeletal branches but also the structures of the
sub-skeletons generated at ns and nt . We sort all the possi-
ble skeletal branch correspondences with ascending cost and
select the first 10% of the skeletal branch correspondences.
For each possible branch correspondence (P, Q) at (ns,nt),
a new node of the correspondence tree is created. After that
we have matched the Mâ€² skeletal branch pairs. The roles of
P and Q are swapped if Mâ€² > Nâ€².
The rotation matrix R can be used for filtering the bad
skeletal branch correspondences which are due to symmetry.
If the determinant of the R is negative (i.e. -1), it represents
that the rotation matrix involves a reflection. Such a skeletal
branch correspondence should be ignored.
We do not adopt MDS [EK03] for computing the branch
vectors. This is because the relative orientations of some
branches may not be maintained, as shown in Fig. 6.
4.2.2. Clustering of Skeletal Branches
Some parts of a mesh have the same semantic meanings,
such as front/back legs and ears. They have similar shapes
and geometric features. We can group these similar parts
as clusters in order to prune bad correspondences. The idea
is as follows. Each part is usually associated with a skele-
tal branch. We divide each skeletal branch b into K pieces,
namely b1, b2, ..., and bK . After that we can compute a
value for the geometric property of each piece. In our case,
we compute MSP value of each piece (see MSP value in
Sec. 5). MSP value captures roughly the local volume around
a skeletal node. The advantage of using MSP value over the
Figure 6: The two skeletons are obtained before and after
applying MDS, respectively. The two branches (n1,n2) and
(n1,n3) are symmetric with respect to the junction node n1
after MDS is performed.
radius of the maximum sphere at a skeletal node is that us-
ing MSP value is more suitable if the objects deform. Con-
sider a deformed circle in Fig. 8. The radius of the cir-
cle changes significantly but its perimeter does not change
much. We have MSP(bk) =
âˆ«
pâˆˆbk
MSP(p)dp
|bk| , where |bk| is the
length of bk. The value MSP(bk) is normalized by the max-
imum MSP value of individual objects so that MSP(bk) is
scale-invariant. There are K values for each branch and they
are assembled as a k-dimension vector, namely, branch de-
scriptor. Assume that there are two branch descriptors `i and
` j. The corresponding two skeletal branches are clustered if
â€–`iâˆ’` jâ€–2 â‰¤ Î»B. The branch clusters are illustrated in Fig. 7.
If two branches are clustered, they cannot be clustered with
other branches. To handle three or more branches with sim-
ilar branch descriptors, we create a new node of the corre-
spondence tree for each pair of the branches.
Figure 7: Clusters of the skeletal branches at a junction
node ni. Each cluster is drawn in the same color. Left: The
two back legs; Middle: The two front legs; Right: The two
two ears.
Figure 8: A deformed circle. Its perimeter does not change
much but the radius of the maximum incircle is changed sig-
nificantly.
cÂ© 2011 The Author(s)
cÂ© 2011 The Eurographics Association and Blackwell Publishing Ltd.
Online submission ID:1077 / A Skeleton-Based Approach for Shape Correspondence
The MSP function is a scalar function defined on the sur-
face of a mesh. Slices of a point p are defined as the inter-
section curves with the set of planes generated by the nor-
mal of the surface in p. The MSP value of p is the minimum
perimeter of all slices of p. The MSP value of a point is usu-
ally approximated by uniformly sampling as it is not easy
to generate all the slices of the point. In our experiments, we
used 12 slices for each point. An example is shown in Fig. 11
for computing the MSP value of a point. The MSP value of
a point can be used for approximating the volume around a
slice by supplying a thickness value.
Figure 11: The MSP value of a point p (red thick line). There
are 12 slices for each model.
An MSP skeleton is built as follows. The slice of each
vertex which has the minimum perimeter is computed. Each
vertex is then transformed to the center point of the inter-
sected curve between the minimum slice and the object. The
transformed vertices likely locate at the interior of the origi-
nal mesh and they form a new mesh which is skinny. We call
this skinny mesh a shrunk mesh. A greedy skeletonization
process is then employed for degenerating the shrunk mesh
by performing a sequence of edge swap operators in order to
obtain a 1D curved skeleton. The greedy skeletonization pro-
cess is similar to [ATCâˆ—08]. During the process, the trans-
formed vertices are merged to obtain skeletal nodes. Hence,
each skeletal node of the curved skeleton is mapped to a
set of the vertices. Some of the vertices may not be associ-
ated with any skeletal nodes because unwanted short skeletal
branches and their corresponding vertices are removed.
6. Results and experiments
We present the results of our method for computing shape
correspondence and then discuss its limitations.
Results. In the preprocessing stage, we computed the
skeletons of the models and AGD of the vertices. We then
applied our method for a variety of models. The dog skele-
ton is the source. The skeleton correspondence results are
shown in Fig. 12. The matched node pairs are drawn in the
same colors but the unmatched nodes are not shown. All of
the semantic parts (e.g. legs, heads, and ears) are matched
correctly. Since our method performs junction node merging
and branch merging, there may be one-to-many or many-
to-many correspondences between junction nodes and also
between branches. This is different from the previous ap-
proaches [HSKK01, BMSF06, ATCOâˆ—10] which establish
only one-to-one mapping. For example, a junction node at
the chest of the dog is matched with two junction nodes at
the chest of the goat. Our method can handle the skeletons
of chairs with loops, as shown in Fig. 13.
Comparisons. We compared our method with the method
by Au et al. [ATCOâˆ—10]. Fig. 14 shows two sets of corre-
spondence results. For the top example, their method mis-
matches an ear of the horse to the jaw of the dog. For the
bottom example, their method mismatches the ears of the pig
to the upper jaw of the dragon. Our method produces correct
results due to branch clustering. The ears form clusters and
they cannot be matched with the non-clustered jaws.
Compared to [BL08], our method can match the internal
nodes of the skeletons. Our method matches the core junc-
tion nodes, and then match the remaining branches and junc-
tion nodes in an interleaving manner. So that our method can
match the internal nodes.
Model #Tri. AGD MSP SE MAS
Function Function
Dog(source) 18976 157.71 25.86 33.23 -
Deer 7402 22.23 5.04 3.57 0.20
Human 11258 43.05 5.10 9.74 0.22
Armadillo 20000 193.32 30.10 23.63 0.24
Dragon 16000 199.02 27.79 28.16 0.19
Triceratops 15764 104.33 18.17 27.44 0.21
Elephant 30000 500.30 52.73 146.08 0.30
Asian dragon 28198 490.70 44.54 37.28 0.41
Table 2: Model complexities, the timings (sec) of the pre-
processing tasks and the timings of matching the augmented
skeletons. SE: Skeleton extraction; MAS: Matching the aug-
mented skeletons.
Timing information. All the results were performed on
Intel Core 2 Duo CPU E8400 3.0GHz with 4GB memory, us-
ing a single thread implementation. We precomputed AGD
function, MSP function, and skeleton extraction. Table 2
shows the timing information of the preprocessing computa-
tion and the timings of performing the shape correspondence
(i.e. matching the augmented skeletons of the objects). The
computation time for shape correspondence is under 0.5 sec-
ond in all our experiments. Table3 shows the information of
the correspondence trees which were constructed for match-
ing the augmented skeletons of the objects.
The searching space of our method is smaller than the
combinatorial searching method [ZSCOâˆ—08, ATCOâˆ—10] as
we perform branch clustering. The total number of the pos-
sible matchings between the two skeletons reduce dramati-
cally. Fig. 15 shows three leaf nodes of the correspondence
tree for matching the skeletons of the dog and giraffe mod-
els. The best result is shown in Fig. 15(a). The cost of
the best node is smaller if more feature nodes and skeletal
branches are matched. Similar to other existing techniques,
our method requires the manual operations to change the pa-
rameters if the results are not good. It usually takes a few
cÂ© 2011 The Author(s)
cÂ© 2011 The Eurographics Association and Blackwell Publishing Ltd.
Online submission ID:1077 / A Skeleton-Based Approach for Shape Correspondence
Figure 14: Comparison with the method [ATCOâˆ—10]. Left: the results of [ATCOâˆ—10]; Right: our results. Their method mis-
matches the nodes at the heads (highlighted by the red squares).
7. Conclusions
We have presented a novel skeleton-based approach for com-
puting shape correspondence. Our method may merge skele-
tal nodes and branches so that it may compute 1-1 corre-
spondences and many-many correspondences. Our method
has been tested for a variety of similar objects and they may
have different poses. The experimental results show that our
method can compute acceptable shape correspondence.
Our method relies on the association between the skeletal
nodes and object vertices, but we do not consider the actual
shape of the parts for matching. Our method may fail to com-
pute a reasonable shape correspondence if the objects are not
similar. One possible extension of our work is to consider
the actual shape of the parts so that partial correspondence
can be computed. Another possible extension is that instead
of selecting the core junction nodes, the parts of the objects
are first extracted by employing skeletons. After that we can
match the parts and build the entire shape correspondence.
Furthermore, we would like to apply prior knowledge with
our method for computing shape correspondence.
References
[ATCâˆ—08] AU O. K.-C., TAI C.-L., CHU H.-K., COHEN-OR
D., LEE T.-Y.: Skeleton extraction by mesh contraction. ACM
TOG 27, 3 (2008).
[ATCOâˆ—10] AU O.-C., TAI C., COHEN-OR D., ZHENG Y., FU.
H.: Electors voting for fast automatic shape correspondence.
Comp. Graph. Forum 29, 2 (2010), 645â€“654.
[BL08] BAI X., LATECKI L.: Path similarity skeleton graph
matching. IEEE Trans. on PAMI 30 (2008), 1282â€“1292.
[BMSF06] BIASOTTI S., MARINI S., SPAGNUOLO M., FALCI-
DIENO B.: Sub-part correspondence by structural descriptors of
3D shapes. Comp. Aided Design 38, 9 (2006), 1002â€“1019.
[EK03] ELAD A., KIMMEL R.: On bending invariant signatures
for surfaces. IEEE Trans. on PAMI 25 (2003), 1285â€“1295.
[HJWC09] HO T. C., JI H. X., WONG S. K., CHUANG J. H.:
Mesh skeletonization using minimum slice perimeter function.
Computer Science Technical Report CS-TR-2010-0001, The Na-
tional Chiao Tung University, Taiwan, R.O.C. (2009).
[HSKK01] HILAGA M., SHINAGAWA Y., KOHMURA T., KUNII
T. L.: Topology matching for fully automatic similarity estima-
tion of 3D shapes. In SIGGRAPH (2001), pp. 203â€“212.
[MHTG05] MÃœLLER M., HEIDELBERGER B., TESCHNER M.,
GROSS M.: Meshless deformations based on shape matching.
ACM TOG 24, 3 (2005), 471â€“478.
[MS01] MORTARA M., SPAGNUOLO M.: Similarity measures
for blending polygonal shapes. Computers and Graphics 25, 1
(2001), 13â€“27.
[SSGD03] SUNDAR H., SILVER D., GAGVANI N., DICKINSON
S.: Skeleton based shape matching and retrieval. In Shape Mod-
eling Intâ€™l (2003), p. 130.
[TS04] TUNG T., SCHMITT F.: Augmented reeb graphs for
content-based retrieval of 3D mesh models. In Shape Modeling
Intâ€™l (2004), pp. 157â€“166.
[vKZHCO10] VAN KAICK O., ZHANG H., HAMARNEH G.,
COHEN-OR D.: A survey on shape correspondence. Eurograph-
ics State-of-the-art Report (2010).
[ZSCOâˆ—08] ZHANG H., SHEFFER A., COHEN-OR D., ZHOU
Q., VAN KAICK O., TAGLIASACCHI A.: Deformation-driven
shape correspondence. Symposium on Geometry Processing
(2008), 1431â€“1439.
cÂ© 2011 The Author(s)
cÂ© 2011 The Eurographics Association and Blackwell Publishing Ltd.
SAI-KEUNG WONG, JAU-AN YANG, TAN-CHI HO AND JUNG-HONG CHUANG 
 
partition a given mesh into patches which are satisfied with certain properties, such as volume, planarity 
and disc-like. On the other hand, there are algorithms which partition a mesh into semantic components 
based on the human perception. Readers are referred to [2,24,8] for details. Different segmentation 
algorithms may generate different segmentations for a mesh. Chen et al. [8] proposed a number of criteria 
to evaluate the similarity of two segmentations. Based on the criteria, they compared different 
segmentations to the ground truth segmentations defined by users. Consistent mesh segmentation aims to 
produce consistent segmentations for a set of meshes [28,25,31]. 
Golovinskiy and Funkhouser [10] employed rigid alignment [5] in a hierarchical clustering approach 
for consistent segmentation. Both the geometric features of individual meshes and the correspondence 
information between the set of meshes are considered. However, rigid alignment may not be able to 
correctly align the meshes in some cases, as reported in [14]. 
Kalogerakis et al. [14] proposed a scheme to compute segmentations and to assign labels for a set of 
meshes. The assignment of labels was formulated as an optimization problem and the objective function 
measured the consistency of primitives (i.e. triangles) with labels. The objective function was computed via 
a training process. Then the objective function was applied to the other meshes for computing consistent 
segmentations. Their approach handled various segmentations for a wide range of meshes. They reported 
that it took eight hours to train on a single Xeon E5355 2.66GHz processor for a database consisting of six 
training meshes of about 20K-30K faces and six labels. Our method computes consistent segmentations for 
similar objects but does not have a training process. Furthermore, our method refines the target boundaries 
so that their geometric details are as similar as possible to the ones of the corresponding source boundaries. 
Parameterization methods [22,17,23] can be adopted for establishing a mapping between two objects. 
The segmentation of one object can then be transferred to another. This kind of approach may not produce 
similar boundaries of segments between the two objects as such techniques often rely on globally 
minimizing certain kind of energies. The segment boundaries may not locate at the desired positions.   
3. PRELIMINARIES AND OVERVIEW 
We present the preliminaries and overview of our method in this section. The inputs of our method are: 
(1) two meshes (source and target), (2) their skeletons, (3) skeleton mesh correspondence and (4) the 
segmentation of the source mesh. The outputs are: (1) the segmentation of the target mesh and (2) the 
boundary correspondence between the source and target segmentation. We not only build the 
correspondence between the segment boundaries but also the points of the segment boundaries. The 
encoding of the source segmentation includes: each segment boundary consists of a set of connected edges; 
and each face of the source mesh is assigned a segment index. 
 
3.1 The Skeleton 
 
We follow the similar notation presented in [34]. A skeleton has a set of skeletal nodes and skeletal 
branches. Two directly connected skeletal nodes form a skeletal branch. The shortest path between two 
skeletal nodes is called a skeletal path. There are two types of skeletal feature nodes: junction nodes and 
terminal nodes. A junction has at least three incident branches and a terminal node has one incident branch. 
A skeletal arc is a skeletal path and it has two feature nodes which are also its two end nodes. Two 
skeletons are shown in the top row of Fig. 1. 
  
3.2 The Skeleton-Mesh Correspondence 
 
Our method exploits the skeleton-mesh correspondence to perform boundary transfer from the source 
segmentation to the target. The skeleton-mesh correspondence can be obtained by applying the method 
presented in [4] to construct the skeleton of the mesh. The method shrinks the mesh and the vertices are 
grouped as skeletal nodes during the skeletonization process. After computing the skeleton, a skeletal node 
is associated with a subset of the mesh vertices. A non-feature node is mapped to a set of vertices forming a 
SAI-KEUNG WONG, JAU-AN YANG, TAN-CHI HO AND JUNG-HONG CHUANG 
 
3.5 Overview 
Fig. 3 The segmentation transfer results (top and bottom) for the four-legged animals. The characteristics of the source 
segmentation (goat and pig) are captured and reproduced to the target models. 
 
There are two major stages in our method: skeleton-boundary correspondence and boundary transfer. 
The skeleton boundary correspondence is useful for computing approximately the target boundaries and it 
is built between segment boundaries and skeleton arcs of the source mesh. A boundary transfer procedure is 
adopted for mapping each source segment boundary enclosing a skeletal arc to the target mesh. In the 
procedure, a cylindrical parameterization is applied for mapping the regions around the source segment 
boundaries to the target mesh. Finally, we refine the segment boundaries on the target mesh such that their 
geometric details are consistent to the ones of the corresponding source segment boundaries. Fig. 3 shows 
some of our results. The interior (i.e. faces) of the segment regions can be computed after the segment 
boundaries are computed.  Table 1 shows the major parameters of our method. 
 
Table 1. The major parameters of our method. 
Parameter Purpose 
Î¸ Determining local maximum of the skeletal-arc profile 
(for computing MSP-gradient-based boundaries) 
K Gaussian smoothing for denoising the skeletal-arc profile 
(Kernel Size) 
Î» Searching region for target boundary refinement 
4. CONSISTENT SEGMENTATION TRANSFER  
Given the skeleton correspondence between the source and target skeletons, we transfer each source 
segment boundary enclosing a skeletal arc to the target mesh. Assume that the source arc (, )  and 
the target arc ( ,  ) are matched, where  and  are the two end nodes of , and   and   are the 
two end nodes of . Besides,  and  are enclosed by the source segment boundary  and the target 
segment boundary   (to be computed), respectively. We perform four steps to transfer   to the target 
mesh so as to obtain : skeleton-boundary correspondence, construction of covering regions, boundary 
transfer, and target segment boundary refinement. 
 
4.1 Skeleton-Boundary Correspondence 
 
We compute the fitting plane of  based on Principal Component Analysis [1]. If the fitting plane of 
  intersects with a skeletal arc   then   encloses  . Assume that p( ) is the intersection point 
between  and the fitting plane. An arc ratio r() of  with respect to  is given as: r() = len(, 
p())/len(, ), where len(Â·, Â·) is the distance between the two points on the skeletal arc . Our goal is 
to compute r() of the target segment boundary on bt and then compute p() based on r(). A skeletal 
arc corresponds to a part of the object. Hence, the parts of the matched skeletal arcs are similar. Consider 
that the part associated with bs is divided into two sub-parts based on r(). Similarly, we can divide the 
part associated with   based on r( ). Hence, we want to compute r( ) such that the two sub-parts 
SAI-KEUNG WONG, JAU-AN YANG, TAN-CHI HO AND JUNG-HONG CHUANG 
 
Denote   as the i-th MSP-gradient-based boundary of the source and   as the j-th MSP-gradient 
based boundary of the target. The cost for matching the MSP-gradient-based boundary pair is given by: 
$, ,   -  -.+ /âˆ‘ |01#|2âˆˆ345 6
456âˆ†789 
âˆ‘ |01#|2âˆˆ3:; 
<
:;<âˆ†789 =
.
, 
where Mq is the MSP gradient of a mesh vertex q, || and 66 are the numbers of the vertices of 
 and 66 , respectively; âˆ†MSP is the maximum of the MSP gradient magnitude of the vertices. We find 
the MSP-gradient-based boundary pair with the lowest cost. Assume that - and - are the arc 
ratios of the best matched source and target MSP gradient-based boundaries, respectively. There are two 
cases to consider: 
1. Case One: p() lies between  and p, then -  C
5C
D; 
D5 ; 
2. Case Two: p() lies between p and , then r() = - ) C
5E C
D5EC
D; E
D5 . 
After r() is computed, p()  can be computed based on proportion, i.e. the linear interpolation on 
the skeletal arc , FGH"I; ,J
;   FGH"I; ,"K;   = r(). Notice that in both cases, if r() = r( ), we have r() = r(). 
In other words, if  lies around ,   lies around  , too. 
 
If the MSP-gradient-based boundaries are not found, r() is set as r(). Then we compute p() based on 
proportion. 
 
4.2 Covering regions 
Fig. 6 Construct a covering region of a boundary: (a) construct a fitting plane; (b) project the points of the boundary to 
the fitting plane and construct the line segments; (c) remove the faces not overlapping with the boundary (red) ; and (d) 
refine faces (blue) around the boundary to obtain the final covering region. 
 
A covering region of a boundary consists of a set of faces and the faces cover the entire boundary. The 
covering region is used for computing and refining the target segment boundaries. We rely on two 
characteristics to construct the covering region of a source segment boundary: (1) the relative orientation 
between the fitting plane of the source boundary and its associated arc; and (2) the distances between the 
points of the source segment boundary and its associated fitting plane. To construct a covering region of Bs, 
we consider the faces of the mesh intersecting with the corresponding fitting plane. If all the faces 
intersected by the fitting plane overlap with Bs, then we simply use these faces as the initial covering 
region. However, the fitting plane may intersect with some faces of the mesh and these faces may not 
overlap with , as shown in Fig. 6(a). Assume that a set Fp contains the faces intersecting with the fitting 
SAI-KEUNG WONG, JAU-AN YANG, TAN-CHI HO AND JUNG-HONG CHUANG 
 
covering region has two boundaries and they bound the internal region of the covering region. These two 
boundaries correspond to the upper and lower boundaries of a cylinder according to their arc ratios (e.g. 
upper boundary with smaller arc ratio). The internal region of the covering region corresponds to the lateral 
side of the cylinder. The cylindrical parameterization can be unfolded to a 2D plane domain. The v 
coordinates of the lower and upper boundaries are set to 0.0 and 1.0, respectively. The range of the 
parameterized coordinates (u, v) is [0, 1) Ã— [0, 1]. 
 
Fig. 8 The parameterized orientation adjustment. (a): The y-coordinate value is chosen as the alignment value as its 
range is larger than the range of the z- coordinate values of the samples. In this case, Âµo is around 6/9 ; (b): The vertices 
of the boundaries are colored according to their alignment values. The u-offsets are computed for minimizing the total 
difference between the coordinates of the boundary sample points. 
 
The origin (i.e. (0, 0)) of the parameterization map is set as a point of the lower boundary of the 
covering region. The parameterized covering regions of the source and target may have a large deviation in 
the U-direction. A parameterized orientation adjustment is performed to address this issue. The 
parameterized orientation adjustment can be treated as rotating the boundaries of the target cylinder so as to 
align with the boundaries of the source cylinder. After the adjustment, the vertices of the boundaries have 
the similar distribution of the coordinates, as shown in Fig. 8. The details are given as follows. All the 
boundary vertices of Cs and Ct are transformed to the local coordinate systems, respectively. 
Notice that the cylinder axis is pointing in the same direction with the x-axis of the coordinate system. 
We compute the two ranges for the yâˆ’ and zâˆ’ coordinates of the boundary vertices of $ and $ . The 
coordinate with the largest range is chosen as the alignment value of all the boundary vertices. We sample 
N points uniformly from the lower boundary L of $ and their parameterized u-coordinates form a N-tuple 
UBs = (u1, u2, ..., uN). Similarly, we have UBt = (v1, v2, ..., vN). Denote that V (L, u) returns the alignment 
value at the sample position whose u-coordinate is u on the boundary L. The u-offset Âµo âˆˆ [0, 1) of L is 
computed by minimizing the following function: 
 
%-MNOPQ âˆ‘ RL, S  RL , T ) UV.WX , 
where T ) ÂµV is wrapped to [0, 1] if T ) ÂµV > 1 (e.g. 1.2 is wrapped to 0.2). If the sample position is 
on an edge, the alignment value is computed by interpolating the values of the two vertices of the edge. 
After the process, we match the sample points of  to the sample points of  . Notice that the vertices of   may lay on the edges of the target mesh. 
 
4.4 Boundary Refinement 
 
We have matched the sample points of the source and target boundaries. The final step here is to refine 
the target boundaries. Most of the mesh segmentations compute boundaries close to the local geometric 
features, such as, curvature or dihedral angle. Some techniques may compute boundaries that have short 
and smooth shapes. In our case, we want to refine the target boundaries that may follow particular patterns 
such as jagged or wavy shapes according to the corresponding source boundaries. We use snake [19] to 
refine   based on the following energy function: 
Z"[\   ] Z^ [_C` ) Za[J` b`âˆˆ
; , 
SAI-KEUNG WONG, JAU-AN YANG, TAN-CHI HO AND JUNG-HONG CHUANG 
 
Comparisons. We compare with the method by [10] and Fig. 10 shows the results. The results 
produced by [10] are poor for the models with large difference in shapes or poses. Our method produces 
better results since our method adopts skeleton correspondence before segmentation transfer is performed. 
 
Fig. 10 Comparison with [10] for segmentation transfer. 
 
In comparing with the method by Kalogerakis et al. [14], our method is more capable of controlling 
the positions of boundaries. Notice the differences to the rightmost airplanes in Fig. 11 and the giraffes in 
Fig. 12. The seat and back of the rightmost chair in Fig. 13 form a single segment since there is no 
boundary on some pillars. The method of [14] is region-based so that it can produce segments for all the 
pillars of the chairs. Finally, we compare with the other segmentation algorithms based on the Princeton 
Benchmark [8]. The results between â€Humanâ€ and our method â€Seg Trans.â€ are similar to each other. Our 
method can consistently transfer the source segmentation to the target mesh. The results also show that our 
method is comparable to the other methods, including Randomized Cuts [9], Shape Diameter Function [26], 
Normalized Cuts [9], Core Extraction [15], RandomWalks [18], Fitting Primitives [1] and K-Means [27], 
as indicated in Fig 14. 
Fig. 11 The comparison with [14] on airplane models. The wings of the rightmost airplanes have difference 
segmentation types. A target segment boundary is not smooth in the second left airplane in our approach due to the 
poor alignment of the fitting plane. 
 
Fig. 12 The comparison with [14]. Our result is better for the giraffe. 
 
SAI-KEUNG WONG, JAU-AN YANG, TAN-CHI HO AND JUNG-HONG CHUANG 
 
Table 2 lists the computation times of our segmentation transfer results presented in Fig. 10, including 
the total computation time, the number of segment boundaries, and the average time for performing a 
boundary transfer. On average it took around four seconds to perform segmentation transfer. Our method 
requires the manual operations to change the parameters if the segmentation results are not good. Usually, 
it took three to four attempts to obtain high quality results.  
Discussions and limitations. The quality of the segmentation transfer results depends on the quality 
of the skeleton correspondence. If the skeletons do not capture the shape of the meshes faithfully, our 
method may not work properly. If the fitting planes do not fit well the source boundary, the arc ratios are 
not reliable for determining the target boundary positions. We cannot handle segment boundaries which 
enclose multiple arcs. The target boundaries may be distorted for non-cylindrical covering regions. Further 
studies are needed for building the local coordinate systems for computing the covering regions of the 
target segment boundaries. 
6. CONCLUSION 
We have presented a segmentation transfer approach for mapping consistently a segmentation of a 
source mesh to a target mesh. The segmentation transfer approach is based on the skeleton correspondence 
between the meshes. The characteristics of boundaries including the relative orientation between the 
boundaries and skeletal arcs, the shape of the corresponding parts and local surface features, are considered. 
We have shown that our method generates consistent segmentations for a variety of similar meshes of 
different shapes and poses. Our approach relies on the skeleton-mesh correspondence and skeleton 
correspondence to perform segmentation transfer. Our method does not handle the segment boundaries that 
do not enclose a skeletal arc.  
In the future, we would like to develop techniques to transfer any kind of segment boundaries by 
combining consistent parameterization with skeletons. We believe that the skeleton-based approach can 
enhance the quality of the segment boundaries for the techniques based on consistent parameterization and 
other segmentation techniques. 
7. REFERENCES 
1. M. Attene, B. Falcidieno, and M. Spagnuolo, â€œHierarchical mesh segmentation based on fitting primitives,â€ 
The Visual Computer, 22(3):181â€“193, 2006. 
2. M. Attene, S. Katz, M. Mortara, G. Patane, M. Spagnuolo, and A. Tal, â€œMesh segmentation - a comparative 
Study,â€ in IEEE Intâ€™l Conf. on Shape Modeling and Applications, page 7, 2006. 
3. O.-C. Au, C. Tai, D. Cohen-Or, Y. Zheng, and H. Fu, â€œElectors voting for fast automatic shape 
correspondence,â€ Comp. Graph. Forum, 29(2):645â€“654, 2010. 
4. O. K.-C. Au, C.-L. Tai, H.-K. Chu, D. Cohen-Or, and T.-Y. Lee, â€œSkeleton extraction by mesh contraction,â€ 
ACM TOG, 27(3), 2008. 
5.  P. Besl and N. McKay, â€œA method for registration of 3-D shapes,â€ IEEE Trans. on PAMI, 14(2):239â€“256, 
1992. 
6. S. Biasotti, S. Marini, M. Spagnuolo, and B. Falcidieno, â€œSub-part correspondence by structural descriptors 
of 3D shapes,â€ Comp. Aided Design, 38(9):1002â€“1019, 2006. 
7. Y. Boykov and V. Kolmogorov, â€œAn experimental comparison of min-cut/max-flow algorithms for energy 
minimization in vision,â€ IEEE Trans. on PAMI, 26(9):1124â€“1137, 2004. 
8. X. Chen, A. Golovinskiy, and T. Funkhouser, â€œA benchmark for 3D mesh segmentation,â€ ACM TOG, 
28(3):1â€“12, 2009. 
9. A. Golovinskiy and T. Funkhouser, â€œRandomized cuts for 3d mesh analysis,â€ ACM TOG, 7(5), 2008. 
10. A. Golovinskiy and T. Funkhouser, â€œConsistent segmentation of 3D models,â€ Computers and Graphics, 
33(3):262â€“269, 2009. 
11. R. Gonzalez and R. Woods, â€œDigital image processingâ€,  Addison-Wesley Publishing Company, 1992. 
12. M. Hilaga, Y. Shinagawa, T. Kohmura, and T. L. Kunii, â€œTopology matching for fully automatic similarity 
estimation of 3D shapes,â€ in SIGGRAPH, pages 203â€“212, 2001. 
1 
 
å‡ºåœ‹è¨ªå•ç ”ç©¶æˆæœå ±å‘Š 
                                                             
è¨ˆç•«ç·¨è™Ÿ NSC 99-2221-E-009-118        åŸ·è¡ŒæœŸé–“ 2010/08/01 ~ 2012/7/31 
è¨ˆç•«åç¨± å¤šé‚Šå½¢ç¶²æ ¼åˆ†å‰²è½‰æ›(2/2) 
å‡ºåœ‹äººå“¡å§“å 
æœå‹™æ©Ÿé—œåŠè·ç¨± 
 èŠæ¦®å®/äº¤å¤§è³‡è¨Šå·¥ç¨‹ç³»æ•™æˆ 
å‡ºåœ‹æ™‚é–“åœ°é» 3/25/2012~4/1/2012 UC Davis, CA, USA 
è¨ªå•ç ”ç©¶ä¸»é¡Œ 
ï¼ˆä¸­æ–‡ï¼‰ç¶²æ ¼åˆ†å‰²è½‰æ›ï¼Œäººè‡‰å½©å¦æ¨¡å‹èˆ‡å³æ™‚é¡¯åƒæŠ€è¡“ï¼Œèˆ‡å·¨é‡è¦–è¨Šè³‡æ–™
åˆ†æèˆ‡æ‡‰ç”¨ä¹‹ç ”ç©¶ 
ï¼ˆè‹±æ–‡ï¼‰Mesh Segmentation Transfer, Facial Cosmetic modeling and real-time 
rendering, analysis of large video data and its applications 
 
ä¸€ã€å‡ºåœ‹è¨ªå•ç¶“é 
è¨ˆç•«ä¸»æŒäººå®‰æ’ 3/25/2012~4/1/2012 åˆ° University of California at Davis ä½œè¨ªå•ç ”ç©¶ã€‚
UC Davis é›»è…¦ç³»åœ¨åœ–å­¸(graphics)èˆ‡è¦–ç®—(visualization)æœ‰å …å¼·çš„ç ”ç©¶åœ˜éšŠï¼Œæœ‰å…©å€‹ç›¸é—œç ”ç©¶
ä¸­å¿ƒï¼š Institute for Data Analysis and Visualization (IDAV) åŠ Institute for Ultra-Scale 
Visualizationã€‚æˆ‘æ­¤æ¬¡è¨ªå•æ˜¯èˆ‡ Institute for Ultra-Scale Visualization çš„é¦¬åŒ¡å…­æ•™æˆåˆä½œï¼Œé€
éåƒèˆ‡é¦¬æ•™æˆçš„å¯¦é©—å®¤ç ”è¨èˆ‡è¨è«–åšäº†å¾ˆè±å¯Œçš„äº¤æµã€‚ 
äºŒã€è¨ªå•ç ”ç©¶æˆæœ 
æ­¤æ¬¡è¨ªå•è¨è«–çš„æ–¹å‘æ˜¯è¨è«–ç¶²æ ¼åˆ†å‰²è½‰æ›ï¼Œäººè‡‰å½©å¦æ¨¡å‹èˆ‡å³æ™‚é¡¯åƒæŠ€è¡“ï¼Œå·¨é‡è¦–è¨Š
è³‡æ–™ä¹‹åˆ†æèˆ‡æ‡‰ç”¨ä¹‹æŠ€è¡“äº¤æµèˆ‡æœªä¾†åˆä½œè¦åŠƒã€‚é ­å…©é …æ˜¯é€²è¡Œä¸­çš„ç ”ç©¶ï¼Œæœ€å¾Œä¸€é …å‰‡æ˜¯æ–°çš„
åˆä½œæ–¹å‘ã€‚ 
3 
 
å¦‚åœ¨é«˜é€Ÿå…¬è·¯ã€å¤§éŠæ¨‚åœ’ã€æ ¡åœ’æˆ–æ˜¯åšç‰©é¤¨ï¼Œå·²å»£è¨­çš„ç›£è¦–æ”å½±æ©Ÿæ‰€ç”¢ç”Ÿçš„å·¨é‡streaming
è³‡æ–™ã€‚è¨è«–çš„æŠ€è¡“ä¸»é¡ŒåŒ…æ¶µ 
1. Streaming data processing and managementï¼Œ å¦‚streaming data extraction, summarization, 
redundant data removal, similarity matchingç­‰ 
2. Movement data analysisï¼Œ å¦‚è·¯ç·šåˆ†æ 
3. Visualizationï¼Œ å¦‚äººç¾¤è¡Œå‹•æˆ–è·¯ç·šä¹‹è¦–è¦ºåŒ–ï¼ŒMulti-resolution viewingç­‰  
4. Simulationï¼Œå¦‚äººç¾¤è¡Œå‹•æ¨¡æ“¬ã€ç«ç½æ¨¡æ“¬ç­‰  
 
æˆ‘å€‘å°‡æŒçºŒè¨è«–é€™äº›ä¸»é¡Œï¼ŒæœŸå¾…èƒ½æˆç‚ºäº¤å¤§åœ–å­¸åŒä»èˆ‡é¦¬æ•™æˆåˆä½œçš„ä¸€å€‹æ•´åˆå‹è¨ˆç•«ã€‚ 
     
 
99ï¦ï¨å°ˆé¡Œç ”ç©¶è¨ˆç•«ç ”ç©¶æˆæœå½™æ•´è¡¨ 
è¨ˆç•«ä¸»æŒäººï¼šèŠæ¦®å® è¨ˆç•«ç·¨è™Ÿï¼š99-2221-E-009-118- 
è¨ˆç•«åç¨±ï¼šå¤šé‚Šå½¢ç¶²æ ¼åˆ†å‰²è½‰æ› 
ï¥¾åŒ– 
æˆæœé …ç›® å¯¦éš›å·²é”æˆ
ï¥©ï¼ˆè¢«æ¥å—
æˆ–å·²ç™¼è¡¨ï¼‰
é æœŸç¸½é”æˆ
ï¥©(å«å¯¦éš›å·²
é”æˆï¥©) 
æœ¬è¨ˆç•«å¯¦
éš›è²¢ç»ç™¾
åˆ†æ¯” 
å–®ä½ 
å‚™ è¨» ï¼ˆ è³ª åŒ– ï¥¯
æ˜ï¼šå¦‚ï¥©å€‹è¨ˆç•«
å…±åŒæˆæœã€æˆæœ
ï¦œ ç‚º è©² æœŸ åˆŠ ä¹‹
å° é¢ æ•… äº‹ ...
ç­‰ï¼‰ 
æœŸåˆŠï¥æ–‡ 0 0 100%  
ç ”ç©¶å ±å‘Š/æŠ€è¡“å ±å‘Š 2 2 100%  
ç ”è¨æœƒï¥æ–‡ 0 0 100% 
ç¯‡ 
 
ï¥æ–‡è‘—ä½œ 
å°ˆæ›¸ 0 0 100%   
ç”³è«‹ä¸­ä»¶ï¥© 0 0 100%  å°ˆï§ å·²ç²å¾—ä»¶ï¥© 0 0 100% ä»¶  
ä»¶ï¥© 0 0 100% ä»¶  
æŠ€è¡“ç§»è½‰ 
æ¬Šï§ï¤Š 0 0 100% åƒå…ƒ  
ç¢©å£«ç”Ÿ 0 0 100%  
åšå£«ç”Ÿ 0 0 100%  
åšå£«å¾Œç ”ç©¶å“¡ 0 0 100%  
åœ‹å…§ 
ï¥«èˆ‡è¨ˆç•«äººï¦Š 
ï¼ˆæœ¬åœ‹ç±ï¼‰ 
å°ˆä»»åŠ©ï§¤ 0 0 100% 
äººæ¬¡ 
 
æœŸåˆŠï¥æ–‡ 0 0 100%  
ç ”ç©¶å ±å‘Š/æŠ€è¡“å ±å‘Š 2 2 100%  
ç ”è¨æœƒï¥æ–‡ 0 0 100% 
ç¯‡ 
 
ï¥æ–‡è‘—ä½œ 
å°ˆæ›¸ 0 0 100% ç« /æœ¬  
ç”³è«‹ä¸­ä»¶ï¥© 0 0 100%  å°ˆï§ å·²ç²å¾—ä»¶ï¥© 0 0 100% ä»¶  
ä»¶ï¥© 0 0 100% ä»¶  
æŠ€è¡“ç§»è½‰ 
æ¬Šï§ï¤Š 0 0 100% åƒå…ƒ  
ç¢©å£«ç”Ÿ 0 0 100%  
åšå£«ç”Ÿ 0 0 100%  
åšå£«å¾Œç ”ç©¶å“¡ 0 0 100%  
åœ‹å¤– 
ï¥«èˆ‡è¨ˆç•«äººï¦Š 
ï¼ˆå¤–åœ‹ç±ï¼‰ 
å°ˆä»»åŠ©ï§¤ 0 0 100% 
äººæ¬¡ 
 
