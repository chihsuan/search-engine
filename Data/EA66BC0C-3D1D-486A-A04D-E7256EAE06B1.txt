ä¸€ã€ å‰è¨€ 
ï¥©åï¦ï¤­ï¼Œï¥©å­¸è¦åŠƒæ³•é‹ç”¨åœ¨å„ç¨®ï¦´åŸŸæœ€ä½³åŒ–å•é¡Œçš„ç ”ç©¶ï¼Œå·²æœ‰è¨±å¤šå…·é«”æˆæœï¼Œå…¶ä¸­
ï§ç”¨æ¢¯ï¨æ–¹å‘åšç‚ºæœå°‹æ–¹å‘çš„è³‡è¨Šï¼Œå°å•é¡Œçš„æ¥µå€¼æ±‚è§£å…·æœ‰å¾ˆå¥½çš„è¨ˆç®—æ•ˆï¥¡ã€‚æ­¤ç¨®æ–¹æ³•çš„
ç‰¹é»ç‚ºåˆå§‹é»ä½åœ¨æœ€ä½³åŒ–å•é¡Œçš„æœ€ä½³è§£é™„è¿‘ï¼Œï¥¥å¾ˆå®¹ï§ æœå°‹åˆ°ï¼›æˆ–è¨­è¨ˆç©ºé–“å‡¸å€åŸŸçš„å•é¡Œ
å…¶æ¥µå€¼äº¦ç‚ºå…¨åŸŸæœ€ä½³è§£ã€‚ç„¶è€Œï¼Œé‡åˆ°å«å¤šæ¥µå€¼é»çš„æœ€ä½³åŒ–å•é¡Œæ™‚ï¼Œå…¨åŸŸæœ€ä½³è§£çš„æœå°‹ï¼Œå‰‡
ç«¯è³´åˆå§‹é»çš„é¸æ“‡ï¼Œå¦‚æœåˆå§‹é»ä½æ–¼å±€éƒ¨æœ€ä½³è§£è™•é™„è¿‘æ™‚ï¼Œå‰‡å®¹ï§ æ”¶æ–‚æ–¼å±€éƒ¨æœ€ä½³å€¼ã€‚ 
ç‚ºï¦ºæ”¹å–„å‚³çµ±ï¥©å­¸è¦åŠƒæ³•çš„ç¼ºé»ï¼Œè¿‘ï¦ï¤­å·²æœ‰è¶Šï¤­è¶Šå¤šçš„ç ”ç©¶æ¡å–ä»¿ç”Ÿç‰©æ™ºæ…§çš„æ¦‚
ï¦£ï¼Œï§ç”¨åœ¨å„ç¨®ï¦´åŸŸæœ€ä½³åŒ–å•é¡Œçš„ç ”ç©¶ä¸Šï¼Œå…¶ä¸»è¦çš„å…±åŒç‰¹é»ç‚ºï¼šéç·šæ€§ã€ï§ä¼¼ç”Ÿç‰©æ¨ï§¤
æ€è€ƒçš„æ–¹æ³•ã€èƒ½ï§ç”¨è‡ªæˆ‘å­¸ç¿’(Self-learning)ã€å°é›œè¨Šï¤å…·å¼·å»ºæ€§(Robust)ã€‚ 
ç„¶è€Œï¼Œç‚ºï¦ºæ‡‰ä»˜å·¥ç¨‹ä¸Šè¤‡é›œçš„å•é¡Œä»¥åŠï¤é«˜ç¶­ï¨çš„æŒ‘æˆ°ï¼Œå¤šç›®æ¨™æœ€ä½³åŒ–çš„ç ”ç©¶ä¹Ÿé¡¯å¾—
ç›¸ç•¶çš„é‡è¦ã€‚åœ¨ä¸€äº›å·¥ç¨‹ä¸Šï¼Œå¸¸å¸¸ç¢°åˆ°å¸Œæœ›èƒ½å¤ æ‰¾åˆ°ä¸€äº›ï¥«ï¥©çš„æœ€ä½³å€¼ï¼Œä½†åœ¨èª¿æ•´çš„éç¨‹
ä¸­ï¼Œï¥«ï¥©ä¹‹é–“ä¹Ÿå°‡äº’ç›¸çš„å½±éŸ¿ï¼Œï¦µå¦‚åœ¨å»ºé€ æ©‹æ¨‘æ™‚ï¼Œæœƒå¸Œæœ›æ•´é«”å»ºæçš„é‡ï¥¾è¶Šä½ä½†é€™ä¹Ÿä½¿
å¾—å …å›ºçš„ç¨‹ï¨ï¨‰ä½ï¼Œè€Œï¥§æ˜¯é æœŸä¸­çš„æé«˜ã€‚åœ¨é£›æ©Ÿè¨­è¨ˆæ™‚ï¼Œå¸Œæœ›èƒ½å¤ æœ€ä½³åŒ–ç‡ƒæ²¹ä½¿çš„æ•ˆï¥¡ï¼Œ
æ•´é«”çš„è¼‰é‡ï¥¾ä»¥åŠæ•´æ¶é£›æ©Ÿçš„é‡ï¥¾é€™å¹¾å€‹ï¥«ï¥©ä¸­å–å¾—æœ‰æ•ˆå¹³è¡¡çš„è§£ã€‚é™¤ï¦ºåœ¨å·¥ç¨‹ä¸Šï¼Œå•†æ¥­
ä¸Šä¹Ÿå¸Œæœ›è—‰ç”±æœ€ä½³åŒ–ï¤­ä½¿å¾—é¢¨éšªæœ€å°ï¼Œä½†å¸Œæœ›åŒæ™‚æ‰€å¾—åˆ°çš„è²¡å‹™å›æ”¶èƒ½å¤ æœ€å¤§åŒ–ã€‚å¦‚ä½•åœ¨
é€™éº¼å¤šçš„è®Šï¥©ä¸­åšå–æ¨åŠèª¿æ•´ï¼Œå°±å¿…éœ€è—‰ç”±å¥½çš„å¤šç›®æ¨™æœ€ä½³åŒ–çš„æ¼”ç®—æ³•ï¤­é”æˆã€‚ 
æœ€ä½³åŒ– (Optimization) æ˜¯åœ¨ä¸€å€‹æœ‰è¨±å¤šé™åˆ¶å’Œæ¢ä»¶ç›¸äº’è¡çªçš„ç’°å¢ƒä¸‹æ‰¾å°‹ä¸€å€‹æœ€åˆé©
è§£æ±ºæ–¹å¼çš„éç¨‹ã€‚å› æ­¤æœ€ä½³åŒ–æ˜¯ä¸€å€‹è¤‡é›œï¨å’Œè§£æ±ºçµæœå¥½å£çš„å¹³è¡¡é»ï¼›æœ€é©ç•¶çš„ç­”æ¡ˆè¡¨ç¤º
æœ€å¥½çš„å¦¥å”ã€‚åœ¨å¯¦éš›æ‡‰ç”¨ä¸Šï¼Œæ”¹é€²æ˜¯ç›¸ç•¶é‡è¦çš„ã€‚ç”šè‡³ï¦šæ¥µå¾®å°çš„æ”¹é€²ï¨¦éå¸¸å€¼å¾—çš„ã€‚æƒ³
æƒ³çœ‹åœ¨å·¥å» ä½œæ¥­ä¸Šå’Œè‚¡ç¥¨å¸‚å ´ä¸­ï¼Œ5ï¼…çš„æ”¹å–„æœƒæœ‰å¤šå¤§çš„å½±éŸ¿ã€‚å³ä½¿çµ•å°çš„æœ€å¥½è§£ç­”ç„¡æ³•è¢«
æ‰¾åˆ°ï¼Œä¸€å€‹è·Ÿé€™å€‹ç­”æ¡ˆç›¸ç•¶æ¥è¿‘çš„è§£æ±ºæ–¹æ¡ˆå°åŸæœ¬çš„å•é¡Œä¹Ÿæœ‰ç›¸ç•¶å¤šçš„æ”¹å–„ã€‚ 
ç¸±ä½¿ç›®å‰é›»è…¦æ™®éæ“æœ‰å¼·å¤§çš„é‹ç®—èƒ½ï¦Šï¼Œä½†è¨±å¤šè¼ƒè¤‡é›œçš„NP-completeå•é¡Œï¼Œä»ç„¡æ³•åœ¨
åˆï§¤çš„æ™‚é–“å…§æ±‚å¾—æœ€ä½³è§£ï¼Œå› æ­¤æœ‰å¾…ç™¼å±•å‡ºï¤æœ‰æ•ˆï¥¡çš„æ¼”ç®—æ³•ä»¥è§£æ±ºæ—¥å¸¸ç”Ÿæ´»ä¸­ç¨®ç¨®æœ€ä½³
åŒ–å•é¡Œã€‚ 
äºŒã€ ç ”ç©¶ç›®çš„ 
æœ¬è¨ˆç•«æå‡ºä»¥ï§¹å­ç¾¤æœ€ä½³åŒ–æ¼”ç®—æ³•ï¼Œä¸¦é‡å°åŸPSOæ¶æ§‹æå‡ºä»¥ä¸‹ç¼ºå¤±æ”¹ï¥¼æ–¹æ³•ï¼Œä»¥æœŸ
èƒ½åœ¨é«˜ç¶­ï¨å•é¡Œæé«˜æ±‚è§£æ•ˆï¥¡åŠæ­£ç¢ºæ€§ã€‚ 
1. æ”¹å–„å…¶å®ƒæ¼”ç®—æ³•å®¹ï§ é™·å…¥å±€éƒ¨æœ€ä½³è§£çš„ç¼ºé» 
ç•¶åˆå§‹ï§¹å­åˆ†ä½ˆï¥§å‡å‹»æˆ–éæ–¼é›†ä¸­æ™‚ï¼ŒåŠ ä¸Šæ¼”åŒ–ç­–ï¥¶ï¥§å¥å…¨ï¼Œå‰‡ï§ å½¢æˆç‹¹éš˜çš„æœå°‹
è§£ç©ºé–“ï¼Œé€™å°‡æœƒä½¿ï§¹å­ç¾¤åœ¨æœå°‹ç©ºä¸Šç”¢ç”Ÿç›²é»è€Œå—é™æ–¼å±€éƒ¨æœ€å°å€¼ï¼Œéœ€ç¶“éè¼ƒå¤šä¸–
ä»£æ¼”åŒ–æ‰æœ‰æ©Ÿæœƒè·³è„«ï¼Œä½†å»ç„¡æ³•ä¿è­‰ä¸€å®šèƒ½è·³è„«ï¼Œå¤§å¤šåªæœå°‹åˆ°æ¬¡ä½³è§£å³å®Œæˆæ”¶æ–‚ã€‚
å› æ­¤é‡å°æ­¤ä¸€ç¼ºå¤±ï¼Œæˆ‘å€‘åœ¨ç ”ç©¶æ–¹æ³•ä¸­æå‡ºæ”¹ï¥¼è¾¦æ³•ã€‚ 
2. æé«˜æ±‚è§£æ•ˆï¥¡ï¼Œç¯€ï¥­è¨ˆç®—æ™‚é–“ 
åˆå§‹ï§¹å­åˆ†ä½ˆï¥§å‡å‹»æˆ–éæ–¼é›†ä¸­æ™‚ï¼Œé™¤ï¦ºï§ é€ æˆç‹¹éš˜çš„ï§¹å­æœå°‹ç©ºé–“ï¼Œä¹Ÿæœƒä½¿ï§¹å­
ç¾¤èŠ±è²»è¼ƒå¤šæ™‚é–“åœ¨è§£ç©ºé–“çš„æ¢æ¸¬(Explore)èˆ‡é–‹ç™¼(Exploit)ä¸Šï¼Œï¨‰ä½ï¦ºæ•´é«”æœå°‹çš„æ•ˆï¥¡
èˆ‡æ•ˆèƒ½ã€‚ 
ä½³è§£çš„æ•ˆï¥¡ã€‚PSO å·²ç¶“è¢«æ‡‰ç”¨ï¤­è§£æ±ºè¨±å¤šéœæ…‹å•é¡Œçš„æœ€ä½³åŒ–ï¼Œä¸”å…¶æ±‚è§£æ€§èƒ½ä¹Ÿè¢«è­‰æ˜æ˜¯æ¥µ
å…·æ•ˆï¥¡çš„ã€‚ç„¶è€Œï¼Œå¤šï¥©çš„çš„å¯¦éš›å•é¡Œèˆ‡æ‡‰ç”¨æ˜¯å±¬æ–¼éç·šæ€§çš„å‹•æ…‹ç³»çµ±ã€‚Eberhart å’Œ Shi ç™¼
ç¾ï¼šåœ¨ PSO çš„ï¥«ï¥©è¨­å®šä¸­ï¼Œå›ºå®šã€æˆ–ç·šæ€§éå¢çš„æ…£æ€§æ¬Šé‡å°æ–¼å‹•æ…‹ç³»çµ±çš„æ±‚è§£è¼ƒç„¡æ•ˆï¥¡ã€‚
è€ƒæ…®å¯¦éš›æ‡‰ç”¨ä¸­çš„ç‰¹æ€§ï¼Œä»–å€‘åœ¨[21] ä»¥éš¨æ©Ÿçš„æ–¹å¼ï¤­è¨­å®šæ…£æ€§æ¬Šé‡ï¼Œè—‰ä»¥ï¤é©ï¨€çš„æ‡‰ç”¨æ–¼
å‹•æ…‹å•é¡Œæ±‚è§£ã€‚ 
æ”¹å–„ PSO æ•ˆèƒ½çš„å¦ä¸€å€‹æœ‰è¶£çš„æ–¹æ³•ï¼Œç”± Angeline [22]æ‰€æå‡ºã€‚è€ƒæ…®ï§¹å­ç•¶ä¸‹çš„é©æ‡‰å‡½
ï¥©ï¼Œè€Œæ¡ç”¨ç«¶è³½çš„æ–¹å¼ï¤­åšå–æ¨ã€‚é€™å€‹æ–¹æ³•æ˜¯å°‡ï§¹å­ç¾¤ä¸­è¡¨ç¾è¼ƒå„ªçš„å‰ç™¾åˆ†ä¹‹äº”åé¸å‡ºï¤­ï¼Œ
å°‡å…¶å…§æ¶µè³‡è¨Šè¤‡è£½å‡ºï¤­ï¼Œç”¨ä»¥å–ä»£ï§¹å­ç¾¤ä¸­è¡¨ç¾è¼ƒå·®çš„ï¼ˆå¾Œç™¾åˆ†ä¹‹äº”åï¼‰ï§¹å­ï¼Œä½†æ˜¯ï¼Œä¸¦
ï¥§å»æ”¹è®Šè¢«å–ä»£ï§¹å­çš„å€‹äººæœ€ä½³è§£ï¼ˆpersonal bestï¼‰ã€‚  
åœ¨å±€éƒ¨æœ€ä½³ç‰ˆçš„ PSOï¼Œlbest å°æ‡‰çš„æ˜¯ç’°ï§ºçš„é„°åŸŸæ¶æ§‹ï¼ˆneighborhood structureï¼‰ã€‚ï§¹å­
å€‘ï¨¦å°‡æœƒè¢«å…¶é„°è¿‘ï§¹å­çš„æœ€ä½³ä½ç½®æ‰€å½±éŸ¿æ­£å¦‚ä»–å€‘å„è‡ªçš„éå»æœ€ä½³è§£ä¹Ÿæœƒå½±éŸ¿è‡ªå·±çš„ç§»å‹•
ä¸€èˆ¬ã€‚ä¸€æ—¦ lbest çš„æ”¶æ–‚é€Ÿï¨æ¯” gbest æ…¢ï¼Œä»£è¡¨çš„æ˜¯ lbest æœ‰è¼ƒä½³çš„æ±‚è§£çµæœä¸”å…¶æœå°‹ï¦ºå¤§
éƒ¨åˆ†çš„æœè©¢ç©ºé–“[23]ã€‚ 
è¿‘æœŸä¸­ï¼ŒKennedy ç ”ç©¶ï¦ºå…¶ä»–é„°åŸŸï¨‚å¢£æ¶æ§‹ç™¼ç¾é¦®ï§æ›¼ï¨‚å¢£æ¶æ§‹å¯ä»¥ç”¢ç”Ÿè¼ƒå¥½çš„æ•ˆèƒ½
èˆ‡çµæœ[24]ã€‚åœ¨[25]ä¸­ï¼ŒParsopoulos å’Œ Vrahatis æå‡ºï¦ºï¦—åˆå¼ï§¹å­ç¾¤æœ€ä½³åŒ–æ¼”ç®—æ³•ï¼ˆUnified 
particle swarm optimizer, UPSOï¼‰ï¼Œå®ƒæ˜¯çµåˆï¦ºâ€å…¨åŸŸç‰ˆï¼ˆGlobal versionï¼‰â€èˆ‡â€å±€éƒ¨ç‰ˆï¼ˆLocal 
versionï¼‰â€çš„ PSO æ¼”ç®—æ³•ã€‚ è€Œåˆä½œå¼ï§¹å­ç¾¤æœ€ä½³åŒ–æ¼”ç®—æ³•ï¼ˆCooperative particle swarm 
optimizer, CPSOï¼‰ä¹Ÿæ–¼ [26]ä¸­è¢«æå‡ºï¼Œå®ƒåŒ…å«ï¦ºï¥¸ç¨®ç‰ˆæœ¬ï¼šCPSO-S å’Œ CPSO-Hã€‚å…¶ä¸­ï¼ŒCPSO-S
æ˜¯å°‡ CCGA ç›´æ¥å¥—ç”¨åœ¨æ¨™æº– PSO ä¸Šï¼›è€Œ CPSO-H å‰‡æ˜¯çµåˆæ¨™æº– PSO å’Œ CPSO-Sï¼Œä¸¦ä¸”å°‡
äºŒè€…åœ¨æ¯æ¬¡çš„æ¼”åŒ–æ˜¯ä»£ä¸­äº¤æ›¿åŸ·ï¨ˆã€‚CPSO å°‡è§£å‘ï¥¾ç©ºé–“åˆ†æˆï¥©å€‹å­ç©ºé–“ï¼Œæ¯ä¸€å€‹å­ç©ºé–“
å€‹åˆ¥ä½¿ç”¨ä¸€çµ„ï§¹å­æ—ç¾¤ï¼ˆSwarmï¼‰ï¤­æ±‚è§£ï¼›ä¹Ÿå°±æ˜¯ï¥¯ï¼ŒCPSO ä½¿ç”¨çš„æ˜¯ä¸€ç¶­ç©ºé–“çš„ï§¹å­æ—ç¾¤
ï¤­æ±‚è§£å–®ä¸€ç¶­ï¨å•é¡Œï¼Œå¾…æ‰€æœ‰ç¶­ï¨æ±‚è§£å®Œæˆï¼Œå†å°‡å…¶åˆä½µã€‚å¦å¤–ï¼ŒPeram ç­‰äººæå‡ºï¦ºä»¥é©
æ‡‰è·ï§ªï¥¡ç‚ºä¸»çš„ï§¹å­ç¾¤æœ€ä½³åŒ–æ¼”ç®—æ³•ï¼ˆFitness-distance-ratio based particle swarm optimization, 
FDR-PSOï¼‰[27]ï¼Œè©²æ¼”ç®—æ³•åœ¨ï§¹å­æ—ç¾¤ä¸­å®šç¾©ï¦º n å€‹è·ï§ªæœ€æ¥è¿‘å…¶è‡ªèº«ï§¹å­çš„å…¶ä»–ï§¹å­ç‚º
é„°åŸŸï¼Œè€Œæ­¤è·ï§ªçš„è¨ˆç®—ï¼Œå³ç‚ºï§¹å­é–“çš„æ­å¹¾ï§©å¾—è·ï§ªï¼ˆEuclidean distanceï¼‰ã€‚åœ¨ In [28]ä¸­ï¼Œ, 
è½‰å‘å› å­( turn-around factor)è¢«æå‡ºï¤­ï¼Œä¸¦åŠ å…¥åŸå§‹ PSO æ¶æ§‹ä¹‹ä¸­ä»¥è§£æ±ºå‹•æ…‹å•é¡Œï¼Œå¦‚ï¼š
éš±è”½å¼è¨Šè™Ÿåˆ†ï§ªå•é¡Œ( blind source separation)ã€‚åœ¨å‹•æ…‹ç³»çµ±ä¸­çš„æ™‚è®Šå‹æœ€ä½³åŒ–å•é¡Œä¸­ï¼Œç”±æ–¼
æœ€ä½³è§£çš„æ‰€åœ¨åœ°å°‡æœƒéš¨æ™‚é–“è€Œæ”¹è®Šï¼Œé€™å°‡æœƒä½¿å¾—ï§¹å­ç¾¤ç„¡æ‰€é©å¾(ä¸Šä¸€æ¬¡çš„æœ€ä½³ç¶“é©—æˆ–æœå°‹
æ–¹å‘ï¼Œåœ¨ä¸‹å€‹æ™‚é–“é»å¯èƒ½ï¥§é©ç”¨)ï¼Œå‡å¦‚åƒ…åƒ…ä¾æ“šå…ˆå‰çš„ç¶“é©—æ±‚è§£ï¼Œå°‡å¯èƒ½æœƒå°è‡´æœå°‹çµæœ
ï¥§å¦‚é æœŸã€‚El-Abd å’Œ Kamel æå‡ºï¦ºéšå±¤å¼åˆä½œï§¹å­ç¾¤æœ€ä½³åŒ–æ¼”ç®—æ³•( hierarchal cooperative 
particle swarm optimizer) [29]ï¼Œè©²æ¼”ç®—æ³•çµåˆï¦ºï¥¸ç¨®å‰æœŸæå‡ºçš„æ¼”ç®—æ³• CONPSO [30]å’Œ
CPSO-Sã€‚é€™æ¨£çš„çµåˆæ–¹å¼æ˜¯è®“ï¥¸ç¨®æ¼”ç®—æ³•å„è‡ªçš„ï§¹å­ç¾¤å„è‡ªæ±‚è§£ï¼Œä¸¦é€²ï¨ˆè³‡è¨Šäº¤æ›å·²å¾—åˆ°
è¼ƒå¥½çš„æ”¶æ–‚æ€§ã€‚åœ¨è¿‘æœŸï¼Œæœ‰ä¸€å€‹å»£æ³›å¼å­¸ç¿’ï§¹å­ç¾¤æœ€ä½³åŒ–æ¼”ç®—æ³•( comprehensive learning 
particle swarm optimizer, CLPSO) [31]è¢«æå‡ºï¤­ã€‚å®ƒçš„å­¸ç¿’ç­–ï¥¶ä½¿æ¨æ£„å…¨åŸŸæœ€ä½³è§£çš„è³‡è¨Šï¼Œ
å–è€Œä»£ä¹‹çš„æ˜¯å…¶ä»–ï§¹å­çš„éå»æœ€ä½³è§£ï¼Œä¸¦è—‰ä»¥æ±ºå®šæ¯ä¸€å€‹ï§¹å­çš„ä¸‹ä¸€å€‹ç§»å‹•é€Ÿï¨å‘ï¥¾ã€‚ åœ¨
å¤šæ¨¡æ…‹å•é¡Œä¸­ï¼ŒCLPSO å¯ä»¥æœ‰æ•ˆçš„æ”¹å–„åŸå§‹ PSO çš„æ±‚è§£æ•ˆèƒ½ã€‚ 
ç”±æ–¼æœ‰è¶Šï¤­è¶Šå¤šçš„ PSO ç‰ˆæœ¬èˆ‡è®Šå½¢ï§“çºŒè¢«æå‡ºï¤­ï¼Œç„¶è€Œé‚£ä¸€å€‹ç‰ˆæœ¬å¯ä»¥è¢«ç¨±ä¹‹ç‚ºâ€æ¨™
æº–â€å‰‡é›£æœ‰å®šï¥ï¼Œå› æ­¤åˆ¶å®šâ€æ¨™æº– PSOâ€çš„æ§‹æƒ³ä¹Ÿè¢«æå‡ºï¤­ã€‚é€™å€‹æ§‹æƒ³æ˜¯ç”± James Kennedy èˆ‡ 
Maurice Clerc æ‰€ä¸»å°çš„ã€‚å°‡ç¾æœ‰çš„ PSO æ¯ï¦æ•´ï§¤ä¸€æ¬¡ï¼Œä¸¦åˆ¶å®šå“ªä¸€å€‹ç‰ˆæœ¬å¯ç¨±ä¹‹ç‚ºæ¨™æº–ä»¥
å…ç ”ç©¶å­¸è€…åœ¨æ¯”è¼ƒæ™‚ç„¡æ‰€é©å¾ã€‚æ¨™æº– PSO çš„åˆ¶å®šä¸¦éåœ¨æå‡ºä¸€å€‹ç¾æœ‰æœ€ä½³çš„æ¼”ç®—æ³•ï¼Œè€Œæ˜¯
ä»¥æœ€æ¥è¿‘åŸå§‹ PSO (1995 è¢«æå‡ºï¦ç‰ˆæœ¬)ä¸¦æ·»åŠ äº›è¨±æ”¹ï¥¼çš„æ”¹ï¥¼ç‰ˆ[32]ã€‚ 
algorithm,â€ in Proc. of WCICA 5th world congress on Intelligent Control and Automation, 
vol. 3, pp. 2240-2244, 2004. 
[18] P. Zheng, Y. Liu, L. Tian and Y. Cao, â€œA blind source separation method based on 
diagonalization of correlation matrices and genetic algorithm,â€ in Proc. of WCICA 5th 
world congress on Intelligent Control and Automation, vol. 3, pp. 2127-2131, 2004. 
[19] J. Kennedy and R. Eberhart, â€œParticle Swarm Optimization,â€ in proceeding of the Fourth 
IEEE International Conference on Neural Networks, pp. 1942-1948, 1995. 
[20] Y. Shi and R. C. Eberhart, â€œA modified particle swarm optimizer,â€ in Proc. of IEEE World 
Congress on Computational Intelligence, pp. 69-73, May 1998. 
[21] R. C. Eberhart and Y. Shi, â€œTracking and optimizing dynamic systems with particle 
swarms,â€ in Proc. of IEEE world congress on Evolutionary Computation 2001 (CEC 2001), 
pp. 94-97, May 2001.  
[22] P. Angeline, â€œUsing selection to improve particle swarm optimization,â€ in Proc. of 
International joint conference on Neural Networks (IJCNNâ€™99), pp. 84-89, Jul. 1999. 
[23] A. P. Engelbrecht, Computational intelligence an introduction, Wiley, pp.185-195, 2002.  
[24] J. Kennedy and R. Mendes, â€œPopulation structure and particle swarm performance,â€ in Proc. 
of IEEE world congress on Evolutionary Computation 2001 (CEC 2002), pp. 1671-1676, 
May 2002. 
[25] K. E. Parsopoulos and M. N. Vrahatis, â€œUPSOâ€”A unified particle swarm optimization 
scheme,â€ in Lecture Series on Computational Sciences, pp. 868-873, 2004. 
[26] F. van den Bergh and A. P. Engelbrecht, â€œA cooperative approach to particle swarm 
optimization,â€ IEEE Trans. on Evolutionary Computation, vol. 8, pp. 225-239, Jun. 2004. 
[27] T. Peram, K. Veeramachaneni and C. K. Mohan, â€œFitness-distance-ratio based particle 
swarm optimization,â€ in Proc. of Swarm Intelligence Symposium, pp. 174-181, 2003. 
[28] C. L. Lin, S. T. Hsieh, T. Y. Sun and C. C. Liu, â€œPSO-based learning rate adjustment for 
blind source separation,â€ in Proc. of International Symposium on Intelligent Signal 
Processing and Communications Systems (ISPACS), pp. 181-184, Dec. 2005. 
[29] M. El-Abd and M. S. Kamel, â€œA Hierarchal Cooperative Particle Swarm Optimizer,â€ in 
Proc. Swarm Intelligence Symposium, pp. 43-47, 2006. 
[30] S. Baskar and P. N. Suganthan, â€œA novel concurrent particle swarm optimization,â€ in Proc. 
of IEEE Congress on Evolutionary Computation, vol. 1, pp. 792-796, 2004. 
[31] J. J. Liang, A. K. Qin, P. N. Suganthan and S. Baskar, â€œComprehensive learning particle 
swarm optimizer for global optimization of multimodal functions,â€ IEEE Trans. on 
Evolutionary Computation, vol. 10, pp. 281-296, Jun, 2006. 
[32] http://particleswarm.info/ 
å››ã€ ç ”ç©¶æ–¹æ³• 
æœ¬ç ”ç©¶ä»¥ï§¹å­ç¾¤æœ€ä½³åŒ–æ¼”ç®—æ³•[20]ç‚ºåŸºç¤ï¼Œé‡å°å…¶æœå°‹ç‰¹æ€§åŠ ä»¥ç ”ç©¶ï¼Œç”±æ–¼åœ¨(3.1)å¼
velocity çš„ï¤æ–°æ–¹ç¨‹å¼ä¸­ï¼Œï§¹å­çš„ç§»å‹•å‘ï¥¾ï¼Œå°‡æœƒæ ¹æ“šè‡ªèº«å…ˆå‰çš„ç§»å‹•å‘ï¥¾ä»¥åŠéå»æœ€ä½³çš„
ä½ç½®ä»¥åŠç¾¤ä¸­æœ€ä½³ä½ç½®ï¤­å‰å¾€æ–°çš„åœ°é»é€²ï¨ˆæœ€ä½³è§£çš„æœå°‹ã€‚ç”±æ–¼ç¾¤ä¸­æœ€ä½³è§£æ¥µæœ‰å¯èƒ½åƒ…åª
æ˜¯æœå°‹ç©ºé–“çš„å±€éƒ¨æœ€ä½³è§£(Local optimum)ã€‚ç•¶ä¸€ç¾¤ï§¹å­æ±Ÿæœå°‹ç„¦é»é›†ä¸­åœ¨æŸä¸€å€‹å±€éƒ¨æœ€ä½³
è§£æ™‚ï¼Œå°æ–¼å»£æ³›æ¢ï¥ªä»¥æ±‚å–æ–°è§£æ˜¯æ²’æœ‰å¹«åŠ©çš„ï¼Œå› æ­¤ï¼Œå¦‚æœå¯ä»¥é©ï¨çš„åŠ å…¥æ“¾å‹•çš„æ©Ÿåˆ¶ï¼Œ
Particle 1
Particle 2
Global best 
solution Past best 
solution 
 
åœ–4.2 ï§¹å­ç§»å‹• 
  å› æ­¤ï¼Œç‚ºï¦ºæ“´å±•æœå°‹è§£ç©ºé–“çš„ç¯„åœï¼Œä»¥æå‡PSOæ•´é«”æœå°‹èƒ½ï¦ŠåŠåŠ é€Ÿæ¢æ¸¬èˆ‡é–‹ç™¼æ™‚é–“ï¼Œ
æˆ‘å€‘æ§‹æƒ³å‡ºï¦ºæ–°çš„PSOç§»å‹•æ©Ÿåˆ¶: 
  )]}()()[(                               
)]()()[()({)1(
22
11
gxggbestgrc
gxgpbestgrcgwvTgv
i
iiii
i
i
ï€­ï€«
ï€­ï€«ï€½ï€«
    (4.2) 
 å…¶ä¸­Tç‚ºè½‰å‘å› å­(turn-around factor),ï¦¨æ‰€æœ‰å¥‡ï¥©ï§¹å­çš„Tç‚º1,å¶ï¥©ï§¹å­çš„Tç‚º-1ï¼Œå¦‚åœ–4.3
æ‰€ç¤ºï¼Œå¯ä»¥ç™¼ç¾åŠ å…¥è½‰å‘å› å­(T =-1)å¾Œï¼Œï§¹å­æœƒåšä¸€å€‹èˆ‡ç›®å‰å­¸ç¿’ç¶“é©—ç›¸åçš„ç§»å‹•ï¼Œä»¥åœ–
ä¸­ï¦µå­ï¥¯æ˜ï¼Œæ­¤æ©Ÿåˆ¶æœƒè¼ƒæœ‰æ•ˆï¥¡çš„æœå°‹åˆ°æœ€å¥½çš„è§£ã€‚ 
Global best solution 
Past best 
solution 
Particleâ€™s next position by (4.2)
Particleâ€™s current position 
Particleâ€™s next position 
by (3.1) or (4.2) Optimal solution 
 
åœ–3.7 åŠ å…¥è½‰å‘å› å­çš„ï§¹å­ç§»å‹•ç©ºé–“ 
äº”ã€ çµæœèˆ‡è¨ï¥ 
 ç‚ºï¦ºé©—è­‰è¨ˆç•«ä¸­æ‰€æå‡ºçš„æ–¹æ³•åœ¨æœå°‹æœ€ä½³è§£ä¸­çš„æ•ˆèƒ½æ”¹é€²ï¼Œè¨ˆç•«ä¸­æ¡ç”¨ï¦º CEC 2005 
Benchmark çš„æ¸¬è©¦å‡½ï¥©(è©³ï¥«é™„ï¤¿)ï¼Œä¸¦æŒ‘é¸ Std. PSO 2006 (æ¨™æº– PSO 2006 ç‰ˆ)åšç‚ºæ¯”è¼ƒé©—è­‰
çš„å°è±¡ã€‚åœ¨æ¸¬è©¦å‡½ï¥©ä¸­ï¼Œæœ€ä½³è§£å€¼è¶Šå°è¶Šå¥½ï¼Œè€Œåˆå§‹è¨­å®šèˆ‡æœ€ä½³è§£çš„ä½ç½®è©³ï¦œæ–¼é™„ï¤¿ä¸­ã€‚ 
 è¨ˆç•«ä¸­æŒ‘é¸ CEC 2005 Benchmark å…¶ä¸­çš„ 12 å€‹å‡½ï¥©ï¼Œå¾è¤‡é›œå•é¡Œä»¥è‡´æ–¼é«˜ï¨è¤‡é›œçš„æ··
åˆå•é¡Œï¼Œä»¥åšç‚ºé©—è­‰æ¼”ç®—æ³•æœå°‹èƒ½ï¦Šå„ªï¦çš„ä¾æ“šã€‚æˆ‘å€‘é‡å°æ¯ä¸€å€‹å•é¡Œï¨¦å€¼å‹ 25 æ¬¡çš„æœ
å°‹ï¼Œè¨ˆç®—çš„ FEs(Fitness Evaluations)è¨­å®šç‚º 50,000ï¼Œä¸¦è¨ˆç®—å…¶æ±‚è§£çš„æœ€å¤§å€¼ã€æœ€å°å€¼ã€å¹³å‡
é™„ï¤¿ 
A. æ¸¬è©¦å‡½ï¥© 
1) Shifted Schwefel Problem 1.2 with Noise in Fitness 
],...,,[ ,
_))1,0(4.01(* 1
2
1 1
1
N
i
i
j
j
xxx
biasfNzf
ï€½ï€­ï€½
ï€«ï€«ïƒ·ïƒ·ïƒ¸
ïƒ¶
ïƒ§ïƒ§ïƒ¨
ïƒ¦
ïƒ·ïƒ·ïƒ¸
ïƒ¶
ïƒ§ïƒ§ïƒ¨
ïƒ¦ï€½ ïƒ¥ ïƒ¥
ï€½ ï€½
xoxz 21 N
   (12) 
2) Schwefel Problem 2.6 with Global Optimum on Bounds 
0*)(],3 ,1[*,...1
},52,72max{ 2121
ï€½ï€½ï€½
ï€­ï€«ï€­ï€«ï€½
xfxni
xxxxf  
Extend to N dimensions: 
] ..., , ,[ ,
...1 ,_}max{
21
22
N
ii
xxx
Nibiasff
ï€½ï€­ï€½
ï€½ï€«ï€­ï€½
xoxz
BxA         (13) 
where A is a N*N matrix, aij are integer random numbers in the range [-500, 500], 
, Ai is the ith row of A. Bi=Ai*o, o is s N*1 vector, oi are random in the range[-100, 
100]. After load the data file, set oi=-100, for 
0)det( ï‚¹A
]4/[,...,2,1 Ni ï€½ , oi=100, for . NNi ],...,4/3[ï€½
3) Shifted Rotated Ackley Function with Global Optimum on Bounds 
 
]..., , ,[ ,*)(
_20)2cos(1exp
12.0exp20
21
3
1
1
2
3
N
N
i
i
N
i
i
xxx
biasfez
N
z
N
f
ï€½ï€­ï€½
ï€«ï€«ï€«ïƒ·ïƒ¸
ïƒ¶ïƒ§ïƒ¨
ïƒ¦ï€­
ïƒ·ïƒ·ïƒ¸
ïƒ¶
ïƒ§ïƒ§ïƒ¨
ïƒ¦ï€­ï€­ï€½
ïƒ¥
ïƒ¥
ï€½
ï€½
xMoxz
ï°      (13) 
where M is the linear transformation matrix, condition number=100. 
4) Shifted Rastrigin Function 
]..., , ,[ ,
_)10)2cos(10(
21
4
1
22
4
N
N
i
iii
xxx
biasfzzzf
ï€½ï€­ï€½
ï€«ï€«ï€­ï€½ïƒ¥
ï€½
xoxz
ï°     (14) 
5) Shifted Expanded Griewank plus Rosenbrock Function 
Griewank Function: ïƒ¥ ïƒ•
ï€½ ï€½
ï€«ï€­ï€½
N
i
N
i
ii
a j
xx
f
1 1
2
1)cos(
4000
       
Rosenbrock Function: ï€¨ ï€© ï€¨ ï€©ï€¨ ï€©ïƒ¥ï€­
ï€½
ï€­ ï€­ï€«ï€­ï€½
1
1
22
1
2 1100
N
i
iiib xxxf        
] ..., , ,[ ,1
_)),(()),((
...)),(()),((
21
511
32215
N
NbaNNba
baba
xxx
biasfzzffzzff
zzffzzfff
ï€½ï€«ï€­ï€½
ï€«ï€«ï€«
ï€«ï€«ï€½
ï€­
xoxz
       (16) 
6) Hybrid Composition Function 1 
f6 is composed using ten different benchmark functions: two Rastrigin functions, two Weierstrass functions, 
two Griewank functions, two Ackley functions and two Sphere functions. 
B å‡½ï¥©åˆå§‹è¨­å®š 
 
f å…¨åŸŸæœ€ä½³è§£ åˆå§‹ç¯„åœ æœå°‹ç¯„åœ å‡½ï¥©åç§»æ¤ 
f1 -450 [-100, 100]N [-100, 100]N -450 
f2 -310 [-100, 100]N [-100, 100]N -310 
f3 -140 [-32, 32]N [-32, 32]N -140 
f4 -330 [-5, 5]N [-5, 5]N -330 
f5 -130 [-3, 1]N [-3, 1]N -130 
f6 120 [-5, 5]N [-5, 5]N 120 
f7 120 [-5, 5]N [-5, 5]N 120 
f8 10 [-5, 5]N [-5, 5]N 10 
f9 10 [-5, 5]N [-5, 5]N 10 
f10 10 [-5, 5]N [-5, 5]N 10 
f11 260 [-5, 5]N [-5, 5]N 260 
f12 260 [-2, 5]N No Boundary 260 
 
 
å…¨æ–‡å®Œ 
 
 åœ–ä¸€ æœƒå ´å‰ªå½± 
åœ¨ 6 æœˆ 5 è™Ÿç•¶å¤©ï¼Œæ—©ä¸Šæœ‰ Takeshi Yamakawa ä¸»è¬›çš„ Bio-inspired Self-Organizing 
Relationship Network as Knowledge Acquisition Tool and Fuzzy Inference Engineï¼Œä¹Ÿå¼•ç™¼æœƒ
å ´å­¸è€…çš„ç†±ï¦Ÿè¨ï¥ï¼Œæ¨¡ç³Šæ¨ï¥å¼•æ“çš„ç›¸é—œç ”ç©¶èˆ‡æ–¹æ³•ä¹Ÿè¢«å……åˆ†çš„äº¤ï§Šã€‚ 
ä¸‹åˆå®‰æ’æœ¬äººçš„å ±å‘Šæ˜¯å±¬æ–¼ Special Session ä¹‹ä¸€ï¼Œæ˜¯é‡å°é«˜ç¶­ï¨è¤‡é›œå•é¡Œæ‰€é–‹è¨­çš„ä¸»é¡Œï¼Œ
é¦–å…ˆå¤§å®¶ï¨¦é‡å°ï¥§åŒçš„æœ€ä½³åŒ–æ–¹æ³•åŠ ä»¥ï¥¯æ˜ï¼Œä¸¦å°å…¥å„è‡ªæ‰€æå‡ºçš„æ–°æ–¹æ³•ï¼Œä¸¦æ–¼å ±å‘Šå¾Œ
çµ¦äºˆ 10~30 åˆ†é˜çš„å•é¡Œè¨å•ï¼Œä¹Ÿå› ç‚ºè¨ï¥éå¸¸ç†±ï¦Ÿï¼Œå› æ­¤çµæŸæ™‚é–“ä¹Ÿé è¶…éåŸæœ¬çš„è­°ç¨‹ã€‚
åœ–äºŒæ˜¯ï¥æ–‡å ±å‘Šçš„å‰ªå½±ï¼Œæœ¬äººçš„å ±å‘Šæ™‚é–“å¤§ç´„ç‚º 15 åˆ†é˜ã€‚ 
 
åœ–äºŒ ï¥æ–‡å ±å‘Š 
äºŒã€èˆ‡æœƒå¿ƒå¾— 
WCCI æ˜¯ 2 ï¦èˆ‰è¾¦ä¸€æ¬¡çš„è¶…å¤§å‹åœ‹éš›æœƒè­°ï¼Œæœƒè­°çµåˆï¦ºä¸‰å€‹åŸæœ¬è¦æ¨¡å°±ï¥§å°çš„ç ”è¨æœƒã€‚
æœ¬æ¬¡å‡ºçš„ç ”è¨æœƒï¼Œçš„ç¢ºå¾—ä»¥è§€æ‘©è¨±å¤šå„ªç§€çš„ç ”ç©¶èˆ‡çš„ï¥æ–‡ï¼Œç•¶ä¸­æœ‰äº›æ–¹æ³•æ¥µå¯Œå·§æ€ï¼Œï¥«è€ƒä»–
äººçš„ï§¤ï¥ä»¥åŠè§£æ±ºå•é¡Œçš„æŠ€å·§ï¼Œä¹Ÿå¾ˆèƒ½æ¿€ç™¼è¨±å¤šåœ¨æœªï¤­ç ”ç©¶æ–¹å‘çš„æƒ³æ³•ï¼Œåœ¨æœƒä¸­çš„æ™šå®´ï¼Œï¤
æ˜¯ä¿ƒé€²äº¤ï§Šçš„æœ€ä½³ç®¡é“ï¼Œèˆ‡ä¸€äº›åœ¨æœƒå ´ä¸­èªï§¼çš„åœ‹éš›å‹äººè¨ï¥ä»–å€‘çš„ï¥æ–‡å…§å®¹ã€æ–¹æ³•èˆ‡ï§¤ï¥ï¼Œ
æˆ–æ˜¯é–’è©±å®¶å¸¸çš„å°è©±ï¼Œç„¡å½¢ä¸­ä¹Ÿäº¤ï§Šï¦ºä¸€äº›ï¥§åŒçš„åƒ¹å€¼è§€é»ã€‚æœ‰è¶£çš„æ˜¯ï¼Œåœ¨æœƒå ´ä¹Ÿé‡åˆ°å°ç£
çš„æ•™æˆå¸¶ï¦´å­¸ç”Ÿä¸€åŒå‡ºå¸­ï¼Œä¹Ÿæœ‰ä¸€äº›ä»¥å¾€æ›¾åœ¨æœƒè­°ä¸­èªï§¼çš„äººä¸€åŒï¥«èˆ‡æœƒè­°ï¼Œï¥§ä½†èƒ½å¤ ï¦ºè§£
ï¥§åŒåœ°å€æˆ–æ˜¯ï¥§åŒåœ‹å®¶çš„å­¸è€…åœ¨åšç ”ç©¶ä¸Šé¢çš„æ…‹ï¨ï¼Œï¤èƒ½ï¦ºè§£è‡ªæˆ‘å­˜åœ¨çš„æ¸ºå°ä»¥åŠå°šå¾…åŠªï¦Š
åŠ å¼·çš„åœ°æ–¹ã€‚ 
åœ¨æœ¬æœƒè­°æœŸé–“ï¼ŒåŒ…å­¸ç”Ÿæ‰€ç™¼è¡¨çš„ï¥æ–‡åœ¨å…§ï¼Œå°ç£æ‰€ç™¼è¡¨çš„ï¥æ–‡åªæœ‰å¯¥å¯¥å¹¾ç¯‡ï¼Œç›¸è¼ƒä¹‹ä¸‹ï¼Œ
å¤§ï§“çš„å­¸è€…åœ¨ç›¸é—œçš„ç ”ç©¶ï¦´åŸŸå°±æœ‰æ¯”è¼ƒå¤šçš„è²¢ç»ã€‚å¯èƒ½æ˜¯å› ç‚ºåœ¨é¦™æ¸¯èˆ‰è¾¦ï¼Œæ‰€ä»¥å¤§ï§“çš„å­¸è€…
æŠ•ç¨¿ä¹Ÿæ¯”è¼ƒè¸´èºã€‚å…¶å¯¦ï¼Œçœ‹åˆ°å…¶ä»–ç ”ç©¶å–®ä½å°æ–¼ä¸€å€‹ç ”ç©¶ç¸½æ˜¯å¾ˆé¡˜æ„æŠ•å…¥å……åˆ†çš„æ™‚é–“ã€äººï¦Š
å’Œç¶“è²»ï¼Œå¦‚æ­¤ä¸€ï¤­ä¹Ÿå¯ä»¥ï¥ç©è¼ƒå¤šçš„ç ”ç©¶æˆæœã€‚ç¸½æœ‰æ™‚å€™å›é ­çœ‹çœ‹è‡ªå·±çš„ç ”ç©¶è³‡æºï¼Œçš„ç¢ºæ˜¯
é‚„æœ‰å¾ˆå¤šå¯ä»¥åŠªï¦Šçš„ç©ºé–“ï¼Œå¦‚æœå¯ä»¥æœ‰æ•™å……è¶³çš„ç¶“è²»èˆ‡äººï¦Šæ”¯æ´ï¼Œç›¸é—œçš„ç ”ç©¶ä¹Ÿå¯ä»¥æ¨å±•å¾—
ï¤é †ï§ã€‚ 
 
 
For all , is the velocity of j-th dimension of the
i-th particle, the c1 and c2 denote the acceleration coefficients,
r1 and r2 are elements from two uniform random sequences in
the range (0, 1), and g is the number of generations. The new
position of a particle is calculated as follows:
Nj ...1 jiv ,
)1()()1(
,,,
 gvgxgx jijiji (2)
The past best position of each particle is updated using
        
      	






gpbestfgxfgx
gpbestfgxfgpbest
gpbest
iii
iii
i 1if,1
1if,
1


(3)
and the global best position gbest found from all particles
during the previous three steps is defined as:
sigpbestfggbest i
ipbest
 1)),1((minarg)1( (4)
The value of moving vector vi can be restricted to the range
[-vmax, vmax] to prevent particles frommoving out of the search
range
B. Some Variants of PSO
Since Kennedy and Eberhart [1] introduced PSO in 1995,
many researchers have worked on improving its performance
in various ways. One of the variants introduces a parameter
called inertia weight of velocity w into the original PSO,
introduced by Shi and Eberhart [6]. The new velocity update
algorithm is shown as follows:
)]()()[(
)]()()[()()1(
,22
,,11,,
,
,
gxggbestgrc
gxgpbestgrcgwvgv
jij
jijijiji
ji
ji

 (5)
It plays the role of balancing the global search and local
search. It can be a positive constant or even a positive linear
or nonlinear function of time. This value is typically setup to
vary linearly from 1 to 0 during the course of a training run.
The inertia weight is similar to the momentum term in a
gradient descent neural network training algorithm.
In population-based optimization methods, how the local
and global exploration is controlled will influence efficiency
on finding the optimal solution directly. PSO has been proven
to be effective while applied to optimizing static problems in
earlier developments. Even so, most real-world applications
are identified as nonlinear dynamic systems. Eberhart and Shi
[7] found that the fixed or liner decreased inertia weight for
PSO is not very effective for tracking dynamic systems.
Considering the dynamic nature of real-world applications, a
random inertia weight factor was proposed for tracking
dynamic systems instead.
Another interesting approach to improve PSO performance
was proposed by Angeline [8] who used a tournament
selection process based on the particlesâ€™ current fitness. This
method copies the current positions and velocities of the
better half of the population to replace the worse half, without
changing the â€œpersonal bestâ€ values of any of the particles in
current step.
The local best version of PSO, lbest, reflects the circle
neighborhood structure. Particles are influenced by the best
position within their neighborhood, as well as their own past
experience. While lbest is slower in convergence than gbest,
lbest results in much better solutions and searches a larger
part of the searching space [9].
More recently, Kennedy investigated other neighborhood
topologies, finding that the von Neumann topology resulted
in superior performance [10]. In [11], Parsopoulos and
Vrahatis proposed a unified particle swarm optimizer (UPSO)
which combined both the global version and local version. A
cooperative particle swarm optimizer (CPSO) [3] which
include two versions: CPSO-S and CPSO-H were also
proposed. The CPSO-S model is a direct application of
Potter' s CCGA model to the standard PSO, while the
CPSO-H model combines the standard PSO with the CPSO-S
model, and performs them both in each generation. CPSO
split the space (solution vector) into several sub-spaces
(smaller vectors) where each sub-space is optimized using a
separate swarm, i.e. CPSO use one-dimensional swarms to
search each dimension separately, the results are then
integrated. Peram et al. proposed the fitness-distance-ratio
based particle swarm optimization (FDR-PSO) [12], which
defines the â€œneighborhoodâ€ of a particle as its n closest
particles of all particles in the population (measured in
Euclidean distance). In [13], the turn-around factor was
involved in original PSO to solve dynamic problems such as
blind source separation. Due to the time-varying optimal
solutions in dynamic systems, it may be harder for the
particles to catch up to various variations in each time slot,
and may produce undesirable results if they move according
to previous experiences only. El-Abd and Kamel proposed a
hierarchal cooperative particle swarm optimizer [14] which
combines two previously proposed models, CONPSO [15]
and CPSO-S. The combination is achieved by having two
swarms searching for a solution concurrently for solution
exchange and performing better convergence. Recently, a
comprehensive learning particle swarm optimizer (CLPSO)
[4] was proposed. Its learning strategy abandons the global
best information, and all other particlesâ€™ past best information
is used to update particlesâ€™ velocity instead. CLPSO can
significantly improve the performance of the original PSO on
multimodal problems. There are more and more improved
variants of PSO have been proposed, but it is hard to define
which variants of PSO is the standard one. Thus, the idea of
the standard PSO is to define a real standard at least for one
year, validated by some researchers of the field, in particular
James Kennedy and Maurice Clerc. This PSO version does
not intend to be the best one on the market (in particular there
is no adaptation of the swarm size nor of the coefficients) but
simply very near of the original version (1995) with just a few
improvements based on some recent works [16].
III. EFFICIENCT POPULATION UTILIZATION STRATEGY FOR
PARTICLE SWARMOPTIMIZER (EPUS-PSO)
Although PSO algorithms have been applied to a wide
range of optimization problems and numerous variants of the
PSO exist, solving high complexity problems with efficient
1778 2008 IEEE Congress on Evolutionary Computation (CEC 2008)
Authorized licensed use limited to: National Dong Hwa University. Downloaded on February 4, 2009 at 21:35 from IEEE Xplore.  Restrictions apply.


	










ijijr
jijiji
ijij
jijiji
ji
Psrandifgxgpbestgrc
gxgpbestgrcgwv
Psrandifgxggbestgrc
gxgpbestgrcgwv
gv
i
i
i
i
)]()()[(
)]()()[()(
)]()()[(
)]()()[()(
)1(
,,22
,,11,
,22
,,11,
,
(6)
where Psi denotes the solution sharing probability, whose
definition will have a detail description later, of the ith
particle. It will decide if the moving vector of the third item in
the velocity update equation is referring to the gbest or
another particleâ€™s pbest (pbestr). The pbestr can be any other
particleâ€™s pbest, not including its own.
In [4], Liang et al. found that different Learning
Probability values will affect the results for the same problem
if the same value of learning probability was used for all the
particles in the swarm. Thus, each particle will be given a
unique sharing probability. Before the particleâ€™s new velocity
is calculated, a random number will be generated. If this
number is larger than or equal to Psi, the guide of the third
item of the velocity update equation will be the gbest. On the
other hand, if this number is smaller than Psi, the particle will
learn from another particleâ€™s pbest. In other words, the guide
of the third item (gbest) of the velocity update equation will
be replaced by pbestr. The selection of pbestr is stated as
follows.
If the random number is smaller than Psi
1) Randomly choose two particlesâ€™ pbest from the
population (Except the pbesti).
2) Compare the fitness values of both pbest and select the
better one as pbestr.
3) pbestr will share its own information of all dimensions.
Thus, the solution searching of all the particles refer to not
only their own pbest but also have the chance for learning
from other particlesâ€™ pbest.
Since the dimensional information is incorporated in
calculating the particlesâ€™ solution sharing probability. The
definition of learning probability in [4] was referred to define
the solution sharing probability for each particle:
 
N
s
iN
Psi
1
1
1
exp1
5.0









 (7)
where N denotes the dimension of problems and s is the
population size. The solution sharing strategy will be not
necessary while solving one-dimensional problems. The
solution sharing probability will be set as zero due
to .01N
There are two main differences between the solution
sharing strategy and the comprehensive learning strategy [4].
1) The solution sharing strategy not only learns from other
particlesâ€™ experiences but also refers to gbestâ€™s
information.
2) For each particle, the solution sharing strategy picks
another particleâ€™s pbest as one of the guides for current
movement instead of fine tuning dimensions one by
one.
C. Searching Range Sharing (SRS)
According to the searching behavior of PSO, the gbest will
be an important clue in leading particles to the global optimal
solution. But it is unavoidable for the solution to fall into the
local minimum while particles try to find better solutions. In
fact, after several generations, particles will gather in several
clusters, or even just one cluster, which is the local minimum.
Each particle in the cluster may perform a local search to
follow evolution, but not be able to explore other better
solutions.
In order to allow the solution exploration in the area to
produce more potential solutions, and find unsearched
solution space. The searching range sharing (SRS) strategy, a
mutation-like evolutionary strategy, was introduced to the
EPUS-PSO algorithm. The SRS strategy can be classified
into two versions: local and global. The two versions of SRS
are classified according to a restricted boundary. Similar to
mutation operation, the SRS activates under a predefined
SRS rate which can be setup to vary linearly from 0 to 0.2
during the course of a training run. Note that this is similar to
the temperature adjustment schedule found in Simulated
Annealing (SA) algorithm.
In the local version, the particleâ€™s new position will be
restricted in the boundary of all past best solution of all
particles ( ). Through local SRS, the
perturbed particles will start solution searching in the reduced
range. This will increase efficiency of solution searching for
particles. Similarly, in the global version, the particlesâ€™ new
positions will be restricted in the search boundary as an initial
state ( ). Through global SRS, the perturbed
particles are randomly distributed in the initial search range.
It will increase the probability of finding potential solutions
in un-searched areas. The local version can share particlesâ€™
searching ranges to make solution searching for particles
more efficient. The global version can prevent solution from
being trapped in the local optimum.
],[ maxmin pbestpbest
],[ maxmin XX
TABLE I
SEARCH RANGE SHARING STRATEGY
Local version Global version
For
Particles
To perturb selected particle
and place them in reduced
range ],[ maxmin pbestpbest
To perturb particle and place
them in initial range
],[ maxmin XX
For
Dimensions
To perturb selected
dimension (d1) of current
particle to another selected
dimension (d2)â€™s searching
range ],[
maxmin 22 dd pbestpbest
To Perturb selected
dimension (d1) of current
particle to another selected
dimension (d2)â€™s searching
range ],[ maxmin XX
The SRS not only can share searching range between
particles but also share searching range between dimensions.
For particles, the particlesâ€™ current positions (solution) for all
dimensions will be perturbed. This particle will be placed at a
new position in the restricted boundaries while the SRS is
activated. For dimensions, a dimension will be picked up
randomly; all particlesâ€™ corresponding dimensions will be
1780 2008 IEEE Congress on Evolutionary Computation (CEC 2008)
Authorized licensed use limited to: National Dong Hwa University. Downloaded on February 4, 2009 at 21:35 from IEEE Xplore.  Restrictions apply.
IV. EXPERIMENTS
In the experiments, seven CEC 2008 test functions
including two unimodal and five multimodal functions was
chosen for testing the proposed method. The system
environments are listed as follows:
TABLE II
ESTIMATED RUNTIME FOR THE TEST SUITE
System Windows XP (SP2)
CPU
Intel Core 2 Duo E4400 (2.0 GHz x
2). Only one of the processors was
used.
RAM 1 G
Language Matlab 7.4
Algorithm EPUS-PSO
Although the system is with a Core 2 Duo processor, for fair
comparison, one of the two processors was used, i.e. only
50% computation resource of this CPU was used.
In the experiments, the parameters of the proposed method
are listed as follows:
 Inertia weight (w):
)2ln(*2
1
w
 Acceleration coefficients (c1 and c2): )2ln(5.021  cc
The experiments of the proposed approaches on the seven test
functions with 100, 500 and 1000 dimensions are executed
for 500000, 2500000 and 5000000 FES respectively. Table
IV, V and VI present the 1st (best), 7th, 13th (median), 19th, 25th
(worse), mean, and standard deviation of 25 runs of the
proposed method on the 7 test functions with 100, 500 and
1000 dimensions respectively. The median convergence
graphs (7th) of the 7 test functions with 1000 dimensions are
presented in Fig. 3 and 4.
The estimated runtime for the test suite are listed as follows:
TABLE III
ESTIMATED RUNTIME FOR THE TEST SUITE
Dimensions 1000-D
Problems Function 1-7
Algorithm EPUS-PSO
Runs Only one time
Max_FEs 5,000,000
PC
CPU: Intel Core 2 Duo E4400
(2.0 GHz x 2). Only one of the
processors was used.
RAM: 1 G
Runtime 6 h 10m 53s
The proposed method spends about 6 hours to execute all the
7 functions with 1000 dimensions for single run.
TABLE IV
ERROR VALUES ACHIEVED FOR PROBLEMS 1-7, WITH D=100
Problems
1 2 3 4 5 6 7FES
1st (Best) 1.59e+05 6.30e+01 2.15e+10 1.51e+03 1.35e+03 2.00e+01 -8.92e+02
7th 1.87e+05 7.53e+01 3.53e+10 1.55e+03 1.61e+03 2.04e+01 -8.19e+02
13th (Median) 2.15e+05 8.03e+01 4.51e+10 1.60e+03 1.68e+03 2.05e+01 -8.12e+02
19th 2.19e+05 8.44e+01 5.11e+10 1.64e+03 1.73e+03 2.06e+01 -7.98e+02
25th (Worst) 2.42e+05 8.82e+01 5.46e+10 1.66e+03 1.94e+03 2.07e+01 -7.84e+02
5.00e+3
Mean 2.07e+05 7.94e+01 4.28e+10 1.60e+03 1.68e+03 2.05e+01 -8.12e+02
Std 2.14e+04 6.81e+00 9.41e+09 4.85e+01 1.42e+02 1.65e-01 2.25e+01
1st (Best) 2.81e+03 3.47e+01 3.33e+07 8.14e+02 2.47e+01 1.13e+01 -8.92e+02
7th 3.76e+03 3.71e+01 5.87e+07 9.48e+02 3.19e+01 1.38e+01 -8.40e+02
13th (Median) 4.17e+03 3.86e+01 8.24e+07 9.90e+02 3.79e+01 1.52e+01 -8.32e+02
19th 4.94e+03 4.08e+01 1.39e+08 1.14e+03 4.46e+01 1.72e+01 -8.22e+02
25th (Worst) 6.81e+03 4.75e+01 2.44e+08 1.47e+03 5.31e+01 2.02e+01 -8.13e+02
Mean 4.43e+03 3.93e+01 9.87e+07 1.06e+03 3.87e+01 1.55e+01 -8.34e+02
5.00e+4
Std 9.46e+02 3.19e+00 4.84e+07 1.91e+02 8.60e+00 2.43e+00 1.75e+01
1st (Best) 4.43e-01 1.46e+01 6.34e+02 3.67e+02 2.52e-01 1.04e+00 -8.92e+02
7th 6.14e-01 1.72e+01 8.63e+02 4.26e+02 3.40e-01 1.78e+00 -8.64e+02
13th (Median) 7.49e-01 1.85e+01 1.59e+03 4.71e+02 3.73e-01 2.00e+00 -8.53e+02
19th 8.82e-01 2.01e+01 8.27e+03 5.18e+02 4.04e-01 2.35e+00 -8.43e+02
25th (Worst) 1.04e+00 2.32e+01 1.68e+04 5.60e+02 5.25e-01 2.90e+00 -8.37e+02
Mean 7.47e-01 1.86e+01 4.99e+03 4.71e+02 3.72e-01 2.06e+00 -8.55e+02
5.00e+5
Std 1.70e-01 2.26e+00 5.35e+03 5.94e+01 5.60e-02 4.40e-01 1.35e+01
1782 2008 IEEE Congress on Evolutionary Computation (CEC 2008)
Authorized licensed use limited to: National Dong Hwa University. Downloaded on February 4, 2009 at 21:35 from IEEE Xplore.  Restrictions apply.
Fig. 3 Convergence Graph for Functions 1-6.
Fig. 4 Convergence Graph for Functions 7.
V. CONCLUSIONS
This paper presents an efficiency population utilization
strategy for particle swarm optimizer (EPUS-PSO) for
solving large scale global optimization which with both
unimodal and multimodal problems. The proposed
population manager and sharing principle can significantly
improve particlesâ€™ searching abilities, to more easily find the
global optimal solution. It also makes PSO more robust,
prevents particles from falling into the local minimum, and
drives particles more efficiently.
Seven test functions were adopted for testing through a
reasonable average and the results are very reliable. Although
the EPUS-PSO contains three main parts which differentiates
from the original PSO, each of them introduce a simple
concept of strategy for particlesâ€™ movement and adjustment
of swarm size. Thus, the EPUS-PSO is simple and easy to
implement for solving optimization.
REFERENCES
[1] R. C. Eberhart and J. Kennedy, â€œA new optimizer using particle swarm
theory,â€ in Proc. 6th Int. Symp. Micro Machine and Human Science,
Nagoya, Japan, pp. 39-43, 1995.
[2] D. E. Goldberg, Genetic Algorithms in Search, Optimization, and
Machine Learning, Addison-Wesley, 1989.
[3] F. van den Bergh and A. P. Engelbrecht, â€œA cooperative approach to
particle swarm optimization,â€ IEEE Transactions on Evolutionary
Computation, vol. 8, pp. 225-239, Jun. 2004.
[4] J. J. Liang, A. K. Qin, P. N. Suganthan and S. Baskar, â€œComprehensive
learning particle swarm optimizer for global optimization of
multimodal functions,â€ IEEE Transactions on Evolutionary
Computation, vol. 10, Jun. pp. 281-296, 2006.
[5] V. G. Gudise and G. K. Venayagamoorthy, â€œComparison of Particle
Swarm Optimization and Backpropagation as Training Algorithms for
Neural Networks.â€ IEEE Swarm Intelligence Symposium, pp. 110-117,
Apr. 2003.
[6] Y. Shi and R. Eberhart, â€œA modified particle swarm optimizerâ€, in Proc.
of IEEE World Congress on Computational Intelligence, pp. 69-73,
May 1998.
[7] R. C. Eberhart and Y. Shi, â€œTracking and optimizing dynamic systems
with particle swarms,â€ in Proc. IEEE world congress on Evolutionary
Computation 2001 (CEC 2001), pp. 94â€“97, May 2001.
[8] P. Angeline, â€œUsing selection to improve particle swarm optimization,â€
in Proc. International joint conference on Neural Networks (IJCNNâ€™99),
pp. 84â€“89, Jul. 1999.
[9] A. P. Engelbrecht, Computational intelligence an introduction, Wiley,
pp.185-195, 2002.
[10] J. Kennedy and R. Mendes, â€œPopulation structure and particle swarm
performance,â€ in Proc. IEEE world congress on Evolutionary
Computation 2001 (CEC 2002), pp. 1671â€“1676, May 2002.
[11] K. E. Parsopoulos and M. N. Vrahatis, â€œUPSOâ€”A unified particle
swarm optimization scheme,â€ in Lecture Series on Computational
Sciences, pp. 868â€“873, 2004.
[12] T. Peram, K. Veeramachaneni, and C. K. Mohan,
â€œFitness-distance-ratio based particle swarm optimization,â€ in Proc.
Swarm Intelligence Symposium, pp. 174-181, 2003.
[13] C. L. Lin, S. T. Hsieh, T. Y. Sun and C. C. Liu, â€œPSO-based learning
rate adjustment for blind source separation,â€ in Proc. of International
Symposium on Intelligent Signal Processing and Communications
Systems (ISPACS), pp. 181-184, Dec. 2005.
[14] M. El-Abd and M. S. Kamel, â€œA Hierarchal Cooperative Particle
SwarmOptimizer,â€ in Proc. Swarm Intelligence Symposium, pp. 43-47,
2006.
[15] S. Baskar and P. N. Suganthan, â€œA novel concurrent particle swarm
optimization,â€ in Proc. IEEE Congress on Evolutionary Computation,
vol. 1, 2004, pp. 792â€“796.
[16] http://particleswarm.info/
1784 2008 IEEE Congress on Evolutionary Computation (CEC 2008)
Authorized licensed use limited to: National Dong Hwa University. Downloaded on February 4, 2009 at 21:35 from IEEE Xplore.  Restrictions apply.
 åœ–ä¸€ æœƒå ´å‰ªå½± 
åœ¨ 6 æœˆ 5 è™Ÿç•¶å¤©ï¼Œæ—©ä¸Šæœ‰ Takeshi Yamakawa ä¸»è¬›çš„ Bio-inspired Self-Organizing 
Relationship Network as Knowledge Acquisition Tool and Fuzzy Inference Engineï¼Œä¹Ÿå¼•ç™¼æœƒ
å ´å­¸è€…çš„ç†±ï¦Ÿè¨ï¥ï¼Œæ¨¡ç³Šæ¨ï¥å¼•æ“çš„ç›¸é—œç ”ç©¶èˆ‡æ–¹æ³•ä¹Ÿè¢«å……åˆ†çš„äº¤ï§Šã€‚ 
ä¸‹åˆå®‰æ’æœ¬äººçš„å ±å‘Šæ˜¯å±¬æ–¼ Special Session ä¹‹ä¸€ï¼Œæ˜¯é‡å°é«˜ç¶­ï¨è¤‡é›œå•é¡Œæ‰€é–‹è¨­çš„ä¸»é¡Œï¼Œ
é¦–å…ˆå¤§å®¶ï¨¦é‡å°ï¥§åŒçš„æœ€ä½³åŒ–æ–¹æ³•åŠ ä»¥ï¥¯æ˜ï¼Œä¸¦å°å…¥å„è‡ªæ‰€æå‡ºçš„æ–°æ–¹æ³•ï¼Œä¸¦æ–¼å ±å‘Šå¾Œ
çµ¦äºˆ 10~30 åˆ†é˜çš„å•é¡Œè¨å•ï¼Œä¹Ÿå› ç‚ºè¨ï¥éå¸¸ç†±ï¦Ÿï¼Œå› æ­¤çµæŸæ™‚é–“ä¹Ÿé è¶…éåŸæœ¬çš„è­°ç¨‹ã€‚
åœ–äºŒæ˜¯ï¥æ–‡å ±å‘Šçš„å‰ªå½±ï¼Œæœ¬äººçš„å ±å‘Šæ™‚é–“å¤§ç´„ç‚º 15 åˆ†é˜ã€‚ 
 
åœ–äºŒ ï¥æ–‡å ±å‘Š 
