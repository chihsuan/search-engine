 II 
ä¸€ã€ ä¸­æ–‡æ‘˜è¦  
é—œéµè©ï¼šç¬é–“æœ€å¤§åŠŸç‡æ¶ˆè€—ï¼ŒèèŸ»æ¼”ç®—æ³•ï¼Œç›¸ä¾ç‹€æ…‹è®Šæ•¸ä¹‹è­˜åˆ¥ï¼Œå¯é”æ€§åˆ†æï¼Œç†±èƒ½å°å‘ä¹‹åŠŸç‡
åˆ†æï¼Œç¬é–“æœ€é«˜æº«åº¦ï¼Œå–®é›»å­é›»æ™¶é«” 
 
éš¨è‘—é›»æ™¶é«”çš„ feature size ä¸æ–·ç¸®å°ï¼Œç›¸å°çš„æ™¶ç‰‡å…§å¯ä»¥å®¹ç´çš„é›»æ™¶é«”æ•¸é‡ä¹Ÿå°±å¢å¤§ï¼Œæ­¤æ™¶
ç‰‡å†…é›»æ™¶é«”å¯†åº¦ä¹‹ä¸Šå‡å°‡ä½¿å¾—æ™¶ç‰‡å…§éƒ¨åŠŸç‡çš„æ¶ˆè€—æé«˜ï¼ŒåŠé€£å¸¶çš„ç”¢ç”Ÿæ™¶ç‰‡éç†±çš„å•é¡Œï¼Œéç†±çš„æ™¶
ç‰‡ä¹Ÿæœƒä½¿å¾—æ™¶ç‰‡çš„å¤±æ•—ç‡æé«˜ã€‚ä¸€å€‹ chipå¾å®Œæˆè¨­è¨ˆï¼Œåˆ°è£½ä½œå‡ºå¯¦é«”ï¼Œé€™å€‹éç¨‹éœ€è¦è€—è²»å¾ˆé•·çš„
æ™‚é–“ï¼Œå€˜è‹¥æˆ‘å€‘åœ¨ chipå·²å®Œæˆå¯¦é«”å¾Œï¼Œæ‰ç™¼ç¾æ™¶ç‰‡å› ç‚ºéç†±çš„å•é¡Œå°è‡´ç„¡æ³•æ­£å¸¸ä½¿ç”¨ï¼Œé€™æ¨£å°‡æœƒ
é€ æˆæˆæœ¬æµªè²»ï¼Œå› æ­¤æˆ‘å€‘å¸Œæœ›åœ¨é›»è·¯è¨­è¨ˆå‡ºä¾†æ™‚ï¼Œèƒ½å¤ å…ˆé ä¼°è©² designçš„ç¬é–“æœ€å¤§åŠŸç‡æ¶ˆè€—ï¼Œä»¥
å…é€ æˆä¸å¿…è¦çš„æ™‚é–“åŠé‡‘éŒ¢çš„æµªè²»ã€‚ 
 
 æœ¬è¨ˆåŠƒç¬¬ä¸€å¹´é‡å°çµ„åˆé›»è·¯ç ”ç©¶ç¬é–“æœ€å¤§åŠŸç‡æ¶ˆè€—çš„å•é¡Œï¼Œæˆ‘å€‘æ›‰å¾—ä¸€å€‹é›»è·¯çš„åŠŸç‡æ¶ˆè€—å’Œé›»
è·¯ä¸­çš„æ¯å€‹ gateçš„ transition ç‹€æ³ï¼Œä»¥åŠæ‰€é€£æ¥çš„ fanout capacitanceæœ‰å¾ˆå¤§çš„é—œä¿‚ï¼Œå¦‚ä½•æ‰¾
åˆ°ä¸€å€‹ pattern pairï¼Œå¯ä»¥ä½¿é›»è·¯ä¸­ä¹‹ transitionæ•¸ç›®æœ€å¤§ï¼Œæ˜¯æ±ºå®šé›»è·¯æ‰€æ¶ˆè€—çš„ peak power
çš„é—œéµã€‚å› æ­¤æˆ‘å€‘å°‡åˆ©ç”¨èèŸ»æ¼”ç®—æ³•ä¾†ç•¶ä½œæˆ‘å€‘çš„æœå°‹å¼•æ“ï¼Œè©¦åœ–æ‰¾å‡ºå…©å€‹ input vectorsï¼Œä½¿å…¶
æœ‰æœ€å¤§æ•¸ç›®çš„ transitionã€‚ 
 
 æœ¬è¨ˆåŠƒç¬¬äºŒå¹´é‡å°åºå‘é›»è·¯ç ”ç©¶ç¬é–“æœ€å¤§åŠŸç‡æ¶ˆè€—çš„å•é¡Œï¼Œå¾ªåºé›»è·¯ç›¸è¼ƒæ–¼çµ„åˆé›»è·¯çš„ä¸åŒåœ¨
æ–¼ï¼Œæˆ‘å€‘å¿…é ‡å»ç¢ºèªé€ æˆç¬é–“æœ€å¤§åŠŸç‡æ¶ˆè€—çš„ç‹€æ…‹æ˜¯å¦ç‚ºå¯åˆ°é”çš„ç‹€æ…‹ï¼Œå¦‚æœæ­¤ç‹€æ…‹ç‚ºéå¯åˆ°é”çš„
è©±ï¼Œé‚£éº¼ç”±æ­¤ç‹€æ…‹æ‰€é€ æˆçš„æœ€å¤§åŠŸç‡æ¶ˆè€—å¯¦éš›ä¸Šæ˜¯ä¸æœƒç™¼ç”Ÿçš„ã€‚æ‰€ä»¥æˆ‘å€‘æœƒå°æ­¤å¾ªåºé›»è·¯ï¼Œå…ˆä½œç›¸
ä¾ç‹€æ…‹è®Šæ•¸ä¹‹è­˜åˆ¥ï¼Œä»¥æ¸›å° state spaceï¼Œæ¥è‘—å†å°å…¶åšå¯é”æ€§åˆ†æï¼Œä¹Ÿå°±æ˜¯å»ç¢ºèªå¾åˆå§‹ç‹€æ…‹æ˜¯
å¦å­˜åœ¨ä¸€æ¢è·¯å¾‘åˆ°é”æ­¤ç‹€æ…‹ã€‚è‹¥æ˜¯å¯åˆ°é”çš„ç‹€æ…‹ï¼Œå‰‡æ­¤å°æ‡‰çš„ vector pairå³æ˜¯æœ‰æ•ˆçš„ã€‚ 
 
å¦å¤–ï¼Œæ™¶ç‰‡ä¸Šçš„ thermal å•é¡Œéš¨è‘—æ™¶ç‰‡å¯†åº¦å¢åŠ ä¹Ÿæ—¥è¶¨åš´é‡ï¼Œç•¶åŠŸç‡æ¶ˆè€—æ‰€ç”¢ç”Ÿçš„ç†±ç„¡æ³•å¿«é€Ÿ
ç§»é™¤æ™‚ï¼Œå°‡ä½¿å¾—æ™¶ç‰‡ä¸Šçš„ç†±ç´¯ç©é€²è€Œé€ æˆæº«åº¦ä¸Šå‡ï¼Œé€£å¸¶å½±éŸ¿æ™¶ç‰‡çš„æ•ˆèƒ½ã€‚æœ€å¤§ç¬é–“åŠŸç‡çš„ç™¼ç”Ÿä¸
ä¸€å®šæœƒé€ æˆæ™¶ç‰‡ä¸Šæœ‰æœ€é«˜çš„æº«åº¦ï¼Œé€™æ˜¯å› ç‚ºæº«åº¦æ˜¯æœ‰åœ°å€æ€§çš„ï¼Œå³ä¸€å€‹å€åŸŸæœ‰æœ€å¤šåŠŸç‡çš„æ¶ˆè€—æ‰æœƒ
é€ æˆé«˜æº«ï¼Œè€Œä¸æ˜¯æ™¶ç‰‡ä¸Šæœ‰ç¬é–“æœ€å¤§åŠŸç‡å³æœƒé€ æˆé«˜æº«ï¼Œæ›è¨€ä¹‹ï¼Œè‹¥æ™¶ç‰‡ä¸Šç¬é–“æœ€å¤§åŠŸç‡ç™¼ç”Ÿäº†ï¼Œ
ä½†æ˜¯å…¶å‡å‹»åˆ†æ•£åœ¨ä¸åŒçš„å€åŸŸå…§ï¼Œé‚£éº¼æ­¤ç¬é–“æœ€å¤§åŠŸç‡ä¸¦ä¸æœƒé€ æˆæœ€é«˜æº«åº¦ã€‚å› æ­¤æˆ‘å€‘æƒ³æ‰¾å‡ºæœƒé€ 
æˆæ™¶ç‰‡æœ€é«˜æº«åº¦çš„ vector pairï¼Œä»¥æä¾›åˆ†æã€‚æ‰€ä»¥æœ¬è¨ˆåŠƒåŸä¾†è¦åŠƒç¬¬ä¸‰å¹´ç ”ç©¶æœ‰è€ƒæ…® thermalæ•ˆ
æ‡‰çš„åŠŸç‡åˆ†æï¼Œä¹Ÿå°±æ˜¯æ™¶ç‰‡ä¸Šæœ€é«˜æº«åº¦çš„é æ¸¬ï¼Œä½†æ˜¯å·²ç¶“æå‰æ–¼ç¬¬äºŒå¹´é€²è¡Œå®Œç•¢ã€‚é‚æ–¼æœ¬è¨ˆåŠƒç¬¬ä¸‰
å¹´é€²è¡Œæ›´å…ˆé€²çš„ä½åŠŸç‡åŠä½è€—èƒ½çš„ç ”ç©¶ï¼Œæˆ‘å€‘é€²è¡Œä»¥å–®é›»å­é›»æ™¶é«”ç‚ºå¥ˆç±³é›»è·¯å…ƒä»¶çš„è¶…ä½è€—èƒ½é›»è…¦
è¼”åŠ©è¨­è¨ˆçš„ç ”ç©¶ã€‚ 
 
 
 
 IV 
ç›®éŒ„ 
ä¸­æ–‡æ‘˜è¦ II 
è‹±æ–‡æ‘˜è¦ III 
ç›®éŒ„ IV 
å…§å®¹ V 
åƒè€ƒæ–‡ç» XII 
è¨ˆç•«æˆæœè‡ªè©• XIV 
é™„éŒ„   
DAC 2011 .................................................................................................................  
SOCC 2011 ...............................................................................................................  
ICCAD 2011 (TO APPEAR) ........................................................................................  
IEEE TRANSACTIONS ON CAD-1 ...............................................................................  
IEEE TRANSACTION ON CAD-2 (TO APPEAR)â€¦â€¦â€¦â€¦â€¦â€¦â€¦â€¦â€¦â€¦â€¦â€¦â€¦â€¦â€¦. 
 
 
 
 
 
 
 VI 
è€—ï¼Œç›¸è¼ƒæ–¼çµ„åˆé›»è·¯çš„ä¸åŒåœ¨æ–¼ï¼Œæˆ‘å€‘å¿…é ‡è¦å»ç¢ºèªé€ æˆç¬é–“æœ€å¤§åŠŸç‡æ¶ˆè€—çš„ç‹€æ…‹æ˜¯å¦ç‚ºå¯åˆ°
é”çš„ç‹€æ…‹ï¼Œä¹Ÿå°±æ˜¯åºå‘é›»è·¯å¾åˆå§‹ç‹€æ…‹å‡ºç™¼æ˜¯å¦å­˜åœ¨ä¸€æ¢è·¯å¾‘å¯ä»¥åˆ°é”é€™å€‹ç‹€æ…‹ã€‚å¦‚æœæ­¤ç‹€æ…‹
ç‚ºéå¯åˆ°é”çš„è©±ï¼Œé‚£éº¼ç”±æ­¤ç‹€æ…‹æ‰€é€ æˆçš„ç¬é–“æœ€å¤§åŠŸç‡æ¶ˆè€—ï¼Œå¯¦éš›ä¸Šæ˜¯ä¸æœƒç™¼ç”Ÿçš„ã€‚ç„¶è€Œï¼Œå¤§
é‡çš„ state variables æœƒå°è‡´é¾å¤§çš„ state spaceï¼Œé€™æœƒä½¿å¾—ç¢ºèªç‹€æ…‹çš„å¯é”æ€§ä¹‹é›£åº¦å¢åŠ è¨±å¤šã€‚å› 
æ­¤ç‚ºäº†ç°¡åŒ–æ­¤åºå‘é›»è·¯çš„ state spaceï¼Œæˆ‘å€‘å¯ä»¥å°‹æ‰¾ state variables ä¹‹é–“å¯èƒ½å­˜åœ¨çš„ functional 
dependencyï¼Œä¾†ç°¡åŒ–æ­¤åºå‘é›»è·¯çš„ state spaceã€‚åˆ©ç”¨æ­¤é—œä¿‚æˆ‘å€‘å¯ä»¥æ‰¾åˆ°æŸäº› dependent state 
variablesï¼Œå…¶å¯ç”±å…¶ä»– state variables æ‰€å–ä»£çš„ã€‚æ›è¨€ä¹‹ï¼Œé€™äº› dependent state variables æ˜¯å¯ä»¥
è¢«å¿½ç•¥çš„ï¼Œä¸¦ä¸”åˆ©ç”¨å…¶ä»– state variables å–ä»£å…¶ functionalityï¼Œä»¥ç°¡åŒ–åŸæœ¬çš„é›»è·¯ã€‚ç„¶è€Œå‚³çµ±çš„
dependent latch identificationï¼Œå…¶ä½¿ç”¨ Binary Decision Diagram (BDD)åŠ sequential automatic test 
pattern generation (ATPG)ï¼Œåªå¯ä»¥æ‰¾å‡º typical functional dependencyï¼Œä¾‹å¦‚ï¼Œequivalence relation 
(Siâ‰¡Sj) and opposition relation (Siâ‰¡ï¿¢Sj)ã€‚ä½†æ˜¯ï¼Œä»æœ‰å…¶å®ƒ general functional dependencies å­˜åœ¨ï¼Œ
ä¸”å¯ä»¥ç”¨ä¾†ç°¡åŒ–é›»è·¯ï¼Œä¾‹å¦‚ï¼ŒAND relation (Si=Sjâ€¢Sk)ã€‚ 
 
        å› æ­¤ï¼Œæˆ‘å€‘çš„ dependent latch identification æ¬²æ‰¾å‡º state variables çš„ typical å’Œ general çš„
functional dependenciesã€‚é™¤æ­¤ä¹‹å¤–ï¼Œæˆ‘å€‘æœƒåˆ©ç”¨ Satisfiability (SAT) solver ä¾†æ‰¾ dependent state 
variablesï¼Œå› æ­¤å¯ä»¥è™•ç†å‚³çµ±æ–¹æ³•æ‰€ä¸èƒ½è™•ç†çš„è¼ƒå¤§åºå‘é›»è·¯ã€‚ 
 
     åœ¨åšå®Œ dependent latch identification ä¹‹å¾Œï¼Œæˆ‘å€‘æ¥è‘—å°ç°¡åŒ–éçš„é›»è·¯åšå¯é”æ€§åˆ†æã€‚æˆ‘å€‘
çš„å¯é”æ€§åˆ†æå’Œå‚³çµ±çš„å¯é”æ€§åˆ†ææœ‰æ‰€ä¸åŒï¼Œå‚³çµ±çš„å¯é”æ€§åˆ†æï¼Œåœ¨æ¯å€‹ timeframe éƒ½æŠŠæ‰€æœ‰
å¯èƒ½å‡ºç¾åœ¨é€™å€‹ timeframe çš„ç‹€æ…‹ç®—å‡ºä¾†ï¼Œå¦‚æ­¤å°‡æœƒèŠ±è²»å¾ˆå¤šæ™‚é–“åœ¨é‡è¤‡è¨ˆç®—åŒä¸€å€‹ç‹€æ…‹é›†
åˆï¼Œç„¶è€Œåœ¨é€™è£¡æˆ‘å€‘çš„ç›®çš„åªæ˜¯è¦å»ç¢ºèªæŸå€‹ç‹€æ…‹æ˜¯å¦ç‚ºå¯åˆ°é”çš„ï¼Œä¸å¿…è¦ä¹Ÿä¸éœ€è¦åœ¨åŒä¸€å€‹
timeframe èŠ±å¤ªå¤šæ™‚é–“è¨ˆç®—ã€‚å‚³çµ±æ–¹æ³•å°æ–¼å¾ˆå¤šå¤§çš„é›»è·¯è€Œè¨€ï¼Œå…¶å®Œæ•´çš„å¯åˆ°é”ç‹€æ…‹é›†åˆåœ¨çŸ­
æ™‚é–“å…§(< 5000ç§’)æ˜¯ç„¡æ³•è¨ˆç®—å‡ºä¾†çš„ã€‚ 
 
     å› æ­¤ï¼Œæˆ‘å€‘åšçš„å¯é”æ€§åˆ†æä¸¦ä¸æ˜¯ç‚ºäº†æ±‚å‡ºå®Œæ•´çš„å¯åˆ°é”ç‹€æ…‹é›†åˆï¼Œè€Œæ˜¯åœ¨æœ‰é™çš„æ™‚é–“å…§
ç¢ºèªæŸå€‹ç‹€æ…‹æ˜¯å¦ç‚ºå¯åˆ°é”çš„ç‹€æ…‹ï¼Œç‚ºæ­¤ï¼Œæˆ‘å€‘å°‡ç›¡é‡æé«˜åœ¨å–®ä½æ™‚é–“å…§æ‰€è¨ˆç®—çš„å¯ä»¥åˆ°é”ä¹‹
ç‹€æ…‹æ•¸ï¼Œä»¥æœŸåœ¨æœ‰é™çš„æ™‚é–“å…§é‘‘åˆ¥é€™å€‹ç‹€æ…‹æ˜¯å¦ç‚ºå¯åˆ°é”çš„ã€‚æ‰€ä»¥æˆ‘å€‘ä¸æœƒä¾ç…§æ¯å€‹ timeframe
å»è¨ˆç®—å¯åˆ°é”ç‹€æ…‹ï¼Œç›¸åçš„ï¼Œæˆ‘å€‘æœƒç›¡é‡æŒ‘å‡ºèˆ‡ next state set ä¸åŒçš„ reached statesï¼Œå°‡å…¶æ”¾åˆ°
previous state è£¡å»è¨ˆç®—å‡ºä¸‹ä¸€å€‹ timeframe æœƒåˆ°é”çš„ statesï¼Œä»¥é¿å…å°åŒä¸€å€‹ state åšé‡è¤‡çš„è¨ˆ
ç®—ï¼Œé‚„æœ‰æˆ‘å€‘ä¹Ÿæå‡ºäº†ä¸€å€‹æ©Ÿåˆ¶ä¾†é¿å…å° reached state åšå¤šé¤˜åœ°è¨ˆç®—ã€‚ 
 
æœ‰äº†ä¸Šè¿°å¯ä»¥åˆ¤æ–·ä¸€å€‹ state æ˜¯å¦ç‚º reachable ä¹‹æ–¹æ³•å¾Œï¼Œæˆ‘å€‘å°±å¯ä»¥çŸ¥é“ ACO æ‰€æ‰¾å‡ºä¾†
ä¹‹å…©å€‹ input vectors æ˜¯å¦ç‚ºçœŸæ­£æœƒé€ æˆæœ€å¤§ç¬é–“åŠŸç‡çš„ vector pairsã€‚ 
 
å¦å¤–ï¼Œæ™¶ç‰‡ä¸Šçš„ thermal å•é¡Œéš¨è‘—æ™¶ç‰‡å¯†åº¦å¢åŠ ä¹Ÿæ—¥è¶¨åš´é‡ï¼Œç•¶åŠŸç‡æ¶ˆè€—æ‰€ç”¢ç”Ÿçš„ç†±ç„¡æ³•
å¿«é€Ÿç§»é™¤æ™‚ï¼Œå°‡ä½¿å¾—æ™¶ç‰‡ä¸Šçš„ç†±ç´¯ç©é€²è€Œé€ æˆæº«åº¦ä¸Šå‡ï¼Œé€£å¸¶å½±éŸ¿æ™¶ç‰‡çš„æ•ˆèƒ½ã€‚æœ€å¤§ç¬é–“åŠŸç‡
çš„ç™¼ç”Ÿä¸ä¸€å®šæœƒé€ æˆæ™¶ç‰‡ä¸Šæœ‰æœ€é«˜çš„æº«åº¦ï¼Œé€™æ˜¯å› ç‚ºæº«åº¦æ˜¯æœ‰åœ°å€æ€§çš„ï¼Œå³ä¸€å€‹å€åŸŸæœ‰æœ€å¤šåŠŸ
ç‡çš„æ¶ˆè€—æ‰æœƒé€ æˆé«˜æº«ï¼Œè€Œä¸æ˜¯æ™¶ç‰‡ä¸Šæœ‰ç¬é–“æœ€å¤§åŠŸç‡å³æœƒé€ æˆé«˜æº«ï¼Œæ›è¨€ä¹‹ï¼Œè‹¥æ™¶ç‰‡ä¸Šç¬é–“
 VIII 
ä»¥ Fig. 2(a)ä¸­çš„ ROBDD ç‚ºä¾‹ï¼Œåˆ©ç”¨ CUDD package æ‰€æä¾›çš„å‡½å¼[19]ï¼Œæˆ‘å€‘å¯ä»¥è¨ˆç®—å‡º
é€£æ¥åˆ°çµ‚é» 1 çš„è·¯å¾‘æœ‰ abcd={11--, 101-, 00-0, 010-, 0110 }ï¼Œé€™äº›å³ç‚ºæ­¤é›»è·¯çš„ product termsã€‚
æ¥è‘—ï¼Œæˆ‘å€‘é–‹å§‹å°æ‡‰(mapping)æ¯å€‹ product term è‡³ SET æ¶æ§‹ä¸­ã€‚çµ¦å®šä¸€å€‹ product term pï¼Œå¾
æ¶æ§‹ä¸­çš„é ‚é»é–‹å§‹ï¼Œæˆ‘å€‘ä¾åºå°‹æ‰¾æˆ–è¨­å®šä¸€å€‹é‚Šçµ¦ p è£¡é¢ç”±å·¦åˆ°å³çš„æ¯å€‹ bitã€‚è¨­å®šé‚Šçš„è¦å‰‡
å¦‚ä¸‹ï¼šç•¶è€ƒæ…®çš„ bit å€¼ç‚º 1 (or 0)ï¼Œæˆ‘å€‘å…ˆè©¦è‘—æ‰¾ä¸€å€‹ active high (or low)çš„é‚Šï¼›å¦‚æœæ‰¾ä¸åˆ°çš„
è©±ï¼Œæˆ‘å€‘å¯è¨­å®šä¸€å€‹é‚Šç‚º active high (or low)ã€‚ç„¶è€Œï¼Œå‡ä½¿æ­¤ bit å€¼ç‚ºâ€œ-â€(donâ€™t care)ï¼Œæˆ‘å€‘
å‰‡å…ˆè©¦è‘—æ‰¾ä¸€ short é‚Šï¼Œä¸è¡Œçš„è©±å†è¨­å®šä¸€å€‹é‚Šç‚º shortã€‚ç•¶æ‰€æœ‰çš„ product terms éƒ½å°æ‡‰å®Œå¾Œï¼Œ
æœªè¨­å®šçš„é‚Šå‰‡è¨­å®šç‚º openã€‚æˆ‘å€‘ä½¿ç”¨ Fig. 3 çš„ä¾‹å­ä¾†èªªæ˜å°æ‡‰çš„æ–¹æ³•ã€‚åœ¨é€™è£¡ï¼Œç”±æ–¼ SET æ¶
æ§‹ä¸­çš„å‚ç›´é‚Šçš†ç‚º shortï¼Œç‚ºç°¡å–®è¡¨ç¤ºæ­¤ SET æ¶æ§‹ï¼Œæˆ‘å€‘çœç•¥é€™äº›å‚ç›´é‚Šè€Œåªé¡¯ç¤ºå¯è¨­å®šçš„æ–œ
é‚Šã€‚å‡è¨­æœ‰å››å€‹ product termsï¼šp0=0110ã€p1=010-ã€p2=11--å’Œ p3=101-ï¼Œå¦‚ Fig. 3(a)æ‰€ç¤ºã€‚é¦–
å…ˆè€ƒæ…® p0=0110ï¼Œå¾é ‚é» n(0, 0)(æ­¤ç‚ºåº§æ¨™ï¼Œx è»¸ä»¥ 0 ç‚ºä¸­å¿ƒï¼Œå¯å¾€å³(æ­£)ï¼Œå¾€å·¦(è² )ï¼Œy è»¸ 0
åœ¨æœ€ä¸Šæ–¹)é–‹å§‹ï¼Œå°æ–¼ç¬¬ä¸€å€‹ bit 0ï¼Œæˆ‘å€‘è¨­å®š n(0, 0)çš„å·¦é‚Šç‚º lowã€‚æ¥ä¸‹ä¾†ï¼Œå°æ–¼ç¬¬äºŒå€‹ bit 1ï¼Œ
æˆ‘å€‘è¨­å®š n(-1, 1)çš„å³é‚Šç‚º highã€‚ä½¿ç”¨ç›¸åŒçš„æ–¹æ³•ï¼Œæˆ‘å€‘æ¥è‘—åˆ†åˆ¥è¨­å®š n(0, 2)çš„å·¦é‚Šå’Œ n(-1, 3)
çš„å³é‚Šç‚º high å’Œ lowï¼Œçµ¦æœ€å¾Œå…©å€‹ bits 10ã€‚å°æ‡‰å¾Œçš„çµæœå¦‚ Fig. 3(b)æ‰€ç¤ºã€‚åœ¨é€™è£¡ï¼Œæˆ‘å€‘æ±º
å®šè¦è¨­å®šä¸€å€‹ç¯€é»çš„å·¦é‚Šæˆ–å³é‚Šä¹ƒæ˜¯å–æ±ºæ–¼æ­¤ç¯€é»çš„ x è»¸åº§æ¨™ä½ç½®ã€‚ç•¶ x å°æ–¼ 0 æ™‚ï¼Œæˆ‘å€‘å…ˆ
è€ƒæ…®å³é‚Šï¼Œä¸æˆåŠŸçš„è©±å†è€ƒæ…®å·¦é‚Šã€‚åä¹‹ï¼Œå‰‡å…ˆè€ƒæ…®å·¦é‚Šã€‚æ­¤æ³•å¯ä»¥å¹³è¡¡å·¦å³å…©é‚Šçš„é›»è·¯ã€‚ 
 
 
Fig. 2. An example of ROBDD by node duplication. (a) The original ROBDD. (b) The 
resultant BDD. 
     
æ¥ä¸‹ä¾†ï¼Œæˆ‘å€‘è€ƒæ…® p1=010-ã€‚ä¸€æ¨£å¾é ‚é» n(0, 0)é–‹å§‹ï¼Œå› ç‚ºå‰å…©å€‹ bits 01 å’Œ p0 çš„å‰å…©å€‹
bits ç›¸åŒï¼Œæˆ‘å€‘éƒ¨ä»½åœ°é‡è¤‡ä½¿ç”¨å…ˆå‰çš„å°æ‡‰çµæœã€‚æ‰€ä»¥æˆ‘å€‘åªé ‡è¨­å®š n(0, 2)çš„å³é‚Šç‚º low å’Œ
n(1, 3)çš„å·¦é‚Šç‚º shortï¼Œçµ¦æœ€å¾Œçš„å…©å€‹ bits 0-ã€‚å°æ‡‰çš„çµæœå¦‚ Fig. 3(c)æ‰€ç¤ºã€‚å°æ–¼ p2=11--ï¼Œç•¶
æˆ‘å€‘è¨­å®šå®Œ n(0, 0)çš„å³é‚Šç‚º high çµ¦ç¬¬ä¸€å€‹ bit å¾Œï¼Œæˆ‘å€‘é¦–å…ˆè©¦è‘—è©¦å®š n(1, 1)çš„å·¦é‚Šç‚º high çµ¦
ç¬¬äºŒå€‹ bit 1ã€‚ç„¶è€Œï¼Œå› ç‚º n(0, 2)çš„å·¦é‚Šå’Œå³é‚Šåˆ†åˆ¥å·²ç¶“è¢«è¨­å®šç‚º high å’Œ lowï¼Œå…¶çš†èˆ‡ç¬¬ä¸‰å€‹
bitâ€œ-â€ä¸ä¸€è‡´ï¼Œæ‰€ä»¥æˆ‘å€‘å–æ¶ˆå…ˆå‰å° n(1, 1)å·¦é‚Šçš„è¨­å®šï¼Œæ”¹è¨­å®š n(1, 1)çš„å³é‚Šç‚º highã€‚ç„¶å¾Œï¼Œ
n(2, 2)å’Œ n(1, 3)çš„å·¦é‚Šéƒ½è¨­å®šç‚º shortï¼Œçµ¦æœ€å¾Œçš„å…©å€‹ bits --ã€‚å°æ‡‰çš„çµæœå¦‚ Fig. 3(d)æ‰€ç¤ºã€‚æœ€
å¾Œï¼Œæˆ‘å€‘è€ƒæ…® p3=101-ã€‚åœ¨æ‰¾åˆ° n(0, 0)çš„å³é‚Šç‚º high çµ¦ç¬¬ä¸€å€‹ bit 1 å¾Œï¼Œæˆ‘å€‘ä¸¦ä¸è¨­å®š n(1, 1)
çš„å·¦é‚Šç‚º low çµ¦ç¬¬äºŒå€‹ bit 0ï¼Œå› ç‚ºå¦‚æ­¤å°‡ç”¢ç”Ÿä¸€è·¯å¾‘ï¼šn(0, 0)->n(1, 1)->n(0, 2)->n(1, 3)->n(0, 
4)ï¼Œæ­¤è·¯å¾‘å°‡å°æ‡‰åˆ°ä¸€å€‹ä¸åˆæ³•çš„ product term 100-ã€‚æ­¤å¤–ï¼Œå› ç‚º n(1, 1)çš„å³é‚Šå·²è¨­å®šç‚º highï¼Œ
æˆ‘å€‘é¸æ“‡æ“´å±•(expand)æ­¤æ¶æ§‹ä¸¦è¨­å®š n(2, 0)çš„å·¦å³å…©é‚Šç‚º shortï¼Œæ¥è‘—å¾ n(3, 1)é–‹å§‹è€ƒæ…®å‰©ä¸‹çš„
ä¸‰å€‹ bitsï¼Œè€Œçµæœå¦‚ Fig. 3(e)æ‰€ç¤ºã€‚æœ€å¾Œï¼Œæˆ‘å€‘æŠŠæœªè¨­å®šçš„é‚Šè¨­å®šç‚º openï¼Œå°æ‡‰çµæœå¦‚ Fig. 3(f)
æ‰€ç¤ºã€‚ 
 X 
æ­¤å¤–ï¼Œå› ç‚ºä¸€å€‹é ‚é»åªæœ‰å·¦å³å…©å€‹é‚Šï¼Œç‚ºäº†è¦èƒ½æˆåŠŸåœ°å°æ‡‰æ‰€æœ‰çš„ product termsï¼Œç•¶ä¸‰
ç¨® bit å€¼:0ã€1 å’Œâ€œ-â€åŒæ™‚å‡ºç¾åœ¨ç¬¬ä¸€å€‹ bit æ™‚ï¼Œæˆ‘å€‘æœƒè¤‡è£½ä»¥â€œ-â€ç‚ºç¬¬ä¸€å€‹ bit çš„ product terms
ä¸¦åˆ†åˆ¥æ”¹æŒ‡å®šç‚º 0 å’Œ 1ã€‚ä¹Ÿå°±æ˜¯ç¢ºä¿æœ€å¤šåªæœ‰å…©ç¨®ä¸åŒçš„å€¼æœƒå‡ºç¾åœ¨ç¬¬ä¸€å€‹ bitã€‚è€Œä¸”ï¼Œä¸€æ—¦
æœ‰å…©ç¨®ä¸åŒçš„å€¼å‡ºç¾åœ¨ç¬¬ä¸€å€‹ bitï¼Œæˆ‘å€‘æœƒåœ¨é–‹å§‹å°æ‡‰ç¨‹åºå‰å…ˆè¨­å®š n(0, 0)çš„å·¦å³é‚Šä¸ç›¸åŒï¼Œ
ä»¥ç¢ºä¿èƒ½æˆåŠŸåœ°å°æ‡‰æ‰€æœ‰çš„ product termsã€‚ 
 
 
Fig. 5. The algorithm of product term mapping. 
 
Fig. 5 ç‚ºæ‰€æå‡ºçš„å°æ‡‰æ¼”ç®—æ³•ã€‚åœ¨ä¸»å‡½å¼ Mapping()ä¸­ï¼Œæˆ‘å€‘é¦–å…ˆä¾æ“šæ‰€æœ‰ product terms
çš„ç¬¬ä¸€å€‹ bit å€¼è¨­å®š n(0, 0)çš„å·¦å³å…©é‚Šã€‚ç•¶æœ‰å…©å€‹ä¸åŒå€¼æ™‚ï¼Œå‰‡è¨­å®š n(0, 0)çš„å·¦å³å…©é‚Šä¸ç›¸ç­‰
(n(0, 0).leftâ‰ n(0, 0).right)ã€‚æ¥è‘—ï¼Œå¾ n(0, 0)é–‹å§‹å°æ‡‰æ‰€æœ‰çš„ product termsã€‚å°æ–¼æ¯å€‹ product term 
t, æˆ‘å€‘ä½¿ç”¨ä¸€å€‹ä»¥ depth first search ç‚ºåŸºç¤çš„æ–¹æ³•å»ºæ§‹ä¸€æ¢è·¯å¾‘çµ¦ tã€‚LeftConfigure()å’Œ
RightConfigure()åˆ†åˆ¥ç‚ºè¨­å®šä¸€å€‹ç¯€é»çš„å·¦é‚Šå’Œå³é‚Šçš„å‡½å¼ã€‚å‡ä½¿æˆ‘å€‘ç„¡æ³•å¾ n(0, 0)é–‹å§‹è€ŒæˆåŠŸ
åœ°å°æ‡‰ tï¼Œå‰‡æˆ‘å€‘ä½¿ç”¨ Expand()ä¾†æ“´å±•æ¶æ§‹ã€‚æœ€å¾Œï¼Œæˆ‘å€‘è¨­å®šæ‰€æœ‰æœªè¨­å®šçš„é‚Šç‚º openã€‚ 
 XII 
 
æœ¬ç ”ç©¶ç¾¤è¿‘ 3å¹´å·²ç™¼è¡¨ä¹‹è«–æ–‡åŠç«¶è³½ç²ççµ±è¨ˆå¦‚ä¸‹: 
 
 97.8-98.7 98.8-99.7 99.8-100.7 
IEEE/ACM Journal 2
$
 1
**
 2
@
 
Int. Conf 5
&
  4
*
  3
#
  
CAD Contest ä½³ä½œ 1 0 0 
&Ref.[1~5]  $Ref.[6~7]  **Ref.[8]  *Ref.[9~12]    @Ref.[13~14]  #Ref.[15~17] 
ï¬ 2009 ASPDAC Best paper nominee, "Dependent Latch Identification in the Reachable State 
Space".  
ï¬ 2009 Student Forum ASPDAC Best poster award, "An Implicit Approach to Minimizing 
Range-Equivalent Circuits". 
ï¬ 2010 DAC Best paper nominee, "Node Addition and Removal in the Presence of Donâ€™t 
Cares ".  
 
å››ã€ çµè«–èˆ‡è¨è«– 
æœ¬ç ”ç©¶æ¢è¨é‡å°ä¸€çµ„åˆé›»è·¯ç ”ç©¶å¦‚ä½•åœ¨é¢ç©æœ€ä½³åŒ–çš„ç›®æ¨™ä¸‹ï¼Œè‡ªå‹•åŒ–åˆæˆè‡³ä¸€å€‹ä»¥äºŒ
å…ƒæ±ºç­–åœ–(BDD)ç‚ºåŸºç¤çš„å–®é›»å­é›»æ™¶é«”(SET)æ¶æ§‹ã€‚æ­¤é …ç ”ç©¶æˆæœå·²ç²å¾—è‚¯å®šä¸”åœ¨åœ‹éš›æœƒè­°
ä¸Šç™¼è¡¨[15]ã€‚å¦å¤–æœ¬ç ”ç©¶ç¾¤åœ¨æœ¬è¨ˆç•«ä¹‹æ”¯æŒä¸‹ï¼ŒåŒæ™‚é€²è¡Œäº†å¤šé …èˆ‡é‚è¼¯åˆæˆï¼Œé©—è­‰ï¼Œæ¸¬è©¦
ç›¸é—œçš„ç ”ç©¶ï¼Œåˆ†åˆ¥ç‚º"Logic Restructuring Using Node Addition and Removal "ï¼Œ" Fast Node 
Merging with Donâ€™t Cares Using Logic Implications "ï¼Œ " A Register-Transfer Level Testability 
Analyzer "åŠ" On Rewiring and Simplification for Canonicity in Threshold Logic Circuits "ï¼Œ
ä¹Ÿå·²ç¶“/å³å°‡ç™¼è¡¨æ–¼åœ‹éš›å­¸è¡“æœƒè­°[16][17]åŠ IEEE Transactions on CAD æœŸåˆŠ[13][14]ã€‚ 
 
äº”ã€ åƒè€ƒæ–‡ç» 
 
[1] C.-H. Lin, C.-Y. Wang, "Dependent Latch Identification in the Reachable State Space", 2009 IEEE 
Asia and South Pacific Design Automation Conference (ASPDAC'09).  
[2] M.-S. Chan, C.-Y. Wang, and Y.-C. Chen, "An Efficient Approach to SiP Design Integration", 2009 
IEEE International Symposium on Quality Electronic Design (ISQED'09). 
[3] Y.-L. Liu, C.-Y. Wang, Y.-C. Chen, and Y.-H. Chang, "A Novel ACO-based Pattern Generation for 
Peak Power Estimation in VLSI Circuits", 2009 IEEE International Symposium on Quality Electronic 
Design (ISQED'09). 
[4] C.-C. Lin, C.-Y. Wang, "Rewiring Using Irredundancy Removal and Addition", 2009 IEEE Design, 
Automation and Test in Europe (DATE'09). 
[5] Y.-C. Chen, C.-Y. Wang, "Enhancing SAT-based Sequential Depth Computation by Pruning Search 
 XIV 
å…­ã€è¨ˆç•«æˆæœè‡ªè©• 
 
(ä¸€)èˆ‡åŸè¨ˆç•«ç›¸ç¬¦ç¨‹åº¦: ç¬¬ä¸€äºŒå¹´ç›¸ç¬¦ï¼Œä¸”ç¬¬ä¸‰å¹´çš„ç›®æ¨™æå‰æ–¼ç¬¬äºŒå¹´å®Œæˆï¼Œæ•…ç¬¬ä¸‰å¹´é€²è¡Œèˆ‡ç†±èƒ½
ç›¸é—œä¹‹æ›´å…ˆé€²çš„ä½åŠŸç‡åŠä½è€—èƒ½çš„ç ”ç©¶ï¼Œæˆ‘å€‘é€²è¡Œä»¥å–®é›»å­é›»æ™¶é«”ç‚ºé›»è·¯å…ƒä»¶çš„è¶…ä½è€—èƒ½é›»è…¦
è¼”åŠ©è¨­è¨ˆçš„ç ”ç©¶[15]ã€‚ 
 
(äºŒ)é”æˆé æœŸç›®æ¨™æƒ…æ³: å‡é †åˆ©é”æˆï¼Œä¸”æœ‰åœ‹éš›å­¸è¡“æœƒè­°è«–æ–‡åŠæœŸåˆŠè«–æ–‡ç™¼è¡¨ã€‚ 
 
(ä¸‰)ç ”ç©¶æˆæœä¹‹å­¸è¡“æˆ–æ‡‰ç”¨åƒ¹å€¼: æˆæœå‡æœ‰åœ‹éš›å­¸è¡“è«–æ–‡ç™¼è¡¨[13~17]ï¼Œå…·å­¸è¡“åŠæ‡‰ç”¨åƒ¹å€¼ã€‚ 
 
(å››)æ˜¯å¦é©åˆåœ¨å­¸è¡“æœŸåˆŠç™¼è¡¨æˆ–ç”³è«‹å°ˆåˆ©: é©åˆï¼Œå·²æŠ•ç¨¿è‡³åœ‹éš›å­¸è¡“æœŸåˆŠ (ACM Journal on 
Emerging Technologies in Computing Systems) ã€‚ 
 
(äº”)ä¸»è¦ç™¼ç¾æˆ–å…¶ä»–æœ‰é—œåƒ¹å€¼ç­‰: æœ¬ç ”ç©¶ç¾¤åœ¨æœ¬è¨ˆç•«ä¹‹æ”¯æŒä¸‹ï¼ŒåŒæ™‚é€²è¡Œäº†å¤šé …èˆ‡é‚è¼¯åˆæˆï¼Œé©—
è­‰ï¼Œæ¸¬è©¦ç›¸é—œçš„ç ”ç©¶ï¼Œåˆ†åˆ¥ç‚º"Logic Restructuring Using Node Addition and Removal "ï¼Œ" Fast Node 
Merging with Donâ€™t Cares Using Logic Implications "ï¼Œ " A Register-Transfer Level Testability 
Analyzer "åŠ" On Rewiring and Simplification for Canonicity in Threshold Logic Circuits "ï¼Œä¹Ÿå·²
ç¶“/å³å°‡ç™¼è¡¨æ–¼åœ‹éš›å­¸è¡“æœƒè­°[16][17]åŠ IEEE Transactions on CAD æœŸåˆŠ[13][14]ã€‚
 
 1 
Current detector 
1 
(a) (b) 
aâŠ•b 
a aâ€™ 
bâ€™ b 
Active high  
Active low 
Short  
Figure 2: (a) A SET array fabric. (b) An example of a
xor b.
a conducting nanowire or have a wrapped gate. Consequently,
this structure is not very regular and cannot be restructured to
implement a different function due to the physical etching process
involved in its realization. Furthermore, if any of the nanowire
segments or the wrap gates is defective, the whole circuit be-
comes non-functional. This is a significant limitation considering
that nanowires and few electron nanodevices have traditionally
suffered from the variability and reliability issues.
To solve the problem, a reconfigurable version of SET using
wrap gate tunable tunnel barriers was proposed [2] and the in-
depth device simulation to study the electrostatic properties was
presented [8]. This device can operate in three distinct operation
states: a) active b) open and c) short state based on the wrap gate
bias voltages. Such programmability leads to immense flexibility
in designing a circuit. The device simulation shows that this
device can provide an order of magnitude lower energy-delay than
CMOS device [8].
However, the synthesis of a BDD using the device in [2] is man-
ual rather than automated. The reason is that mapping a reduced
ordered BDD (ROBDD) into a planar SET array could be very
complicated, especially when the BDD has crossing edges, which
is typical in minimized BDDs. In this work, we address this
mapping problem and propose an automated mapping approach.
Instead of mapping a BDD directly, the proposed approach first
divides a BDD into a set of product terms that represent the
paths leading to the 1 terminal in the BDD. Then, it sequentially
maps these product terms. Since the mapping order of the prod-
uct terms affects the mapping results, we propose four sorting
heuristics to reduce area cost. Additionally, the automated map-
ping approach incorporates the granularity and fabric constraints
that are imposed in order to decrease the number of metal wires
used for programming the SET array and for supplying the input
signals, respectively [2].
We conduct experiments on a set of MCNC benchmarks [10].
The experimental results show that the proposed approach can
complete mapping within 1 second for most of the benchmarks.
The main contribution of this work is proposing an automated
synthesis tool for the promising energy-efficient SET array archi-
tecture.
The rest of this paper is organized as follows: Section 2 uses
an example to demonstrate the problem considered in this paper,
and introduces some notations. Section 3 presents the proposed
mapping approach. Section 4 discusses and addresses two map-
ping constraints. Finally, the experimental results and conclusion
are presented in Sections 5 and 6.
2. BACKGROUND
2.1 An example
A SET array can be presented as a graph composed of hexagons.
As shown in Fig. 2(a), like the hexagonal fabric mentioned above,
there is a current detector at the top that measures the current
coming from the bottom of the hexagonal fabric. All the vertical
edges of the hexagons are electrical short. All the sloping edges
can be configured as active high, active low, short or open. An
active high edge is controlled by a variable x. It is conducting
and non-conducting when x = 1 and x = 0, respectively. Con-
 
root node (0, 0) 
4 
x 1 4 3 2 0 -1 -2 -3 
y 
3 
2 
1 
0 
node (-3, 3) 
left edge 
right edge 
root node (0, 0) 
x 1  3 2 0 -1 -2 -3 
y 
3 
2 
1 
0 
node (-3, 3) 
left edge 
right edge 
-4 4 
Figure 3: An abstract diamond fabric.
versely, an active low edge is an electrical opposite of an active
high edge and it is controlled by a variable xâ€².
A Boolean function can be implemented using a SET array.
All the active edges at the same row of the hexagonal fabric are
controlled by a single variable, i.e., a primary input (PI). They
determine whether there exists a path for the current to pass
through, and thus, be detected at the top. If so, the functional
output of the array is 1; otherwise, it is 0. For example, Fig.
2(b) shows a SET array implementing a xor b. When a = 1
and b = 0, the current can be detected by passing through the
left path. However, if a = 1 and b = 1, the current cannot be
detected.
Thus, the addressed problem of this work is synthesizing a given
Boolean function into a SET array with minimized area, i.e., the
number of configured hexagons.
Previous work [2] tries to manually map a Boolean function
by directly mapping its BDD into a SET array. However, the
mapping process could be very complicated due to the structural
difference of a BDD and a SET array. For example, an ROBDD
usually has some crossing edges. Since a SET array is a planar
architecture, much effort is required to avoid having the crossing
edges in the ROBDD when mapping it into a SET array. Node
duplication could be a trivial method for solving this crossing
edge issue while not considering the area overhead. In addition,
determining the exact location of each ROBDD node in a SET
array is a challenge. Thus, to address this problem, we propose
a product term-based method. It first collects all the paths that
lead to the terminal 1 in the ROBDD, i.e., product terms. Then,
it maps each product term into a path in the SET array. The
proposed method simultaneously avoids the crossing edge and the
BDD node mapping issues.
For example, the product terms of a xor b are 10 and 01. Using
the proposed method, we first map 10 and then 01. Finally, we
obtain the resultant SET array as shown in Fig. 2(b), where the
left path is configured for 10 and the right path is for 01.
2.2 Notations
For ease of discussion, we use an abstract graph to present a
SET array. Compared to Fig. 2(a), only the configurable edges
are preserved as shown in Fig. 3. In this diamond fabric, each
node n, i.e., the root of a pair of left and right edges, has a unique
location (x, y). Based on the root node located at (0, 0), which
is below the current detector, the y value increases from top to
bottom. The x value increases and decreases from center to right
and left, respectively.
For simplification, let n.left and n.right denote the status of the
left and right edges of a node n, respectively. The status could
be empty, high, low, short, or open. empty indicates the edge is
not configured yet (is used primarily for algorithm illustration).
high, low, short, and open indicate the edge is configured as active
high, active low, short, and open, respectively. Additionally, let
n(x,y) denote the node located at (x, y).
3. AUTOMATED MAPPING
In this section, we first discuss the motivation of our method.
Next, we introduce two key mapping procedures. Finally, the
overall flow is presented. Here, we first assume that each edge
can be configured independently without any constraint. In the
879
48.3
= 
1 1 1 â€“ 0 
0 1 0 â€“ 0 
0 1 0 0 1 
 Active high 
Active low 
Short 
Open 
0 
1 
2 
3 
0 1 2 -1 
4 
5 
0 
1 
2 
3 
0 1 2 -1 
4 
5 
1 1 1 â€“ 0 
0 1 â€“ â€“ 0 
0 1 1 1 1 
 
3 
0 
1 
2 
3 
0 1 2 -1 
4 
5 
3 
0 
1 
2 
3 
0 1 2 -1 
4 
5 
3 4 
(a) (b) 
(c) (d) 
4 
Figure 6: Incorrect mapping examples.
p2 = 111âˆ’, and p3 = 101âˆ’, sorted by ForInertiaSort as shown in
Fig. 5(a). First, let us consider p0. Starting from the root node
n(0,0), we first configure n(0,0).left as low for the first bit 0. Next,
we configure n(âˆ’1,1).right as high for the second bit 1. Using the
same method, we configure n(0,2).left and n(âˆ’1,3).right as high
and low for the last two bits 10, respectively. The mapping result
is shown in Fig. 5(b). Here, the decision of configuring the left
edge or the right edge of a node depends on its location (x, y). If
x < 0, we first try to configure its right edge. If inapplicable, we
then try to configure its left edge. Conversely, if x â‰¥ 0, we try
the left edge first and then the right edge.
Next, for p1, because the first two bits are the same as that
of the first product term, we partially reuse this mapping result.
Then, we configure n(0,2).right as low and n(1,3).left as short for
the last two bits 0âˆ’, respectively. The mapping result is shown
in Fig. 5(c).
For p2, after we configure n(0,0).right as high for the first bit 1,
we do not configure n(1,1).left as high for the second bit 1. This
is because if we do so, there will exist a path n(0,0) â†’ n(1,1) â†’
n(0,2) â†’ n(1,3) â†’ n(0,4), which corresponds to an invalid product
term 110âˆ’. Thus, we configure n(1,1).right as high for the second
bit 1. Finally, n(2,2).left and n(1,3).left are configured as high and
short for the last two bits 1âˆ’, respectively. The mapping result
is shown in Fig. 5(d).
Next, let us consider p3. After finding n(0,0).right = high for
the first bit 1, we do not configure n(1,1).left as low for the sec-
ond bit 0. This is because it will construct a path for an invalid
product term 100âˆ’. Additionally, since n(1,1).right has been con-
figured as high, we expand the structure by configuring both
n(2,0).left and n(2,0).right as short, and start from n(3,1) for the
last three bits. The mapping result is shown in Fig. 5(e). Finally,
we configure all the non-configured edges as open, and obtain the
final mapping result in Fig. 5(f).
To avoid creating an invalid path, we need to prevent two paths
from merging and then branching during mapping. Thus, when
we detect a merging node, like n(0,2) for p2 or p3, we will check
if there exists only one path from n(0,2). If not, there possibly
exists an invalid path. Thus, we prevent the paths from merging.
With this checking rule, each path from top to bottom exactly
corresponds to one product term. In addition, from the viewpoint
of conducting paths, this checking rule is not enough and we have
to add another rule considering the conducting path issue. Fig.
6(a), (b) show two mapping examples, which are incorrect while
satisfying the merging and branching rule.
In Fig. 6(a), when the input pattern is 11101, which is not a
minterm, the current can be detected at the top. This is because
the right edge of n(âˆ’1,3), the left edge of n(1,3), and the right
edge of n(1,3) as highlighted are conducting simultaneously. This
partial conducting path forms like a bridge that connects two
paths such that the current can pass through the path n(1,5) â†’
n(2,4) â†’ n(1,3) â†’ n(0,4) â†’ n(âˆ’1,3) â†’ n(0,2) â†’ n(âˆ’1,1) â†’n(0,0).
In addition, a partial conducting path could be composed of the
Mapping(set PTs) // PTs: product terms
1. Configure n(0,0).left and n(0,0).right based on the first bit values
of the product terms in PTs;
2. For each product term t in PTs
2.1. If (LeftConfigure(t, 0, 0)), continue;
2.2. If (RightConfigure(t, 0, 0)), continue;
2.3. Expand(t);
3. Configure all the edges that are not configured yet as open;
bool LeftConfigure(productterm t, int x, int y)
1. If n(x,y).left is inconsistent to the y
th bit in t, return 0;
2. If n(xâˆ’1,y+1) is a merging node and there is more than one path
from n(xâˆ’1,y+1), return 0;
3. If the configuration of n(x,y).left will make the left edge of n(x,y)
and the right edge of n(xâˆ’2,y) could be conducting simultane-
ously, return 0;
4. If n(x,y).left is empty, configure it based on the mapping rules;
5. If (xâˆ’ 1 < 0)
5.1. If (RightConfigure(t, xâˆ’ 1, y + 1)), return 1;
5.2. If (LeftConfigure(t, xâˆ’ 1, y + 1)), return 1;
6. If (xâˆ’ 1 â‰¥ 0)
6.1. If (LeftConfigure(t, xâˆ’ 1, y + 1)), return 1;
6.2. If (RightConfigure(t, xâˆ’ 1, y + 1)), return 1;
7. Undo n(x,y).left if necessary, and return 0;
bool RightConfigure(productterm t, int x, int y)
1. If n(x,y).right is inconsistent to the y
th bit in t, return 0;
2. If n(x+1,y+1) is a merging node and there is more than one path
from n(x+1,y+1), return 0;
3. If the configuration of n(x,y).right will make the right edge of
n(x,y) and the left edge of n(x+2,y) could be conducting simul-
taneously, return 0;
4. If n(x,y).right is empty, configure it based on the mapping rules;
5. If (xâˆ’ 1 < 0)
5.1. If (RightConfigure(t, x + 1, y + 1)), return 1;
5.2. If (LeftConfigure(t, x + 1, y + 1)), return 1;
6. If (xâˆ’ 1 â‰¥ 0)
6.1. If (LeftConfigure(t, x + 1, y + 1)), return 1;
6.2. If (RightConfigure(t, x + 1, y + 1)), return 1;
7. Undo n(x,y).right if necessary, and return 0;
bool Expand(productterm t)
1. Determine the expansion direction (left or right) based on the
first bit in t.
2. If the expansion direction is left, x = âˆ’2; otherwise, x = 2;
3. While(1)
3.1. Configure n(x,0).left and n(x,0).right as short if they are
empty;
3.2. If (xâˆ’ 1 < 0)
3.2.1 If (RightConfigure(t, xâˆ’ 1, 1)), return 1;
3.2.2 If (LeftConfigure(t, xâˆ’ 1, 1)), return 1;
3.2.3 x = xâˆ’ 2;
3.3. If (xâˆ’ 1 â‰¥ 0)
3.3.1 If (LeftConfigure(t, x + 1, 1)), return 1;
3.3.2 If (RightConfigure(t, x + 1, 1)), return 1;
3.3.3 x = x + 2;
Figure 7: The algorithm of product term mapping.
edges at the different rows. For example, Fig. 6(b) shows a par-
tial conducting path that crosses two rows as highlighted. This
path, n(3,3) â†’ n(2,2) â†’ n(1,3) â†’ n(0,4) â†’ n(âˆ’1,3), constructs an
invalid conducting path for the input pattern 11111.
A necessary condition for causing a partial conducting path is
that there exist two pairs of two adjacent conducting edges: one
pair is two lower edges of a diamond that could be conducting si-
multaneously, and the other pair is two upper edges of a diamond
that could be conducting simultaneously. For example, in Fig.
6(a), the right edge of n(âˆ’1,3) and the left edge of n(1,3) are the
former, and the left and right edges of n(1,3) are the latter. One
simple method for avoiding partial conducting paths is to ensure
that one of the mentioned two pairs of two adjacent conducting
edges is never constructed. Thus, if a configuration results in a
merging node, we check if the two edges connecting to the merg-
ing node could be conducting simultaneously. If so, we avoid this
configuration. With this method, we can prevent two lower edges
of a diamond from conducting simultaneously. Fig. 6(c) and Fig.
6(d) show the correct mapping results for the product terms in
Fig. 6(a) and Fig. 6(b), respectively.
Additionally, because the root node has only two edges (left
881
48.3
Table 1: The experimental results of using differ-
ent product term sorting heuristics and mapping con-
straints.
Bench. PI PO PT
Constraint-free Granu. Fabric
Lex Inert. FInert. BFInert. FInert. FInert.
C17 5 2 8 *18 *18 20 20 58 66
cm138a 6 8 48 *116 158 120 120 360 438
x2 10 7 33 *149 152 153 154 725 790
cm85a 11 3 49 219 197 197 *195 608 528
cm151a 12 2 25 406 427 *400 *400 885 1045
cm162a 14 5 37 292 336 294 *287 1077 1163
cu 14 11 24 240 242 *238 *238 609 662
cmb 16 4 26 195 216 *170 *170 710 855
cm163a 16 5 27 275 *257 260 260 907 1029
pm1 16 13 41 337 342 *335 *335 1186 1239
pcle 19 9 45 *291 292 293 293 1553 1775
sct 19 15 142 1890 *1661 1725 1741 4665 5186
cc 21 20 57 618 658 *585 603 2214 2306
i1 25 16 38 632 650 *627 *627 1773 1920
lal 26 19 160 1968 2157 1832 *1799 7838 8684
pcler8 27 17 68 *737 850 *737 *737 3160 3435
frg1 28 3 399 5993 *5602 5612 5612 11029 13731
c8 28 18 94 *836 884 881 894 4663 4869
term1 34 10 1246 23494 25297 *22426 23856 70844 80293
count 35 16 184 1936 1861 *1336 1465 13509 14678
unreg 36 16 64 1288 *1259 1280 1280 4518 4632
b9 41 21 352 *6333 8650 6478 6542 24272 22089
cht 47 36 92 *2380 2390 *2380 *2380 7857 7934
apex7 49 37 1440 36252 44001 *35999 36317 123003 135543
example2 85 66 430 9737 10164 9623 *9494 53597 50471
Total 96632 108721 94001 95819 341620 365361
Best count 8 5 11 11
4.2 Fabric constraint
In SET array implementation, the inputs to the active edges in
a row are supplied by metal wires. We need two wires to supply
both the normal and complement of an input to a row. Each
edge is connected to either x or its complement xâ€² wires for the
row. The pattern of connections of x and xâ€² in a row defines the
SET fabric and it is fixed during manufacturing.
For example, using x to control all left edges and xâ€² to control
the right edges results in the symmetric fabric proposed in [2].
In our mapping tool, we use the symmetric fabric constraint. In
the future, we will extend our mapping tool to accept any fabric
specification.
In such an array, both (high, low) and (low, high) cannot
simultaneously appear at the same row in a SET array. Note
that the entire row pattern of (high, low) (or (low, high)) can be
changed to (low, high) (or (high, low)) by swapping the normal
value and its complement in the control input signals for the row.
To satisfy this symmetric fabric constraint, we need to identify
which combination ((high, low) or (low, high)) appears at a
certain row. One method is to follow the first configuration result
at the row. For example, if (high, low) is first configured at a
row, we then do not configure (low, high) at this row. Another
easy method is to allow only one of (high, low) and (low, high)
to appear in a SET array. For example, for a bit value 1 or 0, we
can always configure the left edge as high and the right edge as
low, i.e., only (high, low) is allowed. For simplification, we use
the second method in this work.
Fig. 9(b) shows the mapping result for the same set of prod-
uct terms in Fig. 5(a) considering the fabric constraint. In this
example, only (high, low), (short, short), and (open, open) are
allowed.
5. EXPERIMENTAL RESULTS
We implemented the algorithm in C language. The experi-
ments were conducted on a 2.67 GHz Linux platform (Red Hat
5.5). The benchmarks are from the MCNC benchmark suite [10].
For each benchmark, we separately map the Boolean function of
each primary output (PO), and measure the total number of con-
figured hexagons and the total CPU time. In the experiments, we
compare different product term sorting heuristics and mapping
constraints.
Table 1 summarizes the experimental results. Column 1 lists
the benchmarks. Except the C17 benchmark, all the benchmarks
have the crossing edge issue in their ROBDDs. Directly mapping
each of these ROBDDs into a SET array could be very diffi-
cult. Columns 2 and 3 list the number of PIs and POs in each
benchmark, respectively. Column 4 lists the number of computed
product terms. The remaining columns list the mapping results
in terms of the number of hexagons by using different sorting
heuristics and constraints. The number marked with â€œ*â€ means
that it is the best result among all sorting heuristics. Columns 5
to 8 are the constraint-free mapping results by using LexSort, In-
ertiaSort, ForInertiaSort, and BackForInertiaSort, respectively.
Columns 9 and 10 are the mapping results of applying the gran-
ularity and fabric constraints by using ForInertiaSort only. This
is because the ForInertiaSort heuristic has better results for con-
sidering all benchmarks or large benchmarks in the experiments.
We omit the results by using the other sorting heuristics due to
page limit.
According to Table 1, there is no a specific sorting heuristic
that completely outperforms the others for all the benchmarks.
By all accounts, ForInertiaSort results in the best mapping for
considering all benchmarks. Additionally, when the constraints
are considered, the number of configured hexagons increases.
This is because the number of edges shared by different paths
decreases. As for the CPU time, the proposed method can map
each benchmark within 1 second except the term1 and apex7
benchmarks that spent approximately 6 seconds.
6. CONCLUSION
In this paper, we propose a product-term-based approach that
can efficiently map a Boolean function into a SET array. It solves
the problem of automatically mapping a BDD into a SET array
that previous works suffer from. The proposed approach sim-
plifies the mapping problem by transforming a BDD into a set
of product terms, and then individually mapping these product
terms. Additionally, four product term sorting heuristics are pro-
posed to enrich the approach. The granularity and fabric con-
straints can also be handled by the proposed approach. The
experimental results show its effectiveness and efficiency of map-
ping a set of MCNC benchmarks. Our automated mapping is a
key enabler for using the promising BDD technology.
7. REFERENCES
[1] R. Bryant, â€œGraph-based Algorithms for Boolean Function
Manipulation,â€ IEEE Trans. Computers, vol. 35, pp. 677-691,
Aug. 1986.
[2] S. Eachempati, V. Saripalli, V. Narayanan, and S. Datta,
â€œReconfigurable Bdd-based Quantum Circuits,â€ in
Proc. Int. Symp. on Nanoscale Architectures, 2008, pp. 61-67.
[3] H. Hasegawa and S. Kasai, â€œHexagonal Binary Decision Diagram
Quantum Logic Circuits Using Schottky In-Plane and Wrap Gate
Control of GaAs and InGaAs Nanowires,â€ Physica E:
Low-dimensional Systems and Nanostructures, vol. 11, pp. 149-154,
Oct. 2001.
[4] S. Kasai, M. Yumoto, and H. Hasegawa, â€œFabrication of GaAs-based
Integrated 2-bit Half and Full Adders by Novel Hexagonal BDD
Quantum Circuit Approach,â€ in Proc. Int. Symp. on Semiconductor
Device Research, 2001, pp. 622-625.
[5] M. Keating, D. Flynn, R. Aitken, A. Gibbons, and K. Shi, Low
Power Methodology Manual: For System-on-Chip Design,
Springer, 2007.
[6] S. W. Keckler, K. Olukotun, and H. P. Hofstee, Multicore
Processors and Systems, Springer, 2009.
[7] C. Piguet, Low-power CMOS Circuits: Technology, Logic Design
and CAD Tools, CRC Press, 2006.
[8] V. Saripalli, L. Liu, S. Datta, and V. Narayanan, â€œEnergy-Delay
Performance of Nanoscale Transistors Exhibiting Single Electron
Behavior and Associated Logic Circuitsâ€, Journal of Low Power
Electronics (JOLPE), vol. 6, pp. 415-428, 2010.
[9] F. Somenzi, CUDD: CU decision diagram package - release 2.4.2,
2009. http://vlsi.colorado.edu/âˆ¼fabio/CUDD/
[10] S. Yang, â€œLogic Synthesis and Optimization Benchmarks, Version
3.0,â€ Tech. Report, Microelectronics Center of North Carolina,
1991.
[11] http://embedded.eecs.berkeley.edu/pubs/downloads/
espresso/index.htm
[12] http://www.intel.com/go/terascale/
883
48.3
nodes. The algorithm may be efficient because
of vectorless. However, the estimated testability
might be inaccurate when the design contains lots
of high-level constructs. This is the constraint of this
work.
In this work, we propose a statistic-based
method to estimate the testability of a design at RTL.
To accomplish this, we propose a new representa-
tion Register-Transfer Level with Assignment Deci-
sion (RTL-AD), which is similar to Assignment De-
cision Diagram (ADD) [3], but is more appropriate
to precisely computing the testability and easily per-
forming parallel simulation. Furthermore, our ap-
proach applies a statistic method in the Monte Carlo
Simulation to bound the error rate and confidence
level. As a result, our approach can directly report the
testability of each assignment statement in an RTL
design.
II. RTL-AD STRUCTURE
A. The Skeleton of RTL-AD
RTL-AD contains six components as shown in
Fig. 1: data node, assignment decision node, assign-
ment selection node, statement flow node, logical
node, and arithmetic node. The data node can be ei-
ther a read node or a write node. The assignment de-
cision node decides whether or not the data source
can be passed to the target. The assignment selec-
tion node has multiple data sources at a time and
decides which data source could be passed through.
The statement flow node determines the switching
timing of all assignment decision nodes and assign-
ment selection nodes. All operators are divided into
logical node, e.g., & (AND), | (OR), or ^ (XOR), and
arithmetic node, e.g., + (addition),  (right shift), or
% (modulo). In other words, logical nodes are the
same as logic gates, and arithmetic nodes have the
functions of high-level arithmetic operations.
Figure 1: The six components of RTL-AD structure.
B. Transformation of RTL-AD from RTL Descrip-
tion
To better explain the construction of RTL-AD, we
use a hierarchical design as shown in Fig. 2 to go
through the construction of RTL-AD, which is very ef-
ficient. There are five steps to construct the RTL-AD
from an RTL description.
B.1 Generate statement flow
The statement flow acts as an FSM to control
the simulation sequence of these assignment state-
ments by controlling the corresponding assignment
decision nodes and assignment selection nodes.
Before generating the statement flow, we first label
each assignment statement a unique ID as shown in
Fig. 2.
In general, the assignment statements within an
always block are sequentially executed. However, for
the assignment statements that belong to the same
high-level construct, e.g., if-else block, case block,
they are parallel executed. For example in Fig. 2,
since the assignment statements 3, 6, 7 of module A
belong to the same if-else block, they are parallel ex-
ecuted. Thus, the initial statement flow of module A is
shown in Fig. 3(a). Since the left-hand side of assign-
ment statement 7 is Dout, which is also the left-hand
side of the assignment statements 4 and 5 which are
controlled by variables con and DFF. Therefore, the
assignment statement 7 is postponed to be executed
in the same level of the assignment statements 4 and
5 as shown in Fig. 3(b).
Figure 2: An example of hierarchical RTL design.
B.2 Build data path and condition flow
The data path is a passage for data transfer. The
condition flow includes the control information in all
conditional statements. We insert assignment deci-
sion nodes and assignment selection nodes in be-
tween the left-hand side and right-hand side of all
assignment statements in building the data path. Af-
terward, we build the condition flow by connecting
is indicated by the index 1. We use a comparator as
shown in Fig. 7(c) to do the comparison operation to
facilitate the parallel simulation.
Figure 7: An example for virtual simulation.
High-level Simulation For the complex arithmetic
operations, such as division and modulo, we imple-
ment them from the high-level viewpoint. We use an
example of division operation A/B as shown in Fig.
8 to demonstrate this idea. We first convert the ran-
dom values of A and B from binary to decimal, and
then repeat the division operation four times to get
the answers (3, 1, 0, 0). The computed results are
converted back from decimal to binary again, and are
saved in the data node C.
Figure 8: An example for high-level simulation.
A.2 Sampling Rule
Each sampling in Monte Carlo method will re-
turn a result for the desired answer, which is the fault
detection probability (testability) of each wire in the
RTL-AD structure in this work. Here, we apply the
similar method in [6] to obtain this value. Due to page
limit, we skip the detail of this part.
A.3 Scoring
With the sampling rule, the data obtained from
a sufficient amount of samplings are collected to
approximate the exact result.
The next important issue we have to deal with
is how many samplings are sufficient for just obtain-
ing an accurate result. Specifically, when considering
parallel simulation in this work, the bit width of one
simulation also relates to the number of samplings
needed. That is, when the bit width is larger, the
number of samplings can be fewer, and vice versa.
On the other hand, since our statistic model uses
the t-distribution [10], which is more appropriate for
the sampling times under 30, to estimate the error
rate and confidence level. We also take this issue
into consideration in determining the bit width r in our
parallel simulation architecture when conducting the
experiments.
Figure 9: A demonstration of confidence level.
A.4 Error Estimation
We exploit the Confidence Interval in statistics to
estimate the error rate of fault detection probability of
a wire as compared with the mean of the normal dis-
tribution. Suppose that we have N samplings of the
fault detection probability of a wire w, then we can
compute the sample standard deviation of this wire
denoted as sd(w) among the samplings. The param-
eter of the predefined confidence level is Î± as shown
in Fig. 9 where (1 âˆ’ Î±) Ã— 100% represents the confi-
dence level. Then we can look up the value tÎ±
2
from
the t-distribution table with (N âˆ’ 1) degrees of free-
dom. Hence, we have (1 âˆ’ Î±) Ã— 100% confidence
level that the estimated error rate of the fault detec-
tion probability ofw, e(w), is expressed as EQ(1) [10].
e(w) =
tÎ±
2
Ã— sd(w)âˆš
N
(1)
Consequently, for a desired error rate  in the
fault detection probability estimation, and for a given
confidence level (1 âˆ’ Î±) Ã— 100%, we have to repeat
sampling until
tÎ±
2
Ã— sd(w)âˆš
N
<  (2)
EQ(2) is called the stopping condition of our
Monte Carlo approach. However, it is time-
consuming to check whether the fault detection prob-
ability of every wire meets the stopping condition de-
fined in EQ(2). As a result, a heuristic of selecting
some appropriate check points such that most wires
would satisfy the stopping condition while the se-
lected check point wires did is proposed. In addition,
after observing EQ(2), we realize that only the sam-
ple standard deviation sd(w) of each wire differs from
others. Thus, we use the sd(w) to represent each
wire and choose the top 10% of wires with higher
sd(w) as the check points after several initial sam-
220 and 215 in our experiments, respectively. We only
report the faults of those matching points by using
the signature-based verification method mentioned.
For example in s9234 benchmark, it has 7546
nodes, total CPU time is 33.86 seconds, and 52% of
matching points are within 0~5% error rate.
According to Table 1, the CPU time required for
the proposed approach is not much which indicates
that the RTL-AD construction is not a burden for the
approach. Furthermore, 56% of matching points in
a benchmark are within the error rate range of 0~5%
on average. Thus, the proposed statistic approach is
quite accurate.
Table 2: The results of low testability point identification.
circuit | node having low testability | ratio
ours exact
s27 5 7 71%
s208 55 98 56%
s298 33 83 40%
s344 65 126 52%
s349 51 108 47%
s382 67 114 59%
s386 63 74 85%
s400 55 103 53%
s420 121 200 51%
s444 62 103 60%
s510 84 128 66%
s526 71 141 50%
s641 162 353 46%
s713 183 389 47%
s820 118 139 85%
s832 123 145 85%
s838 192 276 70%
s953 225 348 65%
s1423 181 386 47%
s1488 188 260 72%
s1494 221 302 73%
s5378 928 1858 50%
s9234 1593 3256 49%
s13207 2037 6333 32%
s15850 2663 6492 41%
s35932 1341 2220 60%
s38417 6073 17692 34%
s38584 7074 14539 49%
counter8 0 0 -
vendor 3 3 100%
blackjack 8 9 89%
rankf 0 0 -
div8 206 212 97%
average - - 61%
From the application viewpoint, we also would
like to know if our approach can identify those low
testability statements in RTL designs. Table 2 shows
the comparison between our approach and exact ap-
proach on identifying the low testability statements.
A point with less than 20% testability is regarded as
a low testability point in this paper. Column 2 shows
the number of low testability points identified by our
approach. Column 3 is the exact number of low testa-
bility points from netlists. The last column shows the
ratio of identified low testability points as compared to
the exact number. Take s832 as an example, 145 low
testability points are identified by the exact method,
and 123 or 85%, low testability points are identified
by our approach. According to Table 2, 61% of low
testability points are identified on average by our ap-
proach.
V. CONCLUSION
In this paper, we propose a statistic-based testa-
bility analyzer based on the proposed RTL-AD struc-
ture and Monte Carlo method at RTL design descrip-
tion. It directly reports the testability of each assign-
ment statement in RTL designs. With this approach,
designers can efficiently identify many low testability
statements such that the design cycle can be short-
ened when considering design-for-testability issue.
REFERENCES
1. V. D. Agrawal and S. C. Seth, â€œProbabilistic testability,â€ in Proc.
ICCD, pp. 562â€“565, 1985.
2. F. Brglez, â€œOn testability of combinational networks,â€ in Proc.
ISCAS, pp. 221â€“225, 1984.
3. V. Chaiyakul and D. D. Gajski, â€œAssignment decision diagram
for high-level synthesis,â€ UC Irvine, Technical Report ICS-TR-
92-103, Dec. 1992.
4. S. Chakravarty and H. Hunt, â€œOn computing signal probabil-
ity and detection probability of stuck-at faults,â€ IEEE TC, pp.
1369â€“1377, Nov. 1990.
5. S. C. Chang, W. B. Jone, and S. S. Chang, â€œTair: Testability
analysis by implication reasoning,â€ IEEE TCAD, pp. 152â€“160,
Jan. 2000.
6. C.-C. Chiou, C.-Y. Wang, and Y.-C. Chen, â€œA statistic-based
approach to testability analysis,â€ in Proc. ISQED, pp. 267â€“270,
2008.
7. L. H. Goldstein and E. L. Thigpen, â€œScoap: Sandia controlla-
bility/observability analysis program,â€ in Proc. DAC, pp. 190â€“
196, 1980.
8. Y. Huang, N. Mukherjee, W.-T. Cheng, and G. Aldrich, â€œA
rtl testability analyzer based on logical virtual prototyping,â€ in
Proc. ATS, pp. 121â€“124, 2007.
9. S. K. Jain and V. D. Agrawal, â€œStatistical fault analysis,â€ IEEE
Design & Test of Computers, vol. 2, pp. 38â€“44, Feb. 1985.
10. I. R. Miller, J. E.Freund, and R. Johnson, â€œProbability and
statistics for engineers,â€ Englewood Cliffs, NJ: Prentice Hall,
1990.
11. K. P. Parker and E. J. McCluskey, â€œProbabilistic treatment
of general combinational networks,â€ IEEE TC, pp. 668â€“670,
1975.
12. C. P. Ravikumar and G. S. Saund, â€œA stafan-like functional
testability measure for register-level circuits,â€ in Proc. ATS, pp.
192â€“198, 1995.
13. J. Savir, G. S. Ditlow, and P. H. Bardell, â€œRandom pattern
testability,â€ IEEE TC, pp. 79â€“90, Jan. 1984.
14. S. C. Seth, L. Pan, and V. D. Agrawal, â€œPredict: Probabilistic
estimation of digital circuit testability,â€ in Proc. FTCS, pp. 220â€“
225, 1985.
15. J. Strnadel, â€œTestability analysis and improvements of register-
transfer level digital circuits,â€ Computing and Informatics, pp.
1001â€“1024, Sep. 2006.
16. SYNOPSYS. [Online]. Available: http://www.synopsys.com
17. M. Takahashi, R. Sakurai, H. Noda, and T. Kambe, â€œA testa-
bility analysis method for register-transfer level descriptions,â€
in Proc. ASP-DAC, pp. 307â€“312, 1997.
18. D. T. Wang, â€œAn algorithm for the generation of test sets for
combinational logic network,â€ IEEE TC, pp. 742â€“746, July
1975.
19. S.-J. Wang and T.-H. Yeh, â€œHigh-level test synthesis with hier-
archical test generation for delay-fault testability,â€ IEEE TCAD,
pp. 1583â€“1596, Oct. 2009.
20. S.-C. Wu, C.-Y. Wang, and Y.-C. Chen, â€œNovel probabilistic
combinational equivalence checkingâ€, IEEE TVLSI, pp.365-
375, April 2008.
ab
1
1 n12
c
d
g
h
3
1
1
1
n24
b
h
2
1
1
2
n5
2
d
f
g
h
1
1
1
1
n44
e
f
1
1
2
2
n3
2
(a)
a
b
1
1 2
c
d
g
h
3
1
1
1
4
d
f
g
h
1
1
1
1
n4
4
2
2
2
n5
2
n7
n1
n2
1
1 2
b
h
1
1 2
2
2
2
n3
2
n6
e
f
(b)
a
b
1
1
n12
c
d
g
2
1
1
n23
2
2
2
n5
2
d
f
g
h
1
1
1
1
n44
2
2
2 n3
2
1
1 n62
b
h
1
1
n72
1
1 n81
c
h
1
1
n92
The rectification network 
for hâ€™s removal 
e
f
(c)
a
b
1
1
n12
c
d
g
2
1
1
n23
2
2
2
n5
2
2
2
2 n3
2
1
1 n62
b
h
1
1
n72
1
1 n81
c
h
1
1
n92
f
g
h
1
1
1
n4
3
d
1
1 n102 The rectification 
network for dâ€™s removal 
e
f
(d)
Figure 1: (a) The original threshold network. (b) The resultant network after input grouping and gate decomposition. (c) The resultant network
after rewiring target wire h. (d) The resultant network after rewiring target wire d.
number2, designers can either resynthesize the network by using
the same synthesis methodology, or remove some wires from the
gates violating this fanin number constraint and add the rectiï¬cation
network for correcting the functionality.
This work makes two main contributions:
1) It is the ï¬rst rewiring algorithm employing on a threshold
networks that changes its connectivity while preserving its
functionality.
2) The proposed simpliï¬cation procedure produces a canonical
representation of a threshold gate.
The rest of the paper is organized as follows. Section II gives
an example of our rewiring algorithm. Section III introduces the
background. Section IV presents the proposed rewiring algorithm.
Section V presents the simpliï¬cation procedure. Section VI shows
the experimental results of our rewiring algorithm. Finally, Section
VII concludes this work.
II. AN EXAMPLE FOR REWIRING
In this section, we use a brief example to demonstrate the capability
of our rewiring algorithm. We take a threshold network consisting of
ï¬ve threshold gates, as shown in Fig. 1(a). Here we assume the fanin
number constraint of the network is four. If we want to produce
another network with the same functionality but with a smaller fanin
number constraint, e.g., three, we can rewire the network by using
our algorithm instead of resynthesizing the whole network.
In the threshold network of Fig. 1(a), gates n2, n3, n4, and n5
violate this fanin number constraint. First, for gates n3 and n5, we
can extract two new gates, n6 and n7, respectively, using the proposed
gate decomposition method, as shown in Fig. 1(b). For gate n2 in
Fig. 1(b), we can remove target wire h. The rectiï¬cation network n8
is inserted at n2â€™s transitive fanout cone, as shown in Fig. 1(c). For
gate n4 in Fig. 1(c), we can remove target wire d. The rectiï¬cation
network n10 is inserted at n4â€™s fanout cone, as shown in Fig. 1(d).
Using our rewiring method, a threshold network with a new
fanin number constraint is obtained. Previous threshold network
synthesis tools resynthesized the network in order to satisfy different
fanin number constraints [17][31]. Our rewiring algorithm, however,
can achieve the same goal by focusing on single gates without
resynthesizing the whole network.
III. PRELIMINARIES
The section introduces deï¬nitions and some characteristics about
threshold logic.
A. Threshold logic
A linear threshold gate (LTG) is an n binary inputs and one
binary output function. The parameters of an LTG are weights
2This operation is trivial for traditional Boolean networks, but it is not the
case for threshold networks.
2
x1
x2
x3
f
2
1
-1
3
x1
x2
y3
f
2
1
1
y3 = x3â€™
(a) (b)
Figure 2: (a) An LTG implementing the function f = x1(x2 + xâ€²3).
(b) The same threshold function f = x1(x2+xâ€²3) after applying the
positive-negative weight transformation.
wi; i = 1 âˆ¼ n, which correspond to inputs xi; i = 1 âˆ¼ n,
and a threshold value T . A Boolean logic function is called a
threshold logic function if and only if it can be realized as a single
LTG. Furthermore, a threshold logic function may have many dif-
ferent threshold logic representations that are represented as weight-
threshold vectors ã€ˆw1, w2, . . . , wn;T ã€‰. A network that is composed
of LTGs is called a threshold network.
The output f of an LTG is evaluated by EQ(1). If the summation
of corresponding weights wi of inputs xi that are assumed to be 1
in an input vector, is greater than or equal to the threshold value T ,
the output f is 1. Otherwise, the output f is 0.
f(x1, x2, . . . , xn) =
â§âªâªâªâ¨
âªâªâªâ©
1 if
nâˆ‘
i=1
xiwi â‰¥ T
0 if
nâˆ‘
i=1
xiwi < T
(1)
For example, in Fig. 2(a), the LTG with a weight-threshold vector
ã€ˆ2, 1,âˆ’1; 2ã€‰ generates 1 if 2x1 + x2 âˆ’ x3 â‰¥ 2, and generates 0
otherwise.
The weights wi; i = 1 âˆ¼ n associated with corresponding inputs
can be any real, positive, or negative numbers. However, these
weights are usually integers due to technological considerations [9].
In this work, we assume the weights are integers for simplicity. In
the last example, since {x1 = 1, x2 = 1} or {x1 = 1, x3 = 0}
can make the LTG become 1, the Boolean function it represents is
f = x1x2 + x1x
â€²
3 = x1(x2 + x
â€²
3). From this example, we can see
that the threshold logic provides a more compact representation than
traditional Boolean logic, with fewer nodes and a shallower depth.
Unateness is an important property of a threshold logic function,
because all threshold logic functions are unate [21]. However, not
all unate functions can be realized as threshold logic functions. If
the weights of an LTG are all positive (negative), the function it
represents is positive (negative) unate.
The rewired threshold network in this work is generated by an
ILP-based approach [31] where each LTG is canonically represented.
Given a unate function, an ILP formulation which describes its
functionality as linear relationships searches the polytope vertices
For example, in Fig. 4, assume that we would like to remove target
wire a from the given LTG. After the grouping and decomposition, as
shown in Fig. 4(b), we remove target wire a. Then the objective gate
consisting of the inputs b, c, and d is useless according to Theorem
1. This is because the summation of 2, 1, 1 in the decomposition gate
ã€ˆ2, 1, 1; 5ã€‰ after removing a is less than 5.
Deï¬nition 2: An input in a single group LTG is critical if and only
if this LTG will become useless after removing this input.
Theorem 2: Given a single group LTG, an input xj with its
corresponding weight wj is critical if and only if it satisï¬es EQ(3),
where n is the number of inputs in this gate.
nâˆ‘
i=1,i =j
wi < T (3)
For example, in Figs. 4(a) and 4(b), input a is critical because
the summation of weights b âˆ¼ d is less than the threshold value.
Similarly, inputs e and f are also critical because removing them
results in empty decomposition gates, and an empty gate is useless
by Deï¬nition 1.
Note that a critical input is important to the uselessness of a
threshold gate. Furthermore, the functionality of a gate strongly
depends on the relationship between the critical input and other
inputs.
Deï¬nition 3: An input is useless if and only if the output of this
LTG is intact when this input toggles under all input combinations.
Theorem 3: Given an input xj with its corresponding weight wj , xj
is useless if and only if it satisï¬es either EQ(4) or EQ(5) for each
input combination, where n is the number of inputs in this gate.
nâˆ‘
i=1,i =j
xiwi < T and (
nâˆ‘
i=1,i =j
xiwi) + wj < T (4)
(
nâˆ‘
i=1,i =j
xiwi) + wj â‰¥ T and
nâˆ‘
i=1,i =j
xiwi â‰¥ T (5)
For example, in Fig. 4(b), input d will become useless after
removing input c because it satisï¬es either EQ(4) or EQ(5) for all
input combinations of a and b.
An objective gate will have two potential outcomes after we
remove a target wire from it: a useless LTG or a normal LTG. If
the objective gate becomes useless after removing the target wire, a
dramatic functional loss occurs in the overall threshold network. To
prevent the difï¬culty from this situation in our rectiï¬cation scheme,
we modify the threshold value of the objective gate if the objective
gate becomes useless after this removal operation. The details about
this modiï¬cation will be addressed in the next section. Furthermore,
since the removal operation may incidentally create useless inputs,
which are not allowed in a normal LTG, we also remove them. On
the other hand, if the objective gate is still a normal LTG after the
removal operation, we do not change its threshold value.
D. Rectiï¬cation network construction
In this section, we introduce the method of adding rectiï¬cation
networks at other locations to rectify the changed functionality of the
original threshold network due to the target wire removal. Since the
construction of the rectiï¬cation network varies with the characteristics
of the target wire, we analyze the relationship among the target wire
and the other inputs, and divide the correction method into three cases
with respect to the characteristics of a target wire, as seen in the ï¬‚ow
of Fig. 3.
Deï¬nition 4: A single group LTG has a critical-effect if and only if
there exists an assignment such that the output changes from 1 to 0
when each one of its inputs in this assignment changes from 1 to 0.
a
b
c
2
1
1
f3
a b c f
0 0 0 0
0 0 1 0
0 1 0 0
0 1 1 0
1 0 0 0
1 0 1 1
1 1 0 1
1 1 1 1
Figure 5: An LTG and its critical-effect vectors.
Theorem 4: Given a single group LTG, the LTG has a critical-effect
if it satisï¬es EQ(6), where n is the number of inputs in this gate.
nâˆ‘
i=1
xiwi = T (6)
An input assignment that satisï¬es the requirement of the critical-
effect for an LTG is called a critical-effect vector. For example, in
Fig. 5, input assignments 100 and 110 are the critical-effect vectors
of LTG ã€ˆ2, 1, 1; 3ã€‰. This is because changing any 1 to 0 in these
assignments will also change the output from 1 to 0. Note that EQ(6)
is only a sufï¬cient condition of Theorem 4. However, EQ(6) is also a
necessary consition if the given LTG is obtained from an ILP-based
synthesis algorithm [31]. That means all critical-effect vectors of the
LTG satisfy EQ(6).
Case 1: The target wire is not critical: When the target wire
is not critical, the remaining objective gate after the removal will
not become useless. Thus, we preserve the functional relationship
among the inputs in the remaining objective gate by keeping the
threshold value intact. Since adding the rectiï¬cation network at the
transitive fanin cone of the objective gate will signiï¬cantly affect
the remaining functionality among other inputs, we only add the
rectiï¬cation network at the transitive fanout cone of the objective
gate in this case.
The critical-effect vector mentioned above can be used to further
analyze the functionality among all inputs of an LTG. Hence, we
will use it in this case to construct the rectiï¬cation network in our
algorithm.
Let us ï¬rst clarify the physical meaning of a critical-effect vector.
In Fig. 5, the LTG has two critical-effect vectors 101 and 110. When
considering 101, we ï¬nd that another input assignment 111 also
produces 1 after checking its truth table. This means that changing
the second input b does not change the output value. Thus, if input b
in this LTG is the target wire and has been removed, the remaining
objective gate preserves the subfunction with respect to these two
assignments 101 and 111. On the other hand, when considering
another critical-effect vector 110, we ï¬nd that vector 100 produces a
different output, 0. Thus, if input b in this LTG is the target wire and
has been removed, the remaining objective gate loses a subfuncion
with respect to these two assignments 110 and 100.
In summary, we observe that the loss of a subfunction only occurs
when removing a target input, which is assumed to be 1 in a
critical-effect vector. Thus, to construct the rectiï¬cation network, it is
important and necessary to have information about the critical-effect
vectors whose target input is assumed to be 1.
To search the critical-effect vectors of an LTG, we can exhaustively
build its truth table and then ï¬nd the input assignments satisfying
EQ(6). However, this method is not scalable. Fortunately, thanks to
the output evaluation mechanism in a positive-weight LTG, we can
make this search process practical and efï¬cient by deduction.
The method of rewiring for this case with the aid of the critical-
effect vectors is described as follows. Given a single group LTG and
a target wire xt, we ï¬rst remove any useless inputs after target wire
removal. Second, we get all the critical-effect vectors of the LTG,
where xt is assumed to be 1. Third, we collect all the inputs that are
assumed to be 1 in these critical-effect vectors. Then, the rectiï¬cation
wt after the removal. Second, we construct the rectiï¬cation network
that is xt only. Finally, we connect this rectiï¬cation network to each
input, respectively, in the remaining objective gate with an AND gate
at the transitive fanin cones.
For example, given an LTG and the target wire a in Fig. 7(a), the
threshold value is reduced to 4 from 10 by decreasing the weight of
a after the removal, as shown in Fig. 7(b). The rectiï¬cation network
is a only. Then, we connect this rectiï¬cation network to each input in
Fig. 7(b) using an AND gate, at the transitive fanin cones, as shown
in Fig. 7(e).
The validity of this rectiï¬cation can be explained in a similar
manner as in Case 2. When xt is a critical input, the output of the
objective gate under an input assignment that has the xt assumed
to be 0 produces 0. Thus, after we AND xt to each input in the
remaining objective gate, the resultant network produces 0 under the
vectors in the subspace of xt = 0. When xt = 1, the resultant
network will act as the original gate with the setting xt = 1.
For the same example in Figs. 7(a) and 7(e), when a = 0, the
functionality in Fig. 7(a) is the same as that in Fig. 7(e). When a = 1,
Figs. 7(a) and 7(e) also get the same result.
V. SIMPLIFICATION
After target wire removal and rectiï¬cation network construction,
the appearances of some LTGs in the threshold network may be
changed such that they cannot be canonically represented. Thus, in
this section, we introduce a simpliï¬cation procedure that transforms
a single group LTG to its canonical representation.
For example, given two LTGs ã€ˆ2, 1; 3ã€‰ and ã€ˆ1, 1; 2ã€‰, we recognize
that both LTGs represent the same function f(a, b) = ab, because
they both output 1 only at {a = 1, b = 1}. Since minimal weights
and threshold value reduce the implementation cost of an LTG, it
is desirable to minimize their values in an LTG [26]. An LTG is
canonical if and only if it represents a function using minimal weights
and threshold value. An LTG generated from the ILP-based synthesis
method [31] is also canonical.
Next, we describe the simpliï¬cation procedure as follows. First, a
larger-than-1 common divisor divides the weights and the threshold
value to get a more minimized representation if it exists. For example
in Fig. 8(a), given an LTG ã€ˆ4, 4, 6, 8; 18ã€‰, a common divisor 2 divides
the weights and the threshold value, as shown in Fig. 8(b).
Then, the weights and the threshold value of an LTG are gradu-
ally decreased while keeping the functionality intact. A decrement
changes the functionality of an LTG is not allowed. To check if the
functionality changes or not after a decrement in the weight and the
threshold value, we only examine signiï¬cant vectors that can exactly
express the complete functionality of this LTG, rather than examine
the whole truth table of this LTG. We will further discuss this idea
later in the paper.
Next, we explain the method of decreasing weights and threshold
value. If we decrease a unique weight by 1 in an LTG, the threshold
value is decreased by 1 as well. However, we must simultaneously
decrease the weights of inputs that have the same weight by 1
owing to their symmetrical property. That is, if the weights of these
symmetric inputs become different after the decrement, the new
representation is nonequivalent to the original one. Additionally, the
corresponding threshold value is decreased by the number of 1 in
these same-weight inputs of any critical-effect vector.
For example, in Fig. 8(b), the critical-effect vectors of the LTG
ã€ˆ2, 2, 3, 4; 9ã€‰ are 0111 and 1011. Inputs a and b have the same weight
2, and the number of 1 in inputs a and b of the critical-effect vectors
is 1. Thus, the weights of a and b are both decreased from 2 to 1,
and these threshold value is decreased from 9 to 8, as shown in Fig.
8(c). The weight-decreasing operation is sequentially conducted and
checked until each weight reaches 1.
a b c d f
0 1 1 1 1
1 0 1 1 1
1 1 0 1 0
1 1 1 0 0
4 
4
6
8
a
b
c
d
f18
(a)
a b c d f
0 1 1 1 1
1 0 1 1 1
1 1 0 1 0
1 1 1 0 0
9
2 
2
3
4
a
b
c
d
f
(b)
8
1 
1
3
4
a
b
c
d
f
Decrease the weights in 
inputs a, b
a b c d f
0 1 1 1 1
1 0 1 1 1
1 1 0 1 0
1 1 1 0 0
(c)
7
1 
1
2
4
a
b
c
d
f
Decrease the weight in 
input c
a b c d f
0 1 1 1 1
1 0 1 1 1
1 1 0 1 0
1 1 1 0 0
(d)
6
1 
1
2
3
a
b
c
d
f
a b c d f
0 1 1 1 1
1 0 1 1 1
1 1 0 1 0
1 1 1 0 0
Decrease the weight in 
input d
(e)
5
1 
1
1
3
a
b
c
d
f
a b c d f
0 1 1 1 1
1 0 1 1 1
1 1 0 1 1
1 1 1 0 0
Decrease the weight in 
input c
(f)
5
1 
1
2
2
a
b
c
d
f
a b c d f
0 1 1 1 1
1 0 1 1 1
1 1 0 1 0
1 1 1 0 0
Decrease the weight in 
input d
(g)
3
1 
1
1
1
a
b
c
d
f
a b c d f
0 1 1 1 1
1 0 1 1 1
1 1 0 1 1
1 1 1 0 1
Decrease the weights in 
inputs c, d
(h)
Figure 8: The simpliï¬cation procedure for an LTG.
After each weight-decreasing operation, to verify if the function-
ality between the original LTG and the new LTG is intact or not is
necessary. First, some terminology used in our functionality checking
is introduced. A subvector of a vector is a vector whose input assumed
to be 1 is the proper subset of this vector. A supervector of a vector
is a vector whose input assumed to be 1 is the proper superset of this
vector. A brothervector of a vector is a vector which has the same
number of inputs assumed to be 1 as this vector.
For example, given a vector 011, its subvectors are 000, 001, and
010. Its supervector is 111. Its brothervectors are 101 and 110. To
determine if the functionality of an LTG after a weight-decreasing
operation is equivalent to the original LTG or not, we propose the
method introduced in Theorem 5.
Theorem 5: Given two single group LTGs, they are functionally
equivalent if and only if they produce the same outputs under all
critical-effect vectors and the brothervectors of all critical-effect
vectors.
Due to the special output evaluation mechanism of a positive-
weight LTG, an LTG under the subvector of a critical-effect vector
will output zero. Similarly, an LTG under the supervector of a
critical-effect vector will output 1. Thus, if the critical-effect vectors
for two LTGs are the same, their subvectors and supervectors will
have the same outputs. However, the output of an LTG under
the brothervectors of a critical-effect vector cannot be deduced by
the output of the critical-effect vector. Thus, we also simulate the
brothervectors of the critical-effect vectors. As a result, the outputs
of the whole input space of an LTG can be derived by using the
critical-effect vectors and their brothervectors.
In summary, after a weight-decreasing operation, if the outputs of
new LTG under the critical-effect vectors and their brothervectors are
the same as that of the original LTG, the functionality of the new
LTG is intact by Theorem 5.
Now we use the same example to demonstrate this simpliï¬cation
procedure. For the LTG ã€ˆ2, 2, 3, 4; 9ã€‰, we ï¬rst get its critical-effect
vectors, 0111 and 1011, as highlighted, and their brothervectors. The
output values under these assignments are shown in Fig. 8(b).
For each iteration of weight-decreasing operation, we decrease
each input weight and the threshold value sequentially. Inputs a and
b have the same weight; therefore, they are simultaneously decreased.
The threshold value decrement for this situation has been addressed in
the previous paragraph. Next, we check the validity of this decrement
by comparing the outputs under these assignments, as shown in Fig.
8(c). Since these outputs are the same, this decrement is valid and
a new representation ã€ˆ1, 1, 3, 4; 8ã€‰ is obtained. Next, the weight-
decreasing operation for input c is shown in Fig. 8(d). After checking
of CPU time reduction. For example, the b20 benchmark has 4431
gates and 14020 wires. [31] requires 364.52 seconds to resynthesize
the whole threshold network for meeting this new fanin number
constraint, while our approach only costs 58.22 seconds to reach
the same objective. The CPU time reduction is 84.0%.
According to Table II, our approach spent less CPU time, with
a ratio of 63.3% reduction, compared to [31], in a benchmark on
average. Furthermore, our approach is 7.1 times faster than [31].
This CPU time reduction increases with the growth of circuit size
due to local, instead of global, resynthesis in our approach.
Table II
THE COMPARISON WITH THE-STATE-OF-THE-ART [31] FOR RESYNTHESIS.
benchmark |gate| |wire| |rewiring| [31] ours impr.time(s) time(s) %
i2c 176 769 28 8.60 3.24 62.3
usb_phy 280 937 55 2.54 1.67 34.3
simple_spi 288 840 37 2.48 1.84 25.8
pci_spoci_ctrl 385 905 43 2.17 2.08 4.1
alu4 410 1407 50 1.73 1.68 28.9
s9234 554 1830 74 5.62 2.85 49.3
C3540 731 1688 101 3.16 2.68 15.2
dalu 810 2579 52 5.06 1.73 65.8
s13207 848 2235 46 2.92 2.32 20.5
C5315 879 2804 192 21.50 9.46 56.0
C6288 970 3485 155 10.65 7.33 31.2
rot 980 2878 121 11.60 4.80 58.6
C7552 1066 3866 110 23.00 3.76 83.7
tv80 1189 3485 349 24.12 14.69 39.1
spi 1646 4703 663 67.85 25.22 62.8
i10 1814 5893 130 54.50 6.37 88.3
systemcdes 1907 4766 474 127.80 22.31 82.5
des 1920 5180 420 83.70 16.75 79.9
aes_core 3417 13622 792 402.60 38.73 90.4
mem_ctrl 3455 14655 1031 210.56 36.32 83.9
s38417 4280 20139 941 142.20 31.22 78.0
b20 4431 14020 1463 364.52 58.22 84.0
ac97_ctrl 5732 17906 1330 288.87 46.33 83.9
b21 5844 13481 1575 177.85 51.86 70.8
usb_funct 6612 21613 1405 293.26 42.13 85.6
systemcaes 6885 22674 1163 286.40 38.73 86.5
s38584 6897 27750 1981 525.72 83.74 84.1
b22 7656 32711 1595 320.04 52.04 83.7
pci_bridge32 8344 29640 1480 355.52 46.12 87.0
b17 13460 39007 2216 941.67 102.12 89.2
wb_conmax 15719 47731 2544 1386.34 108.24 92.2
total 6154.55 866.58
average 198.53 27.95 63.3
ratio 7.1 1
VII. CONCLUSION AND FUTURE WORK
This paper proposes a new rewiring technique for threshold net-
works. It works through the process of ï¬rst removing a target wire
and then correcting the functionality of the threshold network by
adding its corresponding rectiï¬cation network with respect to the
characteristics of a target wire. It efï¬ciently provides the capability
of logic restructuring. A simpliï¬cation procedure for canonicity that is
directly applied to a single LTG is also proposed. When the threshold
logic becomes a mainstream in the research of VLSI circuits, the
contributions of this work will facilitate the applications of logic
synthesis, veriï¬cation, and various optimization goals.
REFERENCES
[1] M. J. Avedillo and J. M. Quintanaa, â€œA Threshold Logic Synthesis Tool for RTD
Circuits,â€ in Proc. European Symp. on Digital System Design, Sep. 2004, pp. 624-
627.
[2] M. J. Avedillo, J. M. Quintana, H. Pettenghi, P. M. Kelly, and C. J. Thompson,
â€œMulti-Threshold Threshold Logic Circuit Design Using Resonant Tunnelling
Devices,â€ Electron. Lett., vol. 39, no. 21, Oct. 2003, pp 1502-1504.
[3] M. J. Avedillo, J. M. Quintana, A. Rueda, and E. JimCnez, â€œLow-Power CMOS
Threshold-Logic Gate,â€ Electron. Lett., vol. 31, no. 35, Dec. 1995, pp. 2157-2159.
[4] V. Beiu, J. M. Quintana, and M. J. Avedillo, â€œVLSI Implementations of Threshold
Logic-a Comprehensive Survey,â€ in Tutorial at Int. Joint Conf. Neural Networks,
2003.
[5] Berkeley Logic Synthesis and Veriï¬cation Group, â€œSIS: Synthesis
of both synchronous and asynchronous sequential circuits,â€
http://embedded.eecs.berkeley.edu/pubs/downloads/sis
[6] P. Celinski, J. F. Lopez, S. Al-Sarawi, and D. Abbott, â€œLow Power, High Speed,
Charge Recycling CMOS Threshold Logic Gate,â€ Electron. Lett., vol. 37, Aug.
2001, pp. 1067-1069.
[7] S.-C. Chang, K.-T. Cheng, N.-S Woo, and M. Marek-Sadowska, â€œPostlayout Logic
Restructuring Using Alternative Wires,â€ IEEE Trans. Computer-Aided Design, vol.
16, pp. 587-596, June 1997.
[8] S.-C. Chang, M. Marek-Sadowska, and K.-T. Cheng, â€œPerturb and Simplify: Multi-
level Boolean Network Optimizer,â€ IEEE Trans. Computer-Aided Design, vol. 15,
pp. 1494-1504, Dec. 1996.
[9] K. J. Chen, K. Maezawa, and M. Yamamoto, â€œInP-Based High-Performance
Monostable-Bistable Transition Logic Elements (MOBILEâ€™s) Using Integrated
Multiple-Input Resonant-Tunneling Devices,â€ IEEE Eletron Device Letters, vol.
17, pp.127-129, Mar. 1996.
[10] Y.-C. Chen, S. Eachempati, C.-Y. Wang, S. Datta, Y. Xie, and V. Narayanan,
â€œAutomated Mapping for Reconï¬gurable Single-Electron Transistor Arrays,â€ IEEE
Design Automation Conf., 2011, pp. 878-883.
[11] Y.-C. Chen and C.-Y. Wang, â€œAn Improved Approach for Alternative Wires
Identiï¬cation,â€ in Proc. Int. Conf. Computer Design, 2005, pp. 711-716.
[12] Y.-C. Chen and C.-Y. Wang, â€œFast Detection of Node Mergers Using Logic
Implications,â€ in Proc. Int. Conf. on Computer-Aided Design, 2009, pp. 785-788.
[13] Y.-C. Chen and C.-Y. Wang, â€œNode Addition and Removal in the Presence of
Donâ€™t Cares,â€ in Proc. Design Automation Conf., 2010, pp. 505-510.
[14] Y.-C. Chen and C.-Y. Wang, â€œFast Node Merging With Donâ€™t Cares Using Logic
Implications,â€ IEEE Trans. Computer-Aided Design, vol. 29, pp. 1827-1832, Nov.
2010.
[15] M. L. Dertouzos, â€œThreshold Logic: A Synthesis Approachâ€. Cambridge, MA:
M.I.T. Press, 1965.
[16] D. Goldharber-Gordon, M. S. Montemerlo, J. C. Love, G. J. Opiteck, and J. C.
Ellenbogen. â€œOverview of Nanoelectronic Devices,â€ in Proc IEEE, vol. 85, no. 4,
pp. 521-540, Jan. 1997.
[17] T. Gowda and S. Vrudhula, â€œDecomposition Based Approach for Synthesis of
Multi-Level Threshold Logic Circuits,â€ in Proc. Asia and South Paciï¬c Design
Automation Conf., 2008, pp. 125-130.
[18] T. Gowda, S. Vrudhula, and G. Konjevod, â€œA Non-ILP Based Threshold Logic
Synthesis Methodology,â€ in Proc. International Workshop on Logic and Synthesis,
2007, pp. 222-229.
[19] T. Gowda, S. Vrudhula, and G. Konjevod, â€œCombinational Equivalence Checking
for Threshold Logic Circuits,â€ in Proc. Great Lake Symp. VLSI, March 2007, pp.
102-107.
[20] P. Gupta, R. Zhang, and N. K. Jha, â€œAutomatic Test Generation for Combina-
tional Threshold Logic Networks,â€ IEEE Trans. Computer-Aided Design, vol. 16,
pp.1035-1045, Aug. 2008.
[21] Z. Kohavi, â€œSwitching and Finite Automata Theoryâ€. New York, NY: McGraw-
Hill, 1978.
[22] C. Lageweg, S. Cotofana, and S. Vassiliadis, â€œA Linear Threshold Gate Implemen-
tation in Single Electron Technology,â€ in Proc. IEEE Coput. Soc. Workshop VLSI,
2001, pp. 93-98.
[23] C.-C. Lin and C.-Y. Wang, â€œRewiring Using IRredundancy Removal and Addition,â€
in Proc. Design, Automation and Test in Europe, 2009, pp. 324-327.
[24] S. Muroga, â€œThreshold Logic and its Applicationsâ€. New York, NY: John Wiley,
1971.
[25] A. Mishchenko, S. Chatterjee, and R. Brayton, â€œDAG-Aware AIG Rewriting: A
Fresh Look at Combinational Logic Synthesis,â€ in Proc. Design Automation Conf.,
2006, pp. 532-536.
[26] K. Maezawa, H. Matsuzaki, M. Yamamoto, and T. Otsuji, â€œHigh-Speed and Low-
Power Operation of A Resonant Tunneling Logic Gate MOBILE,â€ IEEE Eletron
Device Letters, vol. 19, pp.80-82, March 1998.
[27] C. Pacha, P. Glosekotter, K. Goser, W. Prost, U. Auer, and F. Tegude, â€œReso-
nant Tunneling Device Logic Circuit,â€ Dortmund/Gerhard-Mercator University of
Duisburg, Germany, Tech. Rep., July 1999.
[28] M. Perkowski and A. Mishchenko, â€œLogic Synthesis for Regular Fabric Realized
in Quantum Dot Cellular Automata,â€ in Proc. Int. J. Multiple-Valued Logic and
Soft Comput., 2004, pp. 768-773.
[29] G. E. Sobelman and K.Fant, â€œCMOS Circuit Design of Threshold Gates with
Hysteresis,â€ in Proc. Int. Conf. on Circuits and Systems, vol. 2, 1998, pp. 61-64.
[30] R. O. Winder, â€œThreshold Logic.â€ Ph.D. dissertation, Princeton University, Prince-
ton, NJ, 1962.
[31] R. Zhang, P. Gupta, L. Zhong, and N. K. Jha, â€œSynthesis and Optimization of
Threshold Logic Networks with Application to Nanotechnologies,â€ in Proc. Design
Automation Test in Europe Conf., 2004, pp. 904-909.
[32] Y. Zheng, M. S. Hsiao, and C. Huang, â€œSAT-based Equivalence Checking of
Threshold Logic Designs for Nanotechnologies,â€ in Proc. Great Lake Symp. VLSI,
May 2008, pp. 225-230.
[33] http://iwls.org/iwls2005/benchmarks.html
1828 IEEE TRANSACTIONS ON COMPUTER-AIDED DESIGN OF INTEGRATED CIRCUITS AND SYSTEMS, VOL. 29, NO. 11, NOVEMBER 2010
a k-bounded depth to extract local ODCs. With larger values
of k, the method can find more node mergers but spends more
central processing unit (CPU) time.
The work in [11] proposed a fast simulator that computes
global but approximate ODCs from any depth. Although this
method cannot identify the complete set of node mergers,
it finds an average of 25% more node mergers compared
to the local ODC-based method with k = 5 [13]. Further-
more, the work in [4] extended the node-merging technique
for sequential circuit optimization by considering sequential
ODCs.
Although both the works in [13] and [11] proposed methods
to decrease the complexity of observability computation, they
cannot avoid a potentially large number of SAT solving calls.
Thus, in this paper, we propose a non-SAT-based method for
detecting node mergers. Given a target node, we compute the
mandatory assignments for the stuck-at 0 and 1 fault tests on
it using logic implications. Then, we can derive its substitute
nodes directly from the mandatory assignments without trial-
and-error checking. To achieve high efficiency, we do not
compute all mandatory assignments due to the exponential
time complexity, and thus, spend some quality. For circuit size
reduction, we extend the method with three techniquesâ€”wire
replacement, redundancy removal, and mandatory assignment
reuseâ€”that can enhance its performance.
We conduct experiments on a set of IWLS 2005 benchmarks
[14]. The experimental results show that the proposed method
can quickly complement the local ODC-based method with
k = 5 by finding additional node mergers. Additionally, for
circuit size reduction, the proposed method has a speedup of
46 times for overall benchmarks while possessing a competi-
tive capability compared to the state-of-the-art method [11].
The rest of this paper is organized as follows. Section II
uses an example to demonstrate ODC-based node merging.
It also reviews the related concepts in very-large-scale inte-
gration (VLSI) testing used in this paper. Sections III and IV
present the proposed method for finding node mergers and its
application for circuit minimization. Finally, the experimental
results and conclusion are presented in Sections V and VI.
II. Preliminaries
A. Example
We use an example in Fig. 1 to demonstrate ODC-based
node merging. The circuit in Fig. 1(a) is presented by using
an and-inverter graph (AIG). Here, a, b, c, and d are primary
inputs (PIs). v1â€“v5 are 2-input and gates. Their connectivities
are presented by directed edges. A dot marked on an edge
indicates that an inverter inv is in between two nodes. In this
circuit, v1 and v3 are not functionally equivalent. Merging
them potentially affects the overall functionality. However,
their values only differ when d = 1 and b = c. Since b = c
further implies v2 = 0, which is an input-controlling value of
v5, the different values of v3 with respect to v1 are prevented
from being observed. Thus, v3 can be correctly replaced with
v1. The resultant circuit is shown in Fig. 1(b).
In this paper, a node to be replaced is referred to as a target
node and a node that can correctly replace a target node is
called a substitute node of the target node.
Fig. 1. Example of ODC-based node merging. (a) Original circuit.
(b) Resultant circuit of replacing v3 with v1.
For ease of discussion, we only consider circuits presented
as AIGs. Circuits having complex gates can also be handled
by first transforming them into AIGs.
B. Background
An input of a gate g has an input-controlling value of
g if this value determines the output value of g regardless
of the other inputs. The inverse of the input-controlling
value is called the input-noncontrolling value, e.g., the
input-controlling value of an and gate is 0 and its input-
noncontrolling value is 1. A gate g is in the transitive fanout
cone of a gate gs if there exists a path from gs to g.
The dominators [6] of a gate g (or a wire w) are a set of
gates G such that all paths from g (or w) to any PO have to
pass through all gates in G. Consider the dominators of a gate
g (or a wire w): the side inputs of a dominator are its inputs
that are not in the transitive fanout cone of g (or w).
In VLSI testing, a stuck-at fault is a fault model used to
represent a manufacturing defect within a circuit. The effect
of the fault is as if the faulty wire or gate were stuck at either 1
(stuck-at 1) or 0 (stuck-at 0). A stuck-at fault test is a process
for finding a test that can generate different output values in
the fault-free and the faulty circuits. Given a stuck-at fault f ,
if there exists such a test, f is said to be testable; otherwise,
f is untestable. To make a stuck-at fault on a wire w testable,
a test needs to activate and propagate the fault effect to a PO.
In a combinational circuit, an untestable stuck-at fault on a
wire indicates that the wire is redundant and can be replaced
with a constant value 0 or 1. Similarly, if a stuck-at fault on a
gate is untestable, all the wires led by the gate can be replaced
with a constant value.
The mandatory assignments (MAs) are the unique value
assignments to nodes necessary for a test to exist. Consider
a stuck-at fault on a wire w; the assignments obtained by
setting w to the fault-activating value and by setting the side
inputs of dominators of w to the fault-propagating values are
MAs. Then, these assignments can be propagated forward and
backward to infer additional MAs using logic implications.
Recursive learning [8], a learning technique in automatic test
pattern generation (ATPG), whose complexity is exponential
to the recursion depth can be used to infer more MAs. If the
MAs of the fault are inconsistent, the fault is untestable, and
therefore, w is redundant [12].
For convenience, in the rest of this paper, we use MAs(m =
sav) to denote the set of MAs for the stuck-at v fault test on m,
where m can be a node or a wire and v is a logical value 0 or 1.
1830 IEEE TRANSACTIONS ON COMPUTER-AIDED DESIGN OF INTEGRATED CIRCUITS AND SYSTEMS, VOL. 29, NO. 11, NOVEMBER 2010
pattern can simultaneously generate different values for ns and
nt , and make the value of nt observable through w(nt â†’ ni).
Similarly, Condition 2 can be modified by reversing the value
of ns to find complemented substitute wires that replace a
target wire together with an additional inv.
Let us review the example in Fig. 2(a). The MAs for the
stuck-at 0 fault test on w(v1 â†’ v5) are {v1 = 1, a = 0, b = 1,
c = 1, v2 = 1, v6 = 1} and the MAs for the stuck-at 1 fault test
on w(v1 â†’ v5) are {v1 = 0, v6 = 0, c = 1}. Thus, w(v1 â†’ v5)
can be replaced with w(v6 â†’ v5). Next, using the same
method in Fig. 2(b), we can find that w(v1 â†’ v6) can be
replaced with w(a â†’ v6) together with an inv, as shown in
Fig. 2(c). Finally, we can remove v1 because it does not lead
any wires.
B. Redundancy Removal
As mentioned in Section II-B, if the MAs of a stuck-at
fault test on a node are inconsistent, the fault is untestable
and the node is redundant. Our method for substitute node
identification computes the MAs for the stuck-at 0 and stuck-
at 1 fault tests on a target node nt . Once we find that the MAs
are inconsistent, we can replace nt with a constant value 0 or
1 depending on the fault value. Thus, we can simultaneously
detect if nt is redundant without extra effort. Similarly, we use
the same method to detect and remove redundant wires in the
wire replacement technique.
C. MA Reuse
MA reuse is a method to reuse the computed MAs during
circuit optimization. According to the concept of fault collaps-
ing [2], which states that two equivalent stuck-at faults have
the same test set, some stuck-at fault tests on different nodes
can have the same MA set. Thus, we can reuse these MAs
when optimizing a circuit.
Let us consider computing the MAs for the stuck-at fault
tests on a node n with MA reuse. Suppose ni is a fanout node
of n and MAs(ni = sa0) has been computed. If there exists no
inv between n and ni, we can directly set MAs(w(n â†’ ni) =
sa0) to MAs(ni = sa0) rather than re-compute the same MA
set. Additionally, if n only leads ni, we can set MAs(n = sa0)
to MAs(ni = sa0). However, if there exists an inv between n
and ni, we can set MAs(w(n â†’ ni) = sa1) to MAs(ni = sa0),
and set MAs(n = sa1) to MAs(ni = sa0) when n only leads
ni. For each node, only the MAs of its stuck-at 0 fault test
can be reused.
D. Overall Algorithm
In circuit optimization, although the optimization orders of
selecting a target node, a substitute node, and a substitute wire
can affect the optimization results, it is difficult and might be
time-consuming to evaluate which replacement is best. Thus,
we use a heuristic optimization order in this paper. Each node
in a circuit is selected as a target node nt in the depth-first
search (DFS) order from POs to PIs, and it is replaced with
the substitute node that is closest to PIs.
However, if nt is determined having no substitute node, we
then perform wire replacement on the wires led by it. Each
wire led by nt is sequentially selected as a target wire and we
Fig. 3. Overall algorithm for circuit size reduction.
replace it with its substitute wire that is closest to PIs once
we find it. Since our objective is to remove nt , if one target
wire cannot be replaced, nt is non-removable, and thus, we
stop performing wire replacement on the remaining wires.
Fig. 3 shows the overall algorithm for circuit size reduction.
Given a circuit C, the algorithm iteratively selects a target node
nt in the DFS order from POs to PIs. At each iteration, from
steps 1â€“4, the algorithm finds the substitute nodes of nt by
computing MAs(nt = sa0) and MAs(nt = sa1), and replaces nt
with the substitute node that is closest to PIs. If nt is replaced,
the algorithm continues to consider the next target node.
However, if nt has no substitute node, the algorithm starts
performing wire replacement on the wires led by nt in step 5.
Similarly, for each target wire w(nt â†’ ni), the algorithm finds
its substitute wires by computing MAs(w(nt â†’ ni) = sa0)
and MAs(w(nt â†’ ni) = sa1), and replaces it with the
substitute wire that is closest to PIs. If w(nt â†’ ni) is replaced,
the algorithm continues to consider the next target wire.
Otherwise, the algorithm stops performing wire replacement
and returns to consider the next target node.
V. Experimental Results
We implemented our algorithms in C language within an
ABC [3] environment. The experiments were conducted on
a 3.0 GHz Linux platform (CentOS 4.6). The benchmarks
are from the IWLS 2005 suite [14]. Each benchmark is
initially transformed to an AIG format, and we only consider
its combinational portion. Additionally, the recursive learning
technique [8] is applied with the recursion depth 1 in our
algorithms. The experiments consist of two parts. The first
one is to show the efficiency and effectiveness of our method
for finding substitute nodes. The second one is to show the
capability of our method for circuit size reduction.
1832 IEEE TRANSACTIONS ON COMPUTER-AIDED DESIGN OF INTEGRATED CIRCUITS AND SYSTEMS, VOL. 29, NO. 11, NOVEMBER 2010
Table II summarizes the experimental results. Columns 1
and 2 list the benchmarks and the number of nodes in each
benchmark represented by AIG, respectively. Columns 3, 5,
and 7 list the percentage of circuit size reduction in terms
of node count achieved by our method without redundancy
removal, our method without wire replacement, and our overall
method, respectively. Columns 4, 6, and 8 list the CPU time
measured in seconds. Columns 9 and 10 list the corresponding
results reported in [11]. The maximal CPU time in Column
10 is 5000 s, which is the CPU time limit set by the work.
Table II shows that although the efficiency benefits of
our method come at the expense of the optimization quality,
our method can work together with the redundancy removal
and the wire replacement techniques to have a competitive
capability with a speedup of 46.3 times, compared to the
global ODC-based method.
VI. Conclusion
In this paper, we proposed an ATPG-based method for
node merging by using logic implications. The method only
requires two MA computations to find the substitute nodes of
a target node. The process that previously required many SAT
solving calls is thus reduced to be achievable in practically
linear time. The experimental results showed that the proposed
node-merging method can complement the local ODC-based
method with the bounded depth k = 5 by finding additional
node mergers. Moreover, we extend the node-merging method
with three techniques, wire replacement, redundancy removal,
and MA reuse, for circuit optimization. The experimental
results showed that the proposed optimization algorithm has
a competitive capability and expends much less CPU time
compared to the state-of-the-art method.
References
[1] M. S. Abadir, J. Ferguson, and T. E. Kirkland, â€œLogic design verification
via test generation,â€ IEEE Trans. Comput.-Aided Design, vol. 7, no. 1,
pp. 138â€“148, Jan. 1988.
[2] M. Abramovici, M. A. Breuer, and A. D. Friedman, Digital Systems
Testing and Design for Testability. Piscataway, NJ: IEEE Press, 1990.
[3] Berkeley Logic Synthesis and Verification Group. ABC: A Sys-
tem for Sequential Synthesis and Verification [Online]. Available:
http://www.eecs.berkeley.edu/âˆ¼alanmi/abc
[4] M. Case, V. Kravets, A. Mishchenko, and R. Brayton, â€œMerging nodes
under sequential observability,â€ in Proc. Des. Autom. Conf., 2008,
pp. 540â€“545.
[5] Y.-C. Chen and C.-Y. Wang, â€œFast detection of node mergers using logic
implications,â€ in Proc. Int. Conf. Comput.-Aided Design, 2009, pp. 785â€“
788.
[6] T. Kirkland and M. R. Mercer, â€œA topological search algorithm for
ATPG,â€ in Proc. Des. Autom. Conf., 1987, pp. 502â€“508.
[7] A. Kuehlmann, â€œDynamic transition relation simplification for bounded
property checking,â€ in Proc. Int. Conf. Comput.-Aided Design, 2004,
pp. 50â€“57.
[8] W. Kunz and D. K. Pradhan, â€œRecursive learning: A new implication
technique for efficient solutions to CAD problemsâ€”test, verification,
and optimization,â€ IEEE Trans. Comput.-Aided Design, vol. 13, no. 9,
pp. 1143â€“1158, Sep. 1994.
[9] A. Mishchenko, S. Chatterjee, and R. Brayton, â€œDAG-aware AIG rewrit-
ing: A fresh look at combinational logic synthesis,â€ in Proc. Design
Autom. Conf., 2006, pp. 532â€“536.
[10] A. Mishchenko, S. Chatterjee, R. Brayton, and N. Een, â€œImprovements
to combinational equivalence checking,â€ in Proc. Int. Conf. Comput.-
Aided Design, 2006, pp. 836â€“843.
[11] S. M. Plaza, K.-H. Chang, I. L. Markov, and V. Bertacco, â€œNode mergers
in the presence of donâ€™t cares,â€ in Proc. Asia South Pacific Des. Autom.
Conf., 2007, pp. 414â€“419.
[12] M. H. Schulz and E. Auth, â€œAdvanced automatic test pattern generation
and redundancy identification techniques,â€ in Proc. Int. Fault-Tolerant
Comput. Symp., 1988, pp. 30â€“35.
[13] Q. Zhu, N. Kitchen, A. Kuehlmann, and A. Sangiovanni-Vincentelli,
â€œSAT sweeping with local observability donâ€™t cares,â€ in Proc. Design
Autom. Conf., 2006, pp. 229â€“234.
[14] IWLS. (2005) [Online]. Available: http://iwls.org/iwls2005/benchmarks.
html
On Undetectable Faults and Fault Diagnosis
Irith Pomeranz and Sudhakar M. Reddy
Abstractâ€”The presence of an undetectable fault ui may modify the
response of a detectable fault dj to a test set used for fault diagnosis.
This may impact the accuracy of fault diagnosis based on the responses
of single faults. Many state-of-the-art diagnosis processes are based on
the responses of single stuck-at faults even though their goal is to
diagnose defects (including multiple defects) that are different from stuck-
at faults. Therefore, we study the effects of undetectable single stuck-
at faults on the accuracy of fault diagnosis based on the responses of
single stuck-at faults. For this purpose, we consider the cases where
the response of a double stuck-at fault ui&dj , which consists of an
undetectable fault ui and a detectable fault dj , is different from the
response of the single fault dj . We show that there are significant, yet
manageable, numbers of such faults in benchmark circuits under test
sets used for fault diagnosis. In all these cases, a fault diagnosis process
based on single stuck-at faults may not identify the locations of dj and
ui as candidate defect sites if a defect affects the sites of dj and ui. We
conclude that it is important to consider ui&dj during fault diagnosis
in order not to preclude the sites of dj and ui as candidate defect sites.
Index Termsâ€”Diagnostic test generation, fault diagnosis, full-scan
circuits, stuck-at faults.
I. Introduction
Fault diagnosis is a process that identifies the likely loca-
tions of defects present in a chip after the chip produces a
faulty output response to a test set. Conceptually, the fault
diagnosis process compares the observed response of the chip
to the responses expected in the presence of modeled faults.
The defect is assumed to be present at one of the sites of the
modeled faults that best match the observed response. These
sites are referred to as candidate defect sites, and the faults are
referred to as candidate faults. For the results to be considered
accurate, the site of a candidate fault needs to point correctly
to the site of the defect.
Several fault diagnosis procedures [1]â€“[9] use single stuck-
at faults as a basis for diagnosis, noting that responses of com-
mon defects to test sets used for diagnosis can be represented
as deviations from the responses of single stuck-at faults. For
Manuscript received February 7, 2010; revised April 17, 2010. Date of
current version October 20, 2010. The work of I. Pomeranz and S. M. Reddy
was supported in part by Semiconductor Research Corporation, under Grants
2007-TJ-1643 and 2007-TJ-1642. This paper was recommended by Associate
Editor C.-W. Wu.
I. Pomeranz is with the School of Electrical and Computer Engineer-
ing, Purdue University, West Lafayette, IN 47907 USA (e-mail: pomer-
anz@ecn.purdue.edu).
S. M. Reddy is with the Department of Electrical and Computer
Engineering, University of Iowa, Iowa City, IA 52242 USA (e-mail:
reddy@engineering.uiowa.edu).
Digital Object Identifier 10.1109/TCAD.2010.2053476
0278-0070/$26.00 cÂ© 2010 IEEE
IE
EE
 P
ro
of
2 IEEE TRANSACTIONS ON COMPUTER-AIDED DESIGN OF INTEGRATED CIRCUITS AND SYSTEMS
reusing the logic implication results such that the number of
required logic implications can be saved.
We conduct experiments on a set of IWLS 2005 benchmarks
[38] and compare to the node-merging approaches in [14],
[28], and [37]. For replaceable node identification, as com-
pared to our prior ATPG-based approach [14], an average of
28% more nodes can be identified replaceable in a benchmark
circuit by using NAR. Additionally, an average of 72% of
replaceable nodes cannot be found by the SAT-based node-
merging approach with a bounded depth k = 5 [37], and thus,
the proposed approach could complement it.
For circuit size reduction, the proposed approach reduces
2873 more nodes than our prior ATPG-based node-merging
approach [14] for all the benchmarks, with an overall CPU
time overhead of only 4 min. Additionally, the optimization
capability is competitive with that of the SAT-based node-
merging approach [28], which is highly time-consuming.
Moreover, we apply the proposed method to SAT-based
bounded sequential equivalence checking (BSEC) [8], [30],
[33]. Our method is used as a preprocess to reduce the
computation complexity of SAT solving. Not only the
variable count that the SAT solver deals with is minimized
due to logic optimization but also the relationships among
the variables become tighter by logic restructuring. Thus, the
process of SAT solving could be facilitated. The effectiveness
of the proposed method is compared with a logic optimization
technique resyn2 [26]. The experimental results show that
when we use resyn2 to facilitate SAT-based BSEC, a
total of approximately 25 h are saved for verifying all the
benchmarks. However, when we integrate the proposed
method with resyn2, we can save approximately 39 h.
A related work studying SAT-controlled RAR rather than
NAR is presented in [32]. The work proposes a SAT-based
method for finding redundancies to replace a target wire.
Although the work aims to replace a wire rather than a node,
it also introduces a similar sufficient condition for identifying
an added node to replace a wire. However, the objective of our
paper is different from that of [32]. Additionally, our method
is an ATPG-based approach and is more complete, since we
consider a total of eight types of added nodes. Moreover,
we also propose an efficient NAR-based algorithm for circuit
optimization and SAT-based BSEC facilitation.
The remainder of this paper is organized as follows. Sec-
tion II uses an example to demonstrate the NAR technique and
formulates the problem considered in this paper. Section III
reviews the related concepts in very large-scale integrated
(VLSI) testing and our prior ATPG-based node-merging ap-
proach [14]. Section IV presents the proposed algorithm for
NAR. The application of NAR for circuit size reduction is in-
troduced in Section V. Section VI shows the application of the
NAR method on SAT-based BSEC. Finally, the experimental
results and conclusion are presented in Sections VII and VIII.
II. Example of NAR
We use an example in Fig. 1 to demonstrate the
difference between node merging and NAR. For ease
of discussion, the circuits considered in this paper are
Fig. 1. Example for demonstrating node merging and NAR. (a) Original
circuit. (b) Resultant circuit of replacing n5 with n6. (c) Resultant circuit of
adding n8. (d) Resultant circuit of replacing n6 with n8.
presented as and-inverter graphs (AIGs) [22], which
are an efficient and scalable representation for Boolean
networks. Circuits with complex gates can be handled
by transforming them into AIGs first. In the circuit of
Fig. 1(a), a, b, c, and d are primary inputs (PIs). O1 âˆ¼ O4
are POs, and n1 âˆ¼ n8 are 2-input and gates. Their connec-
tivities are presented by directed edges. A dot marked on an
edge indicates that an inverter (inv) is in between two nodes.
First, let us review the node-merging technique. In Fig. 1(a),
n5 and n6 have different functionalities. However, their values
only differ when n2 = 1 and a = c. Because a = c further
implies n1 = 0, which is an input-controlling value of n7,
the value of n5 is prevented from being observed at O1. This
situation makes the different values of n5 with respect to n6
never observed. Thus, n5 can be replaced with n6 without
altering the overall functionality of the circuit. The resultant
circuit is shown in Fig. 1(b). Here, n5 is considered a target
node and n6 is a substitute node of n5.
Next, let us consider n6 in Fig. 1(b). Suppose n6 is a target
node to be replaced. Because n6 does not have any substitute
node, the node-merging technique fails to replace it. However,
we can add a new node into the circuit to replace it. When we
add n8 into the circuit as shown in Fig. 1(c), the functionality
of the circuit is unchanged, because n8 does not drive any
node. Additionally, n8 can correctly replace n6. The resultant
circuit is shown as Fig. 1(d), where n8 drives n7 and O2.
Here, because n2 only drives n6, when n6 is replaced, n2 can
be removed as well. This example demonstrates that a node
which has no substitute node still can be replaced by a newly
added node, and the resultant circuit can be minimized if the
replaced node has one or more single-fanout fanin (SFoFi)
nodes. Thus, the NAR technique can replace a node which
cannot be replaced by the node-merging technique, and can
optimize a circuit as well. Note that although n6 and n8 are
functionally equivalent (n6 = (bâˆ—d)âˆ— c = (bâˆ— c)âˆ— (d âˆ— c) = n8)
in this example, it does not indicate that the proposed NAR
IE
EE
 P
ro
of
4 IEEE TRANSACTIONS ON COMPUTER-AIDED DESIGN OF INTEGRATED CIRCUITS AND SYSTEMS
A. Sufficient Conditions for NAR
Because an NAR technique performs node replacement as
the node-merging technique, we can exploit Condition 1 to
check if an added node is an added substitute node. For
example, in Fig. 1(c), n6 is a target node and n8 is a node
added into the circuit. We find n8 satisfies Condition 1 that
n8 = 1 and n8 = 0 are MAs for the stuck-at 0 and stuck-at 1
fault tests on n6, respectively. Thus, we can conclude that n8
is an added substitute node for n6.
However, it is not efficient to add all possible nodes into
the circuit first and then exploit Condition 1 to identify
which are substitute nodes for the target node. Thus, we
transform the problem of finding an added substitute node
into finding its two fanin nodes that are originally in the
circuit.
Our objective now becomes finding two nodes such that
the added node driven by them will satisfy Condition 1. For
convenience, let nt denote a target node and na denote an
added node driven by two nodes nf1 and nf2. For ease of
discussion, we first suppose that na is directly driven by
nf1 and nf2 without any inv in between them. That is, the
functionality of na is nf1âˆ§nf2. Next, we present two sufficient
conditions for such na. Finally, we also extend the sufficient
conditions for all eight different types of added nodes. The
first condition is presented in Condition 2.
Condition 2: If both nf1 = 1 and nf2 = 1 are MAs for
the stuck-at 0 fault test on nt , na = 1 is an MA for the same
test as well.
Because na is nf1 âˆ§ nf2, {nf1 = 1, nf2 = 1} implies na = 1.
Thus, if both nf1 = 1 and nf2 = 1 are MAs, na = 1 must be
an MA as well by logic implication.
When Condition 2 is held, na satisfies one half of
Condition 1 that na = 1 is an MA for the stuck-at 0 fault test
on nt . Thus, if we can further show that na = 0 is an MA
for the stuck-at 1 fault test on nt , we can conclude that na is
an added substitute node of nt . Based on this idea, the next
sufficient condition as presented in Condition 3 is proposed
to make na satisfy the other half of Condition 1. Here, let
imp(A) denote the set of value assignments logically implied
from a set of value assignments A, and MAs(nt = sav) denote
the set of MAs for the stuck-at v fault test on nt , where v is
a logical value 0 or 1.
Condition 3: If nf2 = 0 is a value assignment in
imp((nf1 = 1) âˆª MAs(nt = sa1)), na = 0 is an MA for the
stuck-at 1 fault test on nt .
To determine whether na = 0 is an MA for the stuck-at 1
fault test on nt , we can check if all the input patterns that can
detect the fault generate na = 0. If so, na = 0 is an MA. Let
T denote the set of input patterns that can detect the stuck-at
1 fault on nt . Based on the value of nf1, we classify T into
two subsets: the first one, Tnf1=0, and the second one, Tnf1=1,
which consist of the patterns generating nf1 = 0 and nf1 = 1,
respectively. Because nf1 = 0 implies na = 0, all patterns in
Tnf1=0 generate na = 0.
As for Tnf1=1, because imp((nf1 = 1) âˆª MAs(nt = sa1)) is
the set of unique value assignments that all patterns in Tnf1=1
generate, if nf2 = 0 is a value assignment in imp((nf1 = 1) âˆª
Fig. 2. Eight different types of added substitute nodes and their correspond-
ing sufficient conditions. (a) Type 1. (b) Type 2. (c) Type 3. (d) Type 4.
(e) Type 5. (f) Type 6. (g) Type 7. (h) Type 8.
MAs(nt = sa1)), all patterns in Tnf1=1 must generate nf2 = 0,
which implies na = 0. As a result, when Condition 3 is held,
each pattern in T generates na = 0, and na = 0 is an MA for
the stuck-at 1 fault test on nt .
In summary, when Conditions 2 and 3 are held simultane-
ously, na = 1 and na = 0 are MAs for the stuck-at 0 and
stuck-at 1 fault tests on nt , respectively, and na is an added
substitute node of nt .
Note that none of nf1 and nf2 represents a particular fanin
node of na. When one fanin node of na is determined as
nf1, the other fanin node is nf2. Thus, although nf1 = 0 âˆˆ
imp((nf2 = 1) âˆª MAs(nt = sa1)) is also a sufficient condition
for na = 0 to be an MA for the stuck-at 1 fault test on nt , we
do not state it in Condition 3. We ignore it by always selecting
the node having a value 1 as nf1.
B. Types of Added Substitute Nodes
In the last section, we suppose that an added node is directly
driven by two nodes without any inv in between them, and
then derive Conditions 2 and 3. In fact, these conditions can
be modified by reversing the values of nf1, nf2, or the stuck-at
fault for different types of added substitute nodes. We present
eight types of added substitute nodes and their corresponding
sufficient conditions in Fig. 2.
For example, Type 1 is the original added node we consider
before. By reversing the value of nf1 in Conditions 2 and 3,
IE
EE
 P
ro
of
6 IEEE TRANSACTIONS ON COMPUTER-AIDED DESIGN OF INTEGRATED CIRCUITS AND SYSTEMS
Fig. 5. Algorithm for computing MAs with MA reuse.
and the optimization process is accelerated. The idea comes
from the concept of fault collapsing [2] that two equivalent
stuck-at faults have the same test set. Based on this concept,
when two stuck-at faults are equivalent, their corresponding
MAs are identical as well. Thus, only one MA computation is
required for them. Here, we simply derive two rules for MA
reuse as shown in Fig. 4.
First, consider computing MAs(nd = sa0) in Fig. 4(a). To
activate the fault effect, nd is set to 1. To propagate the fault
effect, the side inputs of dominators of nd are set to their
corresponding input-noncontrolling values. For simplicity, we
use P to denote these fault-propagating assignments. Then,
MAs(nd = sa0) can be obtained by performing a logic
implication of {nd = 1, P}. They are {nd = 1, n = 1, nj = 1,
imp(P)}. Next, consider computing MAs(n = sa0). n = 1 is
the fault-activating assignment. Because n drives only nd , the
dominators of nd and nd itself are dominators of n. Thus, the
fault-propagating assignments are {nj = 1, P}. MAs(n = sa0)
then can be obtained by performing a logic implication of
{n = 1, nj = 1, P}. They are {nd = 1, n = 1, nj = 1,
imp(P)}, which are identical to MAs(nd = sa0). Thus, when
we compute MAs(n = sa0), we can reuse MAs(nd = sa0).
Based on the same method, we also find that MAs(n = sa1)
equals to MAs(nd = sa0) in Fig. 4(b).
According to these two rules, for each node nd , only
MAs(nd = sa0) could be reused. Additionally, it is reused
when nd has a fanin node n which drives only nd .
Fig. 5 shows the algorithm for computing the MAs of the
stuck-at v fault on a node n with MA reuse. If n drives more
than one node, the algorithm directly computes MAs(n = sav).
On the other hand, if n drives only one node nd , the algorithm
then checks whether v equals Compl(nd , n). Here, Compl(nd ,
n) returns 1 if there is an inv between n and nd ; otherwise,
it returns 0. When v does not equal Compl(nd , n), the
algorithm computes MAs(n = sav) as well. However, if v
equals Compl(nd , n), the algorithm reuses MAs(nd = sa0)
and MAs(n = sav) equals MAs(nd = sa0).
D. Overall Algorithm
During the optimization process, each node in a circuit is
considered a target node, one at a time. We first find the
target nodeâ€™s substitute nodes for replacement using the node-
merging technique [14]. However, if there is no substitute
node, we then consider performing NAR. In order to ensure
that each node replacement can reduce the circuit size, we
only perform NAR for the target nodes that have a fanin node
Fig. 6. Overall algorithm for circuit size reduction.
driving only one node. In this situation, when the target node
is replaced, the fanin node can be removed as well. Thus,
adding one node removes at least two nodes.
As for the optimization order, although the orders of select-
ing a target node, a substitute node, and an added substitute
node can significantly affect the optimization results, it is
difficult to evaluate the most effective optimization order.
Additionally, this evaluation process might be time-consuming
or fruitless. Thus, in this paper, we follow the optimization
order of selecting a target node and a substitute node used
by the node-merging algorithm in [14] for fair comparison. A
target node is selected from POs to PIs in the depth-first search
(DFS) order and is replaced with a substitute node that is
closest to PIs. Additionally, we replace a target node once we
find an added substitute node due to the inefficiency of finding
all added substitute nodes. When we search an added substitute
node, each MA node is selected as nf1 in a topological order
to identify the nf2 that is closest to PIs.
Fig. 6 shows the overall algorithm for circuit size reduction.
Given a circuit C, the algorithm iteratively selects a target
node nt in the DFS order from POs to PIs and replaces it if
applicable. At each iteration, in step 1, the algorithm computes
MAs(nt = sa0). If the MAs are inconsistent, it replaces nt with
0 and continues to consider the next target node. Otherwise,
if nt has a fanin node that drives only nt , the algorithm stores
the computed MAs(nt = sa0) for further reuse. Next, in step 2,
the algorithm computes MAs(nt = sa1). Similarly, if the MAs
in MAs(nt = sa1) are inconsistent, it replaces nt with 1 and
continues to consider the next target node. Otherwise, the
algorithm starts to find substitute nodes.
IE
EE
 P
ro
of
8 IEEE TRANSACTIONS ON COMPUTER-AIDED DESIGN OF INTEGRATED CIRCUITS AND SYSTEMS
TABLE II
Experimental Results of Finding Replaceable Nodes by Using
the Node-Merging Approach [14] and Our Approach
Benchmark N [14] Our Approach
Repl. T (s) Repl. T (s) Impr. k > 5 SFoFi
C3540 1038 2.8 0.3 31.6 0.5 28.8 96.3 13.9
rot 1063 4.0 0.2 36.1 0.3 32.1 83.6 29.9
simpleâˆ’spi 1079 2.4 0.1 21.7 0.3 19.3 74.8 15.4
i2c 1306 6.1 0.2 40.4 0.5 34.3 65.9 29.0
pciâˆ’spociâˆ’ctrl 1451 11.7 0.6 43.4 1.5 31.7 59.7 31.9
dalu 1740 12.5 1.0 50.9 3.1 38.4 60.2 25.5
C5315 1773 1.9 0.2 15.7 0.3 13.8 66.7 16.7
s9234 1958 8.9 0.4 42.2 0.7 33.3 82.7 16.1
C7552 2074 2.9 0.4 33.3 0.7 30.4 71.3 15.8
C6288 2337 0.1 0.5 39.9 1.4 39.8 99.8 0.0
i10 2673 23.4 1.4 55.9 2.8 32.5 55.9 43.0
s13207 2719 5.8 0.6 32.8 1.7 27.0 78.0 19.6
systemcdes 3190 4.6 1.5 42.5 2.6 37.9 75.1 21.3
i8 3310 46.3 3.8 76.2 7.2 29.9 37.5 57.9
spi 4053 1.6 3.4 23.4 6.6 21.8 88.4 11.2
desâˆ’area 4857 1.6 5.6 18.3 13.3 16.7 87.1 17.3
alu4 5270 3.9 54.9 54.1 83.6 50.2 80.1 61.2
s38417 9219 1.9 1.5 25.2 2.4 23.3 84.7 12.4
tv80 9609 5.2 17.2 35.5 41.6 30.3 75.5 15.9
b20 12 219 6.9 17.3 36.2 34.6 29.3 59.4 11.3
s38584 12 400 4.4 17.0 35.4 66.2 31.0 87.4 13.1
b21 12 782 8.6 19.3 41.1 39.5 32.5 54.8 10.6
systemcaes 13 054 1.5 17.7 22.1 36.8 20.6 96.7 8.5
ac97âˆ’ctrl 14 496 0.7 3.2 9.9 7.5 9.2 85.2 7.8
memâˆ’ctrl 15 641 9.8 98.8 22.0 178.0 12.2 22.9 22.9
usbâˆ’funct 15 894 2.3 6.3 21.6 16.7 19.3 62.6 14.0
b22 18 488 5.7 25.0 35.1 53.8 29.4 62.6 10.4
aesâˆ’core 21 513 2.1 15.2 37.5 39.9 35.4 90.6 9.2
pciâˆ’bridge32 24 369 1.3 21.7 15.2 47.2 13.9 86.0 8.2
wbâˆ’conmax 48 429 11.6 28.2 27.9 116.0 16.3 37.5 33.3
b17 52 920 3.0 174.5 33.0 533.8 30.0 48.7 9.6
desâˆ’perf 79 288 3.2 51.4 43.4 82.7 40.2 86.3 20.2
Average 6.5 34.4 27.8 72.0 19.8
Total 589.3 1423.7
Ratio 1 5.26
one shows the effectiveness of the proposed approach on
facilitating SAT-based BSEC.
A. Replaceable Node Identification
In the experiments, we compare the proposed approach
with our prior node-merging approach [14]. Each node in
a benchmark is considered a target node one at a time. We
separately use the node-merging approach and the proposed
approach to check how many nodes in a benchmark are
replaceable. A node is considered replaceable if it has a
substitute node or an added substitute node. Given a target
node, the proposed approach first finds its substitute nodes.
If the proposed approach fails to do so, it further finds
the added substitute nodes. Additionally, to demonstrate that
the proposed approach could complement the local ODC-
based node-merging approach [37], we measure how many
replaceable nodes that the local ODC-based node-merging
approach with a bounded depth k = 5 cannot find.
Table II summarizes the experimental results. Column 1
lists the benchmarks. Column 2 lists the number of nodes in
each benchmark represented as an AIG N. Columns 3 and
4 list the results of our prior node-merging approach. They
are the percentage of the number of replaceable nodes with
respect to N, and the CPU time T , respectively. Columns 5
and 6 list the corresponding results of the proposed approach.
Column 7 shows the improvements of the proposed approach
on the percentage of replaceable nodes. Let Nrepâˆ’k>5 denote
the number of replaceable nodes that cannot be found by the
reimplemented local ODC-based node-merging approach with
a bounded depth k = 5. Column 8 lists the percentage of
Nrepâˆ’k>5 with respect to the number of replaceable nodes. Ad-
ditionally, let Nrepâˆ’k>5âˆ’SFoFi denote the number of replaceable
nodes in Nrepâˆ’k>5 that have at least one SFoFi node. Column 9
lists the percentage of Nrepâˆ’k>5âˆ’SFoFi with respect to Nrepâˆ’k>5.
When a node having a SFoFi node is replaced, the fanin node
can be removed as well. Thus, the resultant circuit is reduced,
even though we add one node into the circuit.
For example, the benchmark C3540 has 1038 nodes. Our
prior node-merging approach found substitute nodes for 2.8%
of nodes with a CPU time of 0.3 s. The proposed approach
found that 31.6% of nodes have substitute nodes or added
substitute nodes with a CPU time of 0.5 s. Thus, the pro-
posed approach can find 28.8% more replaceable nodes.
Additionally, 96.3% replaceable nodes cannot be found by the
reimplemented local ODC-based node-merging approach with
a bounded depth k = 5. Among these nodes, 13.9% of them
have at least one SFoFi node.
According to Table II, our prior node-merging approach
can find substitute nodes for an average of 6.5% of nodes
in a benchmark. The overall CPU time for all benchmarks is
589.3 s. As for the proposed approach, it can find substitute
nodes or added substitute nodes for an average of 34.4% of
nodes in a benchmark. The overall CPU time is 1423.7 s.
As compared with our prior node-merging approach, the
proposed approach can find more replaceable nodes with a
reasonable CPU time overhead. The average number of re-
placeable nodes is 27.8% more with a ratio 5.26, and the CPU
time overhead is only 834.4 s for all benchmarks. Because the
proposed approach identifies much more replaceable nodes,
it has a better logic restructuring capability than that of the
node-merging approach.
Additionally, an average of 72.0% of the replaceable nodes
that identified by the proposed approach cannot be found by
the reimplemented local ODC-based node-merging approach
with a bounded depth k = 5. An average of 19.8% of these
nodes have at least one SFoFi node. Thus, it can be expected
that the proposed approach could complement the local ODC-
based node-merging approach [37]. They could work together
to obtain a better quality.
B. Circuit Size Reduction
In the experiments, we compare the proposed approach
with our prior ATPG-based node-merging approach [14] as
well as the SAT-based node-merging approach [28] for circuit
size reduction. To have a fair comparison with the SAT-based
node-merging approach, which focuses on post-synthesis opti-
mizations, we initially optimize each benchmark by using the
resyn2 script in the ABC package as performed by [28], which
IE
EE
 P
ro
of
10 IEEE TRANSACTIONS ON COMPUTER-AIDED DESIGN OF INTEGRATED CIRCUITS AND SYSTEMS
used to demonstrate that our approach can work together with
the resyn2 script to obtain a better quality. Finally, we also
measure the spent CPU time by the SAT solver for solving
these optimized BSEC models.
The experimental results are summarized in Table V.
Columns 1 and 2 list the benchmarks and the number of flip-
flops (FFs) in each benchmark, respectively. Column 3 lists
the bounded unfolding depth k. Column 4 lists the spent CPU
time by the SAT solver for solving an original BSEC model.
The CPU time limit is 36 000 s. Columns 5â€“7 list the results
of using the resyn2 script to optimize the BSEC models. They
are the spent CPU time for SAT solving, the total CPU time,
and the saved CPU time compared to the CPU time shown
in Column 4. Columns 8â€“10 list the corresponding results of
using the resyn2 script followed by our approach to optimize
the BSEC models. Here, the saved CPU time is compared to
the total CPU time shown in Column 6.
For example, the benchmark b04 has 132 FFs. The SAT
solver spent 1615.7 s to solve its BSEC model which is
unfolded to 12 timeframes. When we optimized the BSEC
model by using the resyn2 script, the SAT solver spent 10.3 s
to solve it, and the total CPU time is 10.9 s. Thus, we
saved 1604.8 s (1615.7 âˆ’ 10.9 = 1604.8). However, when
we optimized the BSEC model by using the resyn2 script
followed by our approach, the SAT solver spent only 0.1 s
and the total CPU time is 3.8 s. Thus, we further saved 7.1 s
(10.9 âˆ’ 3.8 = 7.1).
The experimental results show that logic optimization and
restructuring could be a preprocess before SAT-based BSEC
for reducing the verification complexity. When using the
resyn2 script to optimize BSEC models, we can save a
total of 89344.1 s (approximately 25 h) for all the bench-
marks. Furthermore, when using our approach to complement
the resyn2 script, we can further save a total of 50463.8 s
(approximately 14 h) for all the benchmarks. Additionally, the
time overhead of the BSEC model optimization is less than
20 min (2121.6 âˆ’ 936.9 = 1184.7). Thus, although the resyn2
script is effective for most of the benchmarks, our approach
can be combined with it to achieve a better speedup.
VIII. Conclusion
In this paper, we proposed an ATPG-based NAR approach
that can efficiently find an added node to replace a node in
a circuit. The NAR approach can replace a target node that
a node-merging approach cannot handle, thus enhancing the
capability of circuit restructuring.
We also proposed an efficient algorithm for circuit size
reduction based on the NAR approach. The techniques of
redundancy removal and MA reuse were engaged to make the
algorithm more efficient and effective. Moreover, we applied
the algorithm to facilitate SAT-based BSEC by reducing the
computation complexity.
The experimental results showed that the proposed algo-
rithm enhanced our prior ATPG-based node-merging approach
and could complement a SAT-based node-merging approach.
Additionally, it has a competitive capability of circuit size re-
duction and expends much less CPU time compared to another
SAT-based node-merging approach. The experimental results
also showed that the proposed algorithm can be integrated
with other optimization technique to obtain a better circuit
size reduction. For SAT-based BSEC, the proposed algorithm
can work together with other optimization technique to save
much equivalence checking time for all the benchmarks. All
these results showed the efficiency and effectiveness of the
proposed approach.
References
[1] M. S. Abadir, J. Ferguson, and T. E. Kirkland, â€œLogic design verification
via test generation,â€ IEEE Trans. Comput.-Aided Des., vol. 7, no. 1,
pp. 138â€“148, Jan. 1988.
[2] M. Abramovici, M. A. Breuer, and A. D. Friedman, â€œDigital systems
testing and testable design,â€ in Design for Testability. Piscataway, NJ:
IEEE Press, 1990.
[3] Berkeley Logic Synthesis and Verification Group. ABC: A System for
Sequential Synthesis and Verification [Online]. Available: http://www.
eecs.berkeley.edu/âˆ¼alanmi/abc
[4] A. Biere, A. Cimatti, E. M. Clarke, M. Fujita, and Y. Zhu, â€œSymbolic
model checking using SAT procedures instead of BDDs,â€ in Proc. Des.
Automat. Conf., 1999, pp. 317â€“320.
[5] A. Biere, A. Cimatti, E. M. Clarke, O. Strichmanm, and Y. Zhu,
â€œBounded model checking,â€ Adv. Comput., vol. 58, no. 3, pp. 118â€“149,
2003.
[6] A. Biere, A. Cimatti, E. M. Clarke, and Y. Zhu, â€œSymbolic model
checking without BDDs,â€ in Proc. Tools Algorithms Construct. Anal.
Syst., 1999, pp. 193â€“207.
[7] M. Case, V. Kravets, A. Mishchenko, and R. Brayton, â€œMerging nodes
under sequential observability,â€ in Proc. Des. Automat. Conf., 2008,
pp. 540â€“545.
[8] L. C. L. Chang, C. H. P. Wen, and J. Bhadra, â€œSpeeding up bounded
sequential equivalence checking with cross-timeframe state-pair con-
straints from data learning,â€ in Proc. Int. Test Conf., 2009, pp. 1â€“8.
[9] C. W. J. Chang, M. F. Hsiao, and M. M. Sadowska, â€œA new rea-
soning scheme for efficient redundancy addition and removal,â€ IEEE
Trans. Comput.-Aided Des., vol. 22, no. 7, pp. 945â€“952, Jul. 2003.
[10] S. C. Chang, K. T. Cheng, N. S. Woo, and M. Marek-Sadowska, â€œPost-
layout logic restructuring using alternative wires,â€ IEEE Trans. Comput.-
Aided Des., vol. 16, no. 6, pp. 587â€“596, Jun. 1997.
[11] S. C. Chang, L. P. P. P. Van Ginneken, and M. Marek-Sadowska, â€œCircuit
optimization by rewiring,â€ IEEE Trans. Comput., vol. 48, no. 9, pp. 962â€“
970, Sep. 1999.
[12] S. C. Chang, M. Marek-Sadowska, and K. T. Cheng, â€œPerturb and
simplify: Multi-level boolean network optimizer,â€ IEEE Trans. Comput.-
Aided Des., vol. 15, no. 12, pp. 1494â€“1504, Dec. 1996.
[13] Y. C. Chen and C. Y. Wang, â€œAn Improved approach for alternative wire
identification,â€ in Proc. Int. Conf. Comput. Des., 2005, pp. 711â€“716.
[14] Y. C. Chen and C. Y. Wang, â€œFast detection of node mergers using logic
implications,â€ in Proc. Int. Conf. Comput.-Aided Des., 2009, pp. 785â€“
788.
[15] Y. C. Chen and C. Y. Wang, â€œFast node merging with donâ€™t cares using
logic implications,â€ IEEE Trans. Comput.-Aided Des., vol. 29, no. 11,
pp. 1827â€“1832, Nov. 2010.
[16] Y. C. Chen and C. Y. Wang, â€œNode addition and removal in the presence
of donâ€™t cares,â€ in Proc. Des. Automat. Conf., 2010, pp. 505â€“510.
[17] K. T. Cheng and L. A. Entrena, â€œMulti-level logic optimization by
redundancy addition and removal,â€ in Proc. Eur. Conf. Des. Automat.,
1993, pp. 373â€“377.
[18] F. S. Chim, T. K. Lam, and Y. L. Wu, â€œOn improved scheme for
digital circuit rewiring and application on further improving FPGA
technology mapping,â€ in Proc. Asia South Pacific Des. Automat. Conf.,
2009, pp. 197â€“202.
[19] L. A. Entrena and K. T. Cheng, â€œCombinational and sequential logic
optimization by redundancy addition and removal,â€ IEEE
Trans. Comput.-Aided Des., vol. 14, no. 7, pp. 909â€“916, Jul. 1995.
[20] T. Kirkland and M. R. Mercer, â€œA topological search algorithm for
ATPG,â€ in Proc. Des. Automat. Conf., 1987, pp. 502â€“508.
[21] A. Kuehlmann, â€œDynamic transition relation simplification for bounded
propery checking,â€ in Proc. Int. Conf. Comput.-Aided Des., 2004,
pp. 50â€“57.
[22] A. Kuehlmann, V. Paruthi, F. Krohm, and M. K. Ganai, â€œRobust boolean
reasoning for equivalence checking and functional property verification,â€
IEEE Trans. Comput.-Aided Des., vol. 21, no. 12, pp. 1377â€“1394,
Dec. 2002.
 1 
å‡ºå¸­ 2011 IWLS + DAC å ±å‘Š 
åœ‹ç«‹æ¸…è¯å¤§å­¸è³‡è¨Šå·¥ç¨‹å­¸ç³» ç‹ä¿Šå ¯ å‰¯æ•™æˆ 
2011 å¹´ 07 æœˆ 19 æ—¥ 
    6/2 æ­è¯èˆª CI008 ç›´é£›æ´›æ‰ç£¯åœ‹éš›æ©Ÿå ´ï¼Œåœ¨æ­·ç¶“åå¤šå€‹å°æ™‚
çš„é£›è¡Œå¾Œï¼Œå¾ˆç–²ç´¯åœ°æŠµé”æ´›æ‰ç£¯åœ‹éš›æ©Ÿå ´ï¼Œæ¥è‘—å†è½‰æ©Ÿåˆ°è–åœ°ç‰™
å“¥ï¼Œå‡ºæ©Ÿå ´æ™‚å·²ç¶“åˆå¤œ 11 é»å¤šäº†ï¼Œè¼¾è½‰æ­ä¹˜ local çš„äº¤é€šå·¥å…·ï¼Œ
æŠµé”ä½æ–¼è–åœ°ç‰™å“¥çš„é£¯åº—ã€‚ 
 
2011 å¹´é‚è¼¯èˆ‡åˆæˆåœ‹éš›æœƒè­°(International Workshop on Logic 
and Synthesis 2011)è‡ª 6 æœˆ 3 æ—¥èµ·åœ¨è–åœ°ç‰™å“¥çš„ UC-SD èˆ‰è¡Œï¼Œç‚º
æœŸä¸‰å¤©ã€‚æ­¤æ¬¡ä¹ƒå¤§æœƒçš„ç¬¬ 20 å±†ï¼Œæ¥å—ä¸¦å®‰æ’ç™¼è¡¨çš„è«–æ–‡å…±æœ‰ 25
ç¯‡ï¼Œå…¶ä¸­ 21 ç¯‡ç‚º regular presentationsã€4 ç¯‡ç‚º postersã€‚æ¯å€‹æ™‚æ®µ
åªæœ‰ä¸€å€‹å ´æ¬¡é€²è¡Œï¼Œè®“æ‰€æœ‰èˆ‡æœƒè€…çš†èƒ½é½Šèšä¸€å ‚ã€‚è«–æ–‡æ¶µè“‹ç©é«”
é›»è·¯çš„åˆæˆã€æœ€ä½³åŒ–èˆ‡é©—è­‰ç­‰ä¸»é¡Œï¼Œç„¡è«–æ˜¯ regular presentation
æˆ– poster è«–æ–‡ï¼Œæ¯ç¯‡å…§å®¹å¯é”å…«é ä¸¦æ”¶éŒ„æ–¼è«–æ–‡é›†å…§ã€‚ 
 
    ç­†è€…èˆ‡éš¨è¡Œçš„ç ”ç©¶ç”Ÿåœ¨æœƒä¸­ç™¼è¡¨ä¸€ç¯‡ regular è«–æ–‡ï¼Œå…§å®¹ç‚º
é‡å°è‡¨ç•Œå€¼é‚è¼¯ (threshold logic) æå‡ºé‡æ¥ç·šçš„æ¼”ç®—æ³•ã€‚æˆ‘å€‘æ˜¯
é¦–æ¬¡æå‡ºæ­¤æ–¹æ³•çš„è«–æ–‡ï¼Œå…¶å»ºç«‹äº†é‡è¦çš„ç†è«–åŸºç¤ï¼Œæ‰€ä»¥å¾—åˆ°ä¾†
è‡ªå­¸ç•Œ(å¦‚ UC-Berkeleyã€University of Michiganã€UIUC ç­‰)çš„èˆ‡
æœƒè€…çš„æ³¨æ„èˆ‡ç†±çƒˆè¨è«–ï¼Œæ”¶ç©«é —è±ã€‚    
 
    å¤§æœƒæ­£å¼çš„æ™šå®´ä¹Ÿå®‰æ’æ–¼ç¬¬äºŒå¤©æ™šä¸Šèˆ‰è¾¦ï¼Œæä¾›ä¸€å€‹è®“èˆ‡æœƒ
è€…å½¼æ­¤èªè­˜ä»¥åŠåˆ†äº«ç ”ç©¶æˆæœèˆ‡å¿ƒå¾—çš„ç¤¾äº¤æ©Ÿæœƒã€‚ç­†è€…æ˜¯ç¬¬ä¸‰æ¬¡
åƒåŠ æ­¤æœƒè­°ï¼ŒåƒåŠ å¾Œæ„Ÿè¦ºä¸è™›æ­¤è¡Œï¼Œä¸ä½†èƒ½å’Œé ˜åŸŸç›¸è¿‘çš„å­¸è€…å°ˆ
å®¶å°±ç­†è€…ç™¼è¡¨çš„è«–æ–‡æˆæœé€²è¡Œæ„è¦‹äº¤æ›ï¼Œä¹Ÿå°ä¸€äº›å½¼æ­¤æ„Ÿèˆˆè¶£æˆ–
ç­†è€…æœªæ›¾æ¥è§¸ä¹‹ç ”ç©¶é¡Œææœ‰é€²ä¸€æ­¥çš„æŠ€è¡“æ¢è¨æˆ–åˆæ­¥èªè­˜ã€‚åŒæ™‚
ç­†è€…ä¹Ÿé‡è¦‹äº†è¨±å¤šæœ‰åçš„æ•™æˆå­¸è€…ï¼Œå¦‚ R. Braytonï¼ŒA. Mischehko 
(UC Berkeley)ï¼ŒT. Sasao (Kyushu Institute of Tech.)ç­‰äººï¼Œä¸¦èˆ‡ä»–
å€‘åœ¨é¤æ¡Œä¸Šäº¤è«‡ï¼Œé€™å€‹ç¶“é©—å°æˆ‘ä¾†èªªçœŸçš„å¾ˆå¯¶è²´ã€‚ 
 
 1 
å‡ºå¸­ 2011 PROFIT åœ‹éš›åˆä½œå ±å‘Š 
åœ‹ç«‹æ¸…è¯å¤§å­¸è³‡è¨Šå·¥ç¨‹å­¸ç³» ç‹ä¿Šå ¯ å‰¯æ•™æˆ 
2011 å¹´ 09 æœˆ 30 æ—¥ 
   å…«æœˆåæ—¥æ­è¯èˆª CI511 ç›´é£›åŒ—äº¬æ©Ÿå ´ï¼Œåœ¨æ­·ç¶“ 3 å€‹å¤šå°æ™‚çš„
é£›è¡Œå¾Œï¼Œé †åˆ©æŠµé”åŒ—äº¬æ©Ÿå ´ï¼Œè¼¾è½‰æ­ä¹˜ local çš„äº¤é€šå·¥å…·ï¼ŒæŠµé”
ä½æ–¼åŒ—äº¬å¤§å­¸å…§çš„é£¯åº—ã€‚ 
 
é›–ç„¶ 2011 PROFIT åœ‹éš›åˆä½œæœƒè­°æ–¼å…«æœˆåå››æ—¥æ‰è¦åœ¨å…§è’™
å¤çš„å‘¼å’Œæµ©ç‰¹èˆ‰è¡Œï¼Œä½†æ˜¯ç‚ºäº†åƒè§€åŒ—äº¬å¤§å­¸åŠå¤§é™¸æ¸…è¯å¤§å­¸ï¼Œæ‰€
ä»¥å°±æå‰å‡ºç™¼äº†ï¼Œåœ¨åŒ—äº¬é€²è¡Œäº†å¹¾æ—¥çš„ç§äººè¨ªå•è¡Œç¨‹å¾Œï¼Œæ–¼å…«æœˆ
åä¸‰æ—¥å‰å¾€æœƒè­°åœ°é»å‘¼å’Œæµ©ç‰¹ã€‚ 
 
ä»Šå¹´æœƒè­°å®‰æ’ 2å ´ keynote speechesï¼Œåˆ†åˆ¥æ˜¯ç”±åœ‹ç«‹æ¸…è¯å¤§
å­¸çš„å…©ä½å‰ä»»æ ¡é•·åŠ‰ç‚¯æœ—æ ¡é•·åŠé™³æ–‡æ‘æ ¡é•·ç™¼è¡¨å°ˆé¡Œæ¼”èªªï¼Œå¦å¤–
é‚„æœ‰æµªæ½®é›†åœ˜æœ‰é™å…¬å¸è‘£äº‹é•·å…¼ CEOå­«ä¸•æ•ï¼Œå‰µæ„é›»å­ CEOçŸ³å…‹
å¼ºåŠç™¾åº¦é«˜çº§æŠ€è¡“ç¸½ç›£èŒƒéº—ä¹Ÿç™¼è¡¨å°ˆé¡Œæ¼”èªªï¼Œå…§å®¹æ¶µè“‹ç©é«”é›»è·¯
çš„æ¼”é€²ã€è³‡æ–™ä¸­å¿ƒçš„è¨­ç«‹ã€ä»¥åŠæœå°‹å¼•æ“çš„ä»‹ç´¹ç­‰ä¸»é¡Œã€‚ 
 
ç­†è€…èˆ‡ PROFIT å§”å“¡çš„äº’å‹•è‰¯å¥½(å¦‚åŒ—äº¬æ¸…è¯çš„æ±ªç‰æ•™æˆï¼Œ
UCLA çš„ Jason Cong æ•™æˆï¼ŒLei He æ•™æˆï¼ŒUCSB çš„ Tim Cheng æ•™
æˆï¼ŒåŠ UT Austin çš„ David Pan æ•™æˆç­‰)ï¼Œæˆ‘å€‘è¨è«–å½¼æ­¤æœ€è¿‘çš„ç ”
ç©¶å…§å®¹èˆ‡å¿ƒå¾—ï¼Œä¸¦äº¤æ›æ„è¦‹ï¼Œä¸”å°æ–¼æœ€æ–°çš„ç ”ç©¶é¡Œç›®èˆ‡æ–¹å‘äº’ç›¸
äº¤æµæƒ³æ³•ï¼Œæœ€å¾Œè«‡åŠå­¸ç”Ÿç´ è³ªåŠå­¸ç”Ÿç ”ç©¶æ…‹åº¦çš„å·®ç•°ï¼Œä¸¦äº¤æµä¸€
äº›æƒ³æ³•åŠåšæ³•ï¼Œæ”¶ç©«å¾ˆå¤šã€‚åŒæ™‚ä¹Ÿè¨è«–åˆ°ä¸‹ä¸€æ¬¡æœƒè­°çš„å¬é–‹åœ°é»ã€‚ 
 
 2 
æ¥è‘—ç­†è€…ç¹¼çºŒåƒåŠ  Design Automation Conference 2011 çš„å­¸
è¡“æœƒè­°ã€‚2011 å¹´è¨­è¨ˆè‡ªå‹•åŒ–æœƒè­° (Design Automation Conference 
2011)è‡ª 6 æœˆ 5 æ—¥èµ·åœ¨è–åœ°ç‰™å“¥çš„åœ‹éš›æœƒè­°ä¸­å¿ƒèˆ‰è¡Œï¼Œç‚ºæœŸ 5 å¤©ã€‚
è¢«å¤§æœƒæ¥å—ä¸¦å®‰æ’ç™¼è¡¨çš„è«–æ–‡å…±æœ‰ 156 ç¯‡ï¼Œæ¥å—ç‡åªæœ‰ 23%ã€‚æ¯
å€‹æ™‚æ®µæœ‰ 6 å€‹å ´æ¬¡å¹³è¡Œé€²è¡Œï¼Œæ¯ç¯‡å…§å®¹å¯é” 6 é ä¸¦æ”¶éŒ„æ–¼è«–æ–‡é›†
å…§ã€‚æ­¤æ¬¡ç­†è€…ä¹Ÿèˆ‡éš¨è¡Œçš„ç ”ç©¶ç”Ÿåœ¨æœƒä¸­ç™¼è¡¨ä¸€ç¯‡è«–æ–‡ï¼Œå…§å®¹ç‚ºé‡
å°å–®é›»å­é›»æ™¶é«” (single-electron transistor) çš„å…ƒä»¶æ¶æ§‹ï¼Œæå‡ºè‡ª
å‹•åŒ–åˆæˆé›»è·¯çš„æ¼”ç®—æ³•ã€‚æˆ‘å€‘æ˜¯é¦–ç¯‡æå‡ºè‡ªå‹•åŒ–ç¨‹åºçš„è«–æ–‡ï¼Œå…¶
å°‡æ­¤é ˜åŸŸå¸¶å…¥å…¨æ–°è‡ªå‹•çš„éšæ®µï¼Œæ‰€ä»¥ç²å¾—è¨±å¤šèˆ‡æœƒè€…çš„æ³¨æ„ã€‚ 
åœ¨ DAC æœƒè­°ä¸­ï¼Œæˆ‘ä¹Ÿè†è½è¨±å¤šæ–°çš„æŠ€è¡“å ±å‘Šä¹‹ç™¼è¡¨åŠè‡³åƒ
å±•çš„å…¬å¸æ”¤ä½äº†è§£æ–°ç”¢å“çš„åŠŸèƒ½èªªæ˜èˆ‡å¸‚å ´èµ°å‘ã€‚  
ç­†è€…åœ¨è¿”åœ‹å¾Œåˆ†åˆ¥æ”œå›2011å¹´é‚è¼¯èˆ‡åˆæˆåœ‹éš›æœƒè­°è«–æ–‡é›†ä¸€
å†ŠåŠ 2011 å¹´è¨­è¨ˆè‡ªå‹•åŒ–æœƒè­°è«–æ–‡é›†ä¸€å†Šã€‚ 
 1 
Current detector 
1 
(a) (b) 
aâŠ•b 
a aâ€™ 
bâ€™ b 
Active high  
Active low 
Short  
Figure 2: (a) A SET array fabric. (b) An example of a
xor b.
a conducting nanowire or have a wrapped gate. Consequently,
this structure is not very regular and cannot be restructured to
implement a different function due to the physical etching process
involved in its realization. Furthermore, if any of the nanowire
segments or the wrap gates is defective, the whole circuit be-
comes non-functional. This is a significant limitation considering
that nanowires and few electron nanodevices have traditionally
suffered from the variability and reliability issues.
To solve the problem, a reconfigurable version of SET using
wrap gate tunable tunnel barriers was proposed [2] and the in-
depth device simulation to study the electrostatic properties was
presented [8]. This device can operate in three distinct operation
states: a) active b) open and c) short state based on the wrap gate
bias voltages. Such programmability leads to immense flexibility
in designing a circuit. The device simulation shows that this
device can provide an order of magnitude lower energy-delay than
CMOS device [8].
However, the synthesis of a BDD using the device in [2] is man-
ual rather than automated. The reason is that mapping a reduced
ordered BDD (ROBDD) into a planar SET array could be very
complicated, especially when the BDD has crossing edges, which
is typical in minimized BDDs. In this work, we address this
mapping problem and propose an automated mapping approach.
Instead of mapping a BDD directly, the proposed approach first
divides a BDD into a set of product terms that represent the
paths leading to the 1 terminal in the BDD. Then, it sequentially
maps these product terms. Since the mapping order of the prod-
uct terms affects the mapping results, we propose four sorting
heuristics to reduce area cost. Additionally, the automated map-
ping approach incorporates the granularity and fabric constraints
that are imposed in order to decrease the number of metal wires
used for programming the SET array and for supplying the input
signals, respectively [2].
We conduct experiments on a set of MCNC benchmarks [10].
The experimental results show that the proposed approach can
complete mapping within 1 second for most of the benchmarks.
The main contribution of this work is proposing an automated
synthesis tool for the promising energy-efficient SET array archi-
tecture.
The rest of this paper is organized as follows: Section 2 uses
an example to demonstrate the problem considered in this paper,
and introduces some notations. Section 3 presents the proposed
mapping approach. Section 4 discusses and addresses two map-
ping constraints. Finally, the experimental results and conclusion
are presented in Sections 5 and 6.
2. BACKGROUND
2.1 An example
A SET array can be presented as a graph composed of hexagons.
As shown in Fig. 2(a), like the hexagonal fabric mentioned above,
there is a current detector at the top that measures the current
coming from the bottom of the hexagonal fabric. All the vertical
edges of the hexagons are electrical short. All the sloping edges
can be configured as active high, active low, short or open. An
active high edge is controlled by a variable x. It is conducting
and non-conducting when x = 1 and x = 0, respectively. Con-
 
root node (0, 0) 
4 
x 1 4 3 2 0 -1 -2 -3 
y 
3 
2 
1 
0 
node (-3, 3) 
left edge 
right edge 
root node (0, 0) 
x 1  3 2 0 -1 -2 -3 
y 
3 
2 
1 
0 
node (-3, 3) 
left edge 
right edge 
-4 4 
Figure 3: An abstract diamond fabric.
versely, an active low edge is an electrical opposite of an active
high edge and it is controlled by a variable xâ€².
A Boolean function can be implemented using a SET array.
All the active edges at the same row of the hexagonal fabric are
controlled by a single variable, i.e., a primary input (PI). They
determine whether there exists a path for the current to pass
through, and thus, be detected at the top. If so, the functional
output of the array is 1; otherwise, it is 0. For example, Fig.
2(b) shows a SET array implementing a xor b. When a = 1
and b = 0, the current can be detected by passing through the
left path. However, if a = 1 and b = 1, the current cannot be
detected.
Thus, the addressed problem of this work is synthesizing a given
Boolean function into a SET array with minimized area, i.e., the
number of configured hexagons.
Previous work [2] tries to manually map a Boolean function
by directly mapping its BDD into a SET array. However, the
mapping process could be very complicated due to the structural
difference of a BDD and a SET array. For example, an ROBDD
usually has some crossing edges. Since a SET array is a planar
architecture, much effort is required to avoid having the crossing
edges in the ROBDD when mapping it into a SET array. Node
duplication could be a trivial method for solving this crossing
edge issue while not considering the area overhead. In addition,
determining the exact location of each ROBDD node in a SET
array is a challenge. Thus, to address this problem, we propose
a product term-based method. It first collects all the paths that
lead to the terminal 1 in the ROBDD, i.e., product terms. Then,
it maps each product term into a path in the SET array. The
proposed method simultaneously avoids the crossing edge and the
BDD node mapping issues.
For example, the product terms of a xor b are 10 and 01. Using
the proposed method, we first map 10 and then 01. Finally, we
obtain the resultant SET array as shown in Fig. 2(b), where the
left path is configured for 10 and the right path is for 01.
2.2 Notations
For ease of discussion, we use an abstract graph to present a
SET array. Compared to Fig. 2(a), only the configurable edges
are preserved as shown in Fig. 3. In this diamond fabric, each
node n, i.e., the root of a pair of left and right edges, has a unique
location (x, y). Based on the root node located at (0, 0), which
is below the current detector, the y value increases from top to
bottom. The x value increases and decreases from center to right
and left, respectively.
For simplification, let n.left and n.right denote the status of the
left and right edges of a node n, respectively. The status could
be empty, high, low, short, or open. empty indicates the edge is
not configured yet (is used primarily for algorithm illustration).
high, low, short, and open indicate the edge is configured as active
high, active low, short, and open, respectively. Additionally, let
n(x,y) denote the node located at (x, y).
3. AUTOMATED MAPPING
In this section, we first discuss the motivation of our method.
Next, we introduce two key mapping procedures. Finally, the
overall flow is presented. Here, we first assume that each edge
can be configured independently without any constraint. In the
879
48.3
= 
1 1 1 â€“ 0 
0 1 0 â€“ 0 
0 1 0 0 1 
 Active high 
Active low 
Short 
Open 
0 
1 
2 
3 
0 1 2 -1 
4 
5 
0 
1 
2 
3 
0 1 2 -1 
4 
5 
1 1 1 â€“ 0 
0 1 â€“ â€“ 0 
0 1 1 1 1 
 
3 
0 
1 
2 
3 
0 1 2 -1 
4 
5 
3 
0 
1 
2 
3 
0 1 2 -1 
4 
5 
3 4 
(a) (b) 
(c) (d) 
4 
Figure 6: Incorrect mapping examples.
p2 = 111âˆ’, and p3 = 101âˆ’, sorted by ForInertiaSort as shown in
Fig. 5(a). First, let us consider p0. Starting from the root node
n(0,0), we first configure n(0,0).left as low for the first bit 0. Next,
we configure n(âˆ’1,1).right as high for the second bit 1. Using the
same method, we configure n(0,2).left and n(âˆ’1,3).right as high
and low for the last two bits 10, respectively. The mapping result
is shown in Fig. 5(b). Here, the decision of configuring the left
edge or the right edge of a node depends on its location (x, y). If
x < 0, we first try to configure its right edge. If inapplicable, we
then try to configure its left edge. Conversely, if x â‰¥ 0, we try
the left edge first and then the right edge.
Next, for p1, because the first two bits are the same as that
of the first product term, we partially reuse this mapping result.
Then, we configure n(0,2).right as low and n(1,3).left as short for
the last two bits 0âˆ’, respectively. The mapping result is shown
in Fig. 5(c).
For p2, after we configure n(0,0).right as high for the first bit 1,
we do not configure n(1,1).left as high for the second bit 1. This
is because if we do so, there will exist a path n(0,0) â†’ n(1,1) â†’
n(0,2) â†’ n(1,3) â†’ n(0,4), which corresponds to an invalid product
term 110âˆ’. Thus, we configure n(1,1).right as high for the second
bit 1. Finally, n(2,2).left and n(1,3).left are configured as high and
short for the last two bits 1âˆ’, respectively. The mapping result
is shown in Fig. 5(d).
Next, let us consider p3. After finding n(0,0).right = high for
the first bit 1, we do not configure n(1,1).left as low for the sec-
ond bit 0. This is because it will construct a path for an invalid
product term 100âˆ’. Additionally, since n(1,1).right has been con-
figured as high, we expand the structure by configuring both
n(2,0).left and n(2,0).right as short, and start from n(3,1) for the
last three bits. The mapping result is shown in Fig. 5(e). Finally,
we configure all the non-configured edges as open, and obtain the
final mapping result in Fig. 5(f).
To avoid creating an invalid path, we need to prevent two paths
from merging and then branching during mapping. Thus, when
we detect a merging node, like n(0,2) for p2 or p3, we will check
if there exists only one path from n(0,2). If not, there possibly
exists an invalid path. Thus, we prevent the paths from merging.
With this checking rule, each path from top to bottom exactly
corresponds to one product term. In addition, from the viewpoint
of conducting paths, this checking rule is not enough and we have
to add another rule considering the conducting path issue. Fig.
6(a), (b) show two mapping examples, which are incorrect while
satisfying the merging and branching rule.
In Fig. 6(a), when the input pattern is 11101, which is not a
minterm, the current can be detected at the top. This is because
the right edge of n(âˆ’1,3), the left edge of n(1,3), and the right
edge of n(1,3) as highlighted are conducting simultaneously. This
partial conducting path forms like a bridge that connects two
paths such that the current can pass through the path n(1,5) â†’
n(2,4) â†’ n(1,3) â†’ n(0,4) â†’ n(âˆ’1,3) â†’ n(0,2) â†’ n(âˆ’1,1) â†’n(0,0).
In addition, a partial conducting path could be composed of the
Mapping(set PTs) // PTs: product terms
1. Configure n(0,0).left and n(0,0).right based on the first bit values
of the product terms in PTs;
2. For each product term t in PTs
2.1. If (LeftConfigure(t, 0, 0)), continue;
2.2. If (RightConfigure(t, 0, 0)), continue;
2.3. Expand(t);
3. Configure all the edges that are not configured yet as open;
bool LeftConfigure(productterm t, int x, int y)
1. If n(x,y).left is inconsistent to the y
th bit in t, return 0;
2. If n(xâˆ’1,y+1) is a merging node and there is more than one path
from n(xâˆ’1,y+1), return 0;
3. If the configuration of n(x,y).left will make the left edge of n(x,y)
and the right edge of n(xâˆ’2,y) could be conducting simultane-
ously, return 0;
4. If n(x,y).left is empty, configure it based on the mapping rules;
5. If (xâˆ’ 1 < 0)
5.1. If (RightConfigure(t, xâˆ’ 1, y + 1)), return 1;
5.2. If (LeftConfigure(t, xâˆ’ 1, y + 1)), return 1;
6. If (xâˆ’ 1 â‰¥ 0)
6.1. If (LeftConfigure(t, xâˆ’ 1, y + 1)), return 1;
6.2. If (RightConfigure(t, xâˆ’ 1, y + 1)), return 1;
7. Undo n(x,y).left if necessary, and return 0;
bool RightConfigure(productterm t, int x, int y)
1. If n(x,y).right is inconsistent to the y
th bit in t, return 0;
2. If n(x+1,y+1) is a merging node and there is more than one path
from n(x+1,y+1), return 0;
3. If the configuration of n(x,y).right will make the right edge of
n(x,y) and the left edge of n(x+2,y) could be conducting simul-
taneously, return 0;
4. If n(x,y).right is empty, configure it based on the mapping rules;
5. If (xâˆ’ 1 < 0)
5.1. If (RightConfigure(t, x + 1, y + 1)), return 1;
5.2. If (LeftConfigure(t, x + 1, y + 1)), return 1;
6. If (xâˆ’ 1 â‰¥ 0)
6.1. If (LeftConfigure(t, x + 1, y + 1)), return 1;
6.2. If (RightConfigure(t, x + 1, y + 1)), return 1;
7. Undo n(x,y).right if necessary, and return 0;
bool Expand(productterm t)
1. Determine the expansion direction (left or right) based on the
first bit in t.
2. If the expansion direction is left, x = âˆ’2; otherwise, x = 2;
3. While(1)
3.1. Configure n(x,0).left and n(x,0).right as short if they are
empty;
3.2. If (xâˆ’ 1 < 0)
3.2.1 If (RightConfigure(t, xâˆ’ 1, 1)), return 1;
3.2.2 If (LeftConfigure(t, xâˆ’ 1, 1)), return 1;
3.2.3 x = xâˆ’ 2;
3.3. If (xâˆ’ 1 â‰¥ 0)
3.3.1 If (LeftConfigure(t, x + 1, 1)), return 1;
3.3.2 If (RightConfigure(t, x + 1, 1)), return 1;
3.3.3 x = x + 2;
Figure 7: The algorithm of product term mapping.
edges at the different rows. For example, Fig. 6(b) shows a par-
tial conducting path that crosses two rows as highlighted. This
path, n(3,3) â†’ n(2,2) â†’ n(1,3) â†’ n(0,4) â†’ n(âˆ’1,3), constructs an
invalid conducting path for the input pattern 11111.
A necessary condition for causing a partial conducting path is
that there exist two pairs of two adjacent conducting edges: one
pair is two lower edges of a diamond that could be conducting si-
multaneously, and the other pair is two upper edges of a diamond
that could be conducting simultaneously. For example, in Fig.
6(a), the right edge of n(âˆ’1,3) and the left edge of n(1,3) are the
former, and the left and right edges of n(1,3) are the latter. One
simple method for avoiding partial conducting paths is to ensure
that one of the mentioned two pairs of two adjacent conducting
edges is never constructed. Thus, if a configuration results in a
merging node, we check if the two edges connecting to the merg-
ing node could be conducting simultaneously. If so, we avoid this
configuration. With this method, we can prevent two lower edges
of a diamond from conducting simultaneously. Fig. 6(c) and Fig.
6(d) show the correct mapping results for the product terms in
Fig. 6(a) and Fig. 6(b), respectively.
Additionally, because the root node has only two edges (left
881
48.3
Table 1: The experimental results of using differ-
ent product term sorting heuristics and mapping con-
straints.
Bench. PI PO PT
Constraint-free Granu. Fabric
Lex Inert. FInert. BFInert. FInert. FInert.
C17 5 2 8 *18 *18 20 20 58 66
cm138a 6 8 48 *116 158 120 120 360 438
x2 10 7 33 *149 152 153 154 725 790
cm85a 11 3 49 219 197 197 *195 608 528
cm151a 12 2 25 406 427 *400 *400 885 1045
cm162a 14 5 37 292 336 294 *287 1077 1163
cu 14 11 24 240 242 *238 *238 609 662
cmb 16 4 26 195 216 *170 *170 710 855
cm163a 16 5 27 275 *257 260 260 907 1029
pm1 16 13 41 337 342 *335 *335 1186 1239
pcle 19 9 45 *291 292 293 293 1553 1775
sct 19 15 142 1890 *1661 1725 1741 4665 5186
cc 21 20 57 618 658 *585 603 2214 2306
i1 25 16 38 632 650 *627 *627 1773 1920
lal 26 19 160 1968 2157 1832 *1799 7838 8684
pcler8 27 17 68 *737 850 *737 *737 3160 3435
frg1 28 3 399 5993 *5602 5612 5612 11029 13731
c8 28 18 94 *836 884 881 894 4663 4869
term1 34 10 1246 23494 25297 *22426 23856 70844 80293
count 35 16 184 1936 1861 *1336 1465 13509 14678
unreg 36 16 64 1288 *1259 1280 1280 4518 4632
b9 41 21 352 *6333 8650 6478 6542 24272 22089
cht 47 36 92 *2380 2390 *2380 *2380 7857 7934
apex7 49 37 1440 36252 44001 *35999 36317 123003 135543
example2 85 66 430 9737 10164 9623 *9494 53597 50471
Total 96632 108721 94001 95819 341620 365361
Best count 8 5 11 11
4.2 Fabric constraint
In SET array implementation, the inputs to the active edges in
a row are supplied by metal wires. We need two wires to supply
both the normal and complement of an input to a row. Each
edge is connected to either x or its complement xâ€² wires for the
row. The pattern of connections of x and xâ€² in a row defines the
SET fabric and it is fixed during manufacturing.
For example, using x to control all left edges and xâ€² to control
the right edges results in the symmetric fabric proposed in [2].
In our mapping tool, we use the symmetric fabric constraint. In
the future, we will extend our mapping tool to accept any fabric
specification.
In such an array, both (high, low) and (low, high) cannot
simultaneously appear at the same row in a SET array. Note
that the entire row pattern of (high, low) (or (low, high)) can be
changed to (low, high) (or (high, low)) by swapping the normal
value and its complement in the control input signals for the row.
To satisfy this symmetric fabric constraint, we need to identify
which combination ((high, low) or (low, high)) appears at a
certain row. One method is to follow the first configuration result
at the row. For example, if (high, low) is first configured at a
row, we then do not configure (low, high) at this row. Another
easy method is to allow only one of (high, low) and (low, high)
to appear in a SET array. For example, for a bit value 1 or 0, we
can always configure the left edge as high and the right edge as
low, i.e., only (high, low) is allowed. For simplification, we use
the second method in this work.
Fig. 9(b) shows the mapping result for the same set of prod-
uct terms in Fig. 5(a) considering the fabric constraint. In this
example, only (high, low), (short, short), and (open, open) are
allowed.
5. EXPERIMENTAL RESULTS
We implemented the algorithm in C language. The experi-
ments were conducted on a 2.67 GHz Linux platform (Red Hat
5.5). The benchmarks are from the MCNC benchmark suite [10].
For each benchmark, we separately map the Boolean function of
each primary output (PO), and measure the total number of con-
figured hexagons and the total CPU time. In the experiments, we
compare different product term sorting heuristics and mapping
constraints.
Table 1 summarizes the experimental results. Column 1 lists
the benchmarks. Except the C17 benchmark, all the benchmarks
have the crossing edge issue in their ROBDDs. Directly mapping
each of these ROBDDs into a SET array could be very diffi-
cult. Columns 2 and 3 list the number of PIs and POs in each
benchmark, respectively. Column 4 lists the number of computed
product terms. The remaining columns list the mapping results
in terms of the number of hexagons by using different sorting
heuristics and constraints. The number marked with â€œ*â€ means
that it is the best result among all sorting heuristics. Columns 5
to 8 are the constraint-free mapping results by using LexSort, In-
ertiaSort, ForInertiaSort, and BackForInertiaSort, respectively.
Columns 9 and 10 are the mapping results of applying the gran-
ularity and fabric constraints by using ForInertiaSort only. This
is because the ForInertiaSort heuristic has better results for con-
sidering all benchmarks or large benchmarks in the experiments.
We omit the results by using the other sorting heuristics due to
page limit.
According to Table 1, there is no a specific sorting heuristic
that completely outperforms the others for all the benchmarks.
By all accounts, ForInertiaSort results in the best mapping for
considering all benchmarks. Additionally, when the constraints
are considered, the number of configured hexagons increases.
This is because the number of edges shared by different paths
decreases. As for the CPU time, the proposed method can map
each benchmark within 1 second except the term1 and apex7
benchmarks that spent approximately 6 seconds.
6. CONCLUSION
In this paper, we propose a product-term-based approach that
can efficiently map a Boolean function into a SET array. It solves
the problem of automatically mapping a BDD into a SET array
that previous works suffer from. The proposed approach sim-
plifies the mapping problem by transforming a BDD into a set
of product terms, and then individually mapping these product
terms. Additionally, four product term sorting heuristics are pro-
posed to enrich the approach. The granularity and fabric con-
straints can also be handled by the proposed approach. The
experimental results show its effectiveness and efficiency of map-
ping a set of MCNC benchmarks. Our automated mapping is a
key enabler for using the promising BDD technology.
7. REFERENCES
[1] R. Bryant, â€œGraph-based Algorithms for Boolean Function
Manipulation,â€ IEEE Trans. Computers, vol. 35, pp. 677-691,
Aug. 1986.
[2] S. Eachempati, V. Saripalli, V. Narayanan, and S. Datta,
â€œReconfigurable Bdd-based Quantum Circuits,â€ in
Proc. Int. Symp. on Nanoscale Architectures, 2008, pp. 61-67.
[3] H. Hasegawa and S. Kasai, â€œHexagonal Binary Decision Diagram
Quantum Logic Circuits Using Schottky In-Plane and Wrap Gate
Control of GaAs and InGaAs Nanowires,â€ Physica E:
Low-dimensional Systems and Nanostructures, vol. 11, pp. 149-154,
Oct. 2001.
[4] S. Kasai, M. Yumoto, and H. Hasegawa, â€œFabrication of GaAs-based
Integrated 2-bit Half and Full Adders by Novel Hexagonal BDD
Quantum Circuit Approach,â€ in Proc. Int. Symp. on Semiconductor
Device Research, 2001, pp. 622-625.
[5] M. Keating, D. Flynn, R. Aitken, A. Gibbons, and K. Shi, Low
Power Methodology Manual: For System-on-Chip Design,
Springer, 2007.
[6] S. W. Keckler, K. Olukotun, and H. P. Hofstee, Multicore
Processors and Systems, Springer, 2009.
[7] C. Piguet, Low-power CMOS Circuits: Technology, Logic Design
and CAD Tools, CRC Press, 2006.
[8] V. Saripalli, L. Liu, S. Datta, and V. Narayanan, â€œEnergy-Delay
Performance of Nanoscale Transistors Exhibiting Single Electron
Behavior and Associated Logic Circuitsâ€, Journal of Low Power
Electronics (JOLPE), vol. 6, pp. 415-428, 2010.
[9] F. Somenzi, CUDD: CU decision diagram package - release 2.4.2,
2009. http://vlsi.colorado.edu/âˆ¼fabio/CUDD/
[10] S. Yang, â€œLogic Synthesis and Optimization Benchmarks, Version
3.0,â€ Tech. Report, Microelectronics Center of North Carolina,
1991.
[11] http://embedded.eecs.berkeley.edu/pubs/downloads/
espresso/index.htm
[12] http://www.intel.com/go/terascale/
883
48.3
åœ‹ç§‘æœƒè£œåŠ©è¨ˆç•«è¡ç”Ÿç ”ç™¼æˆæœæ¨å»£è³‡æ–™è¡¨
æ—¥æœŸ:2011/10/24
åœ‹ç§‘æœƒè£œåŠ©è¨ˆç•«
è¨ˆç•«åç¨±: å­è¨ˆç•«ä¸‰ï¼šç†±èƒ½å°å‘çš„æœ€å¤§åŠŸç‡ä¼°è¨ˆå’Œåˆ†æ(3/3)
è¨ˆç•«ä¸»æŒäºº: ç‹ä¿Šå ¯
è¨ˆç•«ç·¨è™Ÿ: 99-2220-E-007-003- å­¸é–€é ˜åŸŸ: æ™¶ç‰‡ç§‘æŠ€è¨ˆç•«--æ•´åˆå‹å­¸è¡“ç ”ç©¶
è¨ˆç•«
ç„¡ç ”ç™¼æˆæœæ¨å»£è³‡æ–™
å…¶ä»–æˆæœ 
(ç„¡æ³•ä»¥é‡åŒ–è¡¨é”ä¹‹æˆ
æœå¦‚è¾¦ç†å­¸è¡“æ´»å‹•ã€ç²
å¾—çé …ã€é‡è¦åœ‹éš›åˆ
ä½œã€ç ”ç©¶æˆæœåœ‹éš›å½±éŸ¿
åŠ›åŠå…¶ä»–å”åŠ©ç”¢æ¥­æŠ€
è¡“ç™¼å±•ä¹‹å…·é«”æ•ˆç›Šäº‹
é …ç­‰ï¼Œè«‹ä»¥æ–‡å­—æ•˜è¿°å¡«
åˆ—ã€‚) 
ç„¡ 
 æˆæœé …ç›® é‡åŒ– åç¨±æˆ–å…§å®¹æ€§è³ªç°¡è¿° 
æ¸¬é©—å·¥å…·(å«è³ªæ€§èˆ‡é‡æ€§) 0  
èª²ç¨‹/æ¨¡çµ„ 0  
é›»è…¦åŠç¶²è·¯ç³»çµ±æˆ–å·¥å…· 0  
æ•™æ 0  
èˆ‰è¾¦ä¹‹æ´»å‹•/ç«¶è³½ 0  
ç ”è¨æœƒ/å·¥ä½œåŠ 0  
é›»å­å ±ã€ç¶²ç«™ 0  
ç§‘ 
æ•™ 
è™• 
è¨ˆ 
ç•« 
åŠ  
å¡« 
é … 
ç›® è¨ˆç•«æˆæœæ¨å»£ä¹‹åƒèˆ‡ï¼ˆé–±è½ï¼‰äººæ•¸ 0  
 
