i 
 
æ‘˜è¦ 
æœ¬è¨ˆç•«æå‡ºè¼”ä»¥å…ˆé€²ä¸‰ç¶­æ“æŽ§ä¹‹ä¸‰ç¶­æ¨¡åž‹è®Šå½¢æŠ€è¡“ï¼Œé™¤ï¦ºé‡å°è¡¨é¢ç´°å¾®æ§‹é€ 
ä¿ï§ï¼Œä¹Ÿä»¥å‚³çµ±å»ºï§·éª¨æž¶æŠ€è¡“ä½œåŸºç¤Žï¼Œå°æ–¼éª¨æž¶ä½ç½®èˆ‡æ¬Šé‡ï¤­ä½œè®Šå½¢æœ€ä½³åŒ–æ±‚è§£, 
ä»¥ç²å¾—ï§¤æƒ³çµæžœã€‚å…¶ä¸­ï¼Œç‚ºï¦ºæ±‚ï¤è‡ªç„¶çš„è®Šå½¢æ•ˆæžœï¼ŒåŠ ä¸Šï¦ºé«˜éšŽé™åˆ¶ï¼šé‡å¿ƒã€é•·
ï¨ã€é—œç¯€è§’ï¨ã€å‰›é«”å½¢è®Šï¼Œä¸¦æå‡ºæ–°ç©Žçš„ï¤…ï§Šæœ€ä½³æ±‚è§£æ³•ï¼Œé”åˆ°å³æ™‚æ“ç¸±å‘ˆç¾è®Š
å½¢æˆæžœã€‚å…¶æ¬¡, æˆ‘å€‘åŠ å…¥å…ˆé€²ä¸‰ç¶­äººæ©Ÿä»‹é¢æ“æŽ§æŠ€è¡“æœ¬æŠ€è¡“(å¦‚ Wii controller ç­‰), 
ä½¿å¾—å‹•ç•«ä¹‹æ“ä½œç°¡ï¥¥åŠè‡ªç„¶. æœ€å¾Œ, åŠ å…¥ç‰©é«”èˆ‡ç’°å¢ƒäº’å‹•, å¦‚æ°´ä¸­é‹å‹•, ä»¥ï¥¥é”
æˆå¦‚åœ¨æ°´ä¸­æ¸¸æ³³ç­‰æœ‰ï¥¢æ–¼ä¸€èˆ¬ç©ºæ°£ä¸­çš„å‹•ç•«æ•ˆæžœ. é™¤ä¸Šè¿°åŠŸèƒ½å¤–, æœ¬è¨ˆç•«æˆæžœå°š
å¯ä»¥ç™¼æ®åœ¨å¤šæ–¹æ‡‰ç”¨ï¼Œå¦‚æ¨¡åž‹é–“è®Šå½¢è½‰ç§»(deformation transfer)ã€ï¨ˆç‚ºè½‰ç§»(motion 
retargeting)ï¼Œæœªï¤­ç ”ç©¶æˆæžœç›¸ç•¶å¯¦ç”¨ã€‚ 
  
2
iii 
 
æœ¬è¨ˆç•«è¿‘å…©å¹´æ‰€æœ‰ç›¸é—œç™¼è¡¨ä¹‹è«–æ–‡åˆ—è¡¨å¦‚ä¸‹ 
1. é™³æ„·è»’, â€œä»¥å‹•æ„Ÿå¼·åŒ–å™¨æ“ä½œä¹‹ä¸‰ç¶­æ¨¡åž‹å½¢è®Šç³»çµ±â€, åœ‹ï§·è‡ºç£å¤§å­¸ç¢©å£«è«–æ–‡, 
2010 
2. Chen Kai-Hsuan, Cheng Yi-Shan, Ho Shing-Han, Ouhyoung Ming, â€œA Three Di-
mensional Mesh Deformation System Using Wii-MotionPlusâ€, Proceedings of 
ChinaGraph 2010, Nanking, China, October 2010. 
3. Che-Hua Yeh, Yuan-chen Ho, Brian A. Barsky, Ming Ouhyoung, â€œPersonalized 
Photo Ranking and Selection Systemâ€, to appear as a full paper, ACM Multiedia 
2010, Italy, October 2010. 
4. Che-Hua Yeh, Wai-Seng Ng, Brian A. Barsky, Ming Ouhyoung,  â€œAn Esthetics 
Rule Based Ranking System for Amateur Photosâ€, Sketches, ACM SIGGRAPH 
Asia 2009, December, Japan, 2009. 
5. Ken-Yi Lee, Yung-Yu Chuang, Bing-yu Chen, Ming Ouhyoung, â€œVideo Stabiliza-
tion using Robust Feature Trajectoriesâ€, Proceedings of IEEE Conference on 
Computer Vision (ICCV 2009), pp. 1397-1404, September, Kyoto, Japan. 
6. Che-Hua Yeh, Pei-Ruu Shih, Yin-Tzu Lin, Kuan-Ting Liu, Huang-Ming Chang, 
Ming Ouhyoung, â€œA Comparison of Three Methods of Face Recognition for 
Home Photosâ€, poster, ACM SIGGRAPH, New Orleans, August 2009. 
7. Virginia Tzeng, Yu Liang, Yi-Ting Cheng, Yung-Yu Chuang, Bing-Yu Chen, Ming 
Ouhyoung, â€œFace Replacement in Videoâ€, poster, ACM SIGGRAPH, New Or-
leans, August 2009. 
  
4
1 
 
ï¼ˆä¸€ï¼‰ç ”ç©¶è¨ˆç•«ä¹‹èƒŒæ™¯åŠç›®æ¨™ 
1. èƒŒæ™¯ã€å‹•æ©ŸåŠé‡è¦æ€§ 
åœ¨äººæ©Ÿä»‹é¢æ–¹é¢ï¼Œè¿‘å¹´æœ‰ç›¸ç•¶å¤§çš„æŠ€è¡“çªç ´,å¦‚ç†±è³£çš„ Wii éŠæˆ²æ©Ÿçš„ä¸‰ç¶­æ“
æŽ§ï¼Œèˆ‡ Apple iPhone/iTouch ä¹‹ Multi-touch æŠ€è¡“ã€‚å¦å¤–æœ¬äººçš„ä½œå“[11]æ›¾åœ¨åœ‹éš›ä¸€
ï§Šæœƒè­° SIGGRAPH2006â€œEmerging Technologyâ€ç¾å ´å±•ç¤º "Hand Shadow Illu-
sions and 3D DDR Based on Efficient Model Retrieval", video demo (1) 
3D_DDR :http://3d.csie.ntu.edu.tw/s2006etech/ddr.mpg (2) Hand Shadow Illusions: 
http://3d.csie.ntu.edu.tw/s2006etech/shadow.mpg , Boston, July, USA, 2006. (å°ç£çš„
ç¬¬ä¸€æ¬¡åœ¨æ­¤é …ç›®è¢«æŽ¥å—)ã€‚é€™å°è·³èˆžæ©Ÿï¥§ç”¨é™æŽ§å™¨ï¼Œè®“äººç«™åœ¨ç¶²ï¤·æ”å½±æ©Ÿå‰ï¼Œè·Ÿ
è‘—èž¢å¹•å‹•ä½œå…¨èº«èˆžå‹•å³å¯ã€‚é€™å°è·³èˆžæ©Ÿ 2006 å¹´é™¤ç²å¾—ç¾Žåœ‹ Siggraph é‚€è«‹ï¥«å±•ï¼Œ
ç¶²ï¤·è¿´éŸ¿æ¥µç‚ºç†±ï¦Ÿï¼Œ2007 å¹´ï¤ç²æ³•åœ‹ Laval Virtual è™›æ“¬å¯¦å¢ƒæœƒè­°é‚€è«‹ï¥«å±•ã€‚è·³èˆž
æ©ŸæŠ“ä½å½±åƒä¹‹å¾Œï¼Œèƒ½å°‡äººèˆ‡èƒŒæ™¯åˆ†ï§ªï¼Œä¸¦æ¯”å°äººçš„å‹•ä½œæ˜¯å¦æ­£ç¢ºï¼Œæœªï¤­å¯æ‡‰ç”¨åœ¨
æ¨¡åž‹å»ºæ¨¡èˆ‡å‹•ç•«,é†«å­¸ï¥¦å¥ã€èˆžè¹ˆå­¸ç¿’èˆ‡æ¸›è‚¥é‹å‹•ã€‚ 
 
åœ¨æ¨¡åž‹å»ºæ¨¡èˆ‡å‹•ç•«æ–¹é¢ï¼Œä¹‹å‰åœ‹ç§‘æœƒå°ˆé¡Œè¨ˆç•«æœ‰å¯¦ä½œå‡ºä¸€äº›é—œæ–¼è‡‰éƒ¨å»ºæ¨¡èˆ‡
å‹•ç•«çš„æŠ€è¡“ã€‚è‡‰éƒ¨è¡¨æƒ…ä¹‹æ¨¡æ“¬ï¼Œæ‡‰ç”¨å…©é¢é¡å­æ”¾åœ¨äººè‡‰å´é¢ï¼Œç”¨æ”å½±æ©ŸåŒæ™‚æ‹æ”
ä¸‰å€‹å‹•æ…‹ï¥¯è©±çš„ç•«é¢ï¼Œä¸¦å³æ™‚è¿½è¹¤å˜´å”‡åŠè‡‰éƒ¨äº”åå€‹è‡³å…©ç™¾å€‹ç‰¹å¾µé»žï¼Œæ¼”ç®—æ³•ç”¨
åˆ°ï¦ºé¡é¢å…¨å°ç¨±çš„ç‰¹æ€§ï¼Œå°‡ä¸€èˆ¬å…©å€‹æ”å½±æ©Ÿï§‘å€‹è‡ªç”±ï¨çš„æ¼”ç®—æ³•ï¼Œç°¡åŒ–ç‚ºç©ºé–“ä¸­
å¹³é¢æ–¹ç¨‹å¼çš„å››å€‹è‡ªç”±ï¨ï¼Œæ‰€ä»¥ï¤å®¹ï§ æ”¶æ–‚ï¼Œä¸”æº–ç¢ºï¨é«˜å‡ºå‚³çµ±æ–¹æ³•[13, 14]ã€‚
ç„¶å¾Œä»¥ï¤ç©©å®šè€Œå¿«é€Ÿçš„æ–¹æ³•ï¼Œç®—å‡ºè¡¨æƒ…åŠå˜´å”‡åœ¨ä¸‰ç¶­é‹å‹•çš„è»Œè·¡ï¼Œä¸¦åšå‡ºå¹¾å¯ï¤›
çœŸçš„å‹•ç•«ã€‚ä¹‹å¾Œ, åˆç™¼å±•ï¦ºéª¨æž¶çš„è‡ªå‹•ç”¢ç”Ÿæ–¹æ³•[8], èˆ‡å¹¾ç¨®åŸºæ–¼éª¨æž¶è®Šå½¢çš„ç°¡å–®
ç”¢ç”Ÿå‹•ç•«çš„æ–¹æ³•[11]ã€‚é™¤æ­¤ä¹‹å¤–ï¼Œåœ‹å…§æˆå¤§ï§¡åŒï¨—æ•™æŽˆæ›¾æœ‰ï§ç”¨å½¢è®Šç”¢ç”Ÿå‹•ç•«çš„
æ–¹æ³•[6,7]ç™¼è¡¨ï¼Œåœ¨åœ‹å¤–æ–¹é¢ï¤æ˜¯ç†±é–€ç ”ç©¶ä¹‹ä¸€[1,15]ã€‚å› æ­¤ï¼Œçµåˆå…ˆé€²äººæ©Ÿä»‹é¢
èˆ‡æ¨¡åž‹å½¢è®Šå‹•ç•«æŠ€è¡“ï¼Œä¿ƒæˆï¦ºä»¥ä¸‹çš„è¨ˆç•«ã€‚ 
 
2. ç›®æ¨™ 
çµåˆå…ˆé€²äººæ©Ÿä»‹é¢èˆ‡æ¨¡åž‹å½¢è®Šå‹•ç•«æŠ€è¡“, ä¿ƒæˆï¦ºä»¥ä¸‹çš„è¨ˆç•«ï¼Œæˆ‘å€‘çš„ç ”ç©¶ä¸»
è¦æœŸç›¼é”åˆ°çš„ç›®æ¨™å¦‚ä¸‹ï¼š 
1. æ¨¡åž‹è®Šå½¢å¾Œéª¨é ­é•·ï¨çš„ï¥§è®Šã€‚ 
2. æ¨¡åž‹è®Šå½¢å¾Œé—œç¯€è§’ï¨å¯ä»¥æœ‰é™åˆ¶(å¦‚æœ€å¤š 45 ï¨)ã€‚ 
3. æ¨¡åž‹è®Šå½¢å¾Œé‡å¿ƒå¹³è¡¡çš„ä¿æŒã€‚ 
4. ä½¿ç”¨è€…æ“ç¸±ä»‹é¢ï¥¥ï§åŒ–ï¼ŒåŠ å…¥å…ˆé€²ä¸‰ç¶­äººæ©Ÿä»‹é¢æ“æŽ§æŠ€è¡“æœ¬æŠ€è¡“, å¦‚ï¼š
ä»¥ Wii controller ä½œæŽ§åˆ¶ã€‚ 
 
 
6
3 
 
æä¾›çš„æ–¹æ³•ä½œæ‹†è§£ï¼Œæœ€å¾Œå†æ±‚è§£ã€‚å…¶æœ€å¤§çš„ç¼ºé»žåœ¨æ–¼ï¼Œä¸€å€‹ä¸‰ç¶­æ¨¡åž‹å¯
èƒ½åŒ…æ•¸åƒæˆ–æ•¸è¬å€‹é ‚é»žï¼Œå› æ­¤å»ºå‡ºï¤­çš„çŸ©é™£æœƒéžå¸¸çš„å¤§ï¼Œé›–ç„¶é€™å€‹çŸ©é™£
ç›¸ç•¶çš„ç¨€ç–ï¼Œä½† GSL ä¸¦æ²’æœ‰æä¾›å„²å­˜ç¨€ç–çŸ©é™£çš„è³‡æ–™çµæ§‹ï¼Œä¹Ÿä¸¦æ²’æœ‰å°
ç¨€ç–çŸ©é™£çš„é‹ç®—ä½œæœ€ä½³åŒ–ï¼Œå› æ­¤é€Ÿï¨ä¸Šä¸¦ï¥§ï§¤æƒ³ï¼Œå°æ–¼é ‚é»žæ•¸ç›®å¤ªå¤§çš„
æ¨¡åž‹è€Œè¨€ï¼Œå¯èƒ½ä¹Ÿæœƒç™¼ç”ŸçŸ©é™£éŽå¤§è€Œè¨˜æ†¶é«”ï¥§è¶³çš„å•é¡Œï¼ˆå°æ–¼ä¸€å€‹é ‚é»ž
æ•¸ç›®ä¸Šè¬çš„æ¨¡åž‹ï¼Œå…¶çŸ©é™£å¤§å°ä¹Ÿæœƒç‚ºä¸Šè¬ä¹˜ä»¥ä¸Šè¬ï¼‰ã€‚ 
 
(3) Sparse Linear Solver: Taucs 
Taucs æ˜¯ç”¨ C å¯¦åšçš„ sparse linear solverï¼Œæ˜¯ä¸€å€‹é‡å°ç¨€ç–çŸ©é™£æ±‚è§£çš„ç¨‹
å¼åº«ã€‚å’Œ GSL ï¥§åŒçš„æ˜¯ï¼Œå…¶æä¾›ï¦ºä¸€å€‹å°ˆé–€ç”¨æ–¼å„²å­˜ç¨€ç–çŸ©é™£çš„è³‡æ–™çµ
æ§‹ï¼ŒCompressed Column Storage (CCS)ï¼Œä¸¦åœ¨çŸ©é™£æ±‚è§£çš„éŽç¨‹ä¸­ï¼Œé‡å°ç¨€
ç–çŸ©é™£ä½œçŸ©é™£çš„é‡æ–°æŽ’åºï¼Œå°‡å…¶å£“ç¸®åˆ°å¯†ï¨è¼ƒé«˜ä»¥å¾Œï¼Œå†åšçŸ©é™£æ‹†è§£ï¼ˆå…¶
å¯¦åš Cholesky factorizationã€LU factorizationã€multifrontal factorizationã€
left-looking factorization ç­‰å¤šç¨®æ‹†è§£æ–¹æ³•ï¼‰ã€‚ç”¨æ­¤é‡å°ç¨€ç–ç·šæ€§çŸ©é™£æ±‚è§£
çš„ç¨‹å¼åº«ï¤­æ±‚è§£ç¨€ç–çŸ©é™£ï¼Œé€Ÿï¨æ˜Žé¡¯çš„è¼ƒå‰å…©è€…å¿«ä¸Šè¨±å¤šã€‚å¦å¤–ï¼Œä½¿ç”¨
é€™å€‹ç¨‹å¼åº«çš„æ–¹æ³•å¯ä»¥æ˜¯ï¼Œæˆ‘å€‘åœ¨æ‹–å‹•æŸäº›å›ºå®šçš„é»žæ™‚ï¼Œå…ˆå°å…¶çŸ©é™£ä½œ
é‡æ–°æŽ’åºã€æ‹†è§£ï¼Œä»¥å¾Œï¥¥åªï¤æ–°è¢«æ‹–å‹•çš„é»žçš„åº§æ¨™ï¼Œç”¨ back-substitution
æ±‚è§£ï¼Œå¦‚æ­¤ä¸€ï¤­ï¼Œåœ¨å°ä¸€å€‹åŒ…å«æ•¸åƒå€‹é ‚é»žçš„æ¨¡åž‹ï¼Œåœ¨å‰é‹ç®—å®Œæˆå¾Œï¼Œ
æŽ¥è‘—ï¥¥å¯ä»¥é”åˆ°å³æ™‚å½¢è®Šçš„é€Ÿï¨ã€‚ 
 
è§£æ³•é€Ÿï¨æ¯”è¼ƒ 
 
Solver 
ï¥§åŒæ¨¡åž‹çš„æ±‚è§£æ™‚é–“ (å–®ä½ï¼šms) 
é¦¬ (502 å€‹é ‚é»žï¼Œ1000
é¢ä¸‰è§’å½¢) 
æé¾ (7146 å€‹é ‚é»žï¼Œ
14288 é¢ä¸‰è§’å½¢) 
Levmar æ”¶æ–‚èª¤å·®ï¼š1e-2 120~750ï¼Œå¹³å‡ç´„ 437 è¨˜æ†¶é«”ï¥§è¶³ 
æ”¶æ–‚èª¤å·®ï¼š1e-4 650-1050ï¼Œå¹³å‡ç´„ 945 è¨˜æ†¶é«”ï¥§è¶³ 
GSL 2451 è¨˜æ†¶é«”ï¥§è¶³ 
TAUCS 75 2 2654 45 
å¯¦é©—ç’°å¢ƒï¼šIntel Core Duo T2400@1.83GHzï¼Œ3GB RAM 
 
 Levmar æ­¤ç¨‹å¼åº«æŽ¡ç”¨çš„æ˜¯ Levenberg-Marquardt æ­¤éžè¿´æ”¶æ–‚çš„æ¼”ç®—æ³•ï¼Œæ•…å¯
èª¿æ•´å…¶æ”¶æ–‚åœæ­¢æ¢ä»¶ï¤­é”åˆ°ï¥§åŒçš„é€Ÿï¨ã€‚åœ¨ levmar å’Œ GSL æ­¤å…©å€‹ç¨‹å¼åº«ä¸­ï¼Œåœ¨
æé¾çš„å½¢è®Šæ¸¬è©¦ï¼Œéƒ½æœƒè¨˜æ†¶é«”ï¥§è¶³è€Œç„¡æ³•é‹ç®—ã€‚åœ¨ TAUCS ä¸­ï¼Œå› ç‚ºä½¿ç”¨å£“ç¸®æ ¼
å¼å„²å­˜çŸ©é™£ï¼Œæ•…ä¸¦ï¥§æœƒç™¼ç”Ÿè¨˜æ†¶é«”ï¥§è¶³çš„å•é¡Œã€‚å¦å¤–ï¼ŒTAUCS åœ¨åœ–è¡¨ä¸­åˆ†ç‚ºå…©
å€‹ï¥§åŒçš„é‹ç®—æ™‚é–“ï¼Œç¬¬ä¸€æ­¥æ˜¯é‡æ–°æŽ’åºèˆ‡æ‹†è§£çŸ©é™£ï¼Œç¬¬äºŒæ­¥ç‚ºï¤æ–°æ‹–å‹•é»žçš„åº§æ¨™ï¼Œ
ä½œ back-subsititutionã€‚å¦‚åŒå…ˆå‰çš„ä»‹ç´¹ï¼Œåœ¨å›ºå®šèˆ‡æ‹–å‹•çš„é»žï¥§è®Šæ™‚ï¼Œæˆ‘å€‘åªéœ€è¦
ä½œç¬¬äºŒæ­¥çš„é‹ç®—ï¼Œæ•…åœ¨æ•¸åƒå€‹é ‚é»žçš„æ¨¡åž‹é‹ç®—ä¸Šï¼ˆå¦‚æé¾ï¼‰ï¼Œä»ç„¶å¯ä»¥æœ‰æ¯ç§’äºŒ
8
5 
 
 
åœ–äºŒã€ç¬¬ä¸€å¼µç‚º Armadillo åŽŸåœ–ï¼Œå…¶é¤˜ç‚ºè®Šå½¢çµæžœ 
 
 
 
 
10
7 
 
æˆ‘å€‘å°‡æˆ‘å€‘è¨­è¨ˆçš„ Wii æŽ§åˆ¶ä»‹é¢ï¼Œï¤­è®“ä½¿ç”¨è€…è·Ÿæ»‘é¼ æ“ä½œæ–¹å¼ï¤­æ¯”è¼ƒï¼Œè§€å¯Ÿ
ï§ç”¨ Wii æŽ§åˆ¶å™¨ï¤­å° 3D æ¨¡åž‹åšå½¢è®Šæ˜¯å¦èƒ½æ¸›å°‘ä½¿ç”¨è€…æŽ§åˆ¶çš„æ™‚é–“ã€‚å¯¦é©—çµæžœå¦‚
ä¸‹è¡¨ï¼Œå¾žçµæžœæˆ‘å€‘å¯ä»¥çœ‹åˆ°æˆ‘å€‘æå‡ºçš„ç³»çµ±å¯ä»¥è®“ä½¿ç”¨è€…åŠ å¿« 9%~23%çš„é€Ÿï¨ã€‚ 
 
(ä»‹é¢\æŽ§åˆ¶æ™‚é–“) T1 æé¾æ¨¡åž‹ T2 é¦¬åŒ¹æ¨¡åž‹ T3 Armadillo 
æ»‘é¼  28.56 ç§’ 36.75 ç§’ 27.97 ç§’ 
Wii æŽ§åˆ¶å™¨ 21.94 ç§’ 33.28 ç§’ 21.88 ç§’ 
åŠ é€Ÿæ¯”ä¾‹ 23.18 % 9.52 % 21.77 % 
 
ï¼ˆä¸‰ï¼‰çµè«–èˆ‡è¨Žè«– 
åœ¨é€™è¨ˆç•«ä¸­ï¼Œæˆ‘å€‘æå‡ºï¦ºä¸€å€‹å‰µæ–°ä¸”æœ‰æ•ˆçš„ä½¿ç”¨è€…ä»‹é¢ï¤­åŠ é€Ÿä¸‰ç¶­æ¨¡åž‹çš„å½¢
è®Šã€‚åœ¨ä¸‰ç¶­æ¨¡åž‹çš„å½¢è®ŠæŠ€è¡“ä¸Šï¼Œæˆ‘å€‘å·²ç¶“åˆ°é”ï¦ºå³æ™‚çš„é‹ç®—ï¼Œæ­é…ç›´è¦ºæ“ä½œçš„
Wii æŽ§åˆ¶å™¨ï¼Œï¨‰ä½Žï¦ºä½¿ç”¨è€…æ“ä½œå½¢è®Šçš„æ™‚é–“ã€‚é€éŽé€™æ¨£ç›´è¦ºçš„æ“ä½œæ–¹å¼ï¼Œï¤å¯ä»¥
å‰µä½œå‡ºå³æ™‚çš„å‹•ç•«ã€‚ 
ç›¸é—œç™¼è¡¨è«–æ–‡ 
8. é™³æ„·è»’, â€œä»¥å‹•æ„Ÿå¼·åŒ–å™¨æ“ä½œä¹‹ä¸‰ç¶­æ¨¡åž‹å½¢è®Šç³»çµ±â€, åœ‹ï§·è‡ºç£å¤§å­¸ç¢©å£«è«–æ–‡, 
2010 
9. Chen Kai-Hsuan, Cheng Yi-Shan, Ho Shing-Han, Ouhyoung Ming, â€œA Three Di-
mensional Mesh Deformation System Using Wii-MotionPlusâ€, Proceedings of 
ChinaGraph 2010, Nanking, China, October 2010. 
10. Che-Hua Yeh, Yuan-chen Ho, Brian A. Barsky, Ming Ouhyoung, â€œPersonalized 
Photo Ranking and Selection Systemâ€, to appear as a full paper, ACM Multiedia 
2010, Italy, October 2010. 
11. Che-Hua Yeh, Wai-Seng Ng, Brian A. Barsky, Ming Ouhyoung,  â€œAn Esthetics 
Rule Based Ranking System for Amateur Photosâ€, Sketches, ACM SIGGRAPH 
Asia 2009, December, Japan, 2009. 
12. Ken-Yi Lee, Yung-Yu Chuang, Bing-yu Chen, Ming Ouhyoung, â€œVideo Stabiliza-
tion using Robust Feature Trajectoriesâ€, Proceedings of IEEE Conference on 
Computer Vision (ICCV 2009), pp. 1397-1404, September, Kyoto, Japan. 
13. Che-Hua Yeh, Pei-Ruu Shih, Yin-Tzu Lin, Kuan-Ting Liu, Huang-Ming Chang, 
Ming Ouhyoung, â€œA Comparison of Three Methods of Face Recognition for 
Home Photosâ€, poster, ACM SIGGRAPH, New Orleans, August 2009. 
14. Virginia Tzeng, Yu Liang, Yi-Ting Cheng, Yung-Yu Chuang, Bing-Yu Chen, Ming 
Ouhyoung, â€œFace Replacement in Videoâ€, poster, ACM SIGGRAPH, New Or-
leans, August 2009. 
 
12
9 
 
[12] Wan-Chun Ma, Sung-Hsiang Chao, Yung-Yu Chuang, Chun-Fa Chang, Bing-Yu 
Chen, Ming Ouhyoung, Level-of-Detail Representation of Bidirectional Texture 
Functions for Real-Time Rendering, Proc. of ACM Interactive 3D Graphics and 
Games 2005 (I3D05), pp. 187-194, Washington, D.C., USA, 2005. 
[13] I-Chen Lin, Ming Ouhyoung, "Mirror MoCap: Automatic and Efficient Capture 
of Dense 3D Facial Motion Parameters from Video", Vol. 12, No. 6, pp.355-372, 
The Visual Computer, July, 2005 
[14] I-Chen Lin, Jeng-Sheng Yeh, Ming Ouhyoung, "Extracting 3D facial animation 
parameters from multi-view video clips", pp. 72-80, IEEE Computer Graphics 
and Applications, Vol. 22, No. 6 , Nov., 2002. 
[15] Ilya Baran, Jovan Popovici, Automatic Rigging and Animation of 3D Characters, 
ACM SIGGRAPH 2007, ACM Transactions on Graphics (TOG) Volume 26, Is-
sue 3, July 2007.  
 
 
é™„éŒ„ä¸€ã€ChinaGraph 2010 è«–æ–‡å…¨æ–‡ 
14
  
    
 
1   Introduction 
Making a 3D model to deform naturally is essential in 3D animation and modeling, which is important in game 
and movie industry. Traditionally, it's achieved by lots of animators' tweaks. Because this work is time-consuming 
and tedious, we observe that there are two directions that might help to speed up this process. First direction is a 
better user interface, and the second one is the help of high level deformation constraints.  
The present modeling and animation software such as Maya and 3dx Max will control the rotation of a model 
through an arcball interface. Ideally, one should be able to rotate one, two, or three axes simultaneously. By dividing 
the screen into some parts, a user observes a 3D model in different direction in the same time and can use the mouse 
to modify the model in one of the divided screens. Because the mouse is basically a two dimensional device, the 
mapping between a mouse and the three dimensional rotation is a 2D to 3D mapping. Therefore, to avoid this 
constraint, we propose a new user interface that provides a 1-1 mapping of three-axis rotation by exploiting the Wii 
Remote MotionPlus. This interface directly maps the user control to 3D rotation, and that means, the model is 
rotated to the same direction as the Wiimote that a user holds. Moreover, translation can able be controlled 
simultaneously during the three-axis rotation by our interface, which is difficult for the traditional mouse and 
keyboard interface.  
Wiimote, abbreviated from Wii Remote, was released by Nintendo in the end of 2006. This controller contains 
a three-axis accelerator that can sense the acceleration in three axes. Its drawback is that it can't sense the uniform 
motion without acceleration, hence we can't properly detect the real 3D direction of Wiimote. Recently, Nintendo 
released the extension of Wiimote, Wii MotionPlus. Wii MotionPlus contains a gyroscope. By connecting this 
extension to the original Wiimote, we can read the relative rotation of Wiimote, even under the motion of uniform 
speed. After we calibrate it, we can calculate the exact direction of Wiimote relative to original direction, and make 
precise control of three dimensional rotations possible. Therefore, we utilize Wiimote and its extension, Wii 
MotionPlus, to build our user interface.  
Modifying an existing model is much easier than creating a new model, and that's the reason why deformation 
method is worth to research. Many methods have been proposed to deform a 3D model. 
Besides the user interface, we build a 3D mesh deformation system that provides convenient editing operations. 
In the editing process, users usually anticipate a model to deform according to certain physical rules, like preserving 
rigidity and geometric details. In our system, users just need to fix certain vertices in the mesh and dragging other 
vertices in the mesh, and the intermediate parts of the mesh will be deformed automatically based on constraints. 
Our implementation is based on Sorkine et al. [2, 3]. 
There is a standard editing procedure for our system. First, a user have to assign two parts of a model, the fixed 
parts and a moving part, by selecting certain desired vertices. Our system provides a handle of the fixed part, and a 
user can rotate and/or move the handle to drive the moving part. The position of those vertices between the fixed and 
moving parts will be optimized during the editing process by our system.  
As conclusions, we present an interactive deformation system uses high level constraints, including details and 
rigidity constraints to speed up the tedious adjustment of animators, and an intuitive user interface by Wiimote 
MotionPlus. The whole deformation system not only makes the deformation process more intuitive but also reduces 
the time of modifying a model. 
2   Related Work 
In these section, we will discuss the works relate to mesh deformation and user interface respectively. And the 
related literatures of the user interface include two classes of works. First, the works related to Wii Remote. Second, 
16
  
    
 
to control a virtual biped character. A user's movements, include walking, jumping, and running, are mapped to a 
virtual character. This mapping enhances the emergence of users. 
Since traditional interfaces, such as mouse and tablet, are 2D devices, it's a challenge to design a 3D geometric 
modeling and deformation interface. The most common modeling software, like 3ds Max and Maya, still use mouse 
as the controlling device. Some works attempt to achieve 3D modeling conveniently using 2D interface. Teddy 
system [14] is a tablet-based sketching interface for 3D freeform design, and it generates a 3D model that fits 
common people's prediction. Teddy system is enough to design rough models in concept design or playing, but it's 
not adequate to design complex models. FiberMesh system [15] is a system similar to Teddy system, but adding 
more modeling operations. However, a user is not able to design sophisticate models using FiberMesh system. 
2D-sketch-based interfaces [16, 17] are another approach for mesh editing systems. Nealen et al. [12] modifies 
a model by a handle, which is determined by silhouette selection or cropping, or directly drawing on the model 
surface. In [17], users draw a line or curve on a model, where the curve acts like a bone of this mesh, and bending 
this curve will drive the neighboring mesh to deform. Gingold et al. [19] presented a shading-based surface editing 
system that allows a user to modify a shape by changing its rendered image. The 2D user input is translated to 3D 
model transformation. In some modeling cases, this system is easier to achieve the deformation goal than standard 
deformation approaches. 
3   Mesh deformation algorithm 
Our goal of mesh deformation algorithm is to preserve geometric details and rigidity during modeling 
operations, and this algorithm should be fast enough for user to manipulate interactively. This goal is achieved by an 
iterative two-step method based on [2, 3]. Generally speaking, during each deformation, we first compute a rough 
deformation as an initial guess using NaÃ¯ve Laplacian coordinates [2], and iteratively refine it using [3].  
3.1   Initial deformation 
It's fundamental to preserve geometric details during modeling operations, and we achieve this goal by 
converting vertices from absolute coordinates to differential coordinates. Differential coordinates captures the 
relative relation, known as details of mesh, between vertices. Absolute Euclidean coordinates changes during 
transformations, such as translation, rotation and scaling, nevertheless, differential coordinates like Laplacian 
coordinate retains its value during transformations. For free-form deformation, we set an object function that 
penalizes changes of value of Laplacian coordinates in all vertices in the targeting mesh, and finding the best mesh 
after deformation by minimizing this object function. 
The Laplacian representation of a vertex I, wi, is shown as below, and N(i) represent one-ring neighboring 
vertices of vertex i in mesh M. 
    

|	
|

 
 
The transformation from absolute Euclidean coordinates to Laplacian coordinates, a forward transformation, 
can be represented in matrix form,    . I is an identity matrix, D is a diagonal matrix with   |	
|, 
and A is the adjacency matrix of mesh M. If we write all vertices in mesh M in a vector V, we can get   . 
Assume we write all vertices in absolute coordinates in a vector V', we can solve    to get the best position. 
We solve this equation in three dimensions separately.  
18
  
    
 
Fig.3 Pitch, Roll, Yaw rotation 
on Wiimote. These rotations are 
local and used to describe the 
rotation in each single time 
interval. 
the pointer position on the screen, which is often used in game interface and shooting game. 
 Wii accelerator device provides a way to capture acceleration from three 
axes. In most sport games the accelerator captures the strength of userâ€™s action, 
like striking the balls, and simulating the action in the game. In most games it 
seems to work well, but actually the precise orientation is still missing; it works 
whether we strike the ball by waving from the right to the left or from the top to 
the bottom. The accelerator is good when asking for the strength of the motion 
only, but bad in detecting the accurate motion of the Wiimote controller. 
In 2009 Nintendo announced Wii-MotionPlus. The MotionPlus device 
contains a small gyroscope, which is often placed on ships to maintain the 
orientation. A mechanical gyroscope is essentially a spinning wheel or disk whose 
axis is free to take any orientation. MotionPlus takes advantage of the function and helps us to detect the precise 
motion of Wiimote in any orientation.   
 For the Wiimote controller local rotation, Pitch is the rotation by X 
axis, Roll is by Y axis, and Yaw is the rotation by Z axis. The following X, 
Y, Z axes are relative and local coordinate of Wiimote itself, so it is more 
precise to describe them as Pitch, Roll and Yaw.  
The main feature of Wii-MotionPlus is that it returns the local 
changing amount of Pitch, Roll, and Yaw at every single time interval, but not the global angle of rotation. Namely 
we have to accumulatively sum the values to guess the global 3D rotation. This property may trigger some 
accumulation error, and certain calibration method must be involved. 
Initialization: 
At the beginning we must correct errors from tiny vibration. Even if we put the controller on the table, the 
small signal errors may still sum up to a visible amount. When initializing, we choose the average value in 300 clock 
time to be the base value, and every forward movement value will be normalized by the base value. In some new 
Wii-Motion-Plus- based games announced by Nintendo, the players also need to calibrate the controller by holding 
it statically for a moment to ensure the quality of the game. 
Getting Wiimote Orientation by MotionPlus: 
 After initialization we can start summing the angular momentum of Pitch, Roll and Yaw. It is a problem to 
directly map the Pitch, Roll and Yaw to three axes rotation. The x-y-z coordinates system acts globally but the 
roll-pitch-yaw coordinates are local; in addition, some coordinate transformation problem and 3D rotation problem 
exists. We have to map the local rotation to global x-y-z rotation. To avoid coordinate transforming problem, we 
have to rotate the coordinate base on Pitch-Roll -Yaw angle for every single movement. 
 Although at the beginning we calibrate the controller and get average error when it is placed at static place, 
there are still small errors exist due to the unstable signal. It will cause an obvious drift in the long run. We need a 
threshold to filter the small movement to avoid the drift, but in this way some tiny movement may go undetected - 
such as the moment wii-controller starts to accelerate or slow down, and therefore accuracy goes down after a period 
of time. There is no effective way to ignore tiny signal errors when silence and keep those tiny movements when 
moving as while, and the situation will get even worse in accumulative system. One Solution is to do calibration 
frequently, like in certain Wii games the players have to re-calibrate the controller orientation in every round. Our 
solution is to re-calibrate the Wiimote controller by its own accelerators. 
20
  
    
 
the result of the â€œfaceâ€ vector, rotate 90 degree along the â€œrightâ€ vector (like elevate the vector), and finally rotate 
along the rolling angle around face direction. The rolling angle can be obtained from the ratio of Gx and Gz. 
Knowing that the =1* @ =>* value will be a constant when rolling, we can compute local rolling angle: 
 
      A"$0 !
B1 B2 B>  
1 2 >! 0#0"C4D#! B9
2 1 4 
       779:#9:7"   ;9<.
 EF|
EFEG|  
      

B1 B2 B>  
B1 B2 B> 0#0" 779:#9:7"#! B9
1 2 > 
 
 At last, we use the â€œfaceâ€ vector and â€œupâ€ vector to get the â€œRightâ€ vector.  
 
      
!1H !2H !>H   
B1H B2H B>H! 0#0"C4D#! B9
1 2 > 
 
 Now we know the face, up and right vectors of the controller by MotionPlus and Accelerator. At the initial 
calibration, the controller is placed flat toward the screen; that is, the face vector, the up vector and the right vector 
are (0,1,0), (0,0,1) and (1,0,0). We can then form a rotation matrix between the old and the new vectors: 
 
      
3/|A|56   3/|A|5 
      6  3/|A|5<.3/|A|5 
 
 Hence we get re-estimate new rotation matrix Mâ€™. 
 Self Calibration method can solve the drifting problem, but two issues must be considered: first, calibration 
can correct the drift error only in two axes, while the drifting on x-y plane cannot be solved. Second, the accelerator 
detects pure gravity when static but heavy pulses when waving the controller. The self calibration algorithm only 
works when computing mere gravity, and therefore it fails when the user is waving the controller. Consequently, in 
our work we only do self calibration when user stops waving the controller. 
 Besides the method that is mentioned above, we find that the accumulation error can be avoided by the 
operation design of our system. In our experiment, we find that users usually rotate the model no more than fifteen 
seconds. Therefore we decide to design in a press-and-rotate operation manner. The user can rotate the model by 
pressing a special button on the Wiimote, and stop the rotation by releasing it. Every period of rotation isnâ€™t long 
enough to cause serious error accumulation. 
5   Experiment and Result 
With the above deformation system which uses Wii Remote and MotionPlus as the user interface, we 
conducted three experiments to demonstrate the advantages of our interface over the mouse. 
We found ten users to participate our experiments as subjects, and designing three deformation tasks for 
subjects to complete. All of the tasks involved both translation and rotation operations. Before the experiment, we 
would take fifteen minutes to train the subject to be familiar with these two interfaces, and let them to exercise for a 
simple task. Then the subject was requested to complete these three tasks with traditional mouse interface and Wii 
MotionPlus interface, respectively. The completion time in seconds for each task was recorded, as shown in Table 1. 
 
 Task 1: Dinosaur Task 2: Horse Task 3: Armadillo 
22
  
    
 
Our deformation algorithm is a cell-based iterative algorithm. At first, we will compute an initial guess using 
the naive Laplacian algorithm. Based on the initial guess, we compute the local rotations relative to the original 
mesh of each cell, and optimizing the mesh using these local rotations.  The two-step computation is kept going 
until convergence, which is usually less than three iterations. Although the cells in this algorithm are surface-based, 
the experiment result is visually convincing. 
In conclusion, our deformation system provides an innovative user interface. We integrate the Nintendo Wii 
Remote MotionPlus to our system for 3D rotation manipulation that is 1-1 mapping. In the inner deformation loop, 
we adopt an algorithm that preserves rigidity during mesh deformations. And the high level rigidity constraint helps 
users to achieve the desired results easier and more efficiently. 
 In the future, we wish to adopt an algorithm that provides different levels of rigidity. In the user interface, we 
believe that the multi-touch technique is another possible option which is appropriate for common users, especially 
for children to have fun playing with. 
References:  
[1]   Sorkine O, Cohen-Or D, Lipman Y, Alexa M. Laplacian Surface Editing. ACM International Conference Proceeding Series Vol. 71, 
2004. 
[2]   Alexa M. Differential coordinates for local mesh morphing and deformation. The Visual Computer, 2003 â€“ Spring. 
[3]   Sorkine O, Alexa M. As-Rigid-As-Possible Surface Modeling. ACM International Conference Proceeding Series, Vol. 257, 2007. 
[4]   Lipman Y, Sorkine O, Levin D and Cohen-Or D. Linear rotation-invariant coordinates for meshes. ACM SIGGRAPH 2005.  
[5]   Botsch M, Kobbelt L. An intuitive framework for real-time freeform modeling. ACM SIGGRAPH, 2004. 
[6]   Yu Y, Zhou K, Xu D, Shi X, Bao H, Guo B, Shum HY. Mesh editing with poisson-based gradient field manipulation.ACM 
SIGGRAPH 2004. 
[7]   Toledo S, Chen D, Rotkin V. TAUCS: a Library of Sparse Linear Solvers. Tel Aviv University, 2003. 
[8]   Botsch M, Pauly M, Gross M, Kobbelt L. PriMo: coupled prisms for intuitive surface modeling. ACM International Conference 
Proceeding Series; Vol. 256, 2006. 
[9]   Shi X, Zhou K, Tong Y, Desbrun M, Bao H, Guo B. Mesh puppetry: cascading optimization of mesh deformation with inverse 
kinematics. ACM SIGGRAPH, 2007. 
[10]   SchlÃ¶mer T, Poppinga B, Henze N, Boll S. Gesture recognition with a Wii controller. Tangible and embedded interaction, 2008. 
[11]   3D input for 3D worlds, Sreedharan S, Zurita ES, Plimmer B. OZCHI, Vol. 251, Proceedings of the 19th Australasian conference on 
Computer-Human Interaction: Entertaining User Interfaces, 2007. 
[12]   Schou T, Gardner HJ. A Wii Remote, a game engine, five sensor bars and a virtual reality theatre. OZCHI, Vol. 251, Proceedings of 
the 19th Australasian conference on Computer-Human Interaction: Entertaining User Interfaces, 2007.  
[13]   Takaaki S, Jessica KH. Accelerometer-based user interfaces for the control of a physically simulated character. ACM Transactions 
on Graphics, 2008 
[14]   Igarashi T, Matsuoka S, Tanaka H. Teddy: a sketching interface for 3D freeform design. ACM SIGGRAPH, 2007. 
[15]   Nealen A, Igarashi T, Sorkine O, Alexa M. FiberMesh: designing freeform surfaces with 3D curves. ACM Transactions on 
Graphics, 2007. 
[16]   Botsch M, Pauly M, Gross M, Kobbelt L. A sketch-based interface for detail-preserving mesh editing. ACM International 
Conference Proceeding Series; Vol. 256, 2006. 
[17]   Kho Y, Garland M. Sketching mesh deformations. ACM SIGGRAPH, 2007. 
[18]   Gingold Y, Zorin, D. Shading-based surface editing, ACM Transactions on Graphics, 2008. 
 
24
 å‰   è¨€ 
 
ACM SIGGRAPH åœ‹éš›æœƒè­°ç‚ºå…¨ä¸–ç•Œé›»è…¦åœ–å­¸ç”šè‡³æ˜¯åŒ…å«äº†æ‰€æœ‰åœ–åƒæ–¹é¢ç ”ç©¶
é ˜åŸŸçš„æœ€é‡è¦ä¸”æœ€é ‚ç´šçš„åœ‹éš›æœƒè­°ï¼Œé™¤äº†å¾žäº‹é›»è…¦åœ–å­¸é ˜åŸŸçš„ç ”ç©¶äººå“¡å¤–ï¼Œé—œæ–¼
åœ–åƒæ–¹é¢çš„ç ”ç©¶äººå“¡ï¼Œå¦‚é›»è…¦è¦–è¦ºã€å½±åƒè™•ç†ã€äººæ©Ÿäº’å‹•ç­‰äº¦ååˆ†é‡è¦–æ­¤ä¸€åœ‹éš›
æœƒè­°ç”šè‡³å°‡å…¶åˆ—ç‚ºé‡è¦æŒ‡æ¨™ä¹‹ä¸€ã€‚ç”±æ–¼è¿‘å¹´äºžæ´²åœ°å€çš„ç ”ç©¶é¢¨æ°£æ—¥æ¼¸èˆˆç››ï¼Œäºžæ´²
åœ°å€æ‰€ç™¼è¡¨çš„è«–æ–‡å“è³ªèˆ‡æ•¸é‡äº¦æ—¥æ¼¸æå‡ï¼Œå› æ­¤ï¼ŒACM SIGGRAPH å”æœƒæ±ºå®šæ–¼
åŽ»ï¼ˆ2008ï¼‰å¹´èµ·ï¼Œé™¤æ¯å¹´å¤å¤©æ–¼åŒ—ç¾Žæ´²åœ°å€èˆ‰è¾¦çš„ ACM SIGGRAPH åœ‹éš›æœƒè­°å¤–ï¼Œ
æ¯å¹´å¹´åº•äº¦æ–¼äºžæ´²åœ°å€èˆ‰è¾¦ ACM SIGGRAPH Asia åœ‹éš›æœƒè­°ï¼ŒåŽ»å¹´å‰‡æ˜¯é¦–æ¬¡èˆ‰
è¡Œï¼Œæœƒè­°åœ°é»žç‚ºæ–°åŠ å¡ï¼Œä»Šï¼ˆ2009ï¼‰å¹´çš„æœƒè­°åœ°é»žå‰‡æ˜¯æ—¥æœ¬æ©«æ¿±ï¼Œå¾€å¾Œå°‡å®šæœŸæ–¼
äºžæ´²èˆ‰è¾¦ï¼Œæ˜Žï¼ˆ2010ï¼‰å¹´çš„æœƒè­°åœ°é»žç‚ºéŸ“åœ‹é¦–çˆ¾ï¼Œå¾Œï¼ˆ2011ï¼‰å¹´å‰‡æš«å®šæ–¼ä¸­åœ‹é¦™
æ¸¯ï¼Œå…¶å¯©ç¨¿ç¨‹åºå®Œå…¨æ¯”ç…§ ACM SIGGRAPH åœ‹éš›æœƒè­°ï¼Œç›´æŽ¥åˆŠç™»æ–¼é ‚å°–æœŸåˆŠ ACM 
Transactions on Graphicsï¼ˆSCI impact factor = 3.413ï¼Œranking = 1/84ï¼‰ã€‚å› æ­¤ï¼Œå·²
ååˆ—é ‚å°–åœ‹éš›æœƒè­°ä¹‹ä¸€ã€‚ 
ç‚ºé…åˆæœ¬æ ¡é‚å‘é ‚å°–å¤§å­¸è¨ˆç•«ã€ææ˜‡åœ‹éš›ç«¶çˆ­åŠ›ã€å¢žé€²åœ‹éš›èƒ½è¦‹åº¦ï¼Œå€¼æ­¤è¦‹è­‰äºž
æ´²å´›èµ·çš„é‡å¤§äº‹ä»¶ï¼Œæœ¬å­¸ç¾¤äº¦ç”±å¾žäº‹é›»è…¦åœ–å­¸é ˜åŸŸçš„å…©ä½ç ”ç©¶äººå“¡ä»£è¡¨ï¼Œå¸¶é ˜è‘—
ç¢©ã€åšå£«ç­çš„åŒå­¸å€‘å…±åŒçµ„åœ˜å‰å¾€è§€æ‘©ï¼Œä¸¦çž­è§£èˆ‡å¾µè©¢æœªä¾†æ‰¿è¾¦æ­¤ä¸€åœ‹éš›æœƒè­°ä¹‹
å¯è¡Œæ€§ã€‚æ­¤å¤–ï¼Œæœ¬å­¸ç¾¤æ­é™½æ˜Žæ•™æŽˆç‚ºæ­¤æœƒè­°ä¹‹ç‡Ÿé‹å§”å“¡ï¼ˆSteering Committeeï¼‰ï¼Œ
é™³ç‚³å®‡å‰¯æ•™æŽˆåŠèŽŠæ°¸è£•å‰¯æ•™æŽˆäº¦ç²é‚€æ“”ä»»æ­¤æœƒè­°ä¹‹æŠ€è¡“è«–æ–‡å§”å“¡ï¼ˆTechnical 
Papers Committeeï¼‰ï¼Œé™³ç‚³å®‡å‰¯æ•™æŽˆäº¦å¦å¤–æ“”ä»»æ­¤æœƒè­°ä¹‹é€Ÿå¯«åŠæµ·å ±è«–æ–‡å§”å“¡
ï¼ˆSketches and Posters Committeeï¼‰ä¸”äº¦æ“”ä»»å…©å ´è«–æ–‡ä¸»æŒäººï¼ˆSession Chairï¼‰ï¼Œ
å› æ­¤ï¼Œåœ¨åƒåŠ æ­¤ä¸€åœ‹éš›æœƒè­°æ™‚ï¼Œäº¦åˆ†åˆ¥è‚©è² äº†ä¸åŒçš„ä»»å‹™ï¼Œä¸”å› æ­¤äº¦æ›´èƒ½æ·±å…¥æ­¤
åœ‹éš›æœƒè­°ä¹‹æ ¸å¿ƒï¼ŒæŽŒæ¡æ‰¿è¾¦æ­¤ä¸€åœ‹éš›æœƒè­°ä¹‹å¯è¡Œæ€§ã€‚æ­¤å¤–ï¼Œæœ¬æ ¡ä»Šå¹´äº¦æœ‰å…©ç¯‡è«–
æ–‡åŠä¸€é …äº’å‹•è£ç½®å°‡æ–¼æ­¤åœ‹éš›æœƒè­°ä¸­ç™¼è¡¨åŠå±•ç¤ºã€‚ 
ä»Šå¹´çµ„åœ˜å‰å¾€åƒåŠ  ACM SIGGRAPH Asia åœ‹éš›æœƒè­°çš„ç ”ç©¶åœ˜éšŠï¼Œé™¤äº†æˆ‘å€‘ä»£è¡¨
æœ¬æ ¡åƒåŠ ä¹‹å¤–ï¼ŒæˆåŠŸå¤§å­¸æŽåŒç›Šæ•™æŽˆäº¦çŽ‡é ˜å››ååšå£«ç­å­¸ç”Ÿå‰å¾€ï¼Œäº¤é€šå¤§å­¸èŽŠæ¦®
å®æ•™æŽˆèˆ‡æž—æ–‡æ°æ•™æŽˆç­‰äººäº¦å…±åŒèˆ‡æœƒã€‚ 
ç”±æ–¼æ­¤æ¬¡çµ„åœ˜å‰å¾€åƒåŠ  ACM SIGGRAPH Asia åœ‹éš›æœƒè­°çš„ç›®çš„ä¹‹ä¸€ä¹ƒç‚ºçž­è§£èˆ‡
å¾µè©¢æœªä¾†æ‰¿è¾¦æ­¤ä¸€åœ‹éš›æœƒè­°ä¹‹å¯è¡Œæ€§ã€‚å…¶ä¸­ï¼Œå¤§éƒ¨åˆ†ä¸»å°Ž ACM SIGGRAPH Asia
åœ‹éš›æœƒè­°äººå£«å‡ååˆ†æœŸå¾…æŸä¸€å¹´å¯ä»¥ç§»å¸«å°åŒ—èˆ‰è¾¦æ­¤ä¸€ç››æœƒï¼Œè€Œä¸»è¾¦æ­¤ä¸€æœƒè­°æ™‚
ACM SIGGRAPH ç¸½æœƒä¼¼ä¹Žæœƒè² è²¬å¤§éƒ¨ä»½çš„ç±Œå‚™å·¥ä½œï¼Œç•¶åœ°çš„æ‰¿è¾¦å–®ä½ä¼¼ä¹Žå·¥ä½œ
é‡ä¸¦ä¸æ˜¯é‚£éº¼çš„å¤§ï¼Œä¹Ÿå› æ­¤ï¼Œæ›´å¢žå¼·äº†ä¸€äº›æˆ‘å€‘æ‰¿è¾¦æ­¤ä¸€åœ‹éš›æœƒè­°ä¹‹ä¿¡å¿ƒã€‚ 
ACM SIGGRAPH åœ‹éš›æœƒè­°èˆ‡ ACM SIGGRAPH Asia åœ‹éš›æœƒè­°é™¤äº†ä¸€èˆ¬çš„è«–æ–‡
ï¼ˆTechnical Papersï¼‰ç™¼è¡¨ä¹‹å¤–ï¼Œæ›´æœ‰è¨±å¤šæ–°å¥‡æœ‰è¶£çš„å­¸è¡“æ´»å‹•ï¼Œå¦‚æ¯å¹´ ACM 
SIGGRAPH åœ‹éš›æœƒè­°çš„ Art Gallery ä»¥åŠ Emerging Technology éƒ½æœƒå¸¶ä¾†è¨±å¤šå‰µ
æ„ï¼Œé€™äº›å‰µæ„éƒ½è®“äººçœ¼ç›ç‚ºä¹‹ä¸€äº®ã€‚å°æ–¼é€™äº›è·³è„«æ¡†æž¶çš„å‰µæ„æ­£æ˜¯æˆ‘å€‘ç ”ç©¶ä¸Šé¢
æ‰€éœ€è¦çš„ â€” ç”¨ä¸åŒçš„è§’åº¦ä¾†æ€è€ƒäº‹æƒ…ã€‚ 
 
 Webcam Clip Art: Appearance and Illuminant Transfer from Time-lapse 
Sequences 
 
  
é€™ç¯‡è«–æ–‡æƒ³åšçš„æ˜¯è®“è¢« webcam ç…§ä¸‹ä¾†çš„ä¸€é€£ä¸²å ´æ™¯ï¼Œå½¢æˆä¸€å€‹å¤§åž‹è³‡æ–™åº«ï¼ŒæŽ¥
è‘—ä½¿ç”¨è€…å¯ä»¥åˆ©ç”¨é€™äº›ç•¶åšå…¶ä»–æ•¸ä½å…§å®¹çš„è³‡æºã€‚æ‰€ä»¥ä»–å€‘çš„ä¸»è¦ä¸‰å€‹è²¢ç»ï¼Œ1.
ä¸€å€‹é«˜å“è³ªçš„æˆ¶å¤–å ´æ™¯è³‡æ–™åº«ã€‚2. åœ¨ä¸åŒå ´æ™¯ï¼Œä¸åŒå…‰ç…§ä¹‹é–“çš„å…‰å½±è½‰æ›ã€‚3. æ
ä¾› HDR å½±åƒç”Ÿæˆçš„æ–°æ¼”ç®—æ³•ã€‚ 
 
 
 
Optimized Image Resizing Using Seam Carving and Scaling 
 
 
 
é€™ç¯‡è«–æ–‡è¦è§£æ±ºçš„æ˜¯ç•¶æˆ‘å€‘ resize å½±åƒæ™‚ï¼Œå› ç‚ºåœ¨é•·å¯¬ä¸åŒæ¯”ä¾‹çš„æ”¾å¤§æˆ–ç¸®å°æ™‚
æ‰€é€ æˆå…§å®¹çš„æ¯”ä¾‹è®Šå½¢å•é¡Œï¼Œå¾ž 2007 çš„ seam carving æå‡ºä¹‹å¾Œå°±æœ‰é™¸çºŒè¨±å¤šç›¸
é—œçš„ paperã€‚é€™ç¯‡çš„åšæ³•å°±æ˜¯åˆ©ç”¨ seam carving æŠ€è¡“åŠ ä¸Šå½±åƒçš„ scalingï¼Œåˆ©ç”¨ä»–
å€‘å®šç¾©å‡ºä¾†çš„ distance functionï¼Œæ‰¾åˆ°ä¸€çµ„æœ€å¥½çš„ seam carving å’Œ scaling åƒæ•¸ï¼Œ
ä»¥é”åˆ° content-aware çš„ resizingã€‚ç”±ä»–å€‘çš„çµæžœçœ‹ä¾†æ•ˆæžœçš„ç¢ºä¸éŒ¯ï¼Œä¸éŽç¼ºé»žå°±
æ˜¯ç„¡æ³•é”åˆ° real time çš„ resizingã€‚ 
 Interactive Reflection Editing 
 
 
 
é€™ç¯‡è«–æ–‡æŽ¢è¨Žçš„å•é¡Œå°±æ˜¯å¦‚ä½•æœ‰æ•ˆçš„æ”¹è®Šå ´æ™¯ï¼Œå°¤å…¶æ˜¯æ”¹è®Šç‰©ç†æ¨¡æ“¬å‡ºä¾†çš„çµ
æžœã€‚ä¸€èˆ¬åšå…‰å½±æ¨¡æ“¬éƒ½æœƒåˆ©ç”¨ç‰©ç†æ–¹å¼ä¾†é”æˆï¼Œå¯æ˜¯æœ‰æ™‚è—è¡“å®¶ä¸æƒ³è¦å–®ç´”çš„ç‰©
ç†æ•ˆæžœæ™‚æœƒéœ€è¦å‹•æ‰‹æ”¹è®Šï¼Œé€™ç¯‡è«–æ–‡æä¾›äº†ä¸€å€‹å³æ™‚æœ‰æ•ˆçš„äº’å‹•å¼ç·¨è¼¯å…§å®¹å·¥
å…·ï¼Œä¾†æä¾›å¿«é€Ÿç”¢ç”Ÿæ•¸ä½å…§å®¹ã€‚ 
 
 
3D Polyomino Puzzle 
 
 
 
é€™ç¯‡è«–æ–‡æƒ³ç ”ç©¶çš„é¡Œç›®æ˜¯å¦‚ä½•åˆ©ç”¨é›»è…¦ä¾†å¹«å¿™è¨­è¨ˆ 3D ç©æœ¨éŠæˆ²ã€‚ä»–å€‘çš„æ–¹æ³•æ˜¯
å…ˆåˆ©ç”¨ç©æœ¨çš„åŽŸåž‹å°‡è¡¨é¢åˆ†å¥½ï¼Œä¹‹å¾Œæ‰¾å‡ºè¡¨é¢å’Œç‰©é«”ä¸­å¿ƒçš„å·®è·æ®µï¼Œä¹‹å¾Œåˆ©ç”¨ç©
æœ¨ä¾†çµ„åˆå‡ºé€™æ®µå·®è·ã€‚é€™ä¸­é–“å¯èƒ½é‡åˆ°çš„å•é¡ŒåŒ…æ‹¬åœ¨åœ“å½¢éƒ¨åˆ†å¯èƒ½æœƒæœ‰ä¸ç¢ºå®šçš„
ç‹€æ³ç”¢ç”Ÿï¼Œä»¥åŠå¦‚ä½•å°‡é€™äº›ç©æœ¨ç‰¢å›ºçš„çµ„åˆåœ¨ä¸€èµ·ï¼Œä»–å€‘æå‡ºäº†ç›¸é—œçš„è§£æ³•ã€‚ 
ç´¹å‹•ç•«è£¡ç”¨åˆ°â€Dutch Cameraâ€çš„æ‰‹æ³•ï¼ŒåŒæ¨£çš„å ´æ™¯é‡è¤‡çš„å‡ºç¾ç¢ºæœ‰ä¸åŒçš„æ„ç¾©ã€‚ 
å…‰ç·šæ•ˆæžœ(Lighting)å‰‡æ˜¯ä»‹ç´¹å ´æ™¯çš„æ‰“å…‰ï¼Œåœ¨ä¸åŒçš„æ‰“å…‰ä¸‹æœƒç”¢ç”Ÿå‡ºä¸åŒçš„æ•ˆæžœã€‚
ä¸»è¦è¬›è§£çš„ä¸»é¡Œæœ‰ã€ŒUP è¦–è¦ºä¸Šçš„å®£è¨€(UP Look Manifesto)ã€ã€ã€Œç®åˆ¶(Clamping)ã€ã€ã€Œå…·
æ–¹å‘æ€§çš„é™°å½±(Directable Shadows)ã€ã€ã€Œé¸æ“‡æ€§çš„ç´°ç¯€(Selective Details)ã€ã€ã€ŒèƒŒæ™¯è¤‡
é›œæ€§(Background Complexity)ã€ã€ã€Œç‰©é«”çš„ç‰¹æ®Šæ‰“å…‰(Object Specific Lighting)ã€ã€ã€Œç´”
å‰ªå½± (Pure Silhouettes)ã€ã€‚èª²ç¨‹è£¡é ­æåŠæ¨¡åž‹ (Model)ã€å…‰ç·š (Light)åŠè¤‡é›œåº¦
(Complexity)çš„æŽ§åˆ¶ï¼Œä»¥åŠå‹•ç•«è£¡æŽ¡ç”¨å¾—æ‰“å…‰é¢¨æ ¼â€”ã€Œå–®ä¸€æˆ²åŠ‡æ•ˆæžœ(Theatrical 
Simplexity)ã€ï¼Œå±•ç¾åœ¨é¡è‰²(color)ã€å½©åº¦(value)ã€ç·š(Line)ã€å½¢ç‹€(Shape)ã€è³ªåœ°(Texture)
ç­‰ä¸Šé¢çš„æ•ˆæžœã€‚ 
è§’è‰²è¨­è¨ˆ(Characters)å‰‡æ˜¯ä»‹ç´¹ UP è£¡å››å€‹ä¸»è¦è§’è‰²çš„è¨­è¨ˆç†å¿µï¼Œå› ç‚ºåœ¨ä¸€éƒ¨å¥½çš„
å‹•ç•«è£¡ï¼Œè§’è‰²çš„é®®æ˜Žåº¦æ˜¯ç›¸ç•¶é‡è¦çš„ã€‚ 
æœ€å¾Œçš„å ´æ™¯ç‰¹æ•ˆ(Set)å‰‡æ˜¯è¬›è§£æ•´å€‹å ´æ™¯åœ¨è£½ä½œçš„è¨­è¨ˆæ–¹å¼ï¼Œåˆ†ç‚ºä¸‰å¤§ä¸»è»¸ï¼šã€Œå¤§
å°è¦æ¨¡(Scale)ã€ã€ã€Œå½¢ç‹€(Shape)ã€ã€ã€Œè³ªåœ°(Texture)ã€ã€‚æ¯å€‹ä¸»é¡Œåˆ†ã€Œç´°ç¯€(Detail)ã€ã€ã€Œè‡ª
ç„¶ç·šç´¢(Natural Cues)ã€ã€ã€Œä¸¦åˆ—(Juxtaposition)ã€ä¸‰å€‹éƒ¨åˆ†èªªæ˜Žã€‚ 
 
èª²ç¨‹éžå¸¸çš„ç´®å¯¦ã€æœ‰è¶£ï¼Œå°æ–¼å‹•ç•«çš„è‡³ä½œè€…è€Œè¨€æ‡‰è©²æœƒæœ‰ç›¸ç•¶çš„å•Ÿç™¼ï¼Œå³ä¾¿ä¸æ˜¯
åšå‹•ç•«çš„è½çœ¾ä¹Ÿæœƒæœ‰ç›¸ç•¶å¤§çš„æ”¶ç©«ã€‚ 
Whatâ€™s Your Story? 
ä»€éº¼æ˜¯ä½ çš„æ•…äº‹ï¼Ÿä½ èƒ½è§£é‡‹å®ƒåœ¨ä¸€
å€‹å¥å­ï¼Ÿå¦‚æžœä¸­å¿ƒæ€æƒ³ä½ çš„é›»å½±ä¸
æ˜¯é‚£éº¼æ¸…æ¥šä½ ï¼Œæ€Žéº¼èƒ½èˆ‡æ‚¨çš„å—
çœ¾ï¼Ÿä½ çš„æ•…äº‹å¯ä»¥é€šéŽã€Œèª°åœ¨ä¹Žã€
çš„æ¸¬è©´å—Žï¼Ÿè€Œä¸”ä½ çŸ¥é“æœ€é‡è¦çš„ä¸
 
åŒé …éŠä¸€èˆ¬å°çš„è£ç½®ã€‚è€Œé€™å€‹è£ç½®æœ‰æŠ•å½±æ©Ÿä»¥åŠæ”ç›¸æ©Ÿï¼Œè—‰ç”±æ”ç›¸æ©Ÿä¾†è¾¨åˆ¥æ‰‹
å‹¢ï¼Œæˆ–æ˜¯è¾¨åˆ¥çœ¼å‰çš„å¯¦é«”ç‰©é«”ï¼Œç„¶å¾Œå°‡è³‡è¨Šæ‰“åœ¨å¯¦é«”ç‰©é«”ä¸Šé¢ã€‚ 
Scope 
 
 
 
Scope é€™å€‹ç ”ç©¶éžå¸¸æœ‰è¶£ï¼Œå®ƒåˆ©ç”¨è¿½è¹¤äººçœ¼çš„è¦–ç·šä¾†é”åˆ°æ“åšè™›æ“¬é¸å–®çš„æ•ˆæžœã€‚
ä½¿ç”¨è€…æœƒé…å¸¶ä¸€å€‹ç°¡å–®çš„å…·æœ‰é¡¯ç¤ºæ•ˆæžœçœ¼é¡ï¼Œè€Œåœ¨çœ¼é¡çš„ä¸Šæ–¹å‰‡æ˜¯æœ‰å°å°çš„æ”ç›¸
æ©Ÿä¾†åµæ¸¬æ¡Œä¸Šçš„ Patternã€‚è—‰ç”±é€™äº›äºŒç¶­çš„ Patternï¼Œå°±å¯ä»¥é¡¯æ˜¯ä¸€äº›è™›æ“¬çš„ 3D
ç‰¹æ•ˆæˆ–æ˜¯ 3D Model åœ¨ç©ºé–“ä¹‹ä¸­ã€‚æ›´æœ‰è¶£çš„æ˜¯ï¼Œé¸æ“‡é€™äº›ç‰¹æ•ˆæˆ–æ˜¯ 3D Model æ™‚ï¼Œ
æ‰€ä½¿ç”¨çš„æ˜¯çœ¼ç›å®šä½çš„æ–¹å¼ï¼Œåªè¦æœæŸä¸€å€‹é¸é …ç›¯ä¹…ä¸€é»žï¼Œå°±æœƒå•Ÿå‹•é‚£å€‹é¸é …çš„
åŠŸèƒ½ã€‚ 
 
 
Kaidan: Japanese Horror Experience in Interactive Mixed Reality 
 
 
 
Kaidan é€™å€‹ç ”ç©¶ä¸»è¦æ˜¯å±•ç¤º Interactive Mixed Reality çš„å¯èƒ½æ€§ã€‚ä»–å€‘åˆ©ç”¨é¬¼å±‹çš„
ç´ æä¾†è®“ä½¿ç”¨è€…é«”é©—è™›æ“¬å¯¦å¢ƒï¼Œä½¿ç”¨è€…åªè¦æˆ´ä¸Šé ­ç›”å¼çš„é¡¯ç¤ºè£ç½®å°±å¯ä»¥åœ¨çœŸå¯¦
çš„ä¸‰ç¶­ç©ºé–“ä¸­é€²è¡Œæ‰“é¬¼çš„è¡Œå‹•ã€‚å…¶æ‰€é«”é©—çš„æ„Ÿå®˜ï¼ŒåŒ…æ‹¬äº†è²éŸ³ã€å½±åƒå›žé¥‹ä¹‹å¤–ï¼Œ
é€£åœ°æ¿éƒ½æœƒéš¨è‘—æƒ…å¢ƒçš„è®ŠåŒ–è€Œéœ‡å‹•ã€‚ 
 
 Tangible 
 
 
 
Tangible æ˜¯ä¸€å€‹å¾ˆæœ‰è¶£çš„ä½œå“ã€‚ä¸»è¦æƒ³è¡¨é”çš„æ¦‚å¿µæ˜¯å¯¦é«”ä¸–ç•Œä¸­çš„ç‰©é«”è·Ÿè™›æ“¬ä¸–
ç•Œä¸­çš„ç‰©é«”çš„äº’å‹•ç‹€æ³ã€‚è€Œè™›æ“¬ä¸–ç•Œä¸­çš„ç‰©é«”å°±æ˜¯ç‰©é«”çš„é™°å½±ã€‚è—‰ç”±é€™äº›é™°å½±çš„
å‹•ç•«ï¼Œä¾†è¡¨ç¾éœæ…‹ç‰©é«”çš„å‹•æ…‹ä¸–ç•Œã€‚ 
 
 
scoreLight 
 
 
scoreLight ä¸»è¦æ˜¯å¸Œæœ›èƒ½å¤ è—‰ç”±åµæ¸¬åˆ°ä½¿ç”¨è€…æ‰€ç¹ªç•«å‡ºä¾†çš„ç·šæ¢ä¾†ç”¢ç”Ÿè²éŸ³ã€‚å…’
æ‰€ç”¢ç”Ÿçš„è²éŸ³æ˜¯è—‰ç”±è¦–è¦ºåŒ–å‡ºä¾†çš„å°é»žé»žä¾†åœç¹žè‘—æ‰€ç¹ªå‡ºä¾†çš„ç·šæ¢è€Œç”¢ç”Ÿè²
éŸ³ã€‚è—‰æ­¤ä¾†é”åˆ°äº’å‹•çš„æ•ˆæžœã€‚ 
 
 
  
 
 
Motion Capture ç³»çµ± 
å¦å¤–ä¸€å€‹ç†±é–€å±•è¦½é …ç›®æ˜¯å‹•æ…‹æ•æ‰ç³»çµ± - motion captureï¼Œå‚³çµ±çš„å‹•æ…‹æ•æ‰ç³»çµ±
éœ€è¦æ”å½±æ©Ÿå’Œä½¿ç”¨è€…èº«ä¸Šè£ä¸Šæ„Ÿæ‡‰å™¨ä¾†å®Œæˆå‹•ä½œæ•æ‰ï¼ŒZeroCSeven ä»–å€‘çš„ç³»çµ±æ
ä¾›äº†å…©ç¨®ä¸åŒçš„è§£æ±ºæ–¹æ¡ˆã€‚ç¬¬ä¸€ç¨®æ˜¯ Xsens MVNï¼Œå¦‚ä¸‹é¢çš„ç…§ç‰‡æ‰€ç¤ºï¼Œä½¿ç”¨è€…ç©¿
ä¸Šç‰¹æ®Šçš„æ„Ÿæ‡‰æœè£å¾Œï¼Œä¾¿å¯ä»¥æ•æ‰åˆ°ä½¿ç”¨è€…çš„å‹•ä½œï¼Œå®Œå…¨ä¸éœ€è¦ç”¨åˆ°æ”å½±æ©Ÿã€‚ 
 
 
97ï¦Žï¨å°ˆé¡Œç ”ç©¶è¨ˆç•«ç ”ç©¶æˆæžœå½™æ•´è¡¨ 
è¨ˆç•«ä¸»æŒäººï¼šæ­é™½æ˜Ž è¨ˆç•«ç·¨è™Ÿï¼š97-2221-E-002-110-MY2 
è¨ˆç•«åç¨±ï¼šä»¥å¤šé‡é™åˆ¶ç‚ºä¸»çš„ç¶²æ ¼å½¢è®Šå‹•ç•«è¼”ä»¥å…ˆé€²ä¹‹ä¸‰ç¶­æ“æŽ§ 
ï¥¾åŒ– 
æˆæžœé …ç›® å¯¦éš›å·²é”æˆ
ï¥©ï¼ˆè¢«æŽ¥å—
æˆ–å·²ç™¼è¡¨ï¼‰
é æœŸç¸½é”æˆ
ï¥©(å«å¯¦éš›å·²
é”æˆï¥©) 
æœ¬è¨ˆç•«å¯¦
éš›è²¢ç»ç™¾
åˆ†æ¯” 
å–®ä½ 
å‚™ è¨» ï¼ˆ è³ª åŒ– ï¥¯
æ˜Žï¼šå¦‚ï¥©å€‹è¨ˆç•«
å…±åŒæˆæžœã€æˆæžœ
ï¦œ ç‚º è©² æœŸ åˆŠ ä¹‹
å° é¢ æ•… äº‹ ...
ç­‰ï¼‰ 
æœŸåˆŠï¥æ–‡ 0 0 100%  
ç ”ç©¶å ±å‘Š/æŠ€è¡“å ±å‘Š 0 0 100%  
ç ”è¨Žæœƒï¥æ–‡ 1 1 100% 
ç¯‡ 
 
ï¥æ–‡è‘—ä½œ 
å°ˆæ›¸ 0 0 100%   
ç”³è«‹ä¸­ä»¶ï¥© 0 0 100%  å°ˆï§ å·²ç²å¾—ä»¶ï¥© 0 0 100% ä»¶  
ä»¶ï¥© 0 0 100% ä»¶  
æŠ€è¡“ç§»è½‰ 
æ¬Šï§ï¤Š 0 0 100% åƒå…ƒ  
ç¢©å£«ç”Ÿ 4 4 100%  
åšå£«ç”Ÿ 0 0 100%  
åšå£«å¾Œç ”ç©¶å“¡ 0 0 100%  
åœ‹å…§ 
ï¥«èˆ‡è¨ˆç•«äººï¦Š 
ï¼ˆæœ¬åœ‹ç±ï¼‰ 
å°ˆä»»åŠ©ï§¤ 0 0 100% 
äººæ¬¡ 
 
æœŸåˆŠï¥æ–‡ 0 0 100%  
ç ”ç©¶å ±å‘Š/æŠ€è¡“å ±å‘Š 0 0 100%  
ç ”è¨Žæœƒï¥æ–‡ 1 1 100% 
ç¯‡ 
 
ï¥æ–‡è‘—ä½œ 
å°ˆæ›¸ 0 0 100% ç« /æœ¬  
ç”³è«‹ä¸­ä»¶ï¥© 0 0 100%  å°ˆï§ å·²ç²å¾—ä»¶ï¥© 0 0 100% ä»¶  
ä»¶ï¥© 0 0 100% ä»¶  
æŠ€è¡“ç§»è½‰ 
æ¬Šï§ï¤Š 0 0 100% åƒå…ƒ  
ç¢©å£«ç”Ÿ 0 0 100%  
åšå£«ç”Ÿ 0 0 100%  
åšå£«å¾Œç ”ç©¶å“¡ 0 0 100%  
åœ‹å¤– 
ï¥«èˆ‡è¨ˆç•«äººï¦Š 
ï¼ˆå¤–åœ‹ç±ï¼‰ 
å°ˆä»»åŠ©ï§¤ 0 0 100% 
äººæ¬¡ 
 
 
