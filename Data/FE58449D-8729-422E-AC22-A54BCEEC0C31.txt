 2 
 
æ–‡å­—å¼çš„é—œéµå­—(Keyword)æª¢ï¥ªä¹Ÿå¤§éƒ¨åˆ†é‡å°å–®ç´”
èƒŒæ™¯çš„æŠ•å½±ç‰‡é€²ï¨ˆæ–‡å­—è™•ï§¤ã€‚æœ¬è¨ˆç•«å³é‡å°æ­¤ä¸€å•
é¡Œï¼Œæå‡ºé‡å°è¤‡é›œèƒŒæ™¯æ•™å­¸è¦–è¨Šï¤…ï¦œæ“·å–æ–‡å­—ä¹‹æ–°
æ–¹æ³•ï¼Œä»¥ï§æ•™å­¸è¦–è¨Šï¤…ï¦œä¹‹æ–‡å­—é—œéµå­—æª¢ï¥ªã€‚ 
æ­¤ä¸€ç ”ç©¶çš„ç›¸é—œä¸»é¡Œæœ‰æŠ•å½±ç‰‡è½‰æ›åµæ¸¬ã€å‰æ™¯
æ“·å–åŠæ–‡ä»¶äºŒå€¼åŒ–ã€‚æŠ•å½±ç‰‡è½‰æ›ä¸€èˆ¬ç™¼ç”Ÿåœ¨è¬›è€…æ“
ä½œéµç›¤ï¤æ›æŠ•å½±ç‰‡ï¼Œè€ŒæŠ•å½±ç‰‡è½‰æ›åµæ¸¬ï§åŒæ–¼å ´
æ™¯åµæ¸¬(Shot boundary detection)ã€‚å‚³çµ±ä¸Šå ´æ™¯åµæ¸¬
å®šç¾©ç‚ºå½±æ ¼é–“ï¥·ï¨æˆ–é¡è‰²åˆ†å¸ƒç”¢ç”Ÿå·®ï¥¢[14-18] ã€‚
ä½†æ˜¯æŠ•å½±ç‰‡è½‰æ›ä¸€èˆ¬ç™¼ç”Ÿåœ¨æ–‡å­—è®ŠåŒ–è™•ï¼Œè€ŒèƒŒæ™¯æ¨¡
æ¿ç¶­æŒï¥§è®Šï¼Œæ‰€ä»¥å‚³çµ±æ–¹æ³•ç„¡æ³•ç›´æ¥å»¶ç”¨ã€‚æ–‡ç»[19]
å³æå‡ºä»¥æ­£æ—‹è½‰æ›ä¿‚ï¥© DCT(DCT, Discrete Cosine 
Transform)ç‚ºåŸºæº–æŠ•å½±ç‰‡è½‰æ›åµæ¸¬æ³•ã€‚ 
åœ¨å®‰å…¨ç›£æ§æ‡‰ç”¨ç ”ç©¶ï¼Œå¸¸ä»¥å‚³çµ±ä¹‹ç§»å‹•ç‰©ä»¶åµ
æ¸¬[20-22]é€²ï¨ˆéæ³•å…¥ä¾µè€…ã€‚è€Œåœ¨ï¥©ä½å­¸ç¿’è¦–è¨Šæ‡‰ç”¨
ç ”ç©¶ï¼Œå‰‡ä»¥å‰æ™¯åµæ¸¬æ“·å–(Foreground extraction)é€²
ï¨ˆè¦–è¨Šèˆ‡å¤–éƒ¨æ–‡ä»¶ä¹‹åŒæ­¥å®šä½ã€‚æ­¤ä¸€éœ€æ±‚ï¼Œå¯è—‰ç”±
æª¢è¦–å…§å®¹å·®ï¥¢ã€èƒŒæ™¯é¡è‰²åŠç©ºé–“ä½ç½®åˆ†å¸ƒ[23-25]
è€Œé”æˆã€‚ä½†æ˜¯é€™ç¨®æ–¹å¼ï¼Œåªé©ç”¨æ–¼å…§å«åœ–åƒæˆ–åœ–è¡¨
ä¹‹æŠ•å½±ç‰‡ä¹‹æ¯”å°ï¼Œä½†ï¥§é©ç”¨æ–¼å…§å«å¤§éƒ¨åˆ†æ˜¯æ–‡å­—çš„
æŠ•å½±ç‰‡ã€‚å¦ä¸€æ–¹é¢ï¼Œè¦–è¨Šæ–‡å­—åµæ¸¬[26-28]æ˜¯ä¸€ç†±é–€
ç ”ç©¶ä¸»é¡Œï¼Œè€Œæ–‡å­—è¾¨ï§¼å‰‡å¯è¦–ç‚ºæ–‡å­—åµæ¸¬å¾Œä¹‹å¾Œè™•
ï§¤[26]ã€‚åœ¨æ–‡ç»[27,28]ä¸­ï§ç”¨æ©Ÿå™¨å­¸ç¿’ä¹‹åˆ†ï§å™¨å®Œ
æˆæ–‡å­—ï¨€å‰²ä¹‹ä»»å‹™ã€‚Wang ç­‰[19]ç™¼å±•ä¸€å¥—åŒ…æ‹¬æœ‰
ä¸»é¡Œå¼ä»¶åµæ¸¬ã€è¦–è¨Šæ–‡å­—åˆ†æåŠå‰‡è¦–è¨Šèˆ‡å¤–éƒ¨æ–‡ä»¶
ä¹‹åŒæ­¥å®šä½ä¹‹ï¥©ä½å­¸ç¿’è¦–è¨Šç€è¦½ç³»çµ±ã€‚åœ¨è©²ç³»çµ±
ä¸­ï¼Œè¦–è¨Šæ–‡å­—ä¾å…¶å­—é«”å¯åˆ†ç‚ºæ¨™é¡ŒåŠå…§æ–‡ï¥¸éƒ¨åˆ†ï¼Œ
é›–ç„¶é‡å°æ¨™é¡Œæ–‡å­—è©²ç³»çµ±å¯å¾—ç›¸ç•¶é«˜çš„æ­£ç¢ºï¥¡
[19]ï¼Œä½†é‡å°å­—é«”è¼ƒå°ä¹‹å…§æ–‡éƒ¨åˆ†ï¼Œè©²ç³»çµ±ä¹‹æ–‡å­—
è¾¨ï§¼ï¥¡å°šæœ‰æ”¹é€²çš„ç©ºé–“æ¨™ã€‚ 
ç”±æ–¼äºŒå€¼åŒ–(Binarization)æ˜¯æ–‡å­—è¾¨ï§¼æˆåŠŸèˆ‡å¦
ä¹‹é—œéµæŠ€è¡“ï¼Œå¦‚ä½•é¸å–é©ç•¶çš„é–€æª»å€¼å‰‡æ˜¯äºŒå€¼åŒ–é
ç¨‹å¿…è¦çš„æ­¥é©Ÿã€‚Otsu æ³•[29]æ˜¯è€³ç†Ÿèƒ½è©³æ–¹æ³•ï¼Œè€ŒäºŒ
å‡å€¼æ³•[30]ä¹Ÿæ˜¯å¸¸è¢«å¼•ç”¨ä¹‹æ–¹æ³•ã€‚ç„¶è€Œä¸Šè¿°æ–¹æ³•ï¨¦
ç„¡æ³•æœ‰æ•ˆè§£æ±ºåœ¨ï¥©ä½å­¸ç¿’è¦–è¨Šä¸­å¸¸é‡åˆ°çš„å…‰æºèƒŒ
æ™¯ï¥§å‡å‹»çš„å•é¡Œã€‚ 
æœ¬è¨ˆç•«æå‡ºä¸€é‡å°è¤‡é›œèƒŒæ™¯æ•™å­¸è¦–è¨Šï¤…ï¦œæ“·
å–æ–‡å­—ä¹‹æ–°æ–¹æ³•ï¼Œä»¥ï§æ•™å­¸è¦–è¨Šï¤…ï¦œä¹‹æ–‡å­—é—œéµå­—
æª¢ï¥ªã€‚å› ç‚ºæ•™å­¸æŠ•å½±ç‰‡çš„èƒŒæ™¯è¤‡é›œä¸”å¤šæ¨£åŒ–ï¼Œç”šè‡³
èˆ‡æ–‡å­—ç‰¹æ€§ç›¸è¿‘ï¼Œæ‰€ä»¥è¨­è¨ˆé‡å°æ•™å­¸è¦–è¨Šï¤…ï¦œä¹‹å‰
æ™¯ï¨€å‰²æ³•ï¼Œä»¥æ“·å–å‰æ™¯æ–‡å­—å€å¡Šï¼Œæ˜¯æœ¬è¨ˆç•«ç ”ç©¶ä¸»
é¡Œä¹‹ä¸€ã€‚å¦å› æ•™å­¸è¦–è¨Šï¤…ï¦œçš„è§£æï¨åä½ï¼Œæ‰€ä»¥å¦‚
ä½•æå‡æ–‡å­—å“è³ªï¼Œä»¥ï§å¾ŒçºŒæ–‡å­—è¾¨ï§¼ï¼Œä¹Ÿæ˜¯æœ¬è¨ˆç•«
çš„å¦ä¸€é‡è¦èª²é¡Œã€‚ 
 
ä¸‰ã€ç ”ç©¶æ–¹æ³• 
1. æ¦‚è¿° 
æœ¬è¨ˆç•«æå‡ºä¸€é‡å°è¤‡é›œèƒŒæ™¯æ•™å­¸è¦–è¨Šï¤…ï¦œæ“·
å–æ–‡å­—ä¹‹æ–°æ–¹æ³•ï¼Œä»¥ï§æ•™å­¸è¦–è¨Šï¤…ï¦œä¹‹æ–‡å­—é—œéµå­—
æª¢ï¥ªã€‚æ‰€ææ–¹æ³•æ¦‚è¿°å¦‚ä¸‹ã€‚é¦–å…ˆå› ç‚ºæ•™å­¸è¦–è¨Šï¤¿è£½
ç’°å¢ƒè®Šï¥¢å¾ˆå¤§ï¼Œç‰¹åˆ¥æ˜¯åœ¨å…‰æºç…§å°„çš„è®Šï¥¢ï¼Œæ‰€ä»¥å…‰
æºçš„æ­£è¦åŒ–æ˜¯é€²ï¨ˆæ•™å­¸è¦–è¨Šè™•ï§¤ä¹‹å¿…è¦å‰è™•ï§¤ä»¥
æå‡å½±åƒå“è³ªï¼ŒåŠå¾ŒçºŒè™•ï§¤ä¹‹ç©©å®šæ€§ã€‚æ¥ä¸‹ï¤­ï¼ŒæŠ•
å½±ç‰‡é—œéµå½±æ ¼(Key frame)å»ºç½®ä¹Ÿæœ‰å…¶å¿…è¦æ€§ï¼Œå› ç‚º
å¾ŒçºŒè™•ï§¤ï¥´åªé ˆåœ¨é—œéµå½±æ ¼ä¸ŠåŸ·ï¨ˆï¼Œå°‡å¤§å¤§ç¸®æ¸›å¾Œ
çºŒè™•ï§¤çš„æ™‚é–“ã€‚ 
åœ¨å‰æ™¯å…ƒä»¶æ“·å–ä¸Šï¼Œæœ¬è¨ˆç•«æå‡ºä»¥ SLEP 
(Structured Local Edge Pattern) [31]ç‚ºå€åŸŸç‰¹å¾µçš„
æ¯”å°æ³•ï¼Œä»¥å€åˆ†å‰æ™¯èˆ‡èƒŒæ™¯çš„å·®ï¥¢ï¼Œé€²è€Œå»ºç½®èƒŒæ™¯
æ¨¡å¼ï¼Œç”šè‡³åˆ†ææ™‚ç©ºçš„ç›¸é—œæ€§ï¼Œé€²ä¸€æ­¥ä¿®æ­£èƒŒæ™¯æ¨¡
å¼ï¼Œä»¥å¾—ï¤ç´°ç·»çš„èƒŒæ™¯æ¨¡å¼ç³»ã€‚æœ€å¾Œå†ä»¥æ‰€æä¹‹é©
æ€§åŒ–äºŒå€¼åŒ–æ³•ï¼Œå°å¯èƒ½ä¹‹æ–‡å­—å‰æ™¯å…ƒä»¶é€²ï¨ˆäºŒå€¼
åŒ–ã€‚æœ€å¾Œå†ï§ç”¨æ™®è¢«æ¡ç”¨ä¹‹å•†æ¥­æ–‡å­—è¾¨ï§¼è»Ÿé«”
(Omni-Page) [32]é€²ï¨ˆæ–‡å­—è¾¨ï§¼ã€‚ 
å€¼å¾—ä¸€æçš„æ˜¯ï¼Œæœ¬è¨ˆç•«ä¹‹æ‰€ä»¥æ¡å–ä»¥èƒŒæ™¯åˆ†æ
é€²ï¨ˆæ–‡å­—æ“·å–ï¼Œè€Œéæ¡ç”¨ä¸€èˆ¬ä¹‹æ–‡å­—åµæ¸¬æ³•ï¼Œæ˜¯å› 
ç‚ºå¦‚å‰æ‰€è¿°æ•™å­¸è¦–è¨Šï¤…ï¦œå…¶èƒŒæ™¯æœ‰æ™‚ç›¸ç•¶è¤‡é›œï¼Œç”š
è‡³å…·æœ‰æ–‡å­—ç‰¹æ€§ï¼Œä½¿å¾—èƒŒæ™¯è¢«è¦–ç‚ºæ–‡å­—ï¼Œè€Œï¨‰ä½æ–‡
å­—è¾¨ï§¼ï¨ç¢ºï¨(Precision)ï¼Œå¦‚åœ–ä¸€æ‰€ç¤ºã€‚å¦ä¸€æ–¹é¢
å› ç‚º Omni-Page å…·æœ‰åœ–æ–‡åˆ†ï§ªçš„èƒ½ï¦Šï¼Œæ‰€ä»¥æœ¬è¨ˆ
ç•«å¸Œæœ›æ•´åˆ Omni-Page çš„åŠŸèƒ½ï¼Œé”åˆ°é‡å°è¤‡é›œèƒŒ
æ™¯æ•™å­¸è¦–è¨Šï¤…ï¦œæ­£ç¢ºæ“·å–æ–‡å­—ä¹‹ç›®æ¨™ã€‚ 
 
2. æŠ•å½±ç‰‡é—œéµå½±æ ¼å»ºç½® 
æœ¬è¨ˆç•«æå‡ºä»¥ SLEP [31]ç‚ºå€åŸŸç‰¹å¾µçš„è¡¨ç¤º
æ³•ï¼Œä»¥æè¿°æ•™å­¸è¦–è¨Šä¸­ç´‹ï§¤è®ŠåŒ–æƒ…å½¢ï¼Œä»¥å€åˆ†å‰æ™¯
èˆ‡èƒŒæ™¯å€åˆ†å‰æ™¯èˆ‡èƒŒæ™¯çš„å·®ï¥¢ï¼Œé€²è€Œå»ºç½®èƒŒæ™¯æ¨¡
å¼ã€‚SLEP ä¹‹å®šç¾©å¦‚åœ–äºŒæ‰€ç¤ºï¼Œæ˜¯ç”¨ä»¥ç·¨ç¢¼é‚Šç·£é»
ä¹‹å››å€‹æ–¹å‘çš„åˆ†å¸ƒçµæ§‹ï¼Œå…¶ç‰¹å¾µç‚ºï¨æ˜¯ 32ã€‚ 
è¨­ä¸€æ•™å­¸è¦–è¨ŠFtç‚ºä¸€äºŒç¶­å½±æ ¼åºï¦œ(a sequence 
of frames)ï¼Œåœ¨æ­¤ t ç‚ºæ™‚é–“ï¥ªå¼•(index) ã€‚ç¾å°‡æ¯ä¸€
åœ¨æ™‚é–“è»¸ä¸Šçš„å½±æ ¼ï¼Œå¦‚åœ–ä¸‰æ‰€ç¤ºçš„ï¼Œå‡å‹»ï¨€å‰²ç‚ºåœ¨
ç©ºé–“è»¸ä¸Šçš„ BNsd Ã— BNsdå€‹å€å¡Šï¼Œåœ¨æ­¤è¨ˆç•« BNsdæ˜¯
è¨­å®šç‚º 4ã€‚é‡å°æ¯ä¸€å€å¡Šè¨ˆç®—å…¶ SLEP ä¹‹å€¼æ–¹åœ–ï¼Œ 
SLEPhã€‚è¨ˆç®—ç©ºé–“ä¸Šå›ºå®šä½ç½® å€å¡Šï¼Œä½†åœ¨æ™‚é–“è»¸
ä¸Šå‰å¾Œ(å³ï¥ªå¼• t åŠ t+1)ä¹‹ SLEPh ä¹‹å€‹åˆ¥å·®ï¥¾ï¼Œå†
å°‡ BNsd Ã— BNsdå€‹å€å¡Šçš„ SLEPh å€‹åˆ¥å·®ï¥¾ï¥åŠ ï¼Œå³
å¯å¾—æŠ•å½±ç‰‡è½‰æ›ï¥¾æ¸¬å€¼ï¼ŒSTDtã€‚STDt å€¼ï¥´è¶…éä¸€
é–€æª»å€¼ï¼ŒTHstdï¼Œå³åˆ¤å®šæ­¤å½±æ ¼ Ft æ˜¯ä¸€è½‰æ›æŠ•å½±ç‰‡ï¼Œ
å…¶ï¥©å­¸å…¬å¼è¡¨ï¦œæ–¼æ–¹ç¨‹å¼(1)ã€‚ 
 
ï€¨ ï€© ï€¨ ï€©ï€¨ ï€©
ï€¨ ï€©
ï€¨ ï€©
ïƒ®ïƒ­
ïƒ¬ ï€¾ï€½
ï€­
ï€½
ïƒ¥ ïƒ¥
ï€½ ï€½
ï€«
otherwiseFALSE
 ifTRUE
2
1 1
,1,
2
stdt
t
sd
BN
i
FeatureDim
d
itit
t
THSTD
Transitive
BN
dd
STD
sd
F
BB
 (1)
 
å°‡è½‰æ›æŠ•å½±ç‰‡åµæ¸¬å‡ºï¤­å¾Œï¼Œè½‰æ›æŠ•å½±ç‰‡ STs èˆ‡ 
STs+1 çš„æ‰€æœ‰å½±æ ¼å¯å–å…¶å¹³å‡å€¼ï¼Œä½œç‚ºé—œéµå½±æ ¼
KFsã€‚è©³è€Œï¥ä¹‹ï¼Œï¥´è½‰æ›æŠ•å½±ç‰‡ STs èˆ‡ STs+1æ‰€å°
æ‡‰çš„å½±æ ¼åˆ†åˆ¥ç‚º Fft åŠ Fntï¼Œå‰‡åŒå±¬é—œéµå½±æ ¼ KFs
çš„ï¦šçºŒå½±æ ¼å€‹ï¥©ï¼ŒFrameNumbersï¼Œå¦‚æ–¹ç¨‹å¼(2)æ‰€
ç¤ºã€‚è€Œé—œéµå½±æ ¼ KFs ä¹‹è¨ˆç®—å…¬å¼å‰‡å¦‚æ–¹ç¨‹å¼(3)æ‰€
ç¤ºã€‚åœ–å››æ˜¯ä¸€é—œéµå½±æ ¼å»ºç½®ä¹‹ç¯„ï¦µã€‚ 
 
ftntrFrameNumbe s ï€­ï€½ (2)
 4 
 
æ“·å–ã€‚è©³è€Œï¥ä¹‹ï¼Œæ¯å¼µé—œéµå½±æ ¼ä¸Šå„å€å¡Šä¹‹ SLEPh 
ç‰¹å¾µï¼ŒWs,iï¼Œç›´æ¥èˆ‡èƒŒæ™¯æ¨¡å¼ä¹‹ SLEPh ç‰¹å¾µï¼ŒMi,jï¼Œ
é€²ï¨ˆæ¯”å°ï¼Œæ¯”å°å…¬å¼è©³æ–¹ç¨‹å¼(9)ï¼Œä¸”ï¥´ç¶“ç”±æ–¹ç¨‹
å¼(9)è¨ˆç®—å‡ºä¹‹ç›¸ä¼¼å€¼å¤§æ–¼é–€æª»å€¼ï¼ŒTHbï¼Œå‰‡åˆ¤å®šæ­¤
å€å¡Šå¯èƒ½æ˜¯å‰æ™¯æ–‡å­—å€å¡Šã€‚åœ–ä¹æ˜¯å‰æ™¯åˆ†ï§ä¹‹çµ
æœï¼Œåœ¨æ­¤åœ–ä¸­å‰æ™¯åŠèƒŒæ™¯åˆ†åˆ¥ä»¥åŸï¥·ï¨å€¼åŠç´«ç´…è‰²
åŠ ä»¥æ¨™è¨˜ã€‚ 
 
ï€¨ ï€© ï€¨ ï€©
ï€¨ ï€©
ïƒ®ïƒ­
ïƒ¬ ï€¾ï€½
ï€­ï€½ ïƒ¥
ï€½
otherwiseFALSE
 ifTRUE ,
,
1
,,
bis
is
FetureDim
d
isis
THBD
Foreground
dBMdBD
W
W
(9)
 
4 æ–‡å­—æ“·å– 
ä¾æ“šç¯€ 3 æ‰€è¿°æ–¹æ³•ï¼Œæ“·å–å‡ºå‰æ™¯éƒ¨åˆ†ï¼Œå…¶ä¸­ä¹Ÿ
åŒ…æ‹¬æ–‡å­—éƒ¨åˆ†ã€‚æ¥ä¸‹ï¤­å°±å¿…é ˆå°‡æ–‡å­—æ‰€åœ¨ä½ç½®åŠ ä»¥
ç¢ºå®šï¼Œä»¥ï§å¾ŒçºŒæ–‡å­—è¾¨ï§¼ã€‚å› ç‚ºå‰æ™¯å¯èƒ½åˆ†æ•£åœ¨é—œ
éµå½±æ ¼çš„ï¥§åŒä½ç½®ï¼Œæ‰€ä»¥å¿…é ˆä»¥ï¦šæ¥ç‰©ä»¶æ¨™è¨˜æ³•
(Connected component labeling)å°‡å„å‰æ™¯å…ƒä»¶æ¨™è¨˜
å‡ºï¤­ï¼Œå†å°‡å…¶ä½œè§£æï¨æå‡ï¼Œä»¥æå‡å½±åƒå“è³ªï¼Œå†
é€²ï¨ˆé©èª¿æ€§ä¹‹äºŒå€¼åŒ–æ³•(Adaptive binarization)ï¼Œä»¥
å¢å¼·æ–‡å­—è¾¨ï§¼çš„æ­£ç¢ºï¥¡ã€‚ 
 
4.1 æ–‡å­—å…ƒä»¶æ“·å– 
è©³è€Œï¥ä¹‹ï¼Œå‰è¿°ï¦šæ¥ç‰©ä»¶æ¨™è¨˜æ³•æ˜¯ä»¥ç›¸é„°å€å¡Š
æ¨™è¨˜æ³•ï¼Œå°‡ï¦šæ¥ç‰©ä»¶ï¼ŒCCnï¼Œæ¨™è¨˜å‡ºï¤­ã€‚å†é‡å°
CCnï¼Œæ‰¾å‡ºå…¶å¤–ï¨‹éƒ¨åˆ†ï¼Œäº¦å³è“‹æ‹¬ CCnä¹‹æœ€å°æ–¹å¡Šï¼Œ 
ä½†å› ç‚ºæ–‡å­—æœ‰ï¨¢å¤šè®Šå½¢ï¼Œæœ‰äº›æ–‡å­—éƒ¨åˆ†ä»æœƒæº¢å‡ºå¤–
ï¨‹å°æ–¹å¡Šã€‚æ‰€ä»¥æœ¬è¨ˆç•«å°‡å¤–ï¨‹å°æ–¹å¡Šä¸»å‹•å¤šå¢ä¸€å€
å¡Šï¼Œä»¥ç¢ºä¿æ–‡å­—éƒ¨åˆ†å®Œæ•´è“‹æ‹¬åœ¨å¯èƒ½æ–‡å­—å€å¡Šå…§ï¼Œ
ä»¥æå‡æ–‡å­—è¾¨ï§¼çš„æ­£ç¢ºï¥¡ã€‚åœ–åæ˜¯æ–‡å­—å…ƒä»¶æ“·å–çš„
ç¯„ï¦µã€‚ 
 
4.2 è§£æï¨æå‡ 
 
ç‚ºç¯€ï¥­æ•™å­¸è¦–è¨Šå‚³é€ä¹‹æˆæœ¬ï¼Œæ•™å­¸è¦–è¨Šå½±åƒä¸€
èˆ¬è€Œè¨€ï¨¦æ˜¯ä½è§£æï¨ï¼Œå¯èƒ½æœƒé€ æˆæ–‡å­—è¾¨ï§¼çš„å›°é›£
ï¨ã€‚æ‰€ä»¥åœ¨é€²ï¨ˆæ–‡å­—è¾¨ï§¼å‰ï¼Œè§£æï¨æå‡æœ‰å…¶å¿…è¦
æ€§ã€‚æœ¬è¨ˆç•«æ˜¯æ¡ç·šæ€§å…§æ’æ³•é”åˆ°è§£æï¨æå‡ä¹‹éœ€
æ±‚ã€‚ 
 
4.3 é©èª¿æ€§äºŒå€¼åŒ–æ³• 
å¤§éƒ¨åˆ†çš„å•†ç”¨æ–‡å­—è¾¨ï§¼ç³»çµ±çš†ä»¥äºŒå€¼åŒ–å½±åƒ
ç‚ºè¼¸å…¥å½±åƒï¼Œè€Œä¸”äºŒå€¼åŒ–å½±åƒä¹‹å“è³ªæ˜¯å½±éŸ¿è¾¨ï§¼ï¥¡
ä¹‹é—œç¾å› ç´ ã€‚æ‰€ä»¥æœ¬è¨ˆç•«æå‡ºä¸€é©èª¿æ€§äºŒå€¼åŒ–æ³•ï¼Œ
é‡å°å„å€å¡Šè‡ªå‹•é¸æ“‡é©å®œä¹‹é–€æª»å€¼ã€‚é¦–å…ˆæœ¬è¨ˆç•«å…ˆ
é‡å°å„æ–‡å­—å€å¡Šï¼Œï§ç”¨å…¨åŸŸ 2-å‡å€¼æ³• (Global 
2-Means) (å³å°‡K-å‡å€¼æ³•ä¹‹Kå€¼å®šç‚º2)å°‡æ‰€æœ‰æ–‡å­—
å€å¡Šå…§ä¹‹å½±åƒé»æ­¸ç‚ºé»‘ç™½ï¥¸ï§ï¼Œä»¥é”åˆ°äºŒå€¼åŒ–ä¹‹ç›®
çš„ã€‚åœ–åä¸€(b)æ˜¯æ–‡å­—å€å¡ŠäºŒå€¼åŒ–çµæœï¼Œå¾ˆæ˜é¡¯çš„
å…¶æˆæ•ˆï¥§å½°ï¼Œä¸»è¦çš„åŸå› æ˜¯æ•™å­¸è¦–è¨Šçš„èƒŒæ™¯å…‰æºï¥§
å‡ã€‚æ‰€ä»¥æœ¬è¨ˆç•«æå‡ºä¸€é©èª¿æ€§äºŒå€¼åŒ–æ³•ï¼Œå³å€åŸŸ
2-å‡å€¼æ³•(Local 2-Means)ï¼Œé€²ï¨ˆäºŒå€¼åŒ–è™•ï§¤ã€‚è©³è€Œ
ï¥ä¹‹ï¼Œæœ¬è¨ˆç•«å°‡ 2-å‡å€¼æ³•åœ¨è¼ƒå°ä¹‹ 20Ã—20 å€å¡Šå…§
åŸ·ï¨ˆã€‚ç”±åœ–åä¸€(c)æ‰€ç¤ºï¼Œæ‰€æå€åŸŸ 2-å‡å€¼æ³•ç¢ºå¯¦
èƒ½æå‡äºŒå€¼åŒ–ä¹‹æˆæ•ˆã€‚åœ¨ç¬¬å››é …å¯¦é©—çµæœéƒ¨åˆ†ï¼Œå°‡
ä»¥è¾¨ï§¼æ­£ç¢ºï¥¡ä¹‹å®šï¥¾æ–¹å¼ï¼Œé€²ä¸€æ­¥è­‰å¯¦æ‰€æäºŒå€¼åŒ–
æ³•ç¢ºå¯¦æœ‰æ•ˆã€‚ 
 
å››ã€å¯¦é©—çµæœèˆ‡è¨ï¥ 
æ‰€ææ–¹æ³•å·²å¯¦ä½œåœ¨å…·æœ‰ 2.67 GHz Core Intel 
Q8400 CPU åŠ 4 Gigabytes DDR2 SDRAM ä¹‹
GIGABYT æ¯ç‰ˆ(Motherboard) ã€‚æ‰€æ¡ä½œæ¥­ç³»çµ±ç‚º
Microsoft Windows 7 professional versionã€‚æ‰€æœ‰ç¨‹
å¼çš†ä»¥ C++ èªè¨€ç·¨æ’°ä¸¦ä½¿ç”¨é–‹æ”¾åŸç¢¼ (Open 
source)ä¹‹ OpenCV ç¨‹å¼åº«ä¸¦ä»¥ Microsoft Visual 
Studio 2010 ä¸‹ä¹‹ç·¨è­¯å™¨ç·¨æ’°ã€‚è¼¸å…¥è¦–è¨Šæ˜¯ä»¥ SONY 
HDR-XR350 High Definition HDD Handycam ï¤¿
è£½ï¼Œä¸¦ä»¥ MTS æ ¼å¼å„²å­˜ã€‚æœ¬è¨ˆç•«æ¡ç¾æœ‰å•†ç”¨è»Ÿé«”
OmniPage OCR system [32] é€²ï¨ˆæ–‡å­—è¾¨ï§¼ã€‚ 
æœ¬è¨ˆç•«åœ¨ç›¸åŒåœ°é»ä½†ï¥§åŒï¤¿è£½ç’°å¢ƒä¸‹ï¤¿è£½ 14
ç¨®æ•™å­¸è¦–è¨Šï¼Œåªè¦æ•´å¼µæŠ•å½±ç‰‡å¯å®Œå…¨å…¥é¡ï¼Œç›¸æ©Ÿè§’
ï¨å¯ï¥§åŒæˆ–å…‰æºè®ŠåŒ–å¯ï¥§åŒã€‚æ¯ä¸€è¦–è¨Šä¹‹æŠ•å½±ç‰‡èƒŒ
æ™¯å°‡ï¥§ç›¸åŒï¼Œè©³ç´°è³‡ï¦¾ï¨Šè¡¨äºŒã€‚ç‚ºæ¨¡æ“¬å£“ç¸®è¦–è¨Šæƒ…
æ³ï¼Œæ•™å­¸è¦–è¨Šæ˜¯ä»¥ä½è§£æï¨ä¹‹å£“ç¸®å½±åƒæ–¹å¼å„²å­˜ã€‚
æ•™å­¸è¦–è¨Šï¤¿è£½æ™‚é–“ï¥§åŒï¼Œç«¯è¦–æ¼”è¬›è€…å ±å‘Šæ™‚é–“è€Œæœ‰
ï¥§åŒã€‚ä¸€èˆ¬è€Œè¨€ï¼Œæ¯ä¸€æ•™å­¸è¦–è¨ŠåŒ…æ‹¬æœ‰ 10 åˆ° 30
å¼µçš„æŠ•å½±ç‰‡ã€‚ï¤¿è£½ç•¶ä¸­ï¼Œå¯èƒ½æœƒæœ‰ï¥¢ç‰©å¹²æ“¾ï¤¿è£½å…§
å®¹ï¼Œï¦µå¦‚è¬›è€…çš„æ‰‹å¯èƒ½å…¥é¡ã€‚å¯¦é©—è¨­è¨ˆæ˜¯ä»¥é©—è­‰ä¸‰
é …ä¸»é¡Œç‚ºåŸºæº–ï¼Œå³é—œéµå½±æ ¼å»ºç½®æˆæ•ˆã€å‰æ™¯åˆ†ï§æˆ
æ•ˆåŠæ–‡å­—è¾¨ï§¼æˆæ•ˆã€‚ 
å°±é—œéµå½±æ ¼å»ºç½®æˆæ•ˆè€Œè¨€ï¼Œï¥´å°‡ç¸®æ¸›ï¥¡
(Reducing rate)å®šç¾©ç‚ºé—œéµå½±æ ¼å€‹ï¥©èˆ‡åŸè¦–è¨Šç¸½å½±
æ ¼ï¥©ä¹‹æ¯”å€¼ï¼Œå‰‡ç¶“ç”±æ­¤ä¸€è™•ï§¤ï¼Œç¸®æ¸›ï¥¡å¯é«˜é”
98%ã€‚è‡³æ–¼é—œéµå½±æ ¼ä¹‹åµæ¸¬æ­£ç¢ºæ€§ï¼Œå‰‡ä»¥äººå·¥æ¨™è¨˜
ä¹‹é—œéµå½±æ ¼ (åŠå°æ‡‰æ¯å¼µæŠ•å½±ç‰‡ )ç‚ºæ­£ç¢ºåŸºæº–
(Ground truth)ï¼Œé€²ï¨ˆè©•ä¼°ã€‚å¬å›ï¥¡(Recall rate)ã€æ­£
ç¢ºï¥¡(Precision rate)åŠ F-åˆ†ï¥©(F-score)åˆ†åˆ¥å®šç¾©å¦‚
ä¸‹ã€‚å¬å›ï¥¡(R)æ˜¯æ­£ç¢ºåµæ¸¬é—œéµå½±æ ¼ï¥©èˆ‡å¯¦éš›çœŸå¯¦
é—œéµå½±æ ¼ï¥©ä¹‹æ¯”ï¥¡; æ­£ç¢ºï¥¡(P)æ˜¯æ­£ç¢ºåµæ¸¬é—œéµå½±
æ ¼ï¥©èˆ‡å¯¦éš›åµæ¸¬é—œéµå½±æ ¼ï¥©ä¹‹æ¯”ï¥¡;è€Œ F-åˆ†ï¥©(F)
å‰‡æ˜¯ P èˆ‡ R ä¹‹å‡½ï¥©ï¼Œå…¶å®šç¾©å¦‚æ–¹ç¨‹å¼(10)ã€‚ 
PR
PRF ï€«
ï‚´ï‚´ï€½ 2  (10)
 
è¡¨ä¸‰ï¦œå‡ºåœ¨ä½¿ç”¨ï¥§åŒç‰¹å¾µåŠï¥§åŒé–€æª»å€¼æ™‚ï¼Œ14
ç¨®æ•™å­¸è¦–è¨Šä¹‹å¹³å‡å¬å›ï¥¡ã€æ­£ç¢ºï¥¡åŠ F-åˆ†ï¥©ã€‚ç”±
è¡¨ä¸‰ç™¼ç¾ï¼Œï¥§åŒé–€æª»å€¼å°æ–¼å¬å›ï¥¡ã€æ­£ç¢ºï¥¡åŠ F-
åˆ†ï¥©å½±éŸ¿ï¥§å¤§ã€‚æ‰€ä»¥æœ¬è¨ˆåŠƒé¸æ“‡å°æ‡‰å¬å›ï¥¡è¼ƒé«˜ä¹‹
é–€æª»å€¼ï¼Œå³ THstd=0.05 åŠ THsd =0.1ã€‚è‡³æ–¼å¦ä¸€ç‰¹
å¾µ LBP [33]æ˜¯å±¬æ–¼ï¥·ï¨ç‰¹å¾µ(Intensity-based)ï¼Œèˆ‡æœ¬
ç ”ç©¶æ¡ç”¨ä¹‹é‚Šç·£ç‰¹å¾µ(Edge-based) SLEP æ€§è³ªï¥§
åŒã€‚ç”±è¡¨ä¸‰ç™¼ç¾ï¼Œæ‰€æ SLEP ç‰¹å¾µåœ¨é—œéµå½±æ ¼å»ºç½®
è¼ƒ LBP æœ‰è¼ƒé«˜çš„å¬å›ï¥¡ã€æ­£ç¢ºï¥¡åŠ F-åˆ†ï¥©ã€‚åˆ†æ
å…¶åŸå› ï¼Œæ‡‰è©²æ˜¯é‚Šç·£ç‰¹å¾µå°æ–¼ï¥§å‡å‹»èƒŒæ™¯æœ‰è¼ƒé«˜å®¹
å¿ï¨;å¦å¤–åœ¨è¡¨ç¾æ–‡å­—ç‰¹æ€§ä¸Šé‚Šç·£ç‰¹å¾µ SLEP è¼ƒï¥·
ï¨ç‰¹å¾µæœ‰è¼ƒé«˜çš„åˆ†è¾¨èƒ½ï¦Šã€‚ 
 6 
 
http://penance.is.cs.cmu.edu/meeting_room/. 
[14] B.L. Yeo and B. Liu, â€œRapid scene analysis on 
compressed video,â€ IEEE Trans. Circuits and 
Systems for Video Technology, vol. 5, pp. 
533-544, 2002. 
[15] A. Nagasaka and Y. Tanaka, â€œAutomatic video 
indexing and full-video search for object 
appearances,â€ Proc. IFIP Second Working 
Conf. Visual Database Systems II, pp. 113-127, 
1992. 
[16] S.X. Ju, M.J. Black, S. Minneman, and D. 
Kimber, â€œSummarization of videotaped 
presentations: automatic analysis of motion 
and gesture,â€ IEEE Trans. Circuits and 
Systems for Video Technology, vol. 8, pp. 
686-696, 1998. 
[17] D. Zhang, W. Qi, and H.J. Zhang, â€œA new shot 
boundary detection algorithm,â€ Proc. IEEE 
Rim Conference on Multimedia, 
vol. 2195, pp. 63-70, 2001. 
[18] R. Zabih, J. Miller, and K. Mai, â€œA 
feature-based algorithm for detecting and 
classifying scene breaks,â€ Proc. ACM Intâ€™l 
Conf. Multimedia, pp.189-200, 1995. 
[19] F. Wang, C.W. Ngo, and T.C. Pong, 
â€œStructuring low-quality videotaped lectures 
for cross-reference browsing by video text 
analysis,â€ Pattern Recognition, vol. 41, pp. 
3257-3269, 2008. 
[20] Y.T. Chen, C.S. Chen, C.R. Huang, and Y.P. 
Hung, â€œEfficient hierarchical method for 
background subtraction,â€ Pattern Recognition, 
vol. 40, pp. 2706-2715, 2007. 
[21] Y. Zha, D. Bia, and Y. Yang, â€œLearning 
complex background by multi-scale 
discriminative model,â€ Pattern Recognition, 
vol. 3, pp. 1003-1014, 2009. 
[22] M. Heikkila and M. Pietikainen, â€œA 
texture-based method for modeling the 
background and detecting moving objects,â€ 
IEEE Trans. Pattern Analysis and Machine 
Intelligence, vol. 28, pp. 657-662, 2006. 
[23] T.F. Syeda-Mahmood, â€œIndexing for topics in 
videos using foils,â€ Proc. IEEE Intâ€™l Conf. 
Computer Vision and Pattern Recognition, vol. 
2, pp. 312-319, 2000. 
[24] B. Erol, J.J. Hull, and D.S. Lee, â€œLinking 
multimedia presentations with their symbolic 
source documents: algorithm and 
applications,â€ Porc. ACM Intâ€™l Conf. 
Multimedia, 2003. 
[25] T. Liu, R. Hjelsvold, and J.R. Kender, 
â€œAnalysis and enhancement of videos of 
electronic slide presentations,â€ Proc. IEEE 
Intâ€™l Conf. Multimedia, vol. 1, pp. 77-80, 
2002. 
[26] R. Lienhart and A. Wernicke, â€œLocalizing and 
segmenting text in images and videos,â€ IEEE 
Trans. Circuits and Systems for Video 
Technology, vol. 12, pp. 256-268, 2002. 
[27] H. Li, D. Doermann, and O. Kia, â€œAutomatic 
text detection and tracking in digital video,â€ 
IEEE Trans. Image Processing, vol. 9, 
pp.147-156, 2000. 
[28] D. Chen, J.M. Odobez, and H. Bourlard â€œText 
detection and recognition in images and video 
frames,â€ Pattern Recognition, vol. 37, pp. 
595-608, 2004. 
[29] O. Otsu, â€œA threshold selection method form 
gray-level histogram,â€ IEEE Trans. System, 
Man and Cybernetics, vol. 9, no. 1, pp. 62-66, 
1979. 
[30] J. Park, G. Lee, E. Kim, J. Lim, S. Kim, H. 
Yang, M. Lee, and S. Hwang, â€œAutomatic 
detection and recognition of Korean text in 
outdoor signboard images,â€ Pattern 
Recognition Letters, vol. 31, no. 12, pp. 
1728-1739, 2010. 
[31] S.Z. Su, S.Y. Chen, S.Z. Li, and D.J. Duh, 
â€œStructured local edge pattern moment for 
pedestrian detection,â€ Proc. Intâ€™l Conf. Image 
Analysis and Signal Processing, pp. 556-560, 
2010. 
[32] OmniPage Pro 17 
http://www.scansoft.com/omnipage/ 
[33] T. Ojala and M. Pietikainen, â€œUnsupervised 
texture segmentation using feature 
distributions,â€ Pattern Recognition, vol. 32, 
no. 9, pp. 477-486, 1999. 
[34] S. Su, S.-Y, Chen, S. Li, S.-A. Li, and D.-J. 
Duh, â€œStructured local binary Haar pattern for 
graphics retrieval,â€ Proc. of IEEE 
International Conference on Intelligent 
Computing and Intelligent Systems, Xiamen, 
China, pp. 670-674, 2010. 
[35] C.-Y. Shiao and S.-Y. Chen, â€œText extraction 
for lecture videos,â€ Proc. of IPPR Conference 
on Computer Vision, Graphics and Image 
Processing, pp. , 2011 
[36] S. Su, S.-Y. Chen, S. Li, S.-A. Li, and D.-J. 
Duh, â€œStructured local binary Haar pattern for 
pixel-based graphics retrieval,â€ Electronics 
Letters, vol. 46, no. 14, pp. 996-998, July, 
2010. 
[37] C.-Y. Shiao and S.-Y. Chen, â€œText extraction 
of lecture videos without text detection,â€ 
submitted to Journal of Electronic Imaging for 
possible publication. 
 
 
 8 
 
 
(a) (b) 
åœ–å…«ã€èƒŒæ™¯æ¨¡å¼ç¯„ï¦µ(a)æœªåŸ·ï¨ˆèƒŒæ™¯æ¨¡å¼å†ä¿®æ­£å‰
ä¹‹èƒŒæ™¯æ¨¡å¼; (b) å·²åŸ·ï¨ˆèƒŒæ™¯æ¨¡å¼å†ä¿®æ­£å¾Œä¹‹èƒŒ
æ™¯æ¨¡å¼ã€‚ 
 
 
(a) (b) 
åœ–ä¹ã€å‰æ™¯æ“·å–ç¯„ï¦µ (a) åŸé—œéµå½±æ ¼; (b)å‰æ™¯åˆ†
ï§çµæœã€‚ 
 
  
(a) (b) 
 
(c) (d) 
åœ–åã€æ–‡å­—å…ƒä»¶æ“·å–ç¯„ï¦µ(a) é—œéµå½±æ ¼ä¸Šå‰æ™¯åˆ†ï§çµ
æœ;(b)ï¦šæ¥å‰æ™¯ç‰©ä»¶æ¨™è¨˜çµæœ;(c)è“‹æ‹¬å‰æ™¯ç‰©ä»¶ä¹‹æœ€
å°æ–¹å¡Š;(d)å¤–ï¨‹å°æ–¹å¡Šå¤šå¢ä¸€å€å¡Šä¹‹æ–‡å­—å€å¡Šã€‚ 
 
 
 
 
 
 
 
 
 
(a) (b) 
 
(c) 
åœ–åä¸€ã€é©èª¿æ€§äºŒå€¼åŒ–ç¯„ï¦µ(a)åŸæ–‡å­—å€å¡Š; (b) å…¨åŸŸ
2-å‡å€¼æ³•ä¹‹äºŒå€¼åŒ–çµæœ; (c)å€åŸŸ 2-å‡å€¼æ³•ä¹‹äºŒå€¼åŒ–çµ
æœã€‚ 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 10 
 
è¡¨äºŒã€ï¤¿è£½æ•™å­¸è¦–è¨Šç¯„ï¦µã€‚ 
è¦–è¨Šåç¨± ï¤¿å½±å…§å®¹ æŠ•å½±ç‰‡å½±æ ¼å€‹ï¥©
2001_Oliva 
 
2245 
2006_Ngo 
 
1600 
2006_Wu 
 
1605 
20 7_Chen 
 
2565 
2007_Yang 
 
 290 
2009_Shen 
 
1655 
200 _Zha 
 
3010 
2010_Amiri 
 
960 
2010_Bai 
 
2060 
2010_Chiu 
 
2185 
2010_Liu 
 
1010 
2010_Phan 
 
1025 
2010_Sidir 
 
1760 
2011_Roy 
 
2245 
 
 
è¡¨ä¸‰ã€ä½¿ç”¨ï¥§åŒç‰¹å¾µåŠï¥§åŒé–€æª»å€¼æ™‚ä¹‹é—œéµå½±æ ¼å»º
ç½®å¹³å‡å¬å›ï¥¡ã€æ­£ç¢ºï¥¡åŠ F-åˆ†ï¥©ã€‚ 
 
æ‰€ææ–¹æ³• 
LBP THstd=0.05
THsd =0.1
THstd=0.05 
THsd =0.15 
F-åˆ†ï¥© 96.40% 96.28% 78.75%
å¬å›ï¥¡ 98.30% 97.45% 94.55%
æ­£ç¢ºï¥¡ 94.57% 95.13% 67.47%
 
è¡¨å››ã€åŸ·ï¨ˆèƒŒæ™¯æ¨¡å¼å†ä¿®æ­£èˆ‡å¦åŠä½¿ç”¨ï¥§åŒç‰¹å¾µä¹‹
å‰æ™¯åˆ†ï§å¹³å‡å¬å›ï¥¡ã€æ­£ç¢ºï¥¡åŠ F-åˆ†ï¥©ã€‚ 
 æ‰€ææ–¹æ³• LBP 
Standard w/o refinement 
F-åˆ†ï¥© 92.58% 84.14% 76.38%
å¬å›ï¥¡ 91.83% 79.96% 85.19%
æ­£ç¢ºï¥¡ 93.35% 88.78% 69.22%
 
 
 
 
 
 
 
 
 
 
 
 
 
 
è¡¨ Y04 
 
äºŒã€ èˆ‡æœƒå¿ƒå¾— 
ã€Œæ™ºæ…§è¨ˆç®—èˆ‡æ™ºæ…§ç³»çµ±ã€ä¸€ç›´ä»¥ï¤­çš†æ˜¯ç†±é–€ç ”ç©¶ä¸»é¡Œã€‚ç‰¹åˆ¥æ˜¯åœ¨å¤šåª’é«”ã€ï¥©ä½åŒ–ç§‘
æŠ€ã€ç¶²éš›ç¶²ï¤·çš„èˆˆèµ·åŠå¯¬é »ç¶²ï¤·çš„æ™®åŠï¼Œä¿ƒæˆ 4Cï¼ˆé›»è…¦ Computerã€é€šè¨Š Communicationã€
å…§å®¹ Contentã€æœ‰ç·šé›»è¦– Cableï¼‰çš„åŒ¯åˆï¼Œé€²è€Œå¸¶å‹•ï¥©ä½å…§å®¹ç”¢æ¥­ç™¼å±•ä¹‹æ™‚ä»£ã€‚å› ç‚ºæ™ºæ…§
è¨ˆç®—èˆ‡æ™ºæ…§ç³»çµ±çš„ç´å…¥ï¼Œå¯ä½¿ï¥©ä½å…§å®¹ä¹‹ç ”ç©¶ï¼Œé™¤é‹ç”¨è³‡è¨Šç§‘æŠ€å°‡åœ–åƒã€æ–‡å­—ã€å½±åƒã€
èªéŸ³ç­‰å¤šåª’é«”åŠ ä»¥ï¥©ä½åŒ–ï¼Œä¸¦å¯ä»¥æ™ºæ…§è¨ˆç®—èˆ‡æ™ºæ…§ç³»çµ±é€²ï¨ˆæ•´åˆï¼Œä»¥è¡ç”Ÿï¤å…·æ™ºæ…§çš„è³‡
è¨Šæœå‹™ï¼Œä½¿è³‡è¨Šæœå‹™ï¤å…·äººæ€§åŒ–åŠè²¼é©æ€§ä¹‹å„ªé»ã€‚ 
 
æ­¤æ¬¡æœƒè­°ï¼Œæœ¬äººç™¼è¡¨çš„ï¥æ–‡ç‚ºå¼µè²¼ï¥æ–‡ï¼Œï¥æ–‡é¡Œç›®æ˜¯ã€ŒStructured Local Binary Haar 
Pattern for Graphics Retrievalã€ã€‚ æœ¬ï¥æ–‡ä¸»è¦æ˜¯æå‡ºä¸€çµæ§‹åŒ–å€åŸŸäºŒå…ƒ Haar æ¨¡å¼ï¼Œä»¥é€²
ï¨ˆæœ‰æ•ˆçš„åœ–åƒæª¢ï¥ª(Graphics Retrieval)ã€‚äº‹å¯¦ä¸Šå½±åƒæª¢ï¥ª(Image Retrieval)å·²æœ‰è±ç¢©çš„ç ”ç©¶æˆ
æœï¼Œç”šè‡³å·²æœ‰å•†æ¥­ç”¢å“ï¼Œä½†å½±åƒæª¢ï¥ªçš„æŠ€å·§ç„¡æ³•ç›´æ¥æ‡‰ç”¨è‡³åœ–åƒ (Graphics)æª¢ï¥ªï¼Œå› ç‚ºå½±åƒ
èˆ‡åœ–åƒæ€§è³ªä¸¦ï¥§å®Œå…¨ç›¸åŒã€‚è€Œç¾æœ‰åœ–åƒæª¢ï¥ªæˆ–è¾¨ï§¼æ–¹æ³•å¤§å¤šæ¡ç”¨å‘ï¥¾åŒ–(Vectorization)æˆ–ï§—ï¨‹
è»Œè·¡(Contour Tracing)ä¹‹ç‰¹å¾µé€²ï¨ˆæª¢ï¥ªï¼Œä½†å°±ä¸€èˆ¬åœ–åƒæˆ–åœ–è¡¨è€Œè¨€ä¸¦ï¥§ä¸€å®šå­˜åœ¨æœ‰æ­¤ç¨®ï§—ï¨‹
ç‰¹å¾µï¼Œï¤ä½•æ³ï§—ï¨‹ç‰¹å¾µçš„æ“·å–ç›¸ç•¶è²»æ™‚ï¼Œæ‰€ä»¥æœ¬ï¥æ–‡ç›´æ¥é‡å°é‚Šç·£é»ï¼Œè¨­è¨ˆæ§‹åŒ–å€åŸŸäºŒå…ƒ
Haar æ¨¡å¼ç‰¹å¾µï¼Œé€²ï¨ˆåœ–åƒæª¢ï¥ªæ³•ã€‚å¯¦é©—çµæœè­‰å¯¦æ‰€ææ–¹æ³•ç¢ºå¯¦è¼ƒç¾æœ‰æ–¹æ³•æœ‰è¼ƒé«˜çš„æª¢ï¥ªæ­£
ç¢ºï¥¡ã€‚ 
     
å› ç‚ºæ­¤æ¬¡ç™¼è¡¨ï¥æ–‡æ˜¯æœ¬äººèˆ‡å»ˆé–€å¤§å­¸ã€Œä¿¡æ¯ç§‘å­¸èˆ‡æŠ€è¡“å­¸é™¢ä¹‹æ™ºæ…§ç§‘å­¸èˆ‡æŠ€è¡“ç³»ã€
ä¹‹ã€Œæ™ºèƒ½å¤šåª’é«”æŠ€è¡“å¯¦é©—å®¤ã€ï§¡ç´¹æ»‹æ•™æˆåŠè˜‡æ¾å¿—åšå£«ç”Ÿï¼Œå…±åŒåˆä½œä¹‹æˆæœã€‚æ•…æ­¤æ¬¡æœ¬
äººé™¤ï¥«åŠ åœ‹éš›æœƒè­°ï¼Œé‚„åŒæ™‚èˆ‡å»ˆé–€å¤§å­¸è©²ç³»ä¸»ç®¡ï§¡ç´¹æ»‹æ•™æˆåŠæ•™å¸«ï¼Œé€²ï¨ˆå­¸è¡“äº¤ï§Šï¼ŒåŒ
æ™‚ï¥«è§€å»ˆé–€å¤§å­¸ã€Œæ™ºèƒ½å¤šåª’é«”æŠ€è¡“å¯¦é©—å®¤ã€ï¼Œå°±é›™æ–¹è¿‘æœŸåˆä½œç ”ç©¶ä¹‹ä¸»é¡Œï¼Œåšé€²ä¸€æ­¥çš„
æºé€šäº¤ï§Šã€‚å¸Œæœ›ç¶“éé•·æœŸé›»å­éƒµä»¶å¾€è¿”è¨ï¥çš„ç ”ç©¶å…§å®¹ï¼Œèƒ½ç¶“ç”±é¢å°é¢çš„ç•¶é¢æºé€šï¼Œæ¿€
ç›ªå‡ºï¤å¤šæ™ºæ…§ç«èŠ±ï¼Œä»¥æœŸæœ‰ï¤é€²ä¸€æ­¥çš„ç ”ç©¶æˆæœã€‚ 
 
ç¶œè€Œï¥ä¹‹ï¼Œæœ¬äººæ·±è¦ºæ­¤ï¨ˆæ”¶ç©«ï¥¼å¤šï¼Œå°æ–¼åœ‹ç§‘æœƒè´ŠåŠ©æ­¤ï¨ˆç¶“è²»ï¼Œæ·±æ„Ÿè¬æ„ã€‚ 
 
ä¸‰ã€ æ”œå›è³‡ï¦¾ 
1. ç ”è¨æœƒï¥æ–‡é›† 
2. ç ”è¨æœƒå…‰ç¢Ÿ 
3. å¤§æœƒè­°ç¨‹æ‰‹å†Š 
 
= ! 
 ,?3@	24&/ ?3@2/4
,#,	,
!/ 1
B !	,/, 
 ,,,, ",  
!$ /#  $  
! + !5G6, 7! ,
     ,   H   I 56 "
   ! ,  : ! ,  
H 1I /%   ,$0 , , 
  &  ,, +     
   ,     ,  ! 	 ,
  $1,-#  ,    ,
#      " ,       
 !+  !!  
"
	 ,  /  - 0#  ! 
 !  ! 56 
         ,
 !   ! $1    ! ,
 /   #  !     A
, ! ! , "
   1, !  ,   !   !  +
  !  ! # !  ,  " +
 ! $     "  /    ,
#,
/ )2-
	
!01+3+

= !7 ?3@/$ !/  ,/ #	
,
&  ,, !E1/ ?3@/
",$<
D
G
2  4 2  4
 



!0 4  -  4  
= 
= âˆ‘
$ 7

- =   2  42  4
G




1 4  ,
 4 
	-
 
> â§ 
= â¨ 
â©
 B = ! 7 $
  , ?3@   #  / # 7 !
	,$ !  Ã— A+! 
//  ,	,="
G :4$ 1 1 = +
7 $ 1 1 = +
$ 4$  $  !  ! " "   # "  $ 
,  5 76 âˆ’  5 76, âˆ’  +#



 &')&'A(?)B?3
B'C	BB'@B&&A'
)/ !10
= ! B",?3	@24=	,J2/4
 !	, $ + !J24"
?3	@+

   ?3 #	
@ 2?3	@4  /  ,  , ?3@ $  	
,?	3 #@2?	3@4/#
I 576   "1/0!
 +  , "   &  ?3	@
 , # , 	 , $   
! , !# + !       
+    !$ = !24
	$+ #   # , 	 ,    ++  
?3	@$ !   
 
/, !/,7;,
?3@,?3	@>+?3	@ ! 
,$%!!  ,1  
&?3@ ?3	@ !
       
 ,  ?  G E
 
 = L    !
671

" $, 1- /
   # ,  !1/  !  A 
  +$ = ! ;
&B3?A
 'A&'
AHB? B))'B)
A = A(A @
& 2A@4 ?3@ 	BB'B(?3	@ *
&		B?=1HA'?B@@
3?)Q	
)*!	 +*!	 ,*!
           
7"7 E;7 DG: ED EE F DF; FG F; F E7; F7; F;
7" E 7 EF EE; F: D:F DG F: F; DE DE; F;D
"7 EE  GE FG7 F7F DG ED F; F:7 EGG D77 FD
" E;G ;E7 7: EF: F7 E DG F:: F:: F D F;E
"E E7 :7G D: E EFE ;E :: FF F7 ;;; :;F FD
E" E :; 7FG E FG ;; ; F7; F7F ;DE :GD F:E
E"E DF G; 7F7 E7D EE F; :F EF EFE ::; F7 F7
&B3?A

 'A&'
AHB?B))'B)
A(A' B
B
A*
&	HB'
B)A ;GB(@A'&'3B&
R	
)*!	 +*!	 ,*!
           
7"7 EE DF EGF E7: D:; DEF FG:G FGE DDED E: F7:E FF;
7" D ;D E:E E;E DF;: D; D;DE F; E:D DF;: DED F:;D
"7 D7:: D77 GF EDG DF;: D: E7D F; ED7 E7 D7G F:FF
" DEGE ;FF7 7:7 EE E;F E7D F;7 FD: EF: D7; DDG F:FF
"E DFF : D;E EG EDEF ;7 ::7 F7GD EFFE ;;D: :;D7 FF;
E" DF7 :DG 7FG7 EE; EE ;:F  F F:: ;FGE :: F:FF
E"E EGG ;7 7F7 ED7 EDE :GGE :7: FG:G FG ::EF E7 F7:E
&B3?A


 'A&'
AHB? B))'B)
A(A'B?&B(@A@@A'
A*
&	@A'&'3B&
G;R	
)*!	 +*!	 ,*!
           
7"7 ;7: DGDD E; E:D FE DF FG7 F7:E 7;G; E7EE F7:E F:DE
7" 7G: :F E:E EG 7DFD D;;D D;DF F:; F7; DF DE;G F;7
"7 77;; D: GF EEG 7D; D7G E:E F:; : EGD D7:: F;7
" DD ;FD ;F EE;7 :FD DE; EEF FF; E DF D7E F;:
"E ;;F; :7EG D: E77 D77 ;7:G :G F77E DFG ;;F; :;G F7
E" ;:7E :DF 7EG ED7D D: ;:FG 7 F7 DEGE ;EED :GD F:;D
E"E DG;  7FG7 E; EGG :G7F :E EFDD E:;; :;GF F7; F77E
&B3?A
H 'A&'
AHB? B))'B)
A*
&	1HA'?B@@
 3?)Q
  ! "
           
7"7 E7G: DGFE FD EDE FG:G DD DE7F F:;D F7:F E:7 E7EE F;E7
7" DFD; :GF EG ED7D EEG D7; EEF F; EFFE D;;D D F:DE
"7 E77; E ;:: EF: EFDD D:F; D F:DE FGE DE;G :G F7:
" EGG ;D7G ;DE EEF: EEF: E ;D F F7 F FG F:
"E DE;G :: 7F7 E:FD EDG ;;D  F7 EF; ;:FG :GGE F7:E
E" DFF :G 7E EG EE;7 ;DD 7F:: F7 F; ;; 7;D F;
E"E D;FF 7F77 7DFD EG E:FD F7; E EE EE :7D 7 FG
H ))?

B+,?3	@/  ! ,
	?3@     &,, +
,?3	@/+/#+ " 
>+ !A@	
 ?3@ ?3	@   +    #
   =   /    " 
 !   + ,    +  1 !
+  + !! -#0#$
B)Q*?A(>A&
&  $0 $  /#     
=  , )  2GEDDF4 ( @!
= ,
  ,	 !A ,)  2
7GGFG7GG74     &!#
' =  2I)7GGFGEGGB
C37GGFGDGFB4      )  ,
& $2)FF17771A1;;1GD74
'A=A'A)A
673
è¡¨ Y04 
ï¨ˆæ”¿é™¢åœ‹å®¶ç§‘å­¸å§”å“¡æœƒè£œåŠ©åœ‹å…§å°ˆå®¶å­¸è€…å‡ºå¸­åœ‹éš›å­¸è¡“æœƒè­°å ±å‘Š 
                                                          100 ï¦ 8 æœˆ 8 æ—¥ 
å ±å‘Šäººå§“å  é™³æ·‘åª› æœå‹™æ©Ÿæ§‹åŠè·ç¨± 
 
å…ƒæ™ºå¤§å­¸è³‡è¨Šå·¥ç¨‹æ•™æˆ 
     æ™‚é–“ 
æœƒè­° 
     åœ°é» 
è‡ª 7 æœˆ 20 æ—¥ï½7 æœˆ 22 æ—¥ï¼Œ
å…± 3 å¤© 
å¸Œï¤¦é›…å…¸ 
æœ¬æœƒæ ¸å®š
è£œåŠ©æ–‡è™Ÿ
 
NSC 99-2221-E-155-072- 
æœƒè­° 
åç¨± 
 (ä¸­æ–‡) åœ‹éš›æ™ºæ…§äº’å‹•å¤šåª’é«”ç³»çµ±èˆ‡æœå‹™æœƒè­° 
 (è‹±æ–‡) International Conference on Intelligent Interactive Multimedia Systems 
and Services 
ç™¼è¡¨ 
ï¥æ–‡ 
é¡Œç›® 
 (ä¸­æ–‡) å…¼å…·æœ‰æ•ˆï¥¡ï§åˆ¥æ“´å……æ€§åŠæœ‰æ•ˆåˆ†ï§èƒ½ï¦Šä¹‹å ´æ™¯åˆ†ï§æ³• 
  NSC 99-2221-E-155-072- 
 (è‹±æ–‡) Scene Categorization with Class Extendibility and Effective 
Discriminative Ability 
é™„ä»¶
 
è¡¨ Y04 
 
äºŒã€ èˆ‡æœƒå¿ƒå¾— 
ã€Œæ™ºæ…§äº’å‹•å¤šåª’é«”ç³»çµ±èˆ‡æœå‹™æœƒè­°ã€æ˜¯è¿‘ï¦ï¤­ç†±é–€ç ”ç©¶ä¸»é¡Œã€‚ç‰¹åˆ¥æ˜¯åœ¨é›»è…¦æ™®åŠï¼Œ
è€Œä½¿ç”¨è€…çš„åˆ†ä½ˆå¯¬å»£ï¼Œå¾ï¨é€šè³‡è¨ŠæŠ€è¡“ä¹‹å°ˆå®¶åˆ°éå°ˆæ¥­ä¹‹ä¸€èˆ¬æ™®ï¤çœ¾ç”Ÿï¼Œæ‰€ä»¥ã€Œå–®ä¸€ç³»
çµ±æ»¿è¶³çœ¾ç”Ÿã€(One-fits-all)çš„æœå‹™æ¨¡å¼å·²ï¥§åºœåˆä½¿ç”¨è€…çš„éœ€æ±‚ã€‚ã€Œæ™ºæ…§äº’å‹•æœå‹™ç³»çµ±ã€ä¹‹
ç ”ç©¶å°±æ˜¯åœ¨æä¾›å€‹äººåŒ–(Personalization)åŠé©æ€§åŒ–(Adaptive)ä¹‹å‹•æ…‹æœå‹™ã€‚å¦ä¸€æ–¹é¢ï¼Œå¤šåª’
é«”ã€ï¥©ä½åŒ–ç§‘æŠ€ã€ç¶²éš›ç¶²ï¤·çš„èˆˆèµ·åŠå¯¬é »ç¶²ï¤·çš„æ™®åŠï¼Œä¿ƒæˆã€Œå¤šåª’é«”æœå‹™ç³»çµ±ã€çš„è“¬å‹ƒ
ç™¼å±•ã€‚æœ¬æœƒè­°å³çµåˆã€Œæ™ºæ…§äº’å‹•æœå‹™ç³»çµ±ã€åŠã€Œå¤šåª’é«”æœå‹™ç³»çµ±ã€ï¼Œå†åŠ ä¸Šã€Œæ™ºæ…§æ±ºç­–
æŠ€è¡“ã€ï¼Œé€²ï¨ˆç ”è¨ã€‚ 
 
æ­¤æ¬¡æœƒè­°ï¼Œæœ¬äººç™¼è¡¨çš„ï¥æ–‡ç‚ºå ±å‘Šï¥æ–‡ï¼Œï¥æ–‡é¡Œç›®æ˜¯ã€ŒScene Categorization with Class 
Extendibility and Effective Discriminative Abilityã€ã€‚ æœ¬ï¥æ–‡ä¸»è¦æ˜¯æå‡ºä¸€ä¾å„ï§åˆ¥åˆ†åˆ¥å»º
ç½®è©å½™å­—å…¸èˆ‡å½±åƒç‰¹å¾µä¹‹å ´æ™¯åˆ†ï§æ³•ï¼Œå› æ‰€ææ–¹æ³•å…·ï§åˆ¥ç‰¹ï¥¢æ€§ï¼Œæ•…æœ‰ï¤é«˜çš„åˆ†ï§èƒ½
ï¦Šã€‚åŒæ™‚å› ç‚ºå„ï§åˆ¥åˆ†åˆ¥å»ºç½®è©å½™å­—å…¸èˆ‡å½±åƒç‰¹å¾µï¼Œå‰‡ç•¶æœ‰ï§åˆ¥æ–°å¢æ™‚ï¼ŒåŸï§åˆ¥å½±åƒç‰¹
å¾µçš†ï¥§å—å½±éŸ¿ï¼Œæ‰€ä»¥åŸè³‡ï¦¾åº«ï¥§éœ€é‡å»ºï¼Œäº¦å³åŸå½±åƒè³‡ï¦¾åº«ï¼Œï¥§éœ€ç›¸å°ï¤æ–°ï¼Œå¦‚æ­¤å¯å…
é™¤é‡å»ºè² æ“”ï¼Œè€Œé”æœ‰æ•ˆï¥¡æ“´å¢ï§åˆ¥ä¹‹ç›®æ¨™ã€‚å¯¦é©—çµæœé¡¯ç¤ºï¼Œåœ¨æ¡ç”¨å–®ä¸€ç‰¹å¾µå‰é¡Œä¸‹ï¼Œï¥§ï¥
æ˜¯å–®ä¸€å°ºï¨(Single-Scale)æˆ–å¤šé‡å°ºï¨(Multi-Scale)æ©Ÿåˆ¶ï¼Œæ‰€ææ–¹æ³•ï¨¦è¼ƒç¾æœ‰æ–¹æ³•æœ‰è¼ƒé«˜çš„
æ­£ç¢ºï¥¡ã€‚ 
     
å› ç‚ºæ­¤æ¬¡å…¶ä¸­ä¸€ä½ keynote æ˜¯ï¤­è‡ªå°ç£çš„æ›¾åœ‹é›„æ•™æˆï¼ŒåŒæ¨£ï¤­è‡ªå°ç£æ‰€ä»¥å€æ„Ÿè¦ª
ï¨€ï¼Œä¹Ÿæ›¾å‘æ›¾åœ‹é›„æ•™æˆè«‹æ•™æœ‰é—œã€Œæ™ºæ…§æ±ºç­–æŠ€è¡“ã€ä¹‹å•é¡Œï¼Œå¸Œæœ›å°‡å…¶ä»–ç›¸é—œï¦´åŸŸä¹‹æŠ€è¡“ï¼Œ
æ‡‰ç”¨æ–¼æœ¬äººä¹‹ç ”ç©¶ä¸»é¡Œï¼Œæ¿€ç›ªå‡ºï¤å¤šæ™ºæ…§ç«èŠ±ï¼Œä»¥æœŸæœ‰ï¤é€²ä¸€æ­¥çš„ç ”ç©¶æˆæœã€‚ 
 
ç¶œè€Œï¥ä¹‹ï¼Œæœ¬äººæ·±è¦ºæ­¤ï¨ˆæ”¶ç©«ï¥¼å¤šï¼Œå°æ–¼åœ‹ç§‘æœƒè´ŠåŠ©æ­¤ï¨ˆç¶“è²»ï¼Œæ·±æ„Ÿè¬æ„ã€‚ 
 
ä¸‰ã€ æ”œå›è³‡ï¦¾ 
1. ç ”è¨æœƒï¥æ–‡é›† 
2. ç ”è¨æœƒå…‰ç¢Ÿ 
3. å¤§æœƒè­°ç¨‹æ‰‹å†Š 
 
 2
Quelhas et al. [1] proposed Bags-of-Visterms to represent invariant local features and Probabilistic 
Latent Semantic Analysis (pLSA) to model scenes. Fei-Fei and Perona [2] represented a scene image 
by a collection of local regions, denoted as codewords obtained by unsupervised learning. They also 
modified the Latent Dirichlet Allocation to model scenes. Lazebnik et al. [3] proposed a spatial 
pyramid matching based on multi-spatial resolutions for recognizing natural scene categories. Zhou et 
al. [4] used Gaussianized vector representation rather than the distribution of visual words to represent 
scene images for categorization. A comparative study was performed in Ref. [5]. 
Some researchers [6-9] have considered contextual information to improve categorization accuracy. 
A detailed survey can be found in Ref. [6]. Some researchers [10-12] have focused on compact 
codebook construction. Some researchers [13-16] have proposed novel features or learning models to 
improve categorization accuracy. 
However, most approaches assume a fixed number of classes, and none categorize images with 
efficient class extendibility while preserving discriminative ability. This capability is crucial for an 
effective image categorization system. The proposed scene categorization method provides 
category-specific visual-word construction and image representation. The proposed method is effective 
for several reasons. First, since the visual-word construction and image representation are 
category-specific, image features related to the original classes need not be recreated when new classes 
are added, which minimizes reconstruction overhead. Second, since the visual-word construction and 
image representation are category-specific, the corresponding learning model for classification has 
substantial discriminating power. Experimental results confirm that the accuracy of the proposed 
method is superior to existing methods when using single-type and single-scale features. 
Section 2 introduces three strategies for codebook construction and image representation, including 
the proposed method. Section 3 gives the experimental results. Section 4 concludes the study and 
proposes future works. 
 
2. Category-Specific Approach 
The scene categorization problem can be formulated as follows. Given an image I, a set of C scene 
categories { }C,,2,1 L , and a training set of labeled images { }CcSsIT cs ,,1,,,,1 LL === , identify 
the category of image I. Here, S is the number of labeled images for each category, i.e., the number in 
the training set T is CÃ—S. To solve the problem, this section describes three possible strategies. The 
former two are existing methods, and the latter is the novel proposed method for achieving class 
extendibility. 
 
2.1 Whole-construction/whole-representation strategy 
 4
( )
( )
( )( )
( ) ( )( ){ } MkSCcNnknLn
n
k
c
s
c
s
NnknL
c
s
c
s
c
s ,1,,,1,s ,,,1,
,,1,
,,1, LLL
L
L ======
âˆ‘
==
xx
x
f x  (2)
 
Note that the dimensions of the C-to-1 SVM classifiers are M and dÃ—M when using the 
histogram-based approach and the vector-based approach, respectively. The experiments in Ref. [4] 
showed that the latter approach generally achieves a higher dimension and thus a higher categorization 
accuracy rate. This study therefore applied the vector-based approach. 
 
2.2 Category-specific-construction/whole-representation strategy 
A category-specific-construction/whole-representation (C-C/W-R) strategy (Figure 1) was recently 
proposed in Ref. [9]. Experimental results in that study confirmed that this strategy is more accurate 
compared to the conventional W-C/W-R strategy [9, 10]. In the training phase of this approach, each 
training image csI is divided into N local image patches of fixed size with local features ( )ncsx . 
However, the codebook is constructed individually for each category c. Restated, only the SÃ—N features 
of images belonging to a specific category i are fed into K-Means clustering to construct a size M 
codebook { }Mkik ,,1L=w . The C codebooks, one for each category, are then combined into one 
codebook of size CÃ—M, denoted as { }MkCiik ,,1,,,1 LL ==w . All subsequent processes in the training 
phase and in the testing phase are identical to those in the conventional W-C/W-R approach except that 
the codebook is { }MkCiik ,,1,,,1 LL ==w  rather than { }Mkk ,,1L=w . 
Specifically, each patch with features ( )ncsx is then labeled a codeword ( )( )( )( ) )( )(inL knL cscsxxw  from the 
codebook { }MkCiik ,,1,,,1 LL ==w  according to the Euclidean distance ( ) ikcs n wx âˆ’ . Each 
training image csI with patch features ( )ncsx  is represented by the feature vector  
( ) ( ) ( ) ( )MCMM cscscscscs Ã—+= ffffF ,,1,,,1 LL  with ( )jcsf  as defined by the following equation. 
( )
( )
( )( ) ( )( )
( ) ( )( ) ( )( ){ }
MCjSCc
NnjremknLjinLn
n
j
c
s
c
s
c
s
NnjremknLjinL
c
s
c
s
c
s
c
s
Ã—===
====
âˆ‘
===
,,1,,1,s ,,,1
,
,,1),()(),mod()(
,,1),()(),mod()(
LLL
L
L
xxx
x
f xx  (3)
where mod(j) and rem(j) are the quotient and remainder, respectively, after dividing j by M. The above 
two strategies use the same codebook to represent whole scene images regardless of category. 
 6
Each training image csI with patch features ( )ncsx is then represented by the mean feature vector  
( ) ( ) ( ) ( )MCCM cscscscscs ,,,1,,,,1,,1,1 ffffF LLL=  with ( )kics ,f  as defined by the following equation. 
 
( )
( )
( )( )
( ) ( )( ){ } MkCiSCcNnknLn
n
ki
c
s
ic
s
NnknL
c
s
c
s
c
s
i
,,1,,,1,,1,s ,,,1,
,,1,
, ,,1, LLLL
L
L =======
âˆ‘
==
xx
x
f x  (4)
 
Notably, each scene image is represented by the same dimension used in the C-C/W-R strategy, 
regardless of whether the approach is histogram-based or vector-based, i.e., CÃ—M and dÃ—CÃ—M, 
respectively. 
The proposed method clearly achieves the goal of efficient class extendibility and effective 
discriminative ability. First, since the visual-word dictionary and image representation are 
category-specific, adding new classes does not require reconstruction of all image features related to 
those in the original class so as to minimize reconstruction overhead. Second, since the visual-word 
construction and image representation are category-specific, the corresponding learning model for 
classification should have sufficient discriminatory power. 
Notably, Expectation-Maximization (EM) in Gaussian mixtures [18] rather than K-means were used 
to construct codebooks and to represent images in Ref. [4], which improved performance [4, 18]. Thus, 
EM is also used in this study, and Eq. (4) should be updated as follows. Each visual word of the 
codebook { },,,1 Mkik L=w  ,,,1 Ci L=  is first updated as one of M uni-model Gaussian components 
by the following equation. 
 
( ) MkCiN ikikik ,1, ,,,1,,; LL === Î£Î¼xw  (5)
where ik
i
k Î£Î¼  and denote the mean vector and covariance matrix of the kth Gaussian component and 
where x denotes the local patch feature. Each patch with features ( )ncsx is then labeled for each 
category i as a codeword ( )( )i nL csi xw  from the codebook { }Mkik ,,1L=w  according to the 
probability ( ) ,,,1,,);( CinN ikikcs L=Î£Î¼x  NnMk ,1,,,1, LL == . Each training image csI with patch 
features ( )ncsx is represented by the feature vector  ( ) ( ) ( ) ( )MCCM cscscscscs ,,,1,,,,1,,1,1 ffffF LLL=  
with ( )kics ,f  as defined by the following equation. 
 
 8
Experiments are performed to test the performance of the Scene-13 and Scene-15 datasets and the 
class extendibility of the Scene-15 dataset. For each issue, experiments are repeated ten times with 100 
randomly selected images per category for training and the rest for testing. 
Tables 1 and 2 show the categorization results for the Scene-13 and Scene-15 datasets for different 
features and codebook sizes and for different strategies, respectively. The tables show that the proposed 
method is more accurate compared to the C-C/W-R strategy. Moreover, for the Scene-13 dataset, the 
highest accuracies obtained in Ref. [4] are 83.6% with 512 visual words and 84.1% with 1024 visual 
words; in the current study, the accuracies are 85.42% with 13Ã—35=455 visual words and 86.65% with 
13Ã—80=1040 visual words. For the Scene-15 dataset, the highest accuracy in Ref. [4] is 83.5% with 
1024 visual words; that in the current study is 84.06% with 15Ã—80=1200 visual words. However, Ref 
[4] adopted SIFT feature for the Scene-13 dataset but SIFT and coordinate information for the 
Scene-15 dataset. The proposed method adopted only SIFT feature for the Scene-13 and Scene-15 
datasets consistently. On the other hand, although Ref. [9] adopted C-C/W-R strategy, it obtains 
87.63% and 85.16% accuracies for the Scene-13 and Scene-15 datasets, respectively. However, Ref. 
[9] adopted multi-scale features rather than single-scale feature as in the proposed method. Thus, the 
proposed method has higher accuracy compared to all existing methods when single-type and 
single-scale features are used. 
 
Table 1 Categorization results for Scene-13 dataset. 
Features HOG SIFT 
M 35 50 80 35 50 80 
C-C/W-R 79.88Â±0.12 80.31Â±0.12 81.45Â±0.06 83.44Â±0.08 85.25Â±0.12 85.47Â±0.14 
C-C/C-R 83.25Â±0.06 83.58Â±0.06 84.03Â±0.09 85.42Â±0.04 86.35Â±0.03 86.65Â±0.48 
 
Table 2 Categorization results for Scene-15 dataset. 
Features HOG SIFT 
M 35 50 80 35 50 80 
C-C/W-R 78.49Â±0.11 79.45Â±0.19 79.81Â±0.13 79.45Â±0.16 79.95Â±0.14 80.21Â±0.06 
C-C/C-R 81.45Â±0.08 81.99Â±0.09 82.63Â±0.10 83.02Â±0.09 83.42Â±0.08 84.06Â±0.07 
 
Class extendibility is verified by simulating an increase in the number of classes from the original 2 
and 5 categories to 15 categories. The experiments were conducted only on Scene-15 dataset. The 
assumptions are 2 and 5 original categories and codebook construction based only on 2 and 5 
categories. Suppose that the number of categories is increased to 15. In this case, if image 
representations of the scene images in the original 2 and 5 categories are not reconstructed, the 
codebook categories are still MÃ—2 and MÃ—5, respectively, rather than MÃ—15 in the original C-C/W-R 
strategy. Categorization accuracy is clearly degraded (Table 3). However, the proposed strategy can 
achieve efficient class extendibility easily since image representation is also category-specific. 
 10
[5] A. Bosch, X. Munoz, and R. Marti, â€œWhich is the best way to organize/classify images by content?,â€ Image Vision 
Computing, vol. 25, no.6, pp. 778â€“791, 2007. 
[6] C. Galleguillos and S. Belongie, â€œContext-based object categorization: A critical survey,â€ Computer Vision and Image 
Understanding, vol. 114, no. 1, pp. 712â€“722, 2010.  
[7] N. V. Hoang, V. Gouet-Brunet, M. Rukoz, and M. Manouvrier, â€œEmbedding spatial information into image content 
description for scene retrieval,â€ Pattern Recognition, vol. 43, no. 9, pp. 3013â€“3024, 2008. 
[8] Z. Lu and H. H. S. Ip, â€œCombining context, consistency, and diversity cues for interactive image categorization,â€ 
IEEE Trans. Multimedia, vol. 12, no. 3, pp. 194â€“203, 2010. 
[9] J. Qin and N. H. C. Yung, â€œScene categorization via contextual visual words,â€ Pattern Recognition, vol. 43, no. 5, pp. 
1874â€“1888, 2010. 
[10] J. C. Van Gemert, C. G. M. Snoek, C. J. Veenman, A. W. M. Smeulders, and J.-M. Geusebroek, â€œComparing 
compact codebooks for visual categorization,â€ Computer Vision and Image Understanding, vol. 114, no. 4, pp. 
450â€“462, 2010. 
[11] J. C. Van Gemert, C. J. Veenman, A. W. M. Smeulders, and J.-M. Geusebroek, â€œVisual word ambiguity,â€ IEEE 
Trans. Pattern Recognition and Machine Intelligence, vol. 32, no. 7, pp. 1271â€“71283, 2010. 
[12] L. Wu, S. C. H. Hoi, and N. Yu, â€œSemantics preserving bag-of-words models and applications,â€ IEEE Trans. Image 
Processing, vol. 19, no. 7, pp. 1908â€“1920, 2010. 
[13] Z.-L. Sun, D. Rajan, and L.-T. Chia, â€œScene Classification using multiple features in a two-stage probabilistic 
classification framework,â€ Neurocomputing, vol. 73, nos. 16â€“18, pp. 2971â€“2979, 2010. 
[14] A. Abdullah, R. C. Veltkamp, and M. A. Wiering, â€œFixed partitioning salient points with MPEG-7 cluster 
correlograms for image categorization,â€ Pattern Recognition, vol. 43, no. 3, pp. 650â€“662, 2010. 
[15] A. Bosch, A. Zisserman, and X. Munoz, â€œScene classification using a hybrid generative/discriminative approach,â€ 
IEEE Trans. Pattern Recognition and Machine Intelligence, vol. 30, no. 4, pp. 712â€“727, 2008. 
[16] H. Cheng and R. Wang, â€œSemantic modeling of natural scenes based on contextual Bayesian networks,â€ Pattern 
Recognition, vol. 43, no. 12, pp. 4042â€“4054, 2010. 
[17] D. G. Lowe, â€œDistinctive image features from scale-invariant keypoints,â€ Int. J. Computer Vision, vol. 60, no.2, 
pp.91â€“110, 2004. 
[18] E. Alpaydin, Introduction to Machine Learning, MIT Press, 2010. 
[19] C.-C. Chang and C.-J. Lin, â€œLIBSVM: A binary for support vector machine,â€ Software available at 
http://www.csie.ntu.edu.tw/cjlin/libsvm. 
[20] N. Dalal and B. Triggs, â€œHistogram of oriented gradient for human detection,â€ Proc. Computer Vision and Pattern 
Recognition, pp. 886â€“893, 2005. 
 
99 å¹´åº¦å°ˆé¡Œç ”ç©¶è¨ˆç•«ç ”ç©¶æˆæœå½™æ•´è¡¨ 
è¨ˆç•«ä¸»æŒäººï¼šé™³æ·‘åª› è¨ˆç•«ç·¨è™Ÿï¼š99-2221-E-155-072- 
è¨ˆç•«åç¨±ï¼šæ•¸ä½å­¸ç¿’è¦–è¨Šæª¢ç´¢èˆ‡æ‘˜è¦ 
é‡åŒ– 
æˆæœé …ç›® å¯¦éš›å·²é”æˆ
æ•¸ï¼ˆè¢«æ¥å—
æˆ–å·²ç™¼è¡¨ï¼‰
é æœŸç¸½é”æˆ
æ•¸(å«å¯¦éš›å·²
é”æˆæ•¸) 
æœ¬è¨ˆç•«å¯¦
éš›è²¢ç»ç™¾
åˆ†æ¯” 
å–®ä½ 
å‚™ è¨» ï¼ˆ è³ª åŒ– èªª
æ˜ï¼šå¦‚æ•¸å€‹è¨ˆç•«
å…±åŒæˆæœã€æˆæœ
åˆ— ç‚º è©² æœŸ åˆŠ ä¹‹
å° é¢ æ•… äº‹ ...
ç­‰ï¼‰ 
æœŸåˆŠè«–æ–‡ 0 0 100%  
ç ”ç©¶å ±å‘Š/æŠ€è¡“å ±å‘Š 0 0 100%  
ç ”è¨æœƒè«–æ–‡ 1 0 100% 
ç¯‡ 
 
è«–æ–‡è‘—ä½œ 
å°ˆæ›¸ 0 0 100%   
ç”³è«‹ä¸­ä»¶æ•¸ 0 0 100%  å°ˆåˆ© å·²ç²å¾—ä»¶æ•¸ 0 0 100% ä»¶  
ä»¶æ•¸ 0 0 100% ä»¶  
æŠ€è¡“ç§»è½‰ 
æ¬Šåˆ©é‡‘ 0 0 100% åƒå…ƒ  
ç¢©å£«ç”Ÿ 1 0 100%  
åšå£«ç”Ÿ 0 0 100%  
åšå£«å¾Œç ”ç©¶å“¡ 0 0 100%  
åœ‹å…§ 
åƒèˆ‡è¨ˆç•«äººåŠ› 
ï¼ˆæœ¬åœ‹ç±ï¼‰ 
å°ˆä»»åŠ©ç† 0 0 100% 
äººæ¬¡ 
 
æœŸåˆŠè«–æ–‡ 1 0 100%  
ç ”ç©¶å ±å‘Š/æŠ€è¡“å ±å‘Š 0 0 100%  
ç ”è¨æœƒè«–æ–‡ 1 0 100% 
ç¯‡ 
 
è«–æ–‡è‘—ä½œ 
å°ˆæ›¸ 0 0 100% ç« /æœ¬  
ç”³è«‹ä¸­ä»¶æ•¸ 0 0 100%  å°ˆåˆ© å·²ç²å¾—ä»¶æ•¸ 0 0 100% ä»¶  
ä»¶æ•¸ 0 0 100% ä»¶  
æŠ€è¡“ç§»è½‰ 
æ¬Šåˆ©é‡‘ 0 0 100% åƒå…ƒ  
ç¢©å£«ç”Ÿ 1 0 100%  
åšå£«ç”Ÿ 1 0 100%  
åšå£«å¾Œç ”ç©¶å“¡ 0 0 100%  
åœ‹å¤– 
åƒèˆ‡è¨ˆç•«äººåŠ› 
ï¼ˆå¤–åœ‹ç±ï¼‰ 
å°ˆä»»åŠ©ç† 0 0 100% 
äººæ¬¡ 
 
